{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 5, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/_shims/registry.ts"],"sourcesContent":["/**\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\n */\nimport { type RequestOptions } from '../core';\n\nexport interface Shims {\n  kind: string;\n  fetch: any;\n  Request: any;\n  Response: any;\n  Headers: any;\n  FormData: any;\n  Blob: any;\n  File: any;\n  ReadableStream: any;\n  getMultipartRequestOptions: <T = Record<string, unknown>>(\n    form: Shims['FormData'],\n    opts: RequestOptions<T>,\n  ) => Promise<RequestOptions<T>>;\n  getDefaultAgent: (url: string) => any;\n  fileFromPath:\n    | ((path: string, filename?: string, options?: {}) => Promise<Shims['File']>)\n    | ((path: string, options?: {}) => Promise<Shims['File']>);\n  isFsReadStream: (value: any) => boolean;\n}\n\nexport let auto = false;\nexport let kind: Shims['kind'] | undefined = undefined;\nexport let fetch: Shims['fetch'] | undefined = undefined;\nexport let Request: Shims['Request'] | undefined = undefined;\nexport let Response: Shims['Response'] | undefined = undefined;\nexport let Headers: Shims['Headers'] | undefined = undefined;\nexport let FormData: Shims['FormData'] | undefined = undefined;\nexport let Blob: Shims['Blob'] | undefined = undefined;\nexport let File: Shims['File'] | undefined = undefined;\nexport let ReadableStream: Shims['ReadableStream'] | undefined = undefined;\nexport let getMultipartRequestOptions: Shims['getMultipartRequestOptions'] | undefined = undefined;\nexport let getDefaultAgent: Shims['getDefaultAgent'] | undefined = undefined;\nexport let fileFromPath: Shims['fileFromPath'] | undefined = undefined;\nexport let isFsReadStream: Shims['isFsReadStream'] | undefined = undefined;\n\nexport function setShims(shims: Shims, options: { auto: boolean } = { auto: false }) {\n  if (auto) {\n    throw new Error(\n      `you must \\`import 'openai/shims/${shims.kind}'\\` before importing anything else from openai`,\n    );\n  }\n  if (kind) {\n    throw new Error(`can't \\`import 'openai/shims/${shims.kind}'\\` after \\`import 'openai/shims/${kind}'\\``);\n  }\n  auto = options.auto;\n  kind = shims.kind;\n  fetch = shims.fetch;\n  Request = shims.Request;\n  Response = shims.Response;\n  Headers = shims.Headers;\n  FormData = shims.FormData;\n  Blob = shims.Blob;\n  File = shims.File;\n  ReadableStream = shims.ReadableStream;\n  getMultipartRequestOptions = shims.getMultipartRequestOptions;\n  getDefaultAgent = shims.getDefaultAgent;\n  fileFromPath = shims.fileFromPath;\n  isFsReadStream = shims.isFsReadStream;\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;AA0BO,IAAI,OAAO;AACX,IAAI,OAAkC;AACtC,IAAI,QAAoC;AACxC,IAAI,UAAwC;AAC5C,IAAI,WAA0C;AAC9C,IAAI,UAAwC;AAC5C,IAAI,WAA0C;AAC9C,IAAI,OAAkC;AACtC,IAAI,OAAkC;AACtC,IAAI,iBAAsD;AAC1D,IAAI,6BAA8E;AAClF,IAAI,kBAAwD;AAC5D,IAAI,eAAkD;AACtD,IAAI,iBAAsD;AAE3D,SAAU,SAAS,KAAY,EAAE,UAA6B;IAAE,MAAM;AAAK,CAAE;IACjF,IAAI,MAAM;QACR,MAAM,IAAI,MACR,CAAA,gCAAA,EAAmC,MAAM,IAAI,CAAA,8CAAA,CAAgD;;IAGjG,IAAI,MAAM;QACR,MAAM,IAAI,MAAM,CAAA,6BAAA,EAAgC,MAAM,IAAI,CAAA,iCAAA,EAAoC,KAAI,GAAA,CAAK;;IAEzG,OAAO,QAAQ,IAAI;IACnB,OAAO,MAAM,IAAI;IACjB,QAAQ,MAAM,KAAK;IACnB,UAAU,MAAM,OAAO;IACvB,WAAW,MAAM,QAAQ;IACzB,UAAU,MAAM,OAAO;IACvB,WAAW,MAAM,QAAQ;IACzB,OAAO,MAAM,IAAI;IACjB,OAAO,MAAM,IAAI;IACjB,iBAAiB,MAAM,cAAc;IACrC,6BAA6B,MAAM,0BAA0B;IAC7D,kBAAkB,MAAM,eAAe;IACvC,eAAe,MAAM,YAAY;IACjC,iBAAiB,MAAM,cAAc;AACvC"}},
    {"offset": {"line": 60, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 65, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/_shims/auto/runtime-node.ts"],"sourcesContent":["/**\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\n */\nexport * from '../node-runtime';\n"],"names":[],"mappings":""}},
    {"offset": {"line": 68, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 81, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/_shims/MultipartBody.ts"],"sourcesContent":["/**\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\n */\nexport class MultipartBody {\n  constructor(public body: any) {}\n  get [Symbol.toStringTag](): string {\n    return 'MultipartBody';\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;AAGM,MAAO;IACX,YAAmB,IAAS,CAAA;QAAT,IAAA,CAAA,IAAI,GAAJ;IAAY;IAC/B,IAAI,CAAC,OAAO,WAAW,CAAC,GAAA;QACtB,OAAO;IACT"}},
    {"offset": {"line": 94, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 99, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/_shims/node-runtime.ts"],"sourcesContent":["/**\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\n */\nimport * as nf from 'node-fetch';\nimport * as fd from 'formdata-node';\nimport { type File, type FilePropertyBag } from 'formdata-node';\nimport KeepAliveAgent from 'agentkeepalive';\nimport { AbortController as AbortControllerPolyfill } from 'abort-controller';\nimport { ReadStream as FsReadStream } from 'node:fs';\nimport { type Agent } from 'node:http';\nimport { FormDataEncoder } from 'form-data-encoder';\nimport { Readable } from 'node:stream';\nimport { type RequestOptions } from '../core';\nimport { MultipartBody } from './MultipartBody';\nimport { type Shims } from './registry';\nimport { ReadableStream } from 'node:stream/web';\n\ntype FileFromPathOptions = Omit<FilePropertyBag, 'lastModified'>;\n\nlet fileFromPathWarned = false;\n\n/**\n * @deprecated use fs.createReadStream('./my/file.txt') instead\n */\nasync function fileFromPath(path: string): Promise<File>;\nasync function fileFromPath(path: string, filename?: string): Promise<File>;\nasync function fileFromPath(path: string, options?: FileFromPathOptions): Promise<File>;\nasync function fileFromPath(path: string, filename?: string, options?: FileFromPathOptions): Promise<File>;\nasync function fileFromPath(path: string, ...args: any[]): Promise<File> {\n  // this import fails in environments that don't handle export maps correctly, like old versions of Jest\n  const { fileFromPath: _fileFromPath } = await import('formdata-node/file-from-path');\n\n  if (!fileFromPathWarned) {\n    console.warn(`fileFromPath is deprecated; use fs.createReadStream(${JSON.stringify(path)}) instead`);\n    fileFromPathWarned = true;\n  }\n  // @ts-ignore\n  return await _fileFromPath(path, ...args);\n}\n\nconst defaultHttpAgent: Agent = new KeepAliveAgent({ keepAlive: true, timeout: 5 * 60 * 1000 });\nconst defaultHttpsAgent: Agent = new KeepAliveAgent.HttpsAgent({ keepAlive: true, timeout: 5 * 60 * 1000 });\n\nasync function getMultipartRequestOptions<T = Record<string, unknown>>(\n  form: fd.FormData,\n  opts: RequestOptions<T>,\n): Promise<RequestOptions<T>> {\n  const encoder = new FormDataEncoder(form);\n  const readable = Readable.from(encoder);\n  const body = new MultipartBody(readable);\n  const headers = {\n    ...opts.headers,\n    ...encoder.headers,\n    'Content-Length': encoder.contentLength,\n  };\n\n  return { ...opts, body: body as any, headers };\n}\n\nexport function getRuntime(): Shims {\n  // Polyfill global object if needed.\n  if (typeof AbortController === 'undefined') {\n    // @ts-expect-error (the types are subtly different, but compatible in practice)\n    globalThis.AbortController = AbortControllerPolyfill;\n  }\n  return {\n    kind: 'node',\n    fetch: nf.default,\n    Request: nf.Request,\n    Response: nf.Response,\n    Headers: nf.Headers,\n    FormData: fd.FormData,\n    Blob: fd.Blob,\n    File: fd.File,\n    ReadableStream,\n    getMultipartRequestOptions,\n    getDefaultAgent: (url: string): Agent => (url.startsWith('https') ? defaultHttpsAgent : defaultHttpAgent),\n    fileFromPath,\n    isFsReadStream: (value: any): value is FsReadStream => value instanceof FsReadStream,\n  };\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;AAmBA,IAAI,qBAAqB;AASzB,eAAe,aAAa,IAAY,EAAE,GAAG,IAAW;IACtD,uGAAuG;IACvG,MAAM,EAAE,cAAc,aAAa,EAAE,GAAG;IAExC,IAAI,CAAC,oBAAoB;QACvB,QAAQ,IAAI,CAAC,CAAA,oDAAA,EAAuD,KAAK,SAAS,CAAC,MAAK,SAAA,CAAW;QACnG,qBAAqB;;IAEvB,aAAa;IACb,OAAO,MAAM,cAAc,SAAS;AACtC;AAEA,MAAM,mBAA0B,IAAI,yIAAA,CAAA,UAAc,CAAC;IAAE,WAAW;IAAM,SAAS,IAAI,KAAK;AAAI;AAC5F,MAAM,oBAA2B,IAAI,yIAAA,CAAA,UAAc,CAAC,UAAU,CAAC;IAAE,WAAW;IAAM,SAAS,IAAI,KAAK;AAAI;AAExG,eAAe,2BACb,IAAiB,EACjB,IAAuB;IAEvB,MAAM,UAAU,IAAI,0KAAA,CAAA,kBAAe,CAAC;IACpC,MAAM,WAAW,iDAAA,CAAA,WAAQ,CAAC,IAAI,CAAC;IAC/B,MAAM,OAAO,IAAI,oJAAA,CAAA,gBAAa,CAAC;IAC/B,MAAM,UAAU;QACd,GAAG,KAAK,OAAO;QACf,GAAG,QAAQ,OAAO;QAClB,kBAAkB,QAAQ,aAAa;;IAGzC,OAAO;QAAE,GAAG,IAAI;QAAE,MAAM;QAAa;IAAO;AAC9C;AAEM,SAAU;IACd,oCAAoC;IACpC,IAAI,OAAO,oBAAoB,aAAa;QAC1C,gFAAgF;QAChF,WAAW,eAAe,GAAG,oKAAA,CAAA,kBAAuB;;IAEtD,OAAO;QACL,MAAM;QACN,OAAO,iJAAG,OAAO;QACjB,SAAS,iJAAG,OAAO;QACnB,UAAU,iJAAG,QAAQ;QACrB,SAAS,iJAAG,OAAO;QACnB,UAAU,0KAAG,QAAQ;QACrB,MAAM,0KAAG,IAAI;QACb,MAAM,0KAAG,IAAI;QACb,gBAAA,wDAAA,CAAA,iBAAc;QACd;QACA,iBAAiB,CAAC,MAAwB,IAAI,UAAU,CAAC,WAAW,oBAAoB;QACxF;QACA,gBAAgB,CAAC,QAAsC,iBAAiB,6CAAA,CAAA,aAAY;;AAExF"}},
    {"offset": {"line": 179, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 206, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/_shims/index.mjs"],"sourcesContent":["/**\n * Disclaimer: modules in _shims aren't intended to be imported by SDK users.\n */\nimport * as shims from './registry.mjs';\nimport * as auto from 'openai/_shims/auto/runtime';\nif (!shims.kind) shims.setShims(auto.getRuntime(), { auto: true });\nexport * from './registry.mjs';\n"],"names":[],"mappings":"AAAA;;CAEC;;;;;;AAGD,IAAI,CAAC,gJAAM,IAAI,EAAE,gJAAM,QAAQ,CAAC,+KAAK,UAAU,IAAI;IAAE,MAAM;AAAK"}},
    {"offset": {"line": 218, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 231, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/internal/decoders/line.ts"],"sourcesContent":["import { OpenAIError } from '../../error';\n\ntype Bytes = string | ArrayBuffer | Uint8Array | Buffer | null | undefined;\n\n/**\n * A re-implementation of httpx's `LineDecoder` in Python that handles incrementally\n * reading lines from text.\n *\n * https://github.com/encode/httpx/blob/920333ea98118e9cf617f246905d7b202510941c/httpx/_decoders.py#L258\n */\nexport class LineDecoder {\n  // prettier-ignore\n  static NEWLINE_CHARS = new Set(['\\n', '\\r']);\n  static NEWLINE_REGEXP = /\\r\\n|[\\n\\r]/g;\n\n  buffer: string[];\n  trailingCR: boolean;\n  textDecoder: any; // TextDecoder found in browsers; not typed to avoid pulling in either \"dom\" or \"node\" types.\n\n  constructor() {\n    this.buffer = [];\n    this.trailingCR = false;\n  }\n\n  decode(chunk: Bytes): string[] {\n    let text = this.decodeText(chunk);\n\n    if (this.trailingCR) {\n      text = '\\r' + text;\n      this.trailingCR = false;\n    }\n    if (text.endsWith('\\r')) {\n      this.trailingCR = true;\n      text = text.slice(0, -1);\n    }\n\n    if (!text) {\n      return [];\n    }\n\n    const trailingNewline = LineDecoder.NEWLINE_CHARS.has(text[text.length - 1] || '');\n    let lines = text.split(LineDecoder.NEWLINE_REGEXP);\n\n    // if there is a trailing new line then the last entry will be an empty\n    // string which we don't care about\n    if (trailingNewline) {\n      lines.pop();\n    }\n\n    if (lines.length === 1 && !trailingNewline) {\n      this.buffer.push(lines[0]!);\n      return [];\n    }\n\n    if (this.buffer.length > 0) {\n      lines = [this.buffer.join('') + lines[0], ...lines.slice(1)];\n      this.buffer = [];\n    }\n\n    if (!trailingNewline) {\n      this.buffer = [lines.pop() || ''];\n    }\n\n    return lines;\n  }\n\n  decodeText(bytes: Bytes): string {\n    if (bytes == null) return '';\n    if (typeof bytes === 'string') return bytes;\n\n    // Node:\n    if (typeof Buffer !== 'undefined') {\n      if (bytes instanceof Buffer) {\n        return bytes.toString();\n      }\n      if (bytes instanceof Uint8Array) {\n        return Buffer.from(bytes).toString();\n      }\n\n      throw new OpenAIError(\n        `Unexpected: received non-Uint8Array (${bytes.constructor.name}) stream chunk in an environment with a global \"Buffer\" defined, which this library assumes to be Node. Please report this error.`,\n      );\n    }\n\n    // Browser\n    if (typeof TextDecoder !== 'undefined') {\n      if (bytes instanceof Uint8Array || bytes instanceof ArrayBuffer) {\n        this.textDecoder ??= new TextDecoder('utf8');\n        return this.textDecoder.decode(bytes);\n      }\n\n      throw new OpenAIError(\n        `Unexpected: received non-Uint8Array/ArrayBuffer (${\n          (bytes as any).constructor.name\n        }) in a web platform. Please report this error.`,\n      );\n    }\n\n    throw new OpenAIError(\n      `Unexpected: neither Buffer nor TextDecoder are available as globals. Please report this error.`,\n    );\n  }\n\n  flush(): string[] {\n    if (!this.buffer.length && !this.trailingCR) {\n      return [];\n    }\n\n    const lines = [this.buffer.join('')];\n    this.buffer = [];\n    this.trailingCR = false;\n    return lines;\n  }\n}\n"],"names":[],"mappings":";;;;;;AAUM,MAAO;IASX,aAAA;QACE,IAAI,CAAC,MAAM,GAAG,EAAE;QAChB,IAAI,CAAC,UAAU,GAAG;IACpB;IAEA,OAAO,KAAY,EAAA;QACjB,IAAI,OAAO,IAAI,CAAC,UAAU,CAAC;QAE3B,IAAI,IAAI,CAAC,UAAU,EAAE;YACnB,OAAO,OAAO;YACd,IAAI,CAAC,UAAU,GAAG;;QAEpB,IAAI,KAAK,QAAQ,CAAC,OAAO;YACvB,IAAI,CAAC,UAAU,GAAG;YAClB,OAAO,KAAK,KAAK,CAAC,GAAG,CAAC;;QAGxB,IAAI,CAAC,MAAM;YACT,OAAO,EAAE;;QAGX,MAAM,kBAAkB,YAAY,aAAa,CAAC,GAAG,CAAC,IAAI,CAAC,KAAK,MAAM,GAAG,EAAE,IAAI;QAC/E,IAAI,QAAQ,KAAK,KAAK,CAAC,YAAY,cAAc;QAEjD,uEAAuE;QACvE,mCAAmC;QACnC,IAAI,iBAAiB;YACnB,MAAM,GAAG;;QAGX,IAAI,MAAM,MAAM,KAAK,KAAK,CAAC,iBAAiB;YAC1C,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,EAAG;YAC1B,OAAO,EAAE;;QAGX,IAAI,IAAI,CAAC,MAAM,CAAC,MAAM,GAAG,GAAG;YAC1B,QAAQ;gBAAC,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,MAAM,KAAK,CAAC,EAAE;mBAAK,MAAM,KAAK,CAAC;aAAG;YAC5D,IAAI,CAAC,MAAM,GAAG,EAAE;;QAGlB,IAAI,CAAC,iBAAiB;YACpB,IAAI,CAAC,MAAM,GAAG;gBAAC,MAAM,GAAG,MAAM;aAAG;;QAGnC,OAAO;IACT;IAEA,WAAW,KAAY,EAAA;QACrB,IAAI,SAAS,MAAM,OAAO;QAC1B,IAAI,OAAO,UAAU,UAAU,OAAO;QAEtC,QAAQ;QACR,IAAI,OAAO,WAAW,aAAa;YACjC,IAAI,iBAAiB,QAAQ;gBAC3B,OAAO,MAAM,QAAQ;;YAEvB,IAAI,iBAAiB,YAAY;gBAC/B,OAAO,OAAO,IAAI,CAAC,OAAO,QAAQ;;YAGpC,MAAM,IAAI,kIAAA,CAAA,cAAW,CACnB,CAAA,qCAAA,EAAwC,MAAM,WAAW,CAAC,IAAI,CAAA,iIAAA,CAAmI;;QAIrM,UAAU;QACV,IAAI,OAAO,gBAAgB,aAAa;YACtC,IAAI,iBAAiB,cAAc,iBAAiB,aAAa;gBAC/D,IAAI,CAAC,WAAW,IAAA,CAAhB,IAAI,CAAC,WAAW,GAAK,IAAI,YAAY,OAAO;gBAC5C,OAAO,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;;YAGjC,MAAM,IAAI,kIAAA,CAAA,cAAW,CACnB,CAAA,iDAAA,EACG,MAAc,WAAW,CAAC,IAC7B,CAAA,8CAAA,CAAgD;;QAIpD,MAAM,IAAI,kIAAA,CAAA,cAAW,CACnB,CAAA,8FAAA,CAAgG;IAEpG;IAEA,QAAK;QACH,IAAI,CAAC,IAAI,CAAC,MAAM,CAAC,MAAM,IAAI,CAAC,IAAI,CAAC,UAAU,EAAE;YAC3C,OAAO,EAAE;;QAGX,MAAM,QAAQ;YAAC,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC;SAAI;QACpC,IAAI,CAAC,MAAM,GAAG,EAAE;QAChB,IAAI,CAAC,UAAU,GAAG;QAClB,OAAO;IACT;;AArGA,kBAAkB;AACX,YAAA,aAAa,GAAG,IAAI,IAAI;IAAC;IAAM;CAAK;AACpC,YAAA,cAAc,GAAG"}},
    {"offset": {"line": 321, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 326, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/streaming.ts"],"sourcesContent":["import { ReadableStream, type Response } from './_shims/index';\nimport { OpenAIError } from './error';\nimport { LineDecoder } from './internal/decoders/line';\n\nimport { APIError } from \"./error\";\n\ntype Bytes = string | ArrayBuffer | Uint8Array | Buffer | null | undefined;\n\nexport type ServerSentEvent = {\n  event: string | null;\n  data: string;\n  raw: string[];\n};\n\nexport class Stream<Item> implements AsyncIterable<Item> {\n  controller: AbortController;\n\n  constructor(\n    private iterator: () => AsyncIterator<Item>,\n    controller: AbortController,\n  ) {\n    this.controller = controller;\n  }\n\n  static fromSSEResponse<Item>(response: Response, controller: AbortController) {\n    let consumed = false;\n\n    async function* iterator(): AsyncIterator<Item, any, undefined> {\n      if (consumed) {\n        throw new Error('Cannot iterate over a consumed stream, use `.tee()` to split the stream.');\n      }\n      consumed = true;\n      let done = false;\n      try {\n        for await (const sse of _iterSSEMessages(response, controller)) {\n          if (done) continue;\n\n          if (sse.data.startsWith('[DONE]')) {\n            done = true;\n            continue;\n          }\n\n          if (sse.event === null) {\n            let data;\n\n            try {\n              data = JSON.parse(sse.data);\n            } catch (e) {\n              console.error(`Could not parse message into JSON:`, sse.data);\n              console.error(`From chunk:`, sse.raw);\n              throw e;\n            }\n\n            if (data && data.error) {\n              throw new APIError(undefined, data.error, undefined, undefined);\n            }\n\n            yield data;\n          } else {\n            let data;\n            try {\n              data = JSON.parse(sse.data);\n            } catch (e) {\n              console.error(`Could not parse message into JSON:`, sse.data);\n              console.error(`From chunk:`, sse.raw);\n              throw e;\n            }\n            // TODO: Is this where the error should be thrown?\n            if (sse.event == 'error') {\n              throw new APIError(undefined, data.error, data.message, undefined);\n            }\n            yield { event: sse.event, data: data } as any;\n          }\n        }\n        done = true;\n      } catch (e) {\n        // If the user calls `stream.controller.abort()`, we should exit without throwing.\n        if (e instanceof Error && e.name === 'AbortError') return;\n        throw e;\n      } finally {\n        // If the user `break`s, abort the ongoing request.\n        if (!done) controller.abort();\n      }\n    }\n\n    return new Stream(iterator, controller);\n  }\n\n  /**\n   * Generates a Stream from a newline-separated ReadableStream\n   * where each item is a JSON value.\n   */\n  static fromReadableStream<Item>(readableStream: ReadableStream, controller: AbortController) {\n    let consumed = false;\n\n    async function* iterLines(): AsyncGenerator<string, void, unknown> {\n      const lineDecoder = new LineDecoder();\n\n      const iter = readableStreamAsyncIterable<Bytes>(readableStream);\n      for await (const chunk of iter) {\n        for (const line of lineDecoder.decode(chunk)) {\n          yield line;\n        }\n      }\n\n      for (const line of lineDecoder.flush()) {\n        yield line;\n      }\n    }\n\n    async function* iterator(): AsyncIterator<Item, any, undefined> {\n      if (consumed) {\n        throw new Error('Cannot iterate over a consumed stream, use `.tee()` to split the stream.');\n      }\n      consumed = true;\n      let done = false;\n      try {\n        for await (const line of iterLines()) {\n          if (done) continue;\n          if (line) yield JSON.parse(line);\n        }\n        done = true;\n      } catch (e) {\n        // If the user calls `stream.controller.abort()`, we should exit without throwing.\n        if (e instanceof Error && e.name === 'AbortError') return;\n        throw e;\n      } finally {\n        // If the user `break`s, abort the ongoing request.\n        if (!done) controller.abort();\n      }\n    }\n\n    return new Stream(iterator, controller);\n  }\n\n  [Symbol.asyncIterator](): AsyncIterator<Item> {\n    return this.iterator();\n  }\n\n  /**\n   * Splits the stream into two streams which can be\n   * independently read from at different speeds.\n   */\n  tee(): [Stream<Item>, Stream<Item>] {\n    const left: Array<Promise<IteratorResult<Item>>> = [];\n    const right: Array<Promise<IteratorResult<Item>>> = [];\n    const iterator = this.iterator();\n\n    const teeIterator = (queue: Array<Promise<IteratorResult<Item>>>): AsyncIterator<Item> => {\n      return {\n        next: () => {\n          if (queue.length === 0) {\n            const result = iterator.next();\n            left.push(result);\n            right.push(result);\n          }\n          return queue.shift()!;\n        },\n      };\n    };\n\n    return [\n      new Stream(() => teeIterator(left), this.controller),\n      new Stream(() => teeIterator(right), this.controller),\n    ];\n  }\n\n  /**\n   * Converts this stream to a newline-separated ReadableStream of\n   * JSON stringified values in the stream\n   * which can be turned back into a Stream with `Stream.fromReadableStream()`.\n   */\n  toReadableStream(): ReadableStream {\n    const self = this;\n    let iter: AsyncIterator<Item>;\n    const encoder = new TextEncoder();\n\n    return new ReadableStream({\n      async start() {\n        iter = self[Symbol.asyncIterator]();\n      },\n      async pull(ctrl: any) {\n        try {\n          const { value, done } = await iter.next();\n          if (done) return ctrl.close();\n\n          const bytes = encoder.encode(JSON.stringify(value) + '\\n');\n\n          ctrl.enqueue(bytes);\n        } catch (err) {\n          ctrl.error(err);\n        }\n      },\n      async cancel() {\n        await iter.return?.();\n      },\n    });\n  }\n}\n\nexport async function* _iterSSEMessages(\n  response: Response,\n  controller: AbortController,\n): AsyncGenerator<ServerSentEvent, void, unknown> {\n  if (!response.body) {\n    controller.abort();\n    throw new OpenAIError(`Attempted to iterate over a response with no body`);\n  }\n\n  const sseDecoder = new SSEDecoder();\n  const lineDecoder = new LineDecoder();\n\n  const iter = readableStreamAsyncIterable<Bytes>(response.body);\n  for await (const sseChunk of iterSSEChunks(iter)) {\n    for (const line of lineDecoder.decode(sseChunk)) {\n      const sse = sseDecoder.decode(line);\n      if (sse) yield sse;\n    }\n  }\n\n  for (const line of lineDecoder.flush()) {\n    const sse = sseDecoder.decode(line);\n    if (sse) yield sse;\n  }\n}\n\n/**\n * Given an async iterable iterator, iterates over it and yields full\n * SSE chunks, i.e. yields when a double new-line is encountered.\n */\nasync function* iterSSEChunks(iterator: AsyncIterableIterator<Bytes>): AsyncGenerator<Uint8Array> {\n  let data = new Uint8Array();\n\n  for await (const chunk of iterator) {\n    if (chunk == null) {\n      continue;\n    }\n\n    const binaryChunk =\n      chunk instanceof ArrayBuffer ? new Uint8Array(chunk)\n      : typeof chunk === 'string' ? new TextEncoder().encode(chunk)\n      : chunk;\n\n    let newData = new Uint8Array(data.length + binaryChunk.length);\n    newData.set(data);\n    newData.set(binaryChunk, data.length);\n    data = newData;\n\n    let patternIndex;\n    while ((patternIndex = findDoubleNewlineIndex(data)) !== -1) {\n      yield data.slice(0, patternIndex);\n      data = data.slice(patternIndex);\n    }\n  }\n\n  if (data.length > 0) {\n    yield data;\n  }\n}\n\nfunction findDoubleNewlineIndex(buffer: Uint8Array): number {\n  // This function searches the buffer for the end patterns (\\r\\r, \\n\\n, \\r\\n\\r\\n)\n  // and returns the index right after the first occurrence of any pattern,\n  // or -1 if none of the patterns are found.\n  const newline = 0x0a; // \\n\n  const carriage = 0x0d; // \\r\n\n  for (let i = 0; i < buffer.length - 2; i++) {\n    if (buffer[i] === newline && buffer[i + 1] === newline) {\n      // \\n\\n\n      return i + 2;\n    }\n    if (buffer[i] === carriage && buffer[i + 1] === carriage) {\n      // \\r\\r\n      return i + 2;\n    }\n    if (\n      buffer[i] === carriage &&\n      buffer[i + 1] === newline &&\n      i + 3 < buffer.length &&\n      buffer[i + 2] === carriage &&\n      buffer[i + 3] === newline\n    ) {\n      // \\r\\n\\r\\n\n      return i + 4;\n    }\n  }\n\n  return -1;\n}\n\nclass SSEDecoder {\n  private data: string[];\n  private event: string | null;\n  private chunks: string[];\n\n  constructor() {\n    this.event = null;\n    this.data = [];\n    this.chunks = [];\n  }\n\n  decode(line: string) {\n    if (line.endsWith('\\r')) {\n      line = line.substring(0, line.length - 1);\n    }\n\n    if (!line) {\n      // empty line and we didn't previously encounter any messages\n      if (!this.event && !this.data.length) return null;\n\n      const sse: ServerSentEvent = {\n        event: this.event,\n        data: this.data.join('\\n'),\n        raw: this.chunks,\n      };\n\n      this.event = null;\n      this.data = [];\n      this.chunks = [];\n\n      return sse;\n    }\n\n    this.chunks.push(line);\n\n    if (line.startsWith(':')) {\n      return null;\n    }\n\n    let [fieldname, _, value] = partition(line, ':');\n\n    if (value.startsWith(' ')) {\n      value = value.substring(1);\n    }\n\n    if (fieldname === 'event') {\n      this.event = value;\n    } else if (fieldname === 'data') {\n      this.data.push(value);\n    }\n\n    return null;\n  }\n}\n\n/** This is an internal helper function that's just used for testing */\nexport function _decodeChunks(chunks: string[]): string[] {\n  const decoder = new LineDecoder();\n  const lines: string[] = [];\n  for (const chunk of chunks) {\n    lines.push(...decoder.decode(chunk));\n  }\n\n  return lines;\n}\n\nfunction partition(str: string, delimiter: string): [string, string, string] {\n  const index = str.indexOf(delimiter);\n  if (index !== -1) {\n    return [str.substring(0, index), delimiter, str.substring(index + delimiter.length)];\n  }\n\n  return [str, '', ''];\n}\n\n/**\n * Most browsers don't yet have async iterable support for ReadableStream,\n * and Node has a very different way of reading bytes from its \"ReadableStream\".\n *\n * This polyfill was pulled from https://github.com/MattiasBuelens/web-streams-polyfill/pull/122#issuecomment-1627354490\n */\nexport function readableStreamAsyncIterable<T>(stream: any): AsyncIterableIterator<T> {\n  if (stream[Symbol.asyncIterator]) return stream;\n\n  const reader = stream.getReader();\n  return {\n    async next() {\n      try {\n        const result = await reader.read();\n        if (result?.done) reader.releaseLock(); // release lock when stream becomes closed\n        return result;\n      } catch (e) {\n        reader.releaseLock(); // release lock when stream becomes errored\n        throw e;\n      }\n    },\n    async return() {\n      const cancelPromise = reader.cancel();\n      reader.releaseLock();\n      await cancelPromise;\n      return { done: true, value: undefined };\n    },\n    [Symbol.asyncIterator]() {\n      return this;\n    },\n  };\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;AAcM,MAAO;IAGX,YACU,QAAmC,EAC3C,UAA2B,CAAA;QADnB,IAAA,CAAA,QAAQ,GAAR;QAGR,IAAI,CAAC,UAAU,GAAG;IACpB;IAEA,OAAO,gBAAsB,QAAkB,EAAE,UAA2B,EAAA;QAC1E,IAAI,WAAW;QAEf,gBAAgB;YACd,IAAI,UAAU;gBACZ,MAAM,IAAI,MAAM;;YAElB,WAAW;YACX,IAAI,OAAO;YACX,IAAI;gBACF,WAAW,MAAM,OAAO,iBAAiB,UAAU,YAAa;oBAC9D,IAAI,MAAM;oBAEV,IAAI,IAAI,IAAI,CAAC,UAAU,CAAC,WAAW;wBACjC,OAAO;wBACP;;oBAGF,IAAI,IAAI,KAAK,KAAK,MAAM;wBACtB,IAAI;wBAEJ,IAAI;4BACF,OAAO,KAAK,KAAK,CAAC,IAAI,IAAI;0BAC1B,OAAO,GAAG;4BACV,QAAQ,KAAK,CAAC,CAAA,kCAAA,CAAoC,EAAE,IAAI,IAAI;4BAC5D,QAAQ,KAAK,CAAC,CAAA,WAAA,CAAa,EAAE,IAAI,GAAG;4BACpC,MAAM;;wBAGR,IAAI,QAAQ,KAAK,KAAK,EAAE;4BACtB,MAAM,IAAI,kIAAA,CAAA,WAAQ,CAAC,WAAW,KAAK,KAAK,EAAE,WAAW;;wBAGvD,MAAM;2BACD;wBACL,IAAI;wBACJ,IAAI;4BACF,OAAO,KAAK,KAAK,CAAC,IAAI,IAAI;0BAC1B,OAAO,GAAG;4BACV,QAAQ,KAAK,CAAC,CAAA,kCAAA,CAAoC,EAAE,IAAI,IAAI;4BAC5D,QAAQ,KAAK,CAAC,CAAA,WAAA,CAAa,EAAE,IAAI,GAAG;4BACpC,MAAM;;wBAER,kDAAkD;wBAClD,IAAI,IAAI,KAAK,IAAI,SAAS;4BACxB,MAAM,IAAI,kIAAA,CAAA,WAAQ,CAAC,WAAW,KAAK,KAAK,EAAE,KAAK,OAAO,EAAE;;wBAE1D,MAAM;4BAAE,OAAO,IAAI,KAAK;4BAAE,MAAM;wBAAI;;;gBAGxC,OAAO;cACP,OAAO,GAAG;gBACV,kFAAkF;gBAClF,IAAI,aAAa,SAAS,EAAE,IAAI,KAAK,cAAc;gBACnD,MAAM;qBACE;gBACR,mDAAmD;gBACnD,IAAI,CAAC,MAAM,WAAW,KAAK;;QAE/B;QAEA,OAAO,IAAI,OAAO,UAAU;IAC9B;IAEA;;;QAIA,OAAO,mBAAyB,cAA8B,EAAE,UAA2B,EAAA;QACzF,IAAI,WAAW;QAEf,gBAAgB;YACd,MAAM,cAAc,IAAI,yJAAA,CAAA,cAAW;YAEnC,MAAM,OAAO,4BAAmC;YAChD,WAAW,MAAM,SAAS,KAAM;gBAC9B,KAAK,MAAM,QAAQ,YAAY,MAAM,CAAC,OAAQ;oBAC5C,MAAM;;;YAIV,KAAK,MAAM,QAAQ,YAAY,KAAK,GAAI;gBACtC,MAAM;;QAEV;QAEA,gBAAgB;YACd,IAAI,UAAU;gBACZ,MAAM,IAAI,MAAM;;YAElB,WAAW;YACX,IAAI,OAAO;YACX,IAAI;gBACF,WAAW,MAAM,QAAQ,YAAa;oBACpC,IAAI,MAAM;oBACV,IAAI,MAAM,MAAM,KAAK,KAAK,CAAC;;gBAE7B,OAAO;cACP,OAAO,GAAG;gBACV,kFAAkF;gBAClF,IAAI,aAAa,SAAS,EAAE,IAAI,KAAK,cAAc;gBACnD,MAAM;qBACE;gBACR,mDAAmD;gBACnD,IAAI,CAAC,MAAM,WAAW,KAAK;;QAE/B;QAEA,OAAO,IAAI,OAAO,UAAU;IAC9B;IAEA,CAAC,OAAO,aAAa,CAAC,GAAA;QACpB,OAAO,IAAI,CAAC,QAAQ;IACtB;IAEA;;;QAIA,MAAG;QACD,MAAM,OAA6C,EAAE;QACrD,MAAM,QAA8C,EAAE;QACtD,MAAM,WAAW,IAAI,CAAC,QAAQ;QAE9B,MAAM,cAAc,CAAC;YACnB,OAAO;gBACL,MAAM;oBACJ,IAAI,MAAM,MAAM,KAAK,GAAG;wBACtB,MAAM,SAAS,SAAS,IAAI;wBAC5B,KAAK,IAAI,CAAC;wBACV,MAAM,IAAI,CAAC;;oBAEb,OAAO,MAAM,KAAK;gBACpB;;QAEJ;QAEA,OAAO;YACL,IAAI,OAAO,IAAM,YAAY,OAAO,IAAI,CAAC,UAAU;YACnD,IAAI,OAAO,IAAM,YAAY,QAAQ,IAAI,CAAC,UAAU;SACrD;IACH;IAEA;;;;QAKA,mBAAgB;QACd,MAAM,OAAO,IAAI;QACjB,IAAI;QACJ,MAAM,UAAU,IAAI;QAEpB,OAAO,IAAI,+IAAA,CAAA,iBAAc,CAAC;YACxB,MAAM;gBACJ,OAAO,IAAI,CAAC,OAAO,aAAa,CAAC;YACnC;YACA,MAAM,MAAK,IAAS;gBAClB,IAAI;oBACF,MAAM,EAAE,KAAK,EAAE,IAAI,EAAE,GAAG,MAAM,KAAK,IAAI;oBACvC,IAAI,MAAM,OAAO,KAAK,KAAK;oBAE3B,MAAM,QAAQ,QAAQ,MAAM,CAAC,KAAK,SAAS,CAAC,SAAS;oBAErD,KAAK,OAAO,CAAC;kBACb,OAAO,KAAK;oBACZ,KAAK,KAAK,CAAC;;YAEf;YACA,MAAM;gBACJ,MAAM,KAAK,MAAM;YACnB;;IAEJ;;AAGK,gBAAgB,iBACrB,QAAkB,EAClB,UAA2B;IAE3B,IAAI,CAAC,SAAS,IAAI,EAAE;QAClB,WAAW,KAAK;QAChB,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC,CAAA,iDAAA,CAAmD;;IAG3E,MAAM,aAAa,IAAI;IACvB,MAAM,cAAc,IAAI,yJAAA,CAAA,cAAW;IAEnC,MAAM,OAAO,4BAAmC,SAAS,IAAI;IAC7D,WAAW,MAAM,YAAY,cAAc,MAAO;QAChD,KAAK,MAAM,QAAQ,YAAY,MAAM,CAAC,UAAW;YAC/C,MAAM,MAAM,WAAW,MAAM,CAAC;YAC9B,IAAI,KAAK,MAAM;;;IAInB,KAAK,MAAM,QAAQ,YAAY,KAAK,GAAI;QACtC,MAAM,MAAM,WAAW,MAAM,CAAC;QAC9B,IAAI,KAAK,MAAM;;AAEnB;AAEA;;;IAIA,gBAAgB,cAAc,QAAsC;IAClE,IAAI,OAAO,IAAI;IAEf,WAAW,MAAM,SAAS,SAAU;QAClC,IAAI,SAAS,MAAM;YACjB;;QAGF,MAAM,cACJ,iBAAiB,cAAc,IAAI,WAAW,SAC5C,OAAO,UAAU,WAAW,IAAI,cAAc,MAAM,CAAC,SACrD;QAEJ,IAAI,UAAU,IAAI,WAAW,KAAK,MAAM,GAAG,YAAY,MAAM;QAC7D,QAAQ,GAAG,CAAC;QACZ,QAAQ,GAAG,CAAC,aAAa,KAAK,MAAM;QACpC,OAAO;QAEP,IAAI;QACJ,MAAO,CAAC,eAAe,uBAAuB,KAAK,MAAM,CAAC,EAAG;YAC3D,MAAM,KAAK,KAAK,CAAC,GAAG;YACpB,OAAO,KAAK,KAAK,CAAC;;;IAItB,IAAI,KAAK,MAAM,GAAG,GAAG;QACnB,MAAM;;AAEV;AAEA,SAAS,uBAAuB,MAAkB;IAChD,gFAAgF;IAChF,yEAAyE;IACzE,2CAA2C;IAC3C,MAAM,UAAU,MAAM,KAAK;IAC3B,MAAM,WAAW,MAAM,KAAK;IAE5B,IAAK,IAAI,IAAI,GAAG,IAAI,OAAO,MAAM,GAAG,GAAG,IAAK;QAC1C,IAAI,MAAM,CAAC,EAAE,KAAK,WAAW,MAAM,CAAC,IAAI,EAAE,KAAK,SAAS;YACtD,OAAO;YACP,OAAO,IAAI;;QAEb,IAAI,MAAM,CAAC,EAAE,KAAK,YAAY,MAAM,CAAC,IAAI,EAAE,KAAK,UAAU;YACxD,OAAO;YACP,OAAO,IAAI;;QAEb,IACE,MAAM,CAAC,EAAE,KAAK,YACd,MAAM,CAAC,IAAI,EAAE,KAAK,WAClB,IAAI,IAAI,OAAO,MAAM,IACrB,MAAM,CAAC,IAAI,EAAE,KAAK,YAClB,MAAM,CAAC,IAAI,EAAE,KAAK,SAClB;YACA,WAAW;YACX,OAAO,IAAI;;;IAIf,OAAO,CAAC;AACV;AAEA,MAAM;IAKJ,aAAA;QACE,IAAI,CAAC,KAAK,GAAG;QACb,IAAI,CAAC,IAAI,GAAG,EAAE;QACd,IAAI,CAAC,MAAM,GAAG,EAAE;IAClB;IAEA,OAAO,IAAY,EAAA;QACjB,IAAI,KAAK,QAAQ,CAAC,OAAO;YACvB,OAAO,KAAK,SAAS,CAAC,GAAG,KAAK,MAAM,GAAG;;QAGzC,IAAI,CAAC,MAAM;YACT,6DAA6D;YAC7D,IAAI,CAAC,IAAI,CAAC,KAAK,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,MAAM,EAAE,OAAO;YAE7C,MAAM,MAAuB;gBAC3B,OAAO,IAAI,CAAC,KAAK;gBACjB,MAAM,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC;gBACrB,KAAK,IAAI,CAAC,MAAM;;YAGlB,IAAI,CAAC,KAAK,GAAG;YACb,IAAI,CAAC,IAAI,GAAG,EAAE;YACd,IAAI,CAAC,MAAM,GAAG,EAAE;YAEhB,OAAO;;QAGT,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC;QAEjB,IAAI,KAAK,UAAU,CAAC,MAAM;YACxB,OAAO;;QAGT,IAAI,CAAC,WAAW,GAAG,MAAM,GAAG,UAAU,MAAM;QAE5C,IAAI,MAAM,UAAU,CAAC,MAAM;YACzB,QAAQ,MAAM,SAAS,CAAC;;QAG1B,IAAI,cAAc,SAAS;YACzB,IAAI,CAAC,KAAK,GAAG;eACR,IAAI,cAAc,QAAQ;YAC/B,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC;;QAGjB,OAAO;IACT;;AAII,SAAU,cAAc,MAAgB;IAC5C,MAAM,UAAU,IAAI,yJAAA,CAAA,cAAW;IAC/B,MAAM,QAAkB,EAAE;IAC1B,KAAK,MAAM,SAAS,OAAQ;QAC1B,MAAM,IAAI,IAAI,QAAQ,MAAM,CAAC;;IAG/B,OAAO;AACT;AAEA,SAAS,UAAU,GAAW,EAAE,SAAiB;IAC/C,MAAM,QAAQ,IAAI,OAAO,CAAC;IAC1B,IAAI,UAAU,CAAC,GAAG;QAChB,OAAO;YAAC,IAAI,SAAS,CAAC,GAAG;YAAQ;YAAW,IAAI,SAAS,CAAC,QAAQ,UAAU,MAAM;SAAE;;IAGtF,OAAO;QAAC;QAAK;QAAI;KAAG;AACtB;AAQM,SAAU,4BAA+B,MAAW;IACxD,IAAI,MAAM,CAAC,OAAO,aAAa,CAAC,EAAE,OAAO;IAEzC,MAAM,SAAS,OAAO,SAAS;IAC/B,OAAO;QACL,MAAM;YACJ,IAAI;gBACF,MAAM,SAAS,MAAM,OAAO,IAAI;gBAChC,IAAI,QAAQ,MAAM,OAAO,WAAW,IAAI,0CAA0C;gBAClF,OAAO;cACP,OAAO,GAAG;gBACV,OAAO,WAAW,IAAI,2CAA2C;gBACjE,MAAM;;QAEV;QACA,MAAM;YACJ,MAAM,gBAAgB,OAAO,MAAM;YACnC,OAAO,WAAW;YAClB,MAAM;YACN,OAAO;gBAAE,MAAM;gBAAM,OAAO;YAAS;QACvC;QACA,CAAC,OAAO,aAAa,CAAC;YACpB,OAAO,IAAI;QACb;;AAEJ"}},
    {"offset": {"line": 655, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 660, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/uploads.ts"],"sourcesContent":["import { type RequestOptions } from './core';\nimport {\n  FormData,\n  File,\n  type Blob,\n  type FilePropertyBag,\n  getMultipartRequestOptions,\n  type FsReadStream,\n  isFsReadStream,\n} from './_shims/index';\nimport { MultipartBody } from './_shims/MultipartBody';\nexport { fileFromPath } from './_shims/index';\n\ntype BlobLikePart = string | ArrayBuffer | ArrayBufferView | BlobLike | Uint8Array | DataView;\nexport type BlobPart = string | ArrayBuffer | ArrayBufferView | Blob | Uint8Array | DataView;\n\n/**\n * Typically, this is a native \"File\" class.\n *\n * We provide the {@link toFile} utility to convert a variety of objects\n * into the File class.\n *\n * For convenience, you can also pass a fetch Response, or in Node,\n * the result of fs.createReadStream().\n */\nexport type Uploadable = FileLike | ResponseLike | FsReadStream;\n\n/**\n * Intended to match web.Blob, node.Blob, node-fetch.Blob, etc.\n */\nexport interface BlobLike {\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/size) */\n  readonly size: number;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/type) */\n  readonly type: string;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/text) */\n  text(): Promise<string>;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/slice) */\n  slice(start?: number, end?: number): BlobLike;\n  // unfortunately @types/node-fetch@^2.6.4 doesn't type the arrayBuffer method\n}\n\n/**\n * Intended to match web.File, node.File, node-fetch.File, etc.\n */\nexport interface FileLike extends BlobLike {\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/File/lastModified) */\n  readonly lastModified: number;\n  /** [MDN Reference](https://developer.mozilla.org/docs/Web/API/File/name) */\n  readonly name: string;\n}\n\n/**\n * Intended to match web.Response, node.Response, node-fetch.Response, etc.\n */\nexport interface ResponseLike {\n  url: string;\n  blob(): Promise<BlobLike>;\n}\n\nexport const isResponseLike = (value: any): value is ResponseLike =>\n  value != null &&\n  typeof value === 'object' &&\n  typeof value.url === 'string' &&\n  typeof value.blob === 'function';\n\nexport const isFileLike = (value: any): value is FileLike =>\n  value != null &&\n  typeof value === 'object' &&\n  typeof value.name === 'string' &&\n  typeof value.lastModified === 'number' &&\n  isBlobLike(value);\n\n/**\n * The BlobLike type omits arrayBuffer() because @types/node-fetch@^2.6.4 lacks it; but this check\n * adds the arrayBuffer() method type because it is available and used at runtime\n */\nexport const isBlobLike = (value: any): value is BlobLike & { arrayBuffer(): Promise<ArrayBuffer> } =>\n  value != null &&\n  typeof value === 'object' &&\n  typeof value.size === 'number' &&\n  typeof value.type === 'string' &&\n  typeof value.text === 'function' &&\n  typeof value.slice === 'function' &&\n  typeof value.arrayBuffer === 'function';\n\nexport const isUploadable = (value: any): value is Uploadable => {\n  return isFileLike(value) || isResponseLike(value) || isFsReadStream(value);\n};\n\nexport type ToFileInput = Uploadable | Exclude<BlobLikePart, string> | AsyncIterable<BlobLikePart>;\n\n/**\n * Helper for creating a {@link File} to pass to an SDK upload method from a variety of different data formats\n * @param value the raw content of the file.  Can be an {@link Uploadable}, {@link BlobLikePart}, or {@link AsyncIterable} of {@link BlobLikePart}s\n * @param {string=} name the name of the file. If omitted, toFile will try to determine a file name from bits if possible\n * @param {Object=} options additional properties\n * @param {string=} options.type the MIME type of the content\n * @param {number=} options.lastModified the last modified timestamp\n * @returns a {@link File} with the given properties\n */\nexport async function toFile(\n  value: ToFileInput | PromiseLike<ToFileInput>,\n  name?: string | null | undefined,\n  options?: FilePropertyBag | undefined,\n): Promise<FileLike> {\n  // If it's a promise, resolve it.\n  value = await value;\n\n  // If we've been given a `File` we don't need to do anything\n  if (isFileLike(value)) {\n    return value;\n  }\n\n  if (isResponseLike(value)) {\n    const blob = await value.blob();\n    name ||= new URL(value.url).pathname.split(/[\\\\/]/).pop() ?? 'unknown_file';\n\n    // we need to convert the `Blob` into an array buffer because the `Blob` class\n    // that `node-fetch` defines is incompatible with the web standard which results\n    // in `new File` interpreting it as a string instead of binary data.\n    const data = isBlobLike(blob) ? [(await blob.arrayBuffer()) as any] : [blob];\n\n    return new File(data, name, options);\n  }\n\n  const bits = await getBytes(value);\n\n  name ||= getName(value) ?? 'unknown_file';\n\n  if (!options?.type) {\n    const type = (bits[0] as any)?.type;\n    if (typeof type === 'string') {\n      options = { ...options, type };\n    }\n  }\n\n  return new File(bits, name, options);\n}\n\nasync function getBytes(value: ToFileInput): Promise<Array<BlobPart>> {\n  let parts: Array<BlobPart> = [];\n  if (\n    typeof value === 'string' ||\n    ArrayBuffer.isView(value) || // includes Uint8Array, Buffer, etc.\n    value instanceof ArrayBuffer\n  ) {\n    parts.push(value);\n  } else if (isBlobLike(value)) {\n    parts.push(await value.arrayBuffer());\n  } else if (\n    isAsyncIterableIterator(value) // includes Readable, ReadableStream, etc.\n  ) {\n    for await (const chunk of value) {\n      parts.push(chunk as BlobPart); // TODO, consider validating?\n    }\n  } else {\n    throw new Error(\n      `Unexpected data type: ${typeof value}; constructor: ${value?.constructor\n        ?.name}; props: ${propsForError(value)}`,\n    );\n  }\n\n  return parts;\n}\n\nfunction propsForError(value: any): string {\n  const props = Object.getOwnPropertyNames(value);\n  return `[${props.map((p) => `\"${p}\"`).join(', ')}]`;\n}\n\nfunction getName(value: any): string | undefined {\n  return (\n    getStringFromMaybeBuffer(value.name) ||\n    getStringFromMaybeBuffer(value.filename) ||\n    // For fs.ReadStream\n    getStringFromMaybeBuffer(value.path)?.split(/[\\\\/]/).pop()\n  );\n}\n\nconst getStringFromMaybeBuffer = (x: string | Buffer | unknown): string | undefined => {\n  if (typeof x === 'string') return x;\n  if (typeof Buffer !== 'undefined' && x instanceof Buffer) return String(x);\n  return undefined;\n};\n\nconst isAsyncIterableIterator = (value: any): value is AsyncIterableIterator<unknown> =>\n  value != null && typeof value === 'object' && typeof value[Symbol.asyncIterator] === 'function';\n\nexport const isMultipartBody = (body: any): body is MultipartBody =>\n  body && typeof body === 'object' && body.body && body[Symbol.toStringTag] === 'MultipartBody';\n\n/**\n * Returns a multipart/form-data request if any part of the given request body contains a File / Blob value.\n * Otherwise returns the request as is.\n */\nexport const maybeMultipartFormRequestOptions = async <T = Record<string, unknown>>(\n  opts: RequestOptions<T>,\n): Promise<RequestOptions<T | MultipartBody>> => {\n  if (!hasUploadableValue(opts.body)) return opts;\n\n  const form = await createForm(opts.body);\n  return getMultipartRequestOptions(form, opts);\n};\n\nexport const multipartFormRequestOptions = async <T = Record<string, unknown>>(\n  opts: RequestOptions<T>,\n): Promise<RequestOptions<T | MultipartBody>> => {\n  const form = await createForm(opts.body);\n  return getMultipartRequestOptions(form, opts);\n};\n\nexport const createForm = async <T = Record<string, unknown>>(body: T | undefined): Promise<FormData> => {\n  const form = new FormData();\n  await Promise.all(Object.entries(body || {}).map(([key, value]) => addFormValue(form, key, value)));\n  return form;\n};\n\nconst hasUploadableValue = (value: unknown): boolean => {\n  if (isUploadable(value)) return true;\n  if (Array.isArray(value)) return value.some(hasUploadableValue);\n  if (value && typeof value === 'object') {\n    for (const k in value) {\n      if (hasUploadableValue((value as any)[k])) return true;\n    }\n  }\n  return false;\n};\n\nconst addFormValue = async (form: FormData, key: string, value: unknown): Promise<void> => {\n  if (value === undefined) return;\n  if (value == null) {\n    throw new TypeError(\n      `Received null for \"${key}\"; to pass null in FormData, you must use the string 'null'`,\n    );\n  }\n\n  // TODO: make nested formats configurable\n  if (typeof value === 'string' || typeof value === 'number' || typeof value === 'boolean') {\n    form.append(key, String(value));\n  } else if (isUploadable(value)) {\n    const file = await toFile(value);\n    form.append(key, file as File);\n  } else if (Array.isArray(value)) {\n    await Promise.all(value.map((entry) => addFormValue(form, key + '[]', entry)));\n  } else if (typeof value === 'object') {\n    await Promise.all(\n      Object.entries(value).map(([name, prop]) => addFormValue(form, `${key}[${name}]`, prop)),\n    );\n  } else {\n    throw new TypeError(\n      `Invalid value given to form, expected a string, number, boolean, object, Array, File or Blob but got ${value} instead`,\n    );\n  }\n};\n"],"names":[],"mappings":";;;;;;;;;;;;;;;AA4DO,MAAM,iBAAiB,CAAC,QAC7B,SAAS,QACT,OAAO,UAAU,YACjB,OAAO,MAAM,GAAG,KAAK,YACrB,OAAO,MAAM,IAAI,KAAK;AAEjB,MAAM,aAAa,CAAC,QACzB,SAAS,QACT,OAAO,UAAU,YACjB,OAAO,MAAM,IAAI,KAAK,YACtB,OAAO,MAAM,YAAY,KAAK,YAC9B,WAAW;AAMN,MAAM,aAAa,CAAC,QACzB,SAAS,QACT,OAAO,UAAU,YACjB,OAAO,MAAM,IAAI,KAAK,YACtB,OAAO,MAAM,IAAI,KAAK,YACtB,OAAO,MAAM,IAAI,KAAK,cACtB,OAAO,MAAM,KAAK,KAAK,cACvB,OAAO,MAAM,WAAW,KAAK;AAExB,MAAM,eAAe,CAAC;IAC3B,OAAO,WAAW,UAAU,eAAe,UAAU,CAAA,GAAA,+IAAA,CAAA,iBAAc,AAAd,EAAe;AACtE;AAaO,eAAe,OACpB,KAA6C,EAC7C,IAAgC,EAChC,OAAqC;IAErC,iCAAiC;IACjC,QAAQ,MAAM;IAEd,4DAA4D;IAC5D,IAAI,WAAW,QAAQ;QACrB,OAAO;;IAGT,IAAI,eAAe,QAAQ;QACzB,MAAM,OAAO,MAAM,MAAM,IAAI;QAC7B,QAAI,CAAJ,OAAS,IAAI,IAAI,MAAM,GAAG,EAAE,QAAQ,CAAC,KAAK,CAAC,SAAS,GAAG,MAAM,cAAc;QAE3E,8EAA8E;QAC9E,gFAAgF;QAChF,oEAAoE;QACpE,MAAM,OAAO,WAAW,QAAQ;YAAE,MAAM,KAAK,WAAW;SAAW,GAAG;YAAC;SAAK;QAE5E,OAAO,IAAI,+IAAA,CAAA,OAAI,CAAC,MAAM,MAAM;;IAG9B,MAAM,OAAO,MAAM,SAAS;IAE5B,QAAI,CAAJ,OAAS,QAAQ,UAAU,cAAc;IAEzC,IAAI,CAAC,SAAS,MAAM;QAClB,MAAM,OAAQ,IAAI,CAAC,EAAU,EAAE;QAC/B,IAAI,OAAO,SAAS,UAAU;YAC5B,UAAU;gBAAE,GAAG,OAAO;gBAAE;YAAI;;;IAIhC,OAAO,IAAI,+IAAA,CAAA,OAAI,CAAC,MAAM,MAAM;AAC9B;AAEA,eAAe,SAAS,KAAkB;IACxC,IAAI,QAAyB,EAAE;IAC/B,IACE,OAAO,UAAU,YACjB,YAAY,MAAM,CAAC,UAAU,oCAAoC;IACjE,iBAAiB,aACjB;QACA,MAAM,IAAI,CAAC;WACN,IAAI,WAAW,QAAQ;QAC5B,MAAM,IAAI,CAAC,MAAM,MAAM,WAAW;WAC7B,IACL,wBAAwB,OAAO,0CAA0C;MACzE;QACA,WAAW,MAAM,SAAS,MAAO;YAC/B,MAAM,IAAI,CAAC,QAAoB,6BAA6B;;WAEzD;QACL,MAAM,IAAI,MACR,CAAA,sBAAA,EAAyB,OAAO,MAAK,eAAA,EAAkB,OAAO,aAC1D,KAAI,SAAA,EAAY,cAAc,OAAM,CAAE;;IAI9C,OAAO;AACT;AAEA,SAAS,cAAc,KAAU;IAC/B,MAAM,QAAQ,OAAO,mBAAmB,CAAC;IACzC,OAAO,CAAA,CAAA,EAAI,MAAM,GAAG,CAAC,CAAC,IAAM,CAAA,CAAA,EAAI,EAAC,CAAA,CAAG,EAAE,IAAI,CAAC,MAAK,CAAA,CAAG;AACrD;AAEA,SAAS,QAAQ,KAAU;IACzB,OACE,yBAAyB,MAAM,IAAI,KACnC,yBAAyB,MAAM,QAAQ,KACvC,oBAAoB;IACpB,yBAAyB,MAAM,IAAI,GAAG,MAAM,SAAS;AAEzD;AAEA,MAAM,2BAA2B,CAAC;IAChC,IAAI,OAAO,MAAM,UAAU,OAAO;IAClC,IAAI,OAAO,WAAW,eAAe,aAAa,QAAQ,OAAO,OAAO;IACxE,OAAO;AACT;AAEA,MAAM,0BAA0B,CAAC,QAC/B,SAAS,QAAQ,OAAO,UAAU,YAAY,OAAO,KAAK,CAAC,OAAO,aAAa,CAAC,KAAK;AAEhF,MAAM,kBAAkB,CAAC,OAC9B,QAAQ,OAAO,SAAS,YAAY,KAAK,IAAI,IAAI,IAAI,CAAC,OAAO,WAAW,CAAC,KAAK;AAMzE,MAAM,mCAAmC,OAC9C;IAEA,IAAI,CAAC,mBAAmB,KAAK,IAAI,GAAG,OAAO;IAE3C,MAAM,OAAO,MAAM,WAAW,KAAK,IAAI;IACvC,OAAO,CAAA,GAAA,+IAAA,CAAA,6BAA0B,AAA1B,EAA2B,MAAM;AAC1C;AAEO,MAAM,8BAA8B,OACzC;IAEA,MAAM,OAAO,MAAM,WAAW,KAAK,IAAI;IACvC,OAAO,CAAA,GAAA,+IAAA,CAAA,6BAA0B,AAA1B,EAA2B,MAAM;AAC1C;AAEO,MAAM,aAAa,OAAoC;IAC5D,MAAM,OAAO,IAAI,+IAAA,CAAA,WAAQ;IACzB,MAAM,QAAQ,GAAG,CAAC,OAAO,OAAO,CAAC,QAAQ,CAAA,GAAI,GAAG,CAAC,CAAC,CAAC,KAAK,MAAM,GAAK,aAAa,MAAM,KAAK;IAC3F,OAAO;AACT;AAEA,MAAM,qBAAqB,CAAC;IAC1B,IAAI,aAAa,QAAQ,OAAO;IAChC,IAAI,MAAM,OAAO,CAAC,QAAQ,OAAO,MAAM,IAAI,CAAC;IAC5C,IAAI,SAAS,OAAO,UAAU,UAAU;QACtC,IAAK,MAAM,KAAK,MAAO;YACrB,IAAI,mBAAoB,KAAa,CAAC,EAAE,GAAG,OAAO;;;IAGtD,OAAO;AACT;AAEA,MAAM,eAAe,OAAO,MAAgB,KAAa;IACvD,IAAI,UAAU,WAAW;IACzB,IAAI,SAAS,MAAM;QACjB,MAAM,IAAI,UACR,CAAA,mBAAA,EAAsB,IAAG,2DAAA,CAA6D;;IAI1F,yCAAyC;IACzC,IAAI,OAAO,UAAU,YAAY,OAAO,UAAU,YAAY,OAAO,UAAU,WAAW;QACxF,KAAK,MAAM,CAAC,KAAK,OAAO;WACnB,IAAI,aAAa,QAAQ;QAC9B,MAAM,OAAO,MAAM,OAAO;QAC1B,KAAK,MAAM,CAAC,KAAK;WACZ,IAAI,MAAM,OAAO,CAAC,QAAQ;QAC/B,MAAM,QAAQ,GAAG,CAAC,MAAM,GAAG,CAAC,CAAC,QAAU,aAAa,MAAM,MAAM,MAAM;WACjE,IAAI,OAAO,UAAU,UAAU;QACpC,MAAM,QAAQ,GAAG,CACf,OAAO,OAAO,CAAC,OAAO,GAAG,CAAC,CAAC,CAAC,MAAM,KAAK,GAAK,aAAa,MAAM,CAAA,EAAG,IAAG,CAAA,EAAI,KAAI,CAAA,CAAG,EAAE;WAE/E;QACL,MAAM,IAAI,UACR,CAAA,qGAAA,EAAwG,MAAK,QAAA,CAAU;;AAG7H"}},
    {"offset": {"line": 789, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 794, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/version.ts"],"sourcesContent":["export const VERSION = '4.67.3'; // x-release-please-version\n"],"names":[],"mappings":";;;AAAO,MAAM,UAAU,UAAU,2BAA2B"}},
    {"offset": {"line": 799, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 804, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/core.ts"],"sourcesContent":["import { VERSION } from './version';\nimport { Stream } from './streaming';\nimport {\n  OpenAIError,\n  APIError,\n  APIConnectionError,\n  APIConnectionTimeoutError,\n  APIUserAbortError,\n} from './error';\nimport {\n  kind as shimsKind,\n  type Readable,\n  getDefaultAgent,\n  type Agent,\n  fetch,\n  type RequestInfo,\n  type RequestInit,\n  type Response,\n  type HeadersInit,\n} from './_shims/index';\nexport { type Response };\nimport { BlobLike, isBlobLike, isMultipartBody } from './uploads';\nexport {\n  maybeMultipartFormRequestOptions,\n  multipartFormRequestOptions,\n  createForm,\n  type Uploadable,\n} from './uploads';\n\nexport type Fetch = (url: RequestInfo, init?: RequestInit) => Promise<Response>;\n\ntype PromiseOrValue<T> = T | Promise<T>;\n\ntype APIResponseProps = {\n  response: Response;\n  options: FinalRequestOptions;\n  controller: AbortController;\n};\n\nasync function defaultParseResponse<T>(props: APIResponseProps): Promise<WithRequestID<T>> {\n  const { response } = props;\n  if (props.options.stream) {\n    debug('response', response.status, response.url, response.headers, response.body);\n\n    // Note: there is an invariant here that isn't represented in the type system\n    // that if you set `stream: true` the response type must also be `Stream<T>`\n\n    if (props.options.__streamClass) {\n      return props.options.__streamClass.fromSSEResponse(response, props.controller) as any;\n    }\n\n    return Stream.fromSSEResponse(response, props.controller) as any;\n  }\n\n  // fetch refuses to read the body when the status code is 204.\n  if (response.status === 204) {\n    return null as WithRequestID<T>;\n  }\n\n  if (props.options.__binaryResponse) {\n    return response as unknown as WithRequestID<T>;\n  }\n\n  const contentType = response.headers.get('content-type');\n  const isJSON =\n    contentType?.includes('application/json') || contentType?.includes('application/vnd.api+json');\n  if (isJSON) {\n    const json = await response.json();\n\n    debug('response', response.status, response.url, response.headers, json);\n\n    return _addRequestID(json, response);\n  }\n\n  const text = await response.text();\n  debug('response', response.status, response.url, response.headers, text);\n\n  // TODO handle blob, arraybuffer, other content types, etc.\n  return text as unknown as WithRequestID<T>;\n}\n\ntype WithRequestID<T> =\n  T extends Array<any> | Response | AbstractPage<any> ? T\n  : T extends Record<string, any> ? T & { _request_id?: string | null }\n  : T;\n\nfunction _addRequestID<T>(value: T, response: Response): WithRequestID<T> {\n  if (!value || typeof value !== 'object' || Array.isArray(value)) {\n    return value as WithRequestID<T>;\n  }\n\n  return Object.defineProperty(value, '_request_id', {\n    value: response.headers.get('x-request-id'),\n    enumerable: false,\n  }) as WithRequestID<T>;\n}\n\n/**\n * A subclass of `Promise` providing additional helper methods\n * for interacting with the SDK.\n */\nexport class APIPromise<T> extends Promise<WithRequestID<T>> {\n  private parsedPromise: Promise<WithRequestID<T>> | undefined;\n\n  constructor(\n    private responsePromise: Promise<APIResponseProps>,\n    private parseResponse: (\n      props: APIResponseProps,\n    ) => PromiseOrValue<WithRequestID<T>> = defaultParseResponse,\n  ) {\n    super((resolve) => {\n      // this is maybe a bit weird but this has to be a no-op to not implicitly\n      // parse the response body; instead .then, .catch, .finally are overridden\n      // to parse the response\n      resolve(null as any);\n    });\n  }\n\n  _thenUnwrap<U>(transform: (data: T, props: APIResponseProps) => U): APIPromise<U> {\n    return new APIPromise(this.responsePromise, async (props) =>\n      _addRequestID(transform(await this.parseResponse(props), props), props.response),\n    );\n  }\n\n  /**\n   * Gets the raw `Response` instance instead of parsing the response\n   * data.\n   *\n   * If you want to parse the response body but still get the `Response`\n   * instance, you can use {@link withResponse()}.\n   *\n   * 👋 Getting the wrong TypeScript type for `Response`?\n   * Try setting `\"moduleResolution\": \"NodeNext\"` if you can,\n   * or add one of these imports before your first `import … from 'openai'`:\n   * - `import 'openai/shims/node'` (if you're running on Node)\n   * - `import 'openai/shims/web'` (otherwise)\n   */\n  asResponse(): Promise<Response> {\n    return this.responsePromise.then((p) => p.response);\n  }\n\n  /**\n   * Gets the parsed response data, the raw `Response` instance and the ID of the request,\n   * returned via the X-Request-ID header which is useful for debugging requests and reporting\n   * issues to OpenAI.\n   *\n   * If you just want to get the raw `Response` instance without parsing it,\n   * you can use {@link asResponse()}.\n   *\n   *\n   * 👋 Getting the wrong TypeScript type for `Response`?\n   * Try setting `\"moduleResolution\": \"NodeNext\"` if you can,\n   * or add one of these imports before your first `import … from 'openai'`:\n   * - `import 'openai/shims/node'` (if you're running on Node)\n   * - `import 'openai/shims/web'` (otherwise)\n   */\n  async withResponse(): Promise<{ data: T; response: Response; request_id: string | null | undefined }> {\n    const [data, response] = await Promise.all([this.parse(), this.asResponse()]);\n    return { data, response, request_id: response.headers.get('x-request-id') };\n  }\n\n  private parse(): Promise<WithRequestID<T>> {\n    if (!this.parsedPromise) {\n      this.parsedPromise = this.responsePromise.then(this.parseResponse) as any as Promise<WithRequestID<T>>;\n    }\n    return this.parsedPromise;\n  }\n\n  override then<TResult1 = WithRequestID<T>, TResult2 = never>(\n    onfulfilled?: ((value: WithRequestID<T>) => TResult1 | PromiseLike<TResult1>) | undefined | null,\n    onrejected?: ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null,\n  ): Promise<TResult1 | TResult2> {\n    return this.parse().then(onfulfilled, onrejected);\n  }\n\n  override catch<TResult = never>(\n    onrejected?: ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null,\n  ): Promise<WithRequestID<T> | TResult> {\n    return this.parse().catch(onrejected);\n  }\n\n  override finally(onfinally?: (() => void) | undefined | null): Promise<WithRequestID<T>> {\n    return this.parse().finally(onfinally);\n  }\n}\n\nexport abstract class APIClient {\n  baseURL: string;\n  maxRetries: number;\n  timeout: number;\n  httpAgent: Agent | undefined;\n\n  private fetch: Fetch;\n  protected idempotencyHeader?: string;\n\n  constructor({\n    baseURL,\n    maxRetries = 2,\n    timeout = 600000, // 10 minutes\n    httpAgent,\n    fetch: overridenFetch,\n  }: {\n    baseURL: string;\n    maxRetries?: number | undefined;\n    timeout: number | undefined;\n    httpAgent: Agent | undefined;\n    fetch: Fetch | undefined;\n  }) {\n    this.baseURL = baseURL;\n    this.maxRetries = validatePositiveInteger('maxRetries', maxRetries);\n    this.timeout = validatePositiveInteger('timeout', timeout);\n    this.httpAgent = httpAgent;\n\n    this.fetch = overridenFetch ?? fetch;\n  }\n\n  protected authHeaders(opts: FinalRequestOptions): Headers {\n    return {};\n  }\n\n  /**\n   * Override this to add your own default headers, for example:\n   *\n   *  {\n   *    ...super.defaultHeaders(),\n   *    Authorization: 'Bearer 123',\n   *  }\n   */\n  protected defaultHeaders(opts: FinalRequestOptions): Headers {\n    return {\n      Accept: 'application/json',\n      'Content-Type': 'application/json',\n      'User-Agent': this.getUserAgent(),\n      ...getPlatformHeaders(),\n      ...this.authHeaders(opts),\n    };\n  }\n\n  protected abstract defaultQuery(): DefaultQuery | undefined;\n\n  /**\n   * Override this to add your own headers validation:\n   */\n  protected validateHeaders(headers: Headers, customHeaders: Headers) {}\n\n  protected defaultIdempotencyKey(): string {\n    return `stainless-node-retry-${uuid4()}`;\n  }\n\n  get<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\n    return this.methodRequest('get', path, opts);\n  }\n\n  post<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\n    return this.methodRequest('post', path, opts);\n  }\n\n  patch<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\n    return this.methodRequest('patch', path, opts);\n  }\n\n  put<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\n    return this.methodRequest('put', path, opts);\n  }\n\n  delete<Req, Rsp>(path: string, opts?: PromiseOrValue<RequestOptions<Req>>): APIPromise<Rsp> {\n    return this.methodRequest('delete', path, opts);\n  }\n\n  private methodRequest<Req, Rsp>(\n    method: HTTPMethod,\n    path: string,\n    opts?: PromiseOrValue<RequestOptions<Req>>,\n  ): APIPromise<Rsp> {\n    return this.request(\n      Promise.resolve(opts).then(async (opts) => {\n        const body =\n          opts && isBlobLike(opts?.body) ? new DataView(await opts.body.arrayBuffer())\n          : opts?.body instanceof DataView ? opts.body\n          : opts?.body instanceof ArrayBuffer ? new DataView(opts.body)\n          : opts && ArrayBuffer.isView(opts?.body) ? new DataView(opts.body.buffer)\n          : opts?.body;\n        return { method, path, ...opts, body };\n      }),\n    );\n  }\n\n  getAPIList<Item, PageClass extends AbstractPage<Item> = AbstractPage<Item>>(\n    path: string,\n    Page: new (...args: any[]) => PageClass,\n    opts?: RequestOptions<any>,\n  ): PagePromise<PageClass, Item> {\n    return this.requestAPIList(Page, { method: 'get', path, ...opts });\n  }\n\n  private calculateContentLength(body: unknown): string | null {\n    if (typeof body === 'string') {\n      if (typeof Buffer !== 'undefined') {\n        return Buffer.byteLength(body, 'utf8').toString();\n      }\n\n      if (typeof TextEncoder !== 'undefined') {\n        const encoder = new TextEncoder();\n        const encoded = encoder.encode(body);\n        return encoded.length.toString();\n      }\n    } else if (ArrayBuffer.isView(body)) {\n      return body.byteLength.toString();\n    }\n\n    return null;\n  }\n\n  buildRequest<Req>(\n    options: FinalRequestOptions<Req>,\n    { retryCount = 0 }: { retryCount?: number } = {},\n  ): { req: RequestInit; url: string; timeout: number } {\n    const { method, path, query, headers: headers = {} } = options;\n\n    const body =\n      ArrayBuffer.isView(options.body) || (options.__binaryRequest && typeof options.body === 'string') ?\n        options.body\n      : isMultipartBody(options.body) ? options.body.body\n      : options.body ? JSON.stringify(options.body, null, 2)\n      : null;\n    const contentLength = this.calculateContentLength(body);\n\n    const url = this.buildURL(path!, query);\n    if ('timeout' in options) validatePositiveInteger('timeout', options.timeout);\n    const timeout = options.timeout ?? this.timeout;\n    const httpAgent = options.httpAgent ?? this.httpAgent ?? getDefaultAgent(url);\n    const minAgentTimeout = timeout + 1000;\n    if (\n      typeof (httpAgent as any)?.options?.timeout === 'number' &&\n      minAgentTimeout > ((httpAgent as any).options.timeout ?? 0)\n    ) {\n      // Allow any given request to bump our agent active socket timeout.\n      // This may seem strange, but leaking active sockets should be rare and not particularly problematic,\n      // and without mutating agent we would need to create more of them.\n      // This tradeoff optimizes for performance.\n      (httpAgent as any).options.timeout = minAgentTimeout;\n    }\n\n    if (this.idempotencyHeader && method !== 'get') {\n      if (!options.idempotencyKey) options.idempotencyKey = this.defaultIdempotencyKey();\n      headers[this.idempotencyHeader] = options.idempotencyKey;\n    }\n\n    const reqHeaders = this.buildHeaders({ options, headers, contentLength, retryCount });\n\n    const req: RequestInit = {\n      method,\n      ...(body && { body: body as any }),\n      headers: reqHeaders,\n      ...(httpAgent && { agent: httpAgent }),\n      // @ts-ignore node-fetch uses a custom AbortSignal type that is\n      // not compatible with standard web types\n      signal: options.signal ?? null,\n    };\n\n    return { req, url, timeout };\n  }\n\n  private buildHeaders({\n    options,\n    headers,\n    contentLength,\n    retryCount,\n  }: {\n    options: FinalRequestOptions;\n    headers: Record<string, string | null | undefined>;\n    contentLength: string | null | undefined;\n    retryCount: number;\n  }): Record<string, string> {\n    const reqHeaders: Record<string, string> = {};\n    if (contentLength) {\n      reqHeaders['content-length'] = contentLength;\n    }\n\n    const defaultHeaders = this.defaultHeaders(options);\n    applyHeadersMut(reqHeaders, defaultHeaders);\n    applyHeadersMut(reqHeaders, headers);\n\n    // let builtin fetch set the Content-Type for multipart bodies\n    if (isMultipartBody(options.body) && shimsKind !== 'node') {\n      delete reqHeaders['content-type'];\n    }\n\n    // Don't set the retry count header if it was already set or removed by the caller. We check `headers`,\n    // which can contain nulls, instead of `reqHeaders` to account for the removal case.\n    if (getHeader(headers, 'x-stainless-retry-count') === undefined) {\n      reqHeaders['x-stainless-retry-count'] = String(retryCount);\n    }\n\n    this.validateHeaders(reqHeaders, headers);\n\n    return reqHeaders;\n  }\n\n  /**\n   * Used as a callback for mutating the given `FinalRequestOptions` object.\n   */\n  protected async prepareOptions(options: FinalRequestOptions): Promise<void> {}\n\n  /**\n   * Used as a callback for mutating the given `RequestInit` object.\n   *\n   * This is useful for cases where you want to add certain headers based off of\n   * the request properties, e.g. `method` or `url`.\n   */\n  protected async prepareRequest(\n    request: RequestInit,\n    { url, options }: { url: string; options: FinalRequestOptions },\n  ): Promise<void> {}\n\n  protected parseHeaders(headers: HeadersInit | null | undefined): Record<string, string> {\n    return (\n      !headers ? {}\n      : Symbol.iterator in headers ?\n        Object.fromEntries(Array.from(headers as Iterable<string[]>).map((header) => [...header]))\n      : { ...headers }\n    );\n  }\n\n  protected makeStatusError(\n    status: number | undefined,\n    error: Object | undefined,\n    message: string | undefined,\n    headers: Headers | undefined,\n  ) {\n    return APIError.generate(status, error, message, headers);\n  }\n\n  request<Req, Rsp>(\n    options: PromiseOrValue<FinalRequestOptions<Req>>,\n    remainingRetries: number | null = null,\n  ): APIPromise<Rsp> {\n    return new APIPromise(this.makeRequest(options, remainingRetries));\n  }\n\n  private async makeRequest<Req>(\n    optionsInput: PromiseOrValue<FinalRequestOptions<Req>>,\n    retriesRemaining: number | null,\n  ): Promise<APIResponseProps> {\n    const options = await optionsInput;\n    const maxRetries = options.maxRetries ?? this.maxRetries;\n    if (retriesRemaining == null) {\n      retriesRemaining = maxRetries;\n    }\n\n    await this.prepareOptions(options);\n\n    const { req, url, timeout } = this.buildRequest(options, { retryCount: maxRetries - retriesRemaining });\n\n    await this.prepareRequest(req, { url, options });\n\n    debug('request', url, options, req.headers);\n\n    if (options.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    const controller = new AbortController();\n    const response = await this.fetchWithTimeout(url, req, timeout, controller).catch(castToError);\n\n    if (response instanceof Error) {\n      if (options.signal?.aborted) {\n        throw new APIUserAbortError();\n      }\n      if (retriesRemaining) {\n        return this.retryRequest(options, retriesRemaining);\n      }\n      if (response.name === 'AbortError') {\n        throw new APIConnectionTimeoutError();\n      }\n      throw new APIConnectionError({ cause: response });\n    }\n\n    const responseHeaders = createResponseHeaders(response.headers);\n\n    if (!response.ok) {\n      if (retriesRemaining && this.shouldRetry(response)) {\n        const retryMessage = `retrying, ${retriesRemaining} attempts remaining`;\n        debug(`response (error; ${retryMessage})`, response.status, url, responseHeaders);\n        return this.retryRequest(options, retriesRemaining, responseHeaders);\n      }\n\n      const errText = await response.text().catch((e) => castToError(e).message);\n      const errJSON = safeJSON(errText);\n      const errMessage = errJSON ? undefined : errText;\n      const retryMessage = retriesRemaining ? `(error; no more retries left)` : `(error; not retryable)`;\n\n      debug(`response (error; ${retryMessage})`, response.status, url, responseHeaders, errMessage);\n\n      const err = this.makeStatusError(response.status, errJSON, errMessage, responseHeaders);\n      throw err;\n    }\n\n    return { response, options, controller };\n  }\n\n  requestAPIList<Item = unknown, PageClass extends AbstractPage<Item> = AbstractPage<Item>>(\n    Page: new (...args: ConstructorParameters<typeof AbstractPage>) => PageClass,\n    options: FinalRequestOptions,\n  ): PagePromise<PageClass, Item> {\n    const request = this.makeRequest(options, null);\n    return new PagePromise<PageClass, Item>(this, request, Page);\n  }\n\n  buildURL<Req>(path: string, query: Req | null | undefined): string {\n    const url =\n      isAbsoluteURL(path) ?\n        new URL(path)\n      : new URL(this.baseURL + (this.baseURL.endsWith('/') && path.startsWith('/') ? path.slice(1) : path));\n\n    const defaultQuery = this.defaultQuery();\n    if (!isEmptyObj(defaultQuery)) {\n      query = { ...defaultQuery, ...query } as Req;\n    }\n\n    if (typeof query === 'object' && query && !Array.isArray(query)) {\n      url.search = this.stringifyQuery(query as Record<string, unknown>);\n    }\n\n    return url.toString();\n  }\n\n  protected stringifyQuery(query: Record<string, unknown>): string {\n    return Object.entries(query)\n      .filter(([_, value]) => typeof value !== 'undefined')\n      .map(([key, value]) => {\n        if (typeof value === 'string' || typeof value === 'number' || typeof value === 'boolean') {\n          return `${encodeURIComponent(key)}=${encodeURIComponent(value)}`;\n        }\n        if (value === null) {\n          return `${encodeURIComponent(key)}=`;\n        }\n        throw new OpenAIError(\n          `Cannot stringify type ${typeof value}; Expected string, number, boolean, or null. If you need to pass nested query parameters, you can manually encode them, e.g. { query: { 'foo[key1]': value1, 'foo[key2]': value2 } }, and please open a GitHub issue requesting better support for your use case.`,\n        );\n      })\n      .join('&');\n  }\n\n  async fetchWithTimeout(\n    url: RequestInfo,\n    init: RequestInit | undefined,\n    ms: number,\n    controller: AbortController,\n  ): Promise<Response> {\n    const { signal, ...options } = init || {};\n    if (signal) signal.addEventListener('abort', () => controller.abort());\n\n    const timeout = setTimeout(() => controller.abort(), ms);\n\n    return (\n      this.getRequestClient()\n        // use undefined this binding; fetch errors if bound to something else in browser/cloudflare\n        .fetch.call(undefined, url, { signal: controller.signal as any, ...options })\n        .finally(() => {\n          clearTimeout(timeout);\n        })\n    );\n  }\n\n  protected getRequestClient(): RequestClient {\n    return { fetch: this.fetch };\n  }\n\n  private shouldRetry(response: Response): boolean {\n    // Note this is not a standard header.\n    const shouldRetryHeader = response.headers.get('x-should-retry');\n\n    // If the server explicitly says whether or not to retry, obey.\n    if (shouldRetryHeader === 'true') return true;\n    if (shouldRetryHeader === 'false') return false;\n\n    // Retry on request timeouts.\n    if (response.status === 408) return true;\n\n    // Retry on lock timeouts.\n    if (response.status === 409) return true;\n\n    // Retry on rate limits.\n    if (response.status === 429) return true;\n\n    // Retry internal errors.\n    if (response.status >= 500) return true;\n\n    return false;\n  }\n\n  private async retryRequest(\n    options: FinalRequestOptions,\n    retriesRemaining: number,\n    responseHeaders?: Headers | undefined,\n  ): Promise<APIResponseProps> {\n    let timeoutMillis: number | undefined;\n\n    // Note the `retry-after-ms` header may not be standard, but is a good idea and we'd like proactive support for it.\n    const retryAfterMillisHeader = responseHeaders?.['retry-after-ms'];\n    if (retryAfterMillisHeader) {\n      const timeoutMs = parseFloat(retryAfterMillisHeader);\n      if (!Number.isNaN(timeoutMs)) {\n        timeoutMillis = timeoutMs;\n      }\n    }\n\n    // About the Retry-After header: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Retry-After\n    const retryAfterHeader = responseHeaders?.['retry-after'];\n    if (retryAfterHeader && !timeoutMillis) {\n      const timeoutSeconds = parseFloat(retryAfterHeader);\n      if (!Number.isNaN(timeoutSeconds)) {\n        timeoutMillis = timeoutSeconds * 1000;\n      } else {\n        timeoutMillis = Date.parse(retryAfterHeader) - Date.now();\n      }\n    }\n\n    // If the API asks us to wait a certain amount of time (and it's a reasonable amount),\n    // just do what it says, but otherwise calculate a default\n    if (!(timeoutMillis && 0 <= timeoutMillis && timeoutMillis < 60 * 1000)) {\n      const maxRetries = options.maxRetries ?? this.maxRetries;\n      timeoutMillis = this.calculateDefaultRetryTimeoutMillis(retriesRemaining, maxRetries);\n    }\n    await sleep(timeoutMillis);\n\n    return this.makeRequest(options, retriesRemaining - 1);\n  }\n\n  private calculateDefaultRetryTimeoutMillis(retriesRemaining: number, maxRetries: number): number {\n    const initialRetryDelay = 0.5;\n    const maxRetryDelay = 8.0;\n\n    const numRetries = maxRetries - retriesRemaining;\n\n    // Apply exponential backoff, but not more than the max.\n    const sleepSeconds = Math.min(initialRetryDelay * Math.pow(2, numRetries), maxRetryDelay);\n\n    // Apply some jitter, take up to at most 25 percent of the retry time.\n    const jitter = 1 - Math.random() * 0.25;\n\n    return sleepSeconds * jitter * 1000;\n  }\n\n  private getUserAgent(): string {\n    return `${this.constructor.name}/JS ${VERSION}`;\n  }\n}\n\nexport type PageInfo = { url: URL } | { params: Record<string, unknown> | null };\n\nexport abstract class AbstractPage<Item> implements AsyncIterable<Item> {\n  #client: APIClient;\n  protected options: FinalRequestOptions;\n\n  protected response: Response;\n  protected body: unknown;\n\n  constructor(client: APIClient, response: Response, body: unknown, options: FinalRequestOptions) {\n    this.#client = client;\n    this.options = options;\n    this.response = response;\n    this.body = body;\n  }\n\n  /**\n   * @deprecated Use nextPageInfo instead\n   */\n  abstract nextPageParams(): Partial<Record<string, unknown>> | null;\n  abstract nextPageInfo(): PageInfo | null;\n\n  abstract getPaginatedItems(): Item[];\n\n  hasNextPage(): boolean {\n    const items = this.getPaginatedItems();\n    if (!items.length) return false;\n    return this.nextPageInfo() != null;\n  }\n\n  async getNextPage(): Promise<this> {\n    const nextInfo = this.nextPageInfo();\n    if (!nextInfo) {\n      throw new OpenAIError(\n        'No next page expected; please check `.hasNextPage()` before calling `.getNextPage()`.',\n      );\n    }\n    const nextOptions = { ...this.options };\n    if ('params' in nextInfo && typeof nextOptions.query === 'object') {\n      nextOptions.query = { ...nextOptions.query, ...nextInfo.params };\n    } else if ('url' in nextInfo) {\n      const params = [...Object.entries(nextOptions.query || {}), ...nextInfo.url.searchParams.entries()];\n      for (const [key, value] of params) {\n        nextInfo.url.searchParams.set(key, value as any);\n      }\n      nextOptions.query = undefined;\n      nextOptions.path = nextInfo.url.toString();\n    }\n    return await this.#client.requestAPIList(this.constructor as any, nextOptions);\n  }\n\n  async *iterPages() {\n    // eslint-disable-next-line @typescript-eslint/no-this-alias\n    let page: AbstractPage<Item> = this;\n    yield page;\n    while (page.hasNextPage()) {\n      page = await page.getNextPage();\n      yield page;\n    }\n  }\n\n  async *[Symbol.asyncIterator]() {\n    for await (const page of this.iterPages()) {\n      for (const item of page.getPaginatedItems()) {\n        yield item;\n      }\n    }\n  }\n}\n\n/**\n * This subclass of Promise will resolve to an instantiated Page once the request completes.\n *\n * It also implements AsyncIterable to allow auto-paginating iteration on an unawaited list call, eg:\n *\n *    for await (const item of client.items.list()) {\n *      console.log(item)\n *    }\n */\nexport class PagePromise<\n    PageClass extends AbstractPage<Item>,\n    Item = ReturnType<PageClass['getPaginatedItems']>[number],\n  >\n  extends APIPromise<PageClass>\n  implements AsyncIterable<Item>\n{\n  constructor(\n    client: APIClient,\n    request: Promise<APIResponseProps>,\n    Page: new (...args: ConstructorParameters<typeof AbstractPage>) => PageClass,\n  ) {\n    super(\n      request,\n      async (props) =>\n        new Page(\n          client,\n          props.response,\n          await defaultParseResponse(props),\n          props.options,\n        ) as WithRequestID<PageClass>,\n    );\n  }\n\n  /**\n   * Allow auto-paginating iteration on an unawaited list call, eg:\n   *\n   *    for await (const item of client.items.list()) {\n   *      console.log(item)\n   *    }\n   */\n  async *[Symbol.asyncIterator]() {\n    const page = await this;\n    for await (const item of page) {\n      yield item;\n    }\n  }\n}\n\nexport const createResponseHeaders = (\n  headers: Awaited<ReturnType<Fetch>>['headers'],\n): Record<string, string> => {\n  return new Proxy(\n    Object.fromEntries(\n      // @ts-ignore\n      headers.entries(),\n    ),\n    {\n      get(target, name) {\n        const key = name.toString();\n        return target[key.toLowerCase()] || target[key];\n      },\n    },\n  );\n};\n\ntype HTTPMethod = 'get' | 'post' | 'put' | 'patch' | 'delete';\n\nexport type RequestClient = { fetch: Fetch };\nexport type Headers = Record<string, string | null | undefined>;\nexport type DefaultQuery = Record<string, string | undefined>;\nexport type KeysEnum<T> = { [P in keyof Required<T>]: true };\n\nexport type RequestOptions<\n  Req = unknown | Record<string, unknown> | Readable | BlobLike | ArrayBufferView | ArrayBuffer,\n> = {\n  method?: HTTPMethod;\n  path?: string;\n  query?: Req | undefined;\n  body?: Req | null | undefined;\n  headers?: Headers | undefined;\n\n  maxRetries?: number;\n  stream?: boolean | undefined;\n  timeout?: number;\n  httpAgent?: Agent;\n  signal?: AbortSignal | undefined | null;\n  idempotencyKey?: string;\n\n  __binaryRequest?: boolean | undefined;\n  __binaryResponse?: boolean | undefined;\n  __streamClass?: typeof Stream;\n};\n\n// This is required so that we can determine if a given object matches the RequestOptions\n// type at runtime. While this requires duplication, it is enforced by the TypeScript\n// compiler such that any missing / extraneous keys will cause an error.\nconst requestOptionsKeys: KeysEnum<RequestOptions> = {\n  method: true,\n  path: true,\n  query: true,\n  body: true,\n  headers: true,\n\n  maxRetries: true,\n  stream: true,\n  timeout: true,\n  httpAgent: true,\n  signal: true,\n  idempotencyKey: true,\n\n  __binaryRequest: true,\n  __binaryResponse: true,\n  __streamClass: true,\n};\n\nexport const isRequestOptions = (obj: unknown): obj is RequestOptions => {\n  return (\n    typeof obj === 'object' &&\n    obj !== null &&\n    !isEmptyObj(obj) &&\n    Object.keys(obj).every((k) => hasOwn(requestOptionsKeys, k))\n  );\n};\n\nexport type FinalRequestOptions<Req = unknown | Record<string, unknown> | Readable | DataView> =\n  RequestOptions<Req> & {\n    method: HTTPMethod;\n    path: string;\n  };\n\ndeclare const Deno: any;\ndeclare const EdgeRuntime: any;\ntype Arch = 'x32' | 'x64' | 'arm' | 'arm64' | `other:${string}` | 'unknown';\ntype PlatformName =\n  | 'MacOS'\n  | 'Linux'\n  | 'Windows'\n  | 'FreeBSD'\n  | 'OpenBSD'\n  | 'iOS'\n  | 'Android'\n  | `Other:${string}`\n  | 'Unknown';\ntype Browser = 'ie' | 'edge' | 'chrome' | 'firefox' | 'safari';\ntype PlatformProperties = {\n  'X-Stainless-Lang': 'js';\n  'X-Stainless-Package-Version': string;\n  'X-Stainless-OS': PlatformName;\n  'X-Stainless-Arch': Arch;\n  'X-Stainless-Runtime': 'node' | 'deno' | 'edge' | `browser:${Browser}` | 'unknown';\n  'X-Stainless-Runtime-Version': string;\n};\nconst getPlatformProperties = (): PlatformProperties => {\n  if (typeof Deno !== 'undefined' && Deno.build != null) {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': normalizePlatform(Deno.build.os),\n      'X-Stainless-Arch': normalizeArch(Deno.build.arch),\n      'X-Stainless-Runtime': 'deno',\n      'X-Stainless-Runtime-Version':\n        typeof Deno.version === 'string' ? Deno.version : Deno.version?.deno ?? 'unknown',\n    };\n  }\n  if (typeof EdgeRuntime !== 'undefined') {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': 'Unknown',\n      'X-Stainless-Arch': `other:${EdgeRuntime}`,\n      'X-Stainless-Runtime': 'edge',\n      'X-Stainless-Runtime-Version': process.version,\n    };\n  }\n  // Check if Node.js\n  if (Object.prototype.toString.call(typeof process !== 'undefined' ? process : 0) === '[object process]') {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': normalizePlatform(process.platform),\n      'X-Stainless-Arch': normalizeArch(process.arch),\n      'X-Stainless-Runtime': 'node',\n      'X-Stainless-Runtime-Version': process.version,\n    };\n  }\n\n  const browserInfo = getBrowserInfo();\n  if (browserInfo) {\n    return {\n      'X-Stainless-Lang': 'js',\n      'X-Stainless-Package-Version': VERSION,\n      'X-Stainless-OS': 'Unknown',\n      'X-Stainless-Arch': 'unknown',\n      'X-Stainless-Runtime': `browser:${browserInfo.browser}`,\n      'X-Stainless-Runtime-Version': browserInfo.version,\n    };\n  }\n\n  // TODO add support for Cloudflare workers, etc.\n  return {\n    'X-Stainless-Lang': 'js',\n    'X-Stainless-Package-Version': VERSION,\n    'X-Stainless-OS': 'Unknown',\n    'X-Stainless-Arch': 'unknown',\n    'X-Stainless-Runtime': 'unknown',\n    'X-Stainless-Runtime-Version': 'unknown',\n  };\n};\n\ntype BrowserInfo = {\n  browser: Browser;\n  version: string;\n};\n\ndeclare const navigator: { userAgent: string } | undefined;\n\n// Note: modified from https://github.com/JS-DevTools/host-environment/blob/b1ab79ecde37db5d6e163c050e54fe7d287d7c92/src/isomorphic.browser.ts\nfunction getBrowserInfo(): BrowserInfo | null {\n  if (typeof navigator === 'undefined' || !navigator) {\n    return null;\n  }\n\n  // NOTE: The order matters here!\n  const browserPatterns = [\n    { key: 'edge' as const, pattern: /Edge(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'ie' as const, pattern: /MSIE(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'ie' as const, pattern: /Trident(?:.*rv\\:(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'chrome' as const, pattern: /Chrome(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'firefox' as const, pattern: /Firefox(?:\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?/ },\n    { key: 'safari' as const, pattern: /(?:Version\\W+(\\d+)\\.(\\d+)(?:\\.(\\d+))?)?(?:\\W+Mobile\\S*)?\\W+Safari/ },\n  ];\n\n  // Find the FIRST matching browser\n  for (const { key, pattern } of browserPatterns) {\n    const match = pattern.exec(navigator.userAgent);\n    if (match) {\n      const major = match[1] || 0;\n      const minor = match[2] || 0;\n      const patch = match[3] || 0;\n\n      return { browser: key, version: `${major}.${minor}.${patch}` };\n    }\n  }\n\n  return null;\n}\n\nconst normalizeArch = (arch: string): Arch => {\n  // Node docs:\n  // - https://nodejs.org/api/process.html#processarch\n  // Deno docs:\n  // - https://doc.deno.land/deno/stable/~/Deno.build\n  if (arch === 'x32') return 'x32';\n  if (arch === 'x86_64' || arch === 'x64') return 'x64';\n  if (arch === 'arm') return 'arm';\n  if (arch === 'aarch64' || arch === 'arm64') return 'arm64';\n  if (arch) return `other:${arch}`;\n  return 'unknown';\n};\n\nconst normalizePlatform = (platform: string): PlatformName => {\n  // Node platforms:\n  // - https://nodejs.org/api/process.html#processplatform\n  // Deno platforms:\n  // - https://doc.deno.land/deno/stable/~/Deno.build\n  // - https://github.com/denoland/deno/issues/14799\n\n  platform = platform.toLowerCase();\n\n  // NOTE: this iOS check is untested and may not work\n  // Node does not work natively on IOS, there is a fork at\n  // https://github.com/nodejs-mobile/nodejs-mobile\n  // however it is unknown at the time of writing how to detect if it is running\n  if (platform.includes('ios')) return 'iOS';\n  if (platform === 'android') return 'Android';\n  if (platform === 'darwin') return 'MacOS';\n  if (platform === 'win32') return 'Windows';\n  if (platform === 'freebsd') return 'FreeBSD';\n  if (platform === 'openbsd') return 'OpenBSD';\n  if (platform === 'linux') return 'Linux';\n  if (platform) return `Other:${platform}`;\n  return 'Unknown';\n};\n\nlet _platformHeaders: PlatformProperties;\nconst getPlatformHeaders = () => {\n  return (_platformHeaders ??= getPlatformProperties());\n};\n\nexport const safeJSON = (text: string) => {\n  try {\n    return JSON.parse(text);\n  } catch (err) {\n    return undefined;\n  }\n};\n\n// https://stackoverflow.com/a/19709846\nconst startsWithSchemeRegexp = new RegExp('^(?:[a-z]+:)?//', 'i');\nconst isAbsoluteURL = (url: string): boolean => {\n  return startsWithSchemeRegexp.test(url);\n};\n\nexport const sleep = (ms: number) => new Promise((resolve) => setTimeout(resolve, ms));\n\nconst validatePositiveInteger = (name: string, n: unknown): number => {\n  if (typeof n !== 'number' || !Number.isInteger(n)) {\n    throw new OpenAIError(`${name} must be an integer`);\n  }\n  if (n < 0) {\n    throw new OpenAIError(`${name} must be a positive integer`);\n  }\n  return n;\n};\n\nexport const castToError = (err: any): Error => {\n  if (err instanceof Error) return err;\n  if (typeof err === 'object' && err !== null) {\n    try {\n      return new Error(JSON.stringify(err));\n    } catch {}\n  }\n  return new Error(err);\n};\n\nexport const ensurePresent = <T>(value: T | null | undefined): T => {\n  if (value == null) throw new OpenAIError(`Expected a value to be given but received ${value} instead.`);\n  return value;\n};\n\n/**\n * Read an environment variable.\n *\n * Trims beginning and trailing whitespace.\n *\n * Will return undefined if the environment variable doesn't exist or cannot be accessed.\n */\nexport const readEnv = (env: string): string | undefined => {\n  if (typeof process !== 'undefined') {\n    return process.env?.[env]?.trim() ?? undefined;\n  }\n  if (typeof Deno !== 'undefined') {\n    return Deno.env?.get?.(env)?.trim();\n  }\n  return undefined;\n};\n\nexport const coerceInteger = (value: unknown): number => {\n  if (typeof value === 'number') return Math.round(value);\n  if (typeof value === 'string') return parseInt(value, 10);\n\n  throw new OpenAIError(`Could not coerce ${value} (type: ${typeof value}) into a number`);\n};\n\nexport const coerceFloat = (value: unknown): number => {\n  if (typeof value === 'number') return value;\n  if (typeof value === 'string') return parseFloat(value);\n\n  throw new OpenAIError(`Could not coerce ${value} (type: ${typeof value}) into a number`);\n};\n\nexport const coerceBoolean = (value: unknown): boolean => {\n  if (typeof value === 'boolean') return value;\n  if (typeof value === 'string') return value === 'true';\n  return Boolean(value);\n};\n\nexport const maybeCoerceInteger = (value: unknown): number | undefined => {\n  if (value === undefined) {\n    return undefined;\n  }\n  return coerceInteger(value);\n};\n\nexport const maybeCoerceFloat = (value: unknown): number | undefined => {\n  if (value === undefined) {\n    return undefined;\n  }\n  return coerceFloat(value);\n};\n\nexport const maybeCoerceBoolean = (value: unknown): boolean | undefined => {\n  if (value === undefined) {\n    return undefined;\n  }\n  return coerceBoolean(value);\n};\n\n// https://stackoverflow.com/a/34491287\nexport function isEmptyObj(obj: Object | null | undefined): boolean {\n  if (!obj) return true;\n  for (const _k in obj) return false;\n  return true;\n}\n\n// https://eslint.org/docs/latest/rules/no-prototype-builtins\nexport function hasOwn(obj: Object, key: string): boolean {\n  return Object.prototype.hasOwnProperty.call(obj, key);\n}\n\n/**\n * Copies headers from \"newHeaders\" onto \"targetHeaders\",\n * using lower-case for all properties,\n * ignoring any keys with undefined values,\n * and deleting any keys with null values.\n */\nfunction applyHeadersMut(targetHeaders: Headers, newHeaders: Headers): void {\n  for (const k in newHeaders) {\n    if (!hasOwn(newHeaders, k)) continue;\n    const lowerKey = k.toLowerCase();\n    if (!lowerKey) continue;\n\n    const val = newHeaders[k];\n\n    if (val === null) {\n      delete targetHeaders[lowerKey];\n    } else if (val !== undefined) {\n      targetHeaders[lowerKey] = val;\n    }\n  }\n}\n\nexport function debug(action: string, ...args: any[]) {\n  if (typeof process !== 'undefined' && process?.env?.['DEBUG'] === 'true') {\n    console.log(`OpenAI:DEBUG:${action}`, ...args);\n  }\n}\n\n/**\n * https://stackoverflow.com/a/2117523\n */\nconst uuid4 = () => {\n  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, (c) => {\n    const r = (Math.random() * 16) | 0;\n    const v = c === 'x' ? r : (r & 0x3) | 0x8;\n    return v.toString(16);\n  });\n};\n\nexport const isRunningInBrowser = () => {\n  return (\n    // @ts-ignore\n    typeof window !== 'undefined' &&\n    // @ts-ignore\n    typeof window.document !== 'undefined' &&\n    // @ts-ignore\n    typeof navigator !== 'undefined'\n  );\n};\n\nexport interface HeadersProtocol {\n  get: (header: string) => string | null | undefined;\n}\nexport type HeadersLike = Record<string, string | string[] | undefined> | HeadersProtocol;\n\nexport const isHeadersProtocol = (headers: any): headers is HeadersProtocol => {\n  return typeof headers?.get === 'function';\n};\n\nexport const getRequiredHeader = (headers: HeadersLike | Headers, header: string): string => {\n  const foundHeader = getHeader(headers, header);\n  if (foundHeader === undefined) {\n    throw new Error(`Could not find ${header} header`);\n  }\n  return foundHeader;\n};\n\nexport const getHeader = (headers: HeadersLike | Headers, header: string): string | undefined => {\n  const lowerCasedHeader = header.toLowerCase();\n  if (isHeadersProtocol(headers)) {\n    // to deal with the case where the header looks like Stainless-Event-Id\n    const intercapsHeader =\n      header[0]?.toUpperCase() +\n      header.substring(1).replace(/([^\\w])(\\w)/g, (_m, g1, g2) => g1 + g2.toUpperCase());\n    for (const key of [header, lowerCasedHeader, header.toUpperCase(), intercapsHeader]) {\n      const value = headers.get(key);\n      if (value) {\n        return value;\n      }\n    }\n  }\n\n  for (const [key, value] of Object.entries(headers)) {\n    if (key.toLowerCase() === lowerCasedHeader) {\n      if (Array.isArray(value)) {\n        if (value.length <= 1) return value[0];\n        console.warn(`Received ${value.length} entries for the ${header} header, using the first entry.`);\n        return value[0];\n      }\n      return value;\n    }\n  }\n\n  return undefined;\n};\n\n/**\n * Encodes a string to Base64 format.\n */\nexport const toBase64 = (str: string | null | undefined): string => {\n  if (!str) return '';\n  if (typeof Buffer !== 'undefined') {\n    return Buffer.from(str).toString('base64');\n  }\n\n  if (typeof btoa !== 'undefined') {\n    return btoa(str);\n  }\n\n  throw new OpenAIError('Cannot generate b64 string; Expected `Buffer` or `btoa` to be defined');\n};\n\nexport function isObj(obj: unknown): obj is Record<string, unknown> {\n  return obj != null && typeof obj === 'object' && !Array.isArray(obj);\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAuCA,eAAe,qBAAwB,KAAuB;IAC5D,MAAM,EAAE,QAAQ,EAAE,GAAG;IACrB,IAAI,MAAM,OAAO,CAAC,MAAM,EAAE;QACxB,MAAM,YAAY,SAAS,MAAM,EAAE,SAAS,GAAG,EAAE,SAAS,OAAO,EAAE,SAAS,IAAI;QAEhF,6EAA6E;QAC7E,4EAA4E;QAE5E,IAAI,MAAM,OAAO,CAAC,aAAa,EAAE;YAC/B,OAAO,MAAM,OAAO,CAAC,aAAa,CAAC,eAAe,CAAC,UAAU,MAAM,UAAU;;QAG/E,OAAO,sIAAA,CAAA,SAAM,CAAC,eAAe,CAAC,UAAU,MAAM,UAAU;;IAG1D,8DAA8D;IAC9D,IAAI,SAAS,MAAM,KAAK,KAAK;QAC3B,OAAO;;IAGT,IAAI,MAAM,OAAO,CAAC,gBAAgB,EAAE;QAClC,OAAO;;IAGT,MAAM,cAAc,SAAS,OAAO,CAAC,GAAG,CAAC;IACzC,MAAM,SACJ,aAAa,SAAS,uBAAuB,aAAa,SAAS;IACrE,IAAI,QAAQ;QACV,MAAM,OAAO,MAAM,SAAS,IAAI;QAEhC,MAAM,YAAY,SAAS,MAAM,EAAE,SAAS,GAAG,EAAE,SAAS,OAAO,EAAE;QAEnE,OAAO,cAAc,MAAM;;IAG7B,MAAM,OAAO,MAAM,SAAS,IAAI;IAChC,MAAM,YAAY,SAAS,MAAM,EAAE,SAAS,GAAG,EAAE,SAAS,OAAO,EAAE;IAEnE,2DAA2D;IAC3D,OAAO;AACT;AAOA,SAAS,cAAiB,KAAQ,EAAE,QAAkB;IACpD,IAAI,CAAC,SAAS,OAAO,UAAU,YAAY,MAAM,OAAO,CAAC,QAAQ;QAC/D,OAAO;;IAGT,OAAO,OAAO,cAAc,CAAC,OAAO,eAAe;QACjD,OAAO,SAAS,OAAO,CAAC,GAAG,CAAC;QAC5B,YAAY;;AAEhB;AAMM,MAAO,mBAAsB;IAGjC,YACU,eAA0C,EAC1C,gBAEgC,oBAAoB,CAAA;QAE5D,KAAK,CAAC,CAAC;YACL,yEAAyE;YACzE,0EAA0E;YAC1E,wBAAwB;YACxB,QAAQ;QACV;QAVQ,IAAA,CAAA,eAAe,GAAf;QACA,IAAA,CAAA,aAAa,GAAb;IAUV;IAEA,YAAe,SAAkD,EAAA;QAC/D,OAAO,IAAI,WAAW,IAAI,CAAC,eAAe,EAAE,OAAO,QACjD,cAAc,UAAU,MAAM,IAAI,CAAC,aAAa,CAAC,QAAQ,QAAQ,MAAM,QAAQ;IAEnF;IAEA;;;;;;;;;;;;QAaA,aAAU;QACR,OAAO,IAAI,CAAC,eAAe,CAAC,IAAI,CAAC,CAAC,IAAM,EAAE,QAAQ;IACpD;IAEA;;;;;;;;;;;;;;QAeA,MAAM,eAAY;QAChB,MAAM,CAAC,MAAM,SAAS,GAAG,MAAM,QAAQ,GAAG,CAAC;YAAC,IAAI,CAAC,KAAK;YAAI,IAAI,CAAC,UAAU;SAAG;QAC5E,OAAO;YAAE;YAAM;YAAU,YAAY,SAAS,OAAO,CAAC,GAAG,CAAC;QAAe;IAC3E;IAEQ,QAAK;QACX,IAAI,CAAC,IAAI,CAAC,aAAa,EAAE;YACvB,IAAI,CAAC,aAAa,GAAG,IAAI,CAAC,eAAe,CAAC,IAAI,CAAC,IAAI,CAAC,aAAa;;QAEnE,OAAO,IAAI,CAAC,aAAa;IAC3B;IAES,KACP,WAAgG,EAChG,UAAmF,EAAA;QAEnF,OAAO,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,aAAa;IACxC;IAES,MACP,UAAiF,EAAA;QAEjF,OAAO,IAAI,CAAC,KAAK,GAAG,KAAK,CAAC;IAC5B;IAES,QAAQ,SAA2C,EAAA;QAC1D,OAAO,IAAI,CAAC,KAAK,GAAG,OAAO,CAAC;IAC9B;;AAGI,MAAgB;IASpB,YAAY,EACV,OAAO,EACP,aAAa,CAAC,EACd,UAAU,MAAM,EAChB,SAAS,EACT,OAAO,cAAc,EAOtB,CAAA;QACC,IAAI,CAAC,OAAO,GAAG;QACf,IAAI,CAAC,UAAU,GAAG,wBAAwB,cAAc;QACxD,IAAI,CAAC,OAAO,GAAG,wBAAwB,WAAW;QAClD,IAAI,CAAC,SAAS,GAAG;QAEjB,IAAI,CAAC,KAAK,GAAG,kBAAkB,+IAAA,CAAA,QAAK;IACtC;IAEU,YAAY,IAAyB,EAAA;QAC7C,OAAO,CAAA;IACT;IAEA;;;;;;;QAQU,eAAe,IAAyB,EAAA;QAChD,OAAO;YACL,QAAQ;YACR,gBAAgB;YAChB,cAAc,IAAI,CAAC,YAAY;YAC/B,GAAG,oBAAoB;YACvB,GAAG,IAAI,CAAC,WAAW,CAAC,KAAK;;IAE7B;IAIA;;QAGU,gBAAgB,OAAgB,EAAE,aAAsB,EAAA,CAAG;IAE3D,wBAAqB;QAC7B,OAAO,CAAA,qBAAA,EAAwB,QAAO,CAAE;IAC1C;IAEA,IAAc,IAAY,EAAE,IAA0C,EAAA;QACpE,OAAO,IAAI,CAAC,aAAa,CAAC,OAAO,MAAM;IACzC;IAEA,KAAe,IAAY,EAAE,IAA0C,EAAA;QACrE,OAAO,IAAI,CAAC,aAAa,CAAC,QAAQ,MAAM;IAC1C;IAEA,MAAgB,IAAY,EAAE,IAA0C,EAAA;QACtE,OAAO,IAAI,CAAC,aAAa,CAAC,SAAS,MAAM;IAC3C;IAEA,IAAc,IAAY,EAAE,IAA0C,EAAA;QACpE,OAAO,IAAI,CAAC,aAAa,CAAC,OAAO,MAAM;IACzC;IAEA,OAAiB,IAAY,EAAE,IAA0C,EAAA;QACvE,OAAO,IAAI,CAAC,aAAa,CAAC,UAAU,MAAM;IAC5C;IAEQ,cACN,MAAkB,EAClB,IAAY,EACZ,IAA0C,EAAA;QAE1C,OAAO,IAAI,CAAC,OAAO,CACjB,QAAQ,OAAO,CAAC,MAAM,IAAI,CAAC,OAAO;YAChC,MAAM,OACJ,QAAQ,CAAA,GAAA,oJAAA,CAAA,aAAU,AAAV,EAAW,MAAM,QAAQ,IAAI,SAAS,MAAM,KAAK,IAAI,CAAC,WAAW,MACvE,MAAM,gBAAgB,WAAW,KAAK,IAAI,GAC1C,MAAM,gBAAgB,cAAc,IAAI,SAAS,KAAK,IAAI,IAC1D,QAAQ,YAAY,MAAM,CAAC,MAAM,QAAQ,IAAI,SAAS,KAAK,IAAI,CAAC,MAAM,IACtE,MAAM;YACV,OAAO;gBAAE;gBAAQ;gBAAM,GAAG,IAAI;gBAAE;YAAI;QACtC;IAEJ;IAEA,WACE,IAAY,EACZ,IAAuC,EACvC,IAA0B,EAAA;QAE1B,OAAO,IAAI,CAAC,cAAc,CAAC,MAAM;YAAE,QAAQ;YAAO;YAAM,GAAG,IAAI;QAAA;IACjE;IAEQ,uBAAuB,IAAa,EAAA;QAC1C,IAAI,OAAO,SAAS,UAAU;YAC5B,IAAI,OAAO,WAAW,aAAa;gBACjC,OAAO,OAAO,UAAU,CAAC,MAAM,QAAQ,QAAQ;;YAGjD,IAAI,OAAO,gBAAgB,aAAa;gBACtC,MAAM,UAAU,IAAI;gBACpB,MAAM,UAAU,QAAQ,MAAM,CAAC;gBAC/B,OAAO,QAAQ,MAAM,CAAC,QAAQ;;eAE3B,IAAI,YAAY,MAAM,CAAC,OAAO;YACnC,OAAO,KAAK,UAAU,CAAC,QAAQ;;QAGjC,OAAO;IACT;IAEA,aACE,OAAiC,EACjC,EAAE,aAAa,CAAC,EAAA,GAA8B,CAAA,CAAE,EAAA;QAEhD,MAAM,EAAE,MAAM,EAAE,IAAI,EAAE,KAAK,EAAE,SAAS,UAAU,CAAA,CAAE,EAAE,GAAG;QAEvD,MAAM,OACJ,YAAY,MAAM,CAAC,QAAQ,IAAI,KAAM,QAAQ,eAAe,IAAI,OAAO,QAAQ,IAAI,KAAK,WACtF,QAAQ,IAAI,GACZ,CAAA,GAAA,oJAAA,CAAA,kBAAe,AAAf,EAAgB,QAAQ,IAAI,IAAI,QAAQ,IAAI,CAAC,IAAI,GACjD,QAAQ,IAAI,GAAG,KAAK,SAAS,CAAC,QAAQ,IAAI,EAAE,MAAM,KAClD;QACJ,MAAM,gBAAgB,IAAI,CAAC,sBAAsB,CAAC;QAElD,MAAM,MAAM,IAAI,CAAC,QAAQ,CAAC,MAAO;QACjC,IAAI,aAAa,SAAS,wBAAwB,WAAW,QAAQ,OAAO;QAC5E,MAAM,UAAU,QAAQ,OAAO,IAAI,IAAI,CAAC,OAAO;QAC/C,MAAM,YAAY,QAAQ,SAAS,IAAI,IAAI,CAAC,SAAS,IAAI,CAAA,GAAA,+IAAA,CAAA,kBAAe,AAAf,EAAgB;QACzE,MAAM,kBAAkB,UAAU;QAClC,IACE,OAAQ,WAAmB,SAAS,YAAY,YAChD,kBAAkB,CAAE,UAAkB,OAAO,CAAC,OAAO,IAAI,CAAC,GAC1D;YACA,mEAAmE;YACnE,qGAAqG;YACrG,mEAAmE;YACnE,2CAA2C;YAC1C,UAAkB,OAAO,CAAC,OAAO,GAAG;;QAGvC,IAAI,IAAI,CAAC,iBAAiB,IAAI,WAAW,OAAO;YAC9C,IAAI,CAAC,QAAQ,cAAc,EAAE,QAAQ,cAAc,GAAG,IAAI,CAAC,qBAAqB;YAChF,OAAO,CAAC,IAAI,CAAC,iBAAiB,CAAC,GAAG,QAAQ,cAAc;;QAG1D,MAAM,aAAa,IAAI,CAAC,YAAY,CAAC;YAAE;YAAS;YAAS;YAAe;QAAU;QAElF,MAAM,MAAmB;YACvB;YACA,GAAI,QAAQ;gBAAE,MAAM;YAAW,CAAE;YACjC,SAAS;YACT,GAAI,aAAa;gBAAE,OAAO;YAAS,CAAE;YACrC,+DAA+D;YAC/D,yCAAyC;YACzC,QAAQ,QAAQ,MAAM,IAAI;;QAG5B,OAAO;YAAE;YAAK;YAAK;QAAO;IAC5B;IAEQ,aAAa,EACnB,OAAO,EACP,OAAO,EACP,aAAa,EACb,UAAU,EAMX,EAAA;QACC,MAAM,aAAqC,CAAA;QAC3C,IAAI,eAAe;YACjB,UAAU,CAAC,iBAAiB,GAAG;;QAGjC,MAAM,iBAAiB,IAAI,CAAC,cAAc,CAAC;QAC3C,gBAAgB,YAAY;QAC5B,gBAAgB,YAAY;QAE5B,8DAA8D;QAC9D,IAAI,CAAA,GAAA,oJAAA,CAAA,kBAAe,AAAf,EAAgB,QAAQ,IAAI,KAAK,+IAAA,CAAA,OAAS,KAAK,QAAQ;YACzD,OAAO,UAAU,CAAC,eAAe;;QAGnC,uGAAuG;QACvG,oFAAoF;QACpF,IAAI,UAAU,SAAS,+BAA+B,WAAW;YAC/D,UAAU,CAAC,0BAA0B,GAAG,OAAO;;QAGjD,IAAI,CAAC,eAAe,CAAC,YAAY;QAEjC,OAAO;IACT;IAEA;;QAGU,MAAM,eAAe,OAA4B,EAAA,CAAkB;IAE7E;;;;;QAMU,MAAM,eACd,OAAoB,EACpB,EAAE,GAAG,EAAE,OAAO,EAAiD,EAAA,CAC/C;IAER,aAAa,OAAuC,EAAA;QAC5D,OACE,CAAC,UAAU,CAAA,IACT,OAAO,QAAQ,IAAI,UACnB,OAAO,WAAW,CAAC,MAAM,IAAI,CAAC,SAA+B,GAAG,CAAC,CAAC,SAAW;mBAAI;aAAO,KACxF;YAAE,GAAG,OAAO;QAAA;IAElB;IAEU,gBACR,MAA0B,EAC1B,KAAyB,EACzB,OAA2B,EAC3B,OAA4B,EAAA;QAE5B,OAAO,kIAAA,CAAA,WAAQ,CAAC,QAAQ,CAAC,QAAQ,OAAO,SAAS;IACnD;IAEA,QACE,OAAiD,EACjD,mBAAkC,IAAI,EAAA;QAEtC,OAAO,IAAI,WAAW,IAAI,CAAC,WAAW,CAAC,SAAS;IAClD;IAEQ,MAAM,YACZ,YAAsD,EACtD,gBAA+B,EAAA;QAE/B,MAAM,UAAU,MAAM;QACtB,MAAM,aAAa,QAAQ,UAAU,IAAI,IAAI,CAAC,UAAU;QACxD,IAAI,oBAAoB,MAAM;YAC5B,mBAAmB;;QAGrB,MAAM,IAAI,CAAC,cAAc,CAAC;QAE1B,MAAM,EAAE,GAAG,EAAE,GAAG,EAAE,OAAO,EAAE,GAAG,IAAI,CAAC,YAAY,CAAC,SAAS;YAAE,YAAY,aAAa;QAAgB;QAEpG,MAAM,IAAI,CAAC,cAAc,CAAC,KAAK;YAAE;YAAK;QAAO;QAE7C,MAAM,WAAW,KAAK,SAAS,IAAI,OAAO;QAE1C,IAAI,QAAQ,MAAM,EAAE,SAAS;YAC3B,MAAM,IAAI,kIAAA,CAAA,oBAAiB;;QAG7B,MAAM,aAAa,IAAI;QACvB,MAAM,WAAW,MAAM,IAAI,CAAC,gBAAgB,CAAC,KAAK,KAAK,SAAS,YAAY,KAAK,CAAC;QAElF,IAAI,oBAAoB,OAAO;YAC7B,IAAI,QAAQ,MAAM,EAAE,SAAS;gBAC3B,MAAM,IAAI,kIAAA,CAAA,oBAAiB;;YAE7B,IAAI,kBAAkB;gBACpB,OAAO,IAAI,CAAC,YAAY,CAAC,SAAS;;YAEpC,IAAI,SAAS,IAAI,KAAK,cAAc;gBAClC,MAAM,IAAI,kIAAA,CAAA,4BAAyB;;YAErC,MAAM,IAAI,kIAAA,CAAA,qBAAkB,CAAC;gBAAE,OAAO;YAAQ;;QAGhD,MAAM,kBAAkB,sBAAsB,SAAS,OAAO;QAE9D,IAAI,CAAC,SAAS,EAAE,EAAE;YAChB,IAAI,oBAAoB,IAAI,CAAC,WAAW,CAAC,WAAW;gBAClD,MAAM,eAAe,CAAA,UAAA,EAAa,iBAAgB,mBAAA,CAAqB;gBACvE,MAAM,CAAA,iBAAA,EAAoB,aAAY,CAAA,CAAG,EAAE,SAAS,MAAM,EAAE,KAAK;gBACjE,OAAO,IAAI,CAAC,YAAY,CAAC,SAAS,kBAAkB;;YAGtD,MAAM,UAAU,MAAM,SAAS,IAAI,GAAG,KAAK,CAAC,CAAC,IAAM,YAAY,GAAG,OAAO;YACzE,MAAM,UAAU,SAAS;YACzB,MAAM,aAAa,UAAU,YAAY;YACzC,MAAM,eAAe,mBAAmB,CAAA,6BAAA,CAA+B,GAAG,CAAA,sBAAA,CAAwB;YAElG,MAAM,CAAA,iBAAA,EAAoB,aAAY,CAAA,CAAG,EAAE,SAAS,MAAM,EAAE,KAAK,iBAAiB;YAElF,MAAM,MAAM,IAAI,CAAC,eAAe,CAAC,SAAS,MAAM,EAAE,SAAS,YAAY;YACvE,MAAM;;QAGR,OAAO;YAAE;YAAU;YAAS;QAAU;IACxC;IAEA,eACE,IAA4E,EAC5E,OAA4B,EAAA;QAE5B,MAAM,UAAU,IAAI,CAAC,WAAW,CAAC,SAAS;QAC1C,OAAO,IAAI,YAA6B,IAAI,EAAE,SAAS;IACzD;IAEA,SAAc,IAAY,EAAE,KAA6B,EAAA;QACvD,MAAM,MACJ,cAAc,QACZ,IAAI,IAAI,QACR,IAAI,IAAI,IAAI,CAAC,OAAO,GAAG,CAAC,IAAI,CAAC,OAAO,CAAC,QAAQ,CAAC,QAAQ,KAAK,UAAU,CAAC,OAAO,KAAK,KAAK,CAAC,KAAK,IAAI;QAErG,MAAM,eAAe,IAAI,CAAC,YAAY;QACtC,IAAI,CAAC,WAAW,eAAe;YAC7B,QAAQ;gBAAE,GAAG,YAAY;gBAAE,GAAG,KAAK;YAAA;;QAGrC,IAAI,OAAO,UAAU,YAAY,SAAS,CAAC,MAAM,OAAO,CAAC,QAAQ;YAC/D,IAAI,MAAM,GAAG,IAAI,CAAC,cAAc,CAAC;;QAGnC,OAAO,IAAI,QAAQ;IACrB;IAEU,eAAe,KAA8B,EAAA;QACrD,OAAO,OAAO,OAAO,CAAC,OACnB,MAAM,CAAC,CAAC,CAAC,GAAG,MAAM,GAAK,OAAO,UAAU,aACxC,GAAG,CAAC,CAAC,CAAC,KAAK,MAAM;YAChB,IAAI,OAAO,UAAU,YAAY,OAAO,UAAU,YAAY,OAAO,UAAU,WAAW;gBACxF,OAAO,CAAA,EAAG,mBAAmB,KAAI,CAAA,EAAI,mBAAmB,OAAM,CAAE;;YAElE,IAAI,UAAU,MAAM;gBAClB,OAAO,CAAA,EAAG,mBAAmB,KAAI,CAAA,CAAG;;YAEtC,MAAM,IAAI,kIAAA,CAAA,cAAW,CACnB,CAAA,sBAAA,EAAyB,OAAO,MAAK,iQAAA,CAAmQ;QAE5S,GACC,IAAI,CAAC;IACV;IAEA,MAAM,iBACJ,GAAgB,EAChB,IAA6B,EAC7B,EAAU,EACV,UAA2B,EAAA;QAE3B,MAAM,EAAE,MAAM,EAAE,GAAG,SAAS,GAAG,QAAQ,CAAA;QACvC,IAAI,QAAQ,OAAO,gBAAgB,CAAC,SAAS,IAAM,WAAW,KAAK;QAEnE,MAAM,UAAU,WAAW,IAAM,WAAW,KAAK,IAAI;QAErD,OACE,IAAI,CAAC,gBAAgB,EACnB,4FAA4F;SAC3F,KAAK,CAAC,IAAI,CAAC,WAAW,KAAK;YAAE,QAAQ,WAAW,MAAa;YAAE,GAAG,OAAO;QAAA,GACzE,OAAO,CAAC;YACP,aAAa;QACf;IAEN;IAEU,mBAAgB;QACxB,OAAO;YAAE,OAAO,IAAI,CAAC,KAAK;QAAA;IAC5B;IAEQ,YAAY,QAAkB,EAAA;QACpC,sCAAsC;QACtC,MAAM,oBAAoB,SAAS,OAAO,CAAC,GAAG,CAAC;QAE/C,+DAA+D;QAC/D,IAAI,sBAAsB,QAAQ,OAAO;QACzC,IAAI,sBAAsB,SAAS,OAAO;QAE1C,6BAA6B;QAC7B,IAAI,SAAS,MAAM,KAAK,KAAK,OAAO;QAEpC,0BAA0B;QAC1B,IAAI,SAAS,MAAM,KAAK,KAAK,OAAO;QAEpC,wBAAwB;QACxB,IAAI,SAAS,MAAM,KAAK,KAAK,OAAO;QAEpC,yBAAyB;QACzB,IAAI,SAAS,MAAM,IAAI,KAAK,OAAO;QAEnC,OAAO;IACT;IAEQ,MAAM,aACZ,OAA4B,EAC5B,gBAAwB,EACxB,eAAqC,EAAA;QAErC,IAAI;QAEJ,mHAAmH;QACnH,MAAM,yBAAyB,iBAAiB,CAAC,iBAAiB;QAClE,IAAI,wBAAwB;YAC1B,MAAM,YAAY,WAAW;YAC7B,IAAI,CAAC,OAAO,KAAK,CAAC,YAAY;gBAC5B,gBAAgB;;;QAIpB,sGAAsG;QACtG,MAAM,mBAAmB,iBAAiB,CAAC,cAAc;QACzD,IAAI,oBAAoB,CAAC,eAAe;YACtC,MAAM,iBAAiB,WAAW;YAClC,IAAI,CAAC,OAAO,KAAK,CAAC,iBAAiB;gBACjC,gBAAgB,iBAAiB;mBAC5B;gBACL,gBAAgB,KAAK,KAAK,CAAC,oBAAoB,KAAK,GAAG;;;QAI3D,sFAAsF;QACtF,0DAA0D;QAC1D,IAAI,CAAC,CAAC,iBAAiB,KAAK,iBAAiB,gBAAgB,KAAK,IAAI,GAAG;YACvE,MAAM,aAAa,QAAQ,UAAU,IAAI,IAAI,CAAC,UAAU;YACxD,gBAAgB,IAAI,CAAC,kCAAkC,CAAC,kBAAkB;;QAE5E,MAAM,MAAM;QAEZ,OAAO,IAAI,CAAC,WAAW,CAAC,SAAS,mBAAmB;IACtD;IAEQ,mCAAmC,gBAAwB,EAAE,UAAkB,EAAA;QACrF,MAAM,oBAAoB;QAC1B,MAAM,gBAAgB;QAEtB,MAAM,aAAa,aAAa;QAEhC,wDAAwD;QACxD,MAAM,eAAe,KAAK,GAAG,CAAC,oBAAoB,KAAK,GAAG,CAAC,GAAG,aAAa;QAE3E,sEAAsE;QACtE,MAAM,SAAS,IAAI,KAAK,MAAM,KAAK;QAEnC,OAAO,eAAe,SAAS;IACjC;IAEQ,eAAY;QAClB,OAAO,CAAA,EAAG,IAAI,CAAC,WAAW,CAAC,IAAI,CAAA,IAAA,EAAO,oIAAA,CAAA,UAAO,CAAA,CAAE;IACjD;;AAKI,MAAgB;IAOpB,YAAY,MAAiB,EAAE,QAAkB,EAAE,IAAa,EAAE,OAA4B,CAAA;QAN9F,qBAAA,GAAA,CAAA,IAAA,EAAA,KAAA;QAOE,uBAAA,IAAI,EAAA,sBAAW,QAAM;QACrB,IAAI,CAAC,OAAO,GAAG;QACf,IAAI,CAAC,QAAQ,GAAG;QAChB,IAAI,CAAC,IAAI,GAAG;IACd;IAUA,cAAW;QACT,MAAM,QAAQ,IAAI,CAAC,iBAAiB;QACpC,IAAI,CAAC,MAAM,MAAM,EAAE,OAAO;QAC1B,OAAO,IAAI,CAAC,YAAY,MAAM;IAChC;IAEA,MAAM,cAAW;QACf,MAAM,WAAW,IAAI,CAAC,YAAY;QAClC,IAAI,CAAC,UAAU;YACb,MAAM,IAAI,kIAAA,CAAA,cAAW,CACnB;;QAGJ,MAAM,cAAc;YAAE,GAAG,IAAI,CAAC,OAAO;QAAA;QACrC,IAAI,YAAY,YAAY,OAAO,YAAY,KAAK,KAAK,UAAU;YACjE,YAAY,KAAK,GAAG;gBAAE,GAAG,YAAY,KAAK;gBAAE,GAAG,SAAS,MAAM;YAAA;eACzD,IAAI,SAAS,UAAU;YAC5B,MAAM,SAAS;mBAAI,OAAO,OAAO,CAAC,YAAY,KAAK,IAAI,CAAA;mBAAQ,SAAS,GAAG,CAAC,YAAY,CAAC,OAAO;aAAG;YACnG,KAAK,MAAM,CAAC,KAAK,MAAM,IAAI,OAAQ;gBACjC,SAAS,GAAG,CAAC,YAAY,CAAC,GAAG,CAAC,KAAK;;YAErC,YAAY,KAAK,GAAG;YACpB,YAAY,IAAI,GAAG,SAAS,GAAG,CAAC,QAAQ;;QAE1C,OAAO,MAAM,uBAAA,IAAI,EAAA,sBAAA,KAAS,cAAc,CAAC,IAAI,CAAC,WAAkB,EAAE;IACpE;IAEA,OAAO,YAAS;QACd,4DAA4D;QAC5D,IAAI,OAA2B,IAAI;QACnC,MAAM;QACN,MAAO,KAAK,WAAW,GAAI;YACzB,OAAO,MAAM,KAAK,WAAW;YAC7B,MAAM;;IAEV;IAEA,OAAO,CAAA,CAAA,uBAAA,IAAA,WAAC,OAAO,aAAa,EAAC,GAAA;QAC3B,WAAW,MAAM,QAAQ,IAAI,CAAC,SAAS,GAAI;YACzC,KAAK,MAAM,QAAQ,KAAK,iBAAiB,GAAI;gBAC3C,MAAM;;;IAGZ;;AAYI,MAAO,oBAIH;IAGR,YACE,MAAiB,EACjB,OAAkC,EAClC,IAA4E,CAAA;QAE5E,KAAK,CACH,SACA,OAAO,QACL,IAAI,KACF,QACA,MAAM,QAAQ,EACd,MAAM,qBAAqB,QAC3B,MAAM,OAAO;IAGrB;IAEA;;;;;;QAOA,OAAO,CAAC,OAAO,aAAa,CAAC,GAAA;QAC3B,MAAM,OAAO,MAAM,IAAI;QACvB,WAAW,MAAM,QAAQ,KAAM;YAC7B,MAAM;;IAEV;;AAGK,MAAM,wBAAwB,CACnC;IAEA,OAAO,IAAI,MACT,OAAO,WAAW,CAChB,aAAa;IACb,QAAQ,OAAO,KAEjB;QACE,KAAI,MAAM,EAAE,IAAI;YACd,MAAM,MAAM,KAAK,QAAQ;YACzB,OAAO,MAAM,CAAC,IAAI,WAAW,GAAG,IAAI,MAAM,CAAC,IAAI;QACjD;;AAGN;AA8BA,yFAAyF;AACzF,qFAAqF;AACrF,wEAAwE;AACxE,MAAM,qBAA+C;IACnD,QAAQ;IACR,MAAM;IACN,OAAO;IACP,MAAM;IACN,SAAS;IAET,YAAY;IACZ,QAAQ;IACR,SAAS;IACT,WAAW;IACX,QAAQ;IACR,gBAAgB;IAEhB,iBAAiB;IACjB,kBAAkB;IAClB,eAAe;;AAGV,MAAM,mBAAmB,CAAC;IAC/B,OACE,OAAO,QAAQ,YACf,QAAQ,QACR,CAAC,WAAW,QACZ,OAAO,IAAI,CAAC,KAAK,KAAK,CAAC,CAAC,IAAM,OAAO,oBAAoB;AAE7D;AA8BA,MAAM,wBAAwB;IAC5B,IAAI,OAAO,SAAS,eAAe,KAAK,KAAK,IAAI,MAAM;QACrD,OAAO;YACL,oBAAoB;YACpB,+BAA+B,oIAAA,CAAA,UAAO;YACtC,kBAAkB,kBAAkB,KAAK,KAAK,CAAC,EAAE;YACjD,oBAAoB,cAAc,KAAK,KAAK,CAAC,IAAI;YACjD,uBAAuB;YACvB,+BACE,OAAO,KAAK,OAAO,KAAK,WAAW,KAAK,OAAO,GAAG,KAAK,OAAO,EAAE,QAAQ;;;IAG9E,IAAI,OAAO,gBAAgB,aAAa;QACtC,OAAO;YACL,oBAAoB;YACpB,+BAA+B,oIAAA,CAAA,UAAO;YACtC,kBAAkB;YAClB,oBAAoB,CAAA,MAAA,EAAS,YAAW,CAAE;YAC1C,uBAAuB;YACvB,+BAA+B,QAAQ,OAAO;;;IAGlD,mBAAmB;IACnB,IAAI,OAAO,SAAS,CAAC,QAAQ,CAAC,IAAI,CAAC,OAAO,YAAY,cAAc,UAAU,OAAO,oBAAoB;QACvG,OAAO;YACL,oBAAoB;YACpB,+BAA+B,oIAAA,CAAA,UAAO;YACtC,kBAAkB,kBAAkB,QAAQ,QAAQ;YACpD,oBAAoB,cAAc,QAAQ,IAAI;YAC9C,uBAAuB;YACvB,+BAA+B,QAAQ,OAAO;;;IAIlD,MAAM,cAAc;IACpB,IAAI,aAAa;QACf,OAAO;YACL,oBAAoB;YACpB,+BAA+B,oIAAA,CAAA,UAAO;YACtC,kBAAkB;YAClB,oBAAoB;YACpB,uBAAuB,CAAA,QAAA,EAAW,YAAY,OAAO,CAAA,CAAE;YACvD,+BAA+B,YAAY,OAAO;;;IAItD,gDAAgD;IAChD,OAAO;QACL,oBAAoB;QACpB,+BAA+B,oIAAA,CAAA,UAAO;QACtC,kBAAkB;QAClB,oBAAoB;QACpB,uBAAuB;QACvB,+BAA+B;;AAEnC;AASA,8IAA8I;AAC9I,SAAS;IACP,IAAI,OAAO,cAAc,eAAe,CAAC,WAAW;QAClD,OAAO;;IAGT,gCAAgC;IAChC,MAAM,kBAAkB;QACtB;YAAE,KAAK;YAAiB,SAAS;QAAsC;QACvE;YAAE,KAAK;YAAe,SAAS;QAAsC;QACrE;YAAE,KAAK;YAAe,SAAS;QAA4C;QAC3E;YAAE,KAAK;YAAmB,SAAS;QAAwC;QAC3E;YAAE,KAAK;YAAoB,SAAS;QAAyC;QAC7E;YAAE,KAAK;YAAmB,SAAS;QAAmE;KACvG;IAED,kCAAkC;IAClC,KAAK,MAAM,EAAE,GAAG,EAAE,OAAO,EAAE,IAAI,gBAAiB;QAC9C,MAAM,QAAQ,QAAQ,IAAI,CAAC,UAAU,SAAS;QAC9C,IAAI,OAAO;YACT,MAAM,QAAQ,KAAK,CAAC,EAAE,IAAI;YAC1B,MAAM,QAAQ,KAAK,CAAC,EAAE,IAAI;YAC1B,MAAM,QAAQ,KAAK,CAAC,EAAE,IAAI;YAE1B,OAAO;gBAAE,SAAS;gBAAK,SAAS,CAAA,EAAG,MAAK,CAAA,EAAI,MAAK,CAAA,EAAI,MAAK,CAAE;YAAA;;;IAIhE,OAAO;AACT;AAEA,MAAM,gBAAgB,CAAC;IACrB,aAAa;IACb,oDAAoD;IACpD,aAAa;IACb,mDAAmD;IACnD,IAAI,SAAS,OAAO,OAAO;IAC3B,IAAI,SAAS,YAAY,SAAS,OAAO,OAAO;IAChD,IAAI,SAAS,OAAO,OAAO;IAC3B,IAAI,SAAS,aAAa,SAAS,SAAS,OAAO;IACnD,IAAI,MAAM,OAAO,CAAA,MAAA,EAAS,KAAI,CAAE;IAChC,OAAO;AACT;AAEA,MAAM,oBAAoB,CAAC;IACzB,kBAAkB;IAClB,wDAAwD;IACxD,kBAAkB;IAClB,mDAAmD;IACnD,kDAAkD;IAElD,WAAW,SAAS,WAAW;IAE/B,oDAAoD;IACpD,yDAAyD;IACzD,iDAAiD;IACjD,8EAA8E;IAC9E,IAAI,SAAS,QAAQ,CAAC,QAAQ,OAAO;IACrC,IAAI,aAAa,WAAW,OAAO;IACnC,IAAI,aAAa,UAAU,OAAO;IAClC,IAAI,aAAa,SAAS,OAAO;IACjC,IAAI,aAAa,WAAW,OAAO;IACnC,IAAI,aAAa,WAAW,OAAO;IACnC,IAAI,aAAa,SAAS,OAAO;IACjC,IAAI,UAAU,OAAO,CAAA,MAAA,EAAS,SAAQ,CAAE;IACxC,OAAO;AACT;AAEA,IAAI;AACJ,MAAM,qBAAqB;IACzB,OAAQ,oBAAgB,CAAhB,mBAAqB,uBAAuB;AACtD;AAEO,MAAM,WAAW,CAAC;IACvB,IAAI;QACF,OAAO,KAAK,KAAK,CAAC;MAClB,OAAO,KAAK;QACZ,OAAO;;AAEX;AAEA,uCAAuC;AACvC,MAAM,yBAAyB,IAAI,OAAO,mBAAmB;AAC7D,MAAM,gBAAgB,CAAC;IACrB,OAAO,uBAAuB,IAAI,CAAC;AACrC;AAEO,MAAM,QAAQ,CAAC,KAAe,IAAI,QAAQ,CAAC,UAAY,WAAW,SAAS;AAElF,MAAM,0BAA0B,CAAC,MAAc;IAC7C,IAAI,OAAO,MAAM,YAAY,CAAC,OAAO,SAAS,CAAC,IAAI;QACjD,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC,CAAA,EAAG,KAAI,mBAAA,CAAqB;;IAEpD,IAAI,IAAI,GAAG;QACT,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC,CAAA,EAAG,KAAI,2BAAA,CAA6B;;IAE5D,OAAO;AACT;AAEO,MAAM,cAAc,CAAC;IAC1B,IAAI,eAAe,OAAO,OAAO;IACjC,IAAI,OAAO,QAAQ,YAAY,QAAQ,MAAM;QAC3C,IAAI;YACF,OAAO,IAAI,MAAM,KAAK,SAAS,CAAC;UAChC,OAAM,CAAA;;IAEV,OAAO,IAAI,MAAM;AACnB;AAEO,MAAM,gBAAgB,CAAI;IAC/B,IAAI,SAAS,MAAM,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC,CAAA,0CAAA,EAA6C,MAAK,SAAA,CAAW;IACtG,OAAO;AACT;AASO,MAAM,UAAU,CAAC;IACtB,IAAI,OAAO,YAAY,aAAa;QAClC,OAAO,QAAQ,GAAG,EAAE,CAAC,IAAI,EAAE,UAAU;;IAEvC,IAAI,OAAO,SAAS,aAAa;QAC/B,OAAO,KAAK,GAAG,EAAE,MAAM,MAAM;;IAE/B,OAAO;AACT;AAEO,MAAM,gBAAgB,CAAC;IAC5B,IAAI,OAAO,UAAU,UAAU,OAAO,KAAK,KAAK,CAAC;IACjD,IAAI,OAAO,UAAU,UAAU,OAAO,SAAS,OAAO;IAEtD,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC,CAAA,iBAAA,EAAoB,MAAK,QAAA,EAAW,OAAO,MAAK,eAAA,CAAiB;AACzF;AAEO,MAAM,cAAc,CAAC;IAC1B,IAAI,OAAO,UAAU,UAAU,OAAO;IACtC,IAAI,OAAO,UAAU,UAAU,OAAO,WAAW;IAEjD,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC,CAAA,iBAAA,EAAoB,MAAK,QAAA,EAAW,OAAO,MAAK,eAAA,CAAiB;AACzF;AAEO,MAAM,gBAAgB,CAAC;IAC5B,IAAI,OAAO,UAAU,WAAW,OAAO;IACvC,IAAI,OAAO,UAAU,UAAU,OAAO,UAAU;IAChD,OAAO,QAAQ;AACjB;AAEO,MAAM,qBAAqB,CAAC;IACjC,IAAI,UAAU,WAAW;QACvB,OAAO;;IAET,OAAO,cAAc;AACvB;AAEO,MAAM,mBAAmB,CAAC;IAC/B,IAAI,UAAU,WAAW;QACvB,OAAO;;IAET,OAAO,YAAY;AACrB;AAEO,MAAM,qBAAqB,CAAC;IACjC,IAAI,UAAU,WAAW;QACvB,OAAO;;IAET,OAAO,cAAc;AACvB;AAGM,SAAU,WAAW,GAA8B;IACvD,IAAI,CAAC,KAAK,OAAO;IACjB,IAAK,MAAM,MAAM,IAAK,OAAO;IAC7B,OAAO;AACT;AAGM,SAAU,OAAO,GAAW,EAAE,GAAW;IAC7C,OAAO,OAAO,SAAS,CAAC,cAAc,CAAC,IAAI,CAAC,KAAK;AACnD;AAEA;;;;;IAMA,SAAS,gBAAgB,aAAsB,EAAE,UAAmB;IAClE,IAAK,MAAM,KAAK,WAAY;QAC1B,IAAI,CAAC,OAAO,YAAY,IAAI;QAC5B,MAAM,WAAW,EAAE,WAAW;QAC9B,IAAI,CAAC,UAAU;QAEf,MAAM,MAAM,UAAU,CAAC,EAAE;QAEzB,IAAI,QAAQ,MAAM;YAChB,OAAO,aAAa,CAAC,SAAS;eACzB,IAAI,QAAQ,WAAW;YAC5B,aAAa,CAAC,SAAS,GAAG;;;AAGhC;AAEM,SAAU,MAAM,MAAc,EAAE,GAAG,IAAW;IAClD,IAAI,OAAO,YAAY,eAAe,SAAS,KAAK,CAAC,QAAQ,KAAK,QAAQ;QACxE,QAAQ,GAAG,CAAC,CAAA,aAAA,EAAgB,OAAM,CAAE,KAAK;;AAE7C;AAEA;;IAGA,MAAM,QAAQ;IACZ,OAAO,uCAAuC,OAAO,CAAC,SAAS,CAAC;QAC9D,MAAM,IAAI,AAAC,KAAK,MAAM,KAAK,KAAM;QACjC,MAAM,IAAI,MAAM,MAAM,IAAI,AAAC,IAAI,MAAO;QACtC,OAAO,EAAE,QAAQ,CAAC;IACpB;AACF;AAEO,MAAM,qBAAqB;IAChC,OACE,aAAa;IACb,OAAO,WAAW,eAClB,aAAa;IACb,OAAO,OAAO,QAAQ,KAAK,eAC3B,aAAa;IACb,OAAO,cAAc;AAEzB;AAOO,MAAM,oBAAoB,CAAC;IAChC,OAAO,OAAO,SAAS,QAAQ;AACjC;AAEO,MAAM,oBAAoB,CAAC,SAAgC;IAChE,MAAM,cAAc,UAAU,SAAS;IACvC,IAAI,gBAAgB,WAAW;QAC7B,MAAM,IAAI,MAAM,CAAA,eAAA,EAAkB,OAAM,OAAA,CAAS;;IAEnD,OAAO;AACT;AAEO,MAAM,YAAY,CAAC,SAAgC;IACxD,MAAM,mBAAmB,OAAO,WAAW;IAC3C,IAAI,kBAAkB,UAAU;QAC9B,uEAAuE;QACvE,MAAM,kBACJ,MAAM,CAAC,EAAE,EAAE,gBACX,OAAO,SAAS,CAAC,GAAG,OAAO,CAAC,gBAAgB,CAAC,IAAI,IAAI,KAAO,KAAK,GAAG,WAAW;QACjF,KAAK,MAAM,OAAO;YAAC;YAAQ;YAAkB,OAAO,WAAW;YAAI;SAAgB,CAAE;YACnF,MAAM,QAAQ,QAAQ,GAAG,CAAC;YAC1B,IAAI,OAAO;gBACT,OAAO;;;;IAKb,KAAK,MAAM,CAAC,KAAK,MAAM,IAAI,OAAO,OAAO,CAAC,SAAU;QAClD,IAAI,IAAI,WAAW,OAAO,kBAAkB;YAC1C,IAAI,MAAM,OAAO,CAAC,QAAQ;gBACxB,IAAI,MAAM,MAAM,IAAI,GAAG,OAAO,KAAK,CAAC,EAAE;gBACtC,QAAQ,IAAI,CAAC,CAAA,SAAA,EAAY,MAAM,MAAM,CAAA,iBAAA,EAAoB,OAAM,+BAAA,CAAiC;gBAChG,OAAO,KAAK,CAAC,EAAE;;YAEjB,OAAO;;;IAIX,OAAO;AACT;AAKO,MAAM,WAAW,CAAC;IACvB,IAAI,CAAC,KAAK,OAAO;IACjB,IAAI,OAAO,WAAW,aAAa;QACjC,OAAO,OAAO,IAAI,CAAC,KAAK,QAAQ,CAAC;;IAGnC,IAAI,OAAO,SAAS,aAAa;QAC/B,OAAO,KAAK;;IAGd,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC;AACxB;AAEM,SAAU,MAAM,GAAY;IAChC,OAAO,OAAO,QAAQ,OAAO,QAAQ,YAAY,CAAC,MAAM,OAAO,CAAC;AAClE"}},
    {"offset": {"line": 1709, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1714, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/error.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { castToError, Headers } from './core';\n\nexport class OpenAIError extends Error {}\n\nexport class APIError extends OpenAIError {\n  readonly status: number | undefined;\n  readonly headers: Headers | undefined;\n  readonly error: Object | undefined;\n\n  readonly code: string | null | undefined;\n  readonly param: string | null | undefined;\n  readonly type: string | undefined;\n\n  readonly request_id: string | null | undefined;\n\n  constructor(\n    status: number | undefined,\n    error: Object | undefined,\n    message: string | undefined,\n    headers: Headers | undefined,\n  ) {\n    super(`${APIError.makeMessage(status, error, message)}`);\n    this.status = status;\n    this.headers = headers;\n    this.request_id = headers?.['x-request-id'];\n\n    const data = error as Record<string, any>;\n    this.error = data;\n    this.code = data?.['code'];\n    this.param = data?.['param'];\n    this.type = data?.['type'];\n  }\n\n  private static makeMessage(status: number | undefined, error: any, message: string | undefined) {\n    const msg =\n      error?.message ?\n        typeof error.message === 'string' ?\n          error.message\n        : JSON.stringify(error.message)\n      : error ? JSON.stringify(error)\n      : message;\n\n    if (status && msg) {\n      return `${status} ${msg}`;\n    }\n    if (status) {\n      return `${status} status code (no body)`;\n    }\n    if (msg) {\n      return msg;\n    }\n    return '(no status code or body)';\n  }\n\n  static generate(\n    status: number | undefined,\n    errorResponse: Object | undefined,\n    message: string | undefined,\n    headers: Headers | undefined,\n  ) {\n    if (!status) {\n      return new APIConnectionError({ message, cause: castToError(errorResponse) });\n    }\n\n    const error = (errorResponse as Record<string, any>)?.['error'];\n\n    if (status === 400) {\n      return new BadRequestError(status, error, message, headers);\n    }\n\n    if (status === 401) {\n      return new AuthenticationError(status, error, message, headers);\n    }\n\n    if (status === 403) {\n      return new PermissionDeniedError(status, error, message, headers);\n    }\n\n    if (status === 404) {\n      return new NotFoundError(status, error, message, headers);\n    }\n\n    if (status === 409) {\n      return new ConflictError(status, error, message, headers);\n    }\n\n    if (status === 422) {\n      return new UnprocessableEntityError(status, error, message, headers);\n    }\n\n    if (status === 429) {\n      return new RateLimitError(status, error, message, headers);\n    }\n\n    if (status >= 500) {\n      return new InternalServerError(status, error, message, headers);\n    }\n\n    return new APIError(status, error, message, headers);\n  }\n}\n\nexport class APIUserAbortError extends APIError {\n  override readonly status: undefined = undefined;\n\n  constructor({ message }: { message?: string } = {}) {\n    super(undefined, undefined, message || 'Request was aborted.', undefined);\n  }\n}\n\nexport class APIConnectionError extends APIError {\n  override readonly status: undefined = undefined;\n\n  constructor({ message, cause }: { message?: string | undefined; cause?: Error | undefined }) {\n    super(undefined, undefined, message || 'Connection error.', undefined);\n    // in some environments the 'cause' property is already declared\n    // @ts-ignore\n    if (cause) this.cause = cause;\n  }\n}\n\nexport class APIConnectionTimeoutError extends APIConnectionError {\n  constructor({ message }: { message?: string } = {}) {\n    super({ message: message ?? 'Request timed out.' });\n  }\n}\n\nexport class BadRequestError extends APIError {\n  override readonly status: 400 = 400;\n}\n\nexport class AuthenticationError extends APIError {\n  override readonly status: 401 = 401;\n}\n\nexport class PermissionDeniedError extends APIError {\n  override readonly status: 403 = 403;\n}\n\nexport class NotFoundError extends APIError {\n  override readonly status: 404 = 404;\n}\n\nexport class ConflictError extends APIError {\n  override readonly status: 409 = 409;\n}\n\nexport class UnprocessableEntityError extends APIError {\n  override readonly status: 422 = 422;\n}\n\nexport class RateLimitError extends APIError {\n  override readonly status: 429 = 429;\n}\n\nexport class InternalServerError extends APIError {}\n\nexport class LengthFinishReasonError extends OpenAIError {\n  constructor() {\n    super(`Could not parse response content as the length limit was reached`);\n  }\n}\n\nexport class ContentFilterFinishReasonError extends OpenAIError {\n  constructor() {\n    super(`Could not parse response content as the request was rejected by the content filter`);\n  }\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;;;;;;;;;;;;;AAIhF,MAAO,oBAAoB;;AAE3B,MAAO,iBAAiB;IAW5B,YACE,MAA0B,EAC1B,KAAyB,EACzB,OAA2B,EAC3B,OAA4B,CAAA;QAE5B,KAAK,CAAC,CAAA,EAAG,SAAS,WAAW,CAAC,QAAQ,OAAO,SAAQ,CAAE;QACvD,IAAI,CAAC,MAAM,GAAG;QACd,IAAI,CAAC,OAAO,GAAG;QACf,IAAI,CAAC,UAAU,GAAG,SAAS,CAAC,eAAe;QAE3C,MAAM,OAAO;QACb,IAAI,CAAC,KAAK,GAAG;QACb,IAAI,CAAC,IAAI,GAAG,MAAM,CAAC,OAAO;QAC1B,IAAI,CAAC,KAAK,GAAG,MAAM,CAAC,QAAQ;QAC5B,IAAI,CAAC,IAAI,GAAG,MAAM,CAAC,OAAO;IAC5B;IAEQ,OAAO,YAAY,MAA0B,EAAE,KAAU,EAAE,OAA2B,EAAA;QAC5F,MAAM,MACJ,OAAO,UACL,OAAO,MAAM,OAAO,KAAK,WACvB,MAAM,OAAO,GACb,KAAK,SAAS,CAAC,MAAM,OAAO,IAC9B,QAAQ,KAAK,SAAS,CAAC,SACvB;QAEJ,IAAI,UAAU,KAAK;YACjB,OAAO,CAAA,EAAG,OAAM,CAAA,EAAI,IAAG,CAAE;;QAE3B,IAAI,QAAQ;YACV,OAAO,CAAA,EAAG,OAAM,sBAAA,CAAwB;;QAE1C,IAAI,KAAK;YACP,OAAO;;QAET,OAAO;IACT;IAEA,OAAO,SACL,MAA0B,EAC1B,aAAiC,EACjC,OAA2B,EAC3B,OAA4B,EAAA;QAE5B,IAAI,CAAC,QAAQ;YACX,OAAO,IAAI,mBAAmB;gBAAE;gBAAS,OAAO,CAAA,GAAA,iJAAA,CAAA,cAAW,AAAX,EAAY;YAAc;;QAG5E,MAAM,QAAS,eAAuC,CAAC,QAAQ;QAE/D,IAAI,WAAW,KAAK;YAClB,OAAO,IAAI,gBAAgB,QAAQ,OAAO,SAAS;;QAGrD,IAAI,WAAW,KAAK;YAClB,OAAO,IAAI,oBAAoB,QAAQ,OAAO,SAAS;;QAGzD,IAAI,WAAW,KAAK;YAClB,OAAO,IAAI,sBAAsB,QAAQ,OAAO,SAAS;;QAG3D,IAAI,WAAW,KAAK;YAClB,OAAO,IAAI,cAAc,QAAQ,OAAO,SAAS;;QAGnD,IAAI,WAAW,KAAK;YAClB,OAAO,IAAI,cAAc,QAAQ,OAAO,SAAS;;QAGnD,IAAI,WAAW,KAAK;YAClB,OAAO,IAAI,yBAAyB,QAAQ,OAAO,SAAS;;QAG9D,IAAI,WAAW,KAAK;YAClB,OAAO,IAAI,eAAe,QAAQ,OAAO,SAAS;;QAGpD,IAAI,UAAU,KAAK;YACjB,OAAO,IAAI,oBAAoB,QAAQ,OAAO,SAAS;;QAGzD,OAAO,IAAI,SAAS,QAAQ,OAAO,SAAS;IAC9C;;AAGI,MAAO,0BAA0B;IAGrC,YAAY,EAAE,OAAO,EAAA,GAA2B,CAAA,CAAE,CAAA;QAChD,KAAK,CAAC,WAAW,WAAW,WAAW,wBAAwB;QAH/C,IAAA,CAAA,MAAM,GAAc;IAItC;;AAGI,MAAO,2BAA2B;IAGtC,YAAY,EAAE,OAAO,EAAE,KAAK,EAA+D,CAAA;QACzF,KAAK,CAAC,WAAW,WAAW,WAAW,qBAAqB;QAH5C,IAAA,CAAA,MAAM,GAAc;QAIpC,gEAAgE;QAChE,aAAa;QACb,IAAI,OAAO,IAAI,CAAC,KAAK,GAAG;IAC1B;;AAGI,MAAO,kCAAkC;IAC7C,YAAY,EAAE,OAAO,EAAA,GAA2B,CAAA,CAAE,CAAA;QAChD,KAAK,CAAC;YAAE,SAAS,WAAW;QAAoB;IAClD;;AAGI,MAAO,wBAAwB;IAArC,aAAA;;QACoB,IAAA,CAAA,MAAM,GAAQ;IAClC;;AAEM,MAAO,4BAA4B;IAAzC,aAAA;;QACoB,IAAA,CAAA,MAAM,GAAQ;IAClC;;AAEM,MAAO,8BAA8B;IAA3C,aAAA;;QACoB,IAAA,CAAA,MAAM,GAAQ;IAClC;;AAEM,MAAO,sBAAsB;IAAnC,aAAA;;QACoB,IAAA,CAAA,MAAM,GAAQ;IAClC;;AAEM,MAAO,sBAAsB;IAAnC,aAAA;;QACoB,IAAA,CAAA,MAAM,GAAQ;IAClC;;AAEM,MAAO,iCAAiC;IAA9C,aAAA;;QACoB,IAAA,CAAA,MAAM,GAAQ;IAClC;;AAEM,MAAO,uBAAuB;IAApC,aAAA;;QACoB,IAAA,CAAA,MAAM,GAAQ;IAClC;;AAEM,MAAO,4BAA4B;;AAEnC,MAAO,gCAAgC;IAC3C,aAAA;QACE,KAAK,CAAC,CAAA,gEAAA,CAAkE;IAC1E;;AAGI,MAAO,uCAAuC;IAClD,aAAA;QACE,KAAK,CAAC,CAAA,kFAAA,CAAoF;IAC5F"}},
    {"offset": {"line": 1873, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1927, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/internal/qs/formats.ts"],"sourcesContent":["import type { Format } from './types';\n\nexport const default_format: Format = 'RFC3986';\nexport const formatters: Record<Format, (str: PropertyKey) => string> = {\n  RFC1738: (v: PropertyKey) => String(v).replace(/%20/g, '+'),\n  RFC3986: (v: PropertyKey) => String(v),\n};\nexport const RFC1738 = 'RFC1738';\nexport const RFC3986 = 'RFC3986';\n"],"names":[],"mappings":";;;;;;AAEO,MAAM,iBAAyB;AAC/B,MAAM,aAA2D;IACtE,SAAS,CAAC,IAAmB,OAAO,GAAG,OAAO,CAAC,QAAQ;IACvD,SAAS,CAAC,IAAmB,OAAO;;AAE/B,MAAM,UAAU;AAChB,MAAM,UAAU"}},
    {"offset": {"line": 1940, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1945, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/internal/qs/index.ts"],"sourcesContent":["import { default_format, formatters, RFC1738, RFC3986 } from './formats';\n\nconst formats = {\n  formatters,\n  RFC1738,\n  RFC3986,\n  default: default_format,\n};\n\nexport { stringify } from './stringify';\nexport { formats };\n\nexport type { DefaultDecoder, DefaultEncoder, Format, ParseOptions, StringifyOptions } from './types';\n"],"names":[],"mappings":";;;;;;AAEA,MAAM,UAAU;IACd,YAAA,sJAAA,CAAA,aAAU;IACV,SAAA,sJAAA,CAAA,UAAO;IACP,SAAA,sJAAA,CAAA,UAAO;IACP,SAAS,sJAAA,CAAA,iBAAc"}},
    {"offset": {"line": 1960, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 1973, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/internal/qs/utils.ts"],"sourcesContent":["import { RFC1738 } from './formats';\nimport type { DefaultEncoder, Format } from './types';\n\nconst has = Object.prototype.hasOwnProperty;\nconst is_array = Array.isArray;\n\nconst hex_table = (() => {\n  const array = [];\n  for (let i = 0; i < 256; ++i) {\n    array.push('%' + ((i < 16 ? '0' : '') + i.toString(16)).toUpperCase());\n  }\n\n  return array;\n})();\n\nfunction compact_queue<T extends Record<string, any>>(queue: Array<{ obj: T; prop: string }>) {\n  while (queue.length > 1) {\n    const item = queue.pop();\n    if (!item) continue;\n\n    const obj = item.obj[item.prop];\n\n    if (is_array(obj)) {\n      const compacted: unknown[] = [];\n\n      for (let j = 0; j < obj.length; ++j) {\n        if (typeof obj[j] !== 'undefined') {\n          compacted.push(obj[j]);\n        }\n      }\n\n      // @ts-ignore\n      item.obj[item.prop] = compacted;\n    }\n  }\n}\n\nfunction array_to_object(source: any[], options: { plainObjects: boolean }) {\n  const obj = options && options.plainObjects ? Object.create(null) : {};\n  for (let i = 0; i < source.length; ++i) {\n    if (typeof source[i] !== 'undefined') {\n      obj[i] = source[i];\n    }\n  }\n\n  return obj;\n}\n\nexport function merge(\n  target: any,\n  source: any,\n  options: { plainObjects?: boolean; allowPrototypes?: boolean } = {},\n) {\n  if (!source) {\n    return target;\n  }\n\n  if (typeof source !== 'object') {\n    if (is_array(target)) {\n      target.push(source);\n    } else if (target && typeof target === 'object') {\n      if (\n        (options && (options.plainObjects || options.allowPrototypes)) ||\n        !has.call(Object.prototype, source)\n      ) {\n        target[source] = true;\n      }\n    } else {\n      return [target, source];\n    }\n\n    return target;\n  }\n\n  if (!target || typeof target !== 'object') {\n    return [target].concat(source);\n  }\n\n  let mergeTarget = target;\n  if (is_array(target) && !is_array(source)) {\n    // @ts-ignore\n    mergeTarget = array_to_object(target, options);\n  }\n\n  if (is_array(target) && is_array(source)) {\n    source.forEach(function (item, i) {\n      if (has.call(target, i)) {\n        const targetItem = target[i];\n        if (targetItem && typeof targetItem === 'object' && item && typeof item === 'object') {\n          target[i] = merge(targetItem, item, options);\n        } else {\n          target.push(item);\n        }\n      } else {\n        target[i] = item;\n      }\n    });\n    return target;\n  }\n\n  return Object.keys(source).reduce(function (acc, key) {\n    const value = source[key];\n\n    if (has.call(acc, key)) {\n      acc[key] = merge(acc[key], value, options);\n    } else {\n      acc[key] = value;\n    }\n    return acc;\n  }, mergeTarget);\n}\n\nexport function assign_single_source(target: any, source: any) {\n  return Object.keys(source).reduce(function (acc, key) {\n    acc[key] = source[key];\n    return acc;\n  }, target);\n}\n\nexport function decode(str: string, _: any, charset: string) {\n  const strWithoutPlus = str.replace(/\\+/g, ' ');\n  if (charset === 'iso-8859-1') {\n    // unescape never throws, no try...catch needed:\n    return strWithoutPlus.replace(/%[0-9a-f]{2}/gi, unescape);\n  }\n  // utf-8\n  try {\n    return decodeURIComponent(strWithoutPlus);\n  } catch (e) {\n    return strWithoutPlus;\n  }\n}\n\nconst limit = 1024;\n\nexport const encode: (\n  str: any,\n  defaultEncoder: DefaultEncoder,\n  charset: string,\n  type: 'key' | 'value',\n  format: Format,\n) => string = (str, _defaultEncoder, charset, _kind, format: Format) => {\n  // This code was originally written by Brian White for the io.js core querystring library.\n  // It has been adapted here for stricter adherence to RFC 3986\n  if (str.length === 0) {\n    return str;\n  }\n\n  let string = str;\n  if (typeof str === 'symbol') {\n    string = Symbol.prototype.toString.call(str);\n  } else if (typeof str !== 'string') {\n    string = String(str);\n  }\n\n  if (charset === 'iso-8859-1') {\n    return escape(string).replace(/%u[0-9a-f]{4}/gi, function ($0) {\n      return '%26%23' + parseInt($0.slice(2), 16) + '%3B';\n    });\n  }\n\n  let out = '';\n  for (let j = 0; j < string.length; j += limit) {\n    const segment = string.length >= limit ? string.slice(j, j + limit) : string;\n    const arr = [];\n\n    for (let i = 0; i < segment.length; ++i) {\n      let c = segment.charCodeAt(i);\n      if (\n        c === 0x2d || // -\n        c === 0x2e || // .\n        c === 0x5f || // _\n        c === 0x7e || // ~\n        (c >= 0x30 && c <= 0x39) || // 0-9\n        (c >= 0x41 && c <= 0x5a) || // a-z\n        (c >= 0x61 && c <= 0x7a) || // A-Z\n        (format === RFC1738 && (c === 0x28 || c === 0x29)) // ( )\n      ) {\n        arr[arr.length] = segment.charAt(i);\n        continue;\n      }\n\n      if (c < 0x80) {\n        arr[arr.length] = hex_table[c];\n        continue;\n      }\n\n      if (c < 0x800) {\n        arr[arr.length] = hex_table[0xc0 | (c >> 6)]! + hex_table[0x80 | (c & 0x3f)];\n        continue;\n      }\n\n      if (c < 0xd800 || c >= 0xe000) {\n        arr[arr.length] =\n          hex_table[0xe0 | (c >> 12)]! + hex_table[0x80 | ((c >> 6) & 0x3f)] + hex_table[0x80 | (c & 0x3f)];\n        continue;\n      }\n\n      i += 1;\n      c = 0x10000 + (((c & 0x3ff) << 10) | (segment.charCodeAt(i) & 0x3ff));\n\n      arr[arr.length] =\n        hex_table[0xf0 | (c >> 18)]! +\n        hex_table[0x80 | ((c >> 12) & 0x3f)] +\n        hex_table[0x80 | ((c >> 6) & 0x3f)] +\n        hex_table[0x80 | (c & 0x3f)];\n    }\n\n    out += arr.join('');\n  }\n\n  return out;\n};\n\nexport function compact(value: any) {\n  const queue = [{ obj: { o: value }, prop: 'o' }];\n  const refs = [];\n\n  for (let i = 0; i < queue.length; ++i) {\n    const item = queue[i];\n    // @ts-ignore\n    const obj = item.obj[item.prop];\n\n    const keys = Object.keys(obj);\n    for (let j = 0; j < keys.length; ++j) {\n      const key = keys[j]!;\n      const val = obj[key];\n      if (typeof val === 'object' && val !== null && refs.indexOf(val) === -1) {\n        queue.push({ obj: obj, prop: key });\n        refs.push(val);\n      }\n    }\n  }\n\n  compact_queue(queue);\n\n  return value;\n}\n\nexport function is_regexp(obj: any) {\n  return Object.prototype.toString.call(obj) === '[object RegExp]';\n}\n\nexport function is_buffer(obj: any) {\n  if (!obj || typeof obj !== 'object') {\n    return false;\n  }\n\n  return !!(obj.constructor && obj.constructor.isBuffer && obj.constructor.isBuffer(obj));\n}\n\nexport function combine(a: any, b: any) {\n  return [].concat(a, b);\n}\n\nexport function maybe_map<T>(val: T[], fn: (v: T) => T) {\n  if (is_array(val)) {\n    const mapped = [];\n    for (let i = 0; i < val.length; i += 1) {\n      mapped.push(fn(val[i]!));\n    }\n    return mapped;\n  }\n  return fn(val);\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;AAGA,MAAM,MAAM,OAAO,SAAS,CAAC,cAAc;AAC3C,MAAM,WAAW,MAAM,OAAO;AAE9B,MAAM,YAAY,CAAC;IACjB,MAAM,QAAQ,EAAE;IAChB,IAAK,IAAI,IAAI,GAAG,IAAI,KAAK,EAAE,EAAG;QAC5B,MAAM,IAAI,CAAC,MAAM,CAAC,CAAC,IAAI,KAAK,MAAM,EAAE,IAAI,EAAE,QAAQ,CAAC,GAAG,EAAE,WAAW;;IAGrE,OAAO;AACT,CAAC;AAED,SAAS,cAA6C,KAAsC;IAC1F,MAAO,MAAM,MAAM,GAAG,EAAG;QACvB,MAAM,OAAO,MAAM,GAAG;QACtB,IAAI,CAAC,MAAM;QAEX,MAAM,MAAM,KAAK,GAAG,CAAC,KAAK,IAAI,CAAC;QAE/B,IAAI,SAAS,MAAM;YACjB,MAAM,YAAuB,EAAE;YAE/B,IAAK,IAAI,IAAI,GAAG,IAAI,IAAI,MAAM,EAAE,EAAE,EAAG;gBACnC,IAAI,OAAO,GAAG,CAAC,EAAE,KAAK,aAAa;oBACjC,UAAU,IAAI,CAAC,GAAG,CAAC,EAAE;;;YAIzB,aAAa;YACb,KAAK,GAAG,CAAC,KAAK,IAAI,CAAC,GAAG;;;AAG5B;AAEA,SAAS,gBAAgB,MAAa,EAAE,OAAkC;IACxE,MAAM,MAAM,WAAW,QAAQ,YAAY,GAAG,OAAO,MAAM,CAAC,QAAQ,CAAA;IACpE,IAAK,IAAI,IAAI,GAAG,IAAI,OAAO,MAAM,EAAE,EAAE,EAAG;QACtC,IAAI,OAAO,MAAM,CAAC,EAAE,KAAK,aAAa;YACpC,GAAG,CAAC,EAAE,GAAG,MAAM,CAAC,EAAE;;;IAItB,OAAO;AACT;AAEM,SAAU,MACd,MAAW,EACX,MAAW,EACX,UAAiE,CAAA,CAAE;IAEnE,IAAI,CAAC,QAAQ;QACX,OAAO;;IAGT,IAAI,OAAO,WAAW,UAAU;QAC9B,IAAI,SAAS,SAAS;YACpB,OAAO,IAAI,CAAC;eACP,IAAI,UAAU,OAAO,WAAW,UAAU;YAC/C,IACE,AAAC,WAAW,CAAC,QAAQ,YAAY,IAAI,QAAQ,eAAe,KAC5D,CAAC,IAAI,IAAI,CAAC,OAAO,SAAS,EAAE,SAC5B;gBACA,MAAM,CAAC,OAAO,GAAG;;eAEd;YACL,OAAO;gBAAC;gBAAQ;aAAO;;QAGzB,OAAO;;IAGT,IAAI,CAAC,UAAU,OAAO,WAAW,UAAU;QACzC,OAAO;YAAC;SAAO,CAAC,MAAM,CAAC;;IAGzB,IAAI,cAAc;IAClB,IAAI,SAAS,WAAW,CAAC,SAAS,SAAS;QACzC,aAAa;QACb,cAAc,gBAAgB,QAAQ;;IAGxC,IAAI,SAAS,WAAW,SAAS,SAAS;QACxC,OAAO,OAAO,CAAC,SAAU,IAAI,EAAE,CAAC;YAC9B,IAAI,IAAI,IAAI,CAAC,QAAQ,IAAI;gBACvB,MAAM,aAAa,MAAM,CAAC,EAAE;gBAC5B,IAAI,cAAc,OAAO,eAAe,YAAY,QAAQ,OAAO,SAAS,UAAU;oBACpF,MAAM,CAAC,EAAE,GAAG,MAAM,YAAY,MAAM;uBAC/B;oBACL,OAAO,IAAI,CAAC;;mBAET;gBACL,MAAM,CAAC,EAAE,GAAG;;QAEhB;QACA,OAAO;;IAGT,OAAO,OAAO,IAAI,CAAC,QAAQ,MAAM,CAAC,SAAU,GAAG,EAAE,GAAG;QAClD,MAAM,QAAQ,MAAM,CAAC,IAAI;QAEzB,IAAI,IAAI,IAAI,CAAC,KAAK,MAAM;YACtB,GAAG,CAAC,IAAI,GAAG,MAAM,GAAG,CAAC,IAAI,EAAE,OAAO;eAC7B;YACL,GAAG,CAAC,IAAI,GAAG;;QAEb,OAAO;IACT,GAAG;AACL;AAEM,SAAU,qBAAqB,MAAW,EAAE,MAAW;IAC3D,OAAO,OAAO,IAAI,CAAC,QAAQ,MAAM,CAAC,SAAU,GAAG,EAAE,GAAG;QAClD,GAAG,CAAC,IAAI,GAAG,MAAM,CAAC,IAAI;QACtB,OAAO;IACT,GAAG;AACL;AAEM,SAAU,OAAO,GAAW,EAAE,CAAM,EAAE,OAAe;IACzD,MAAM,iBAAiB,IAAI,OAAO,CAAC,OAAO;IAC1C,IAAI,YAAY,cAAc;QAC5B,gDAAgD;QAChD,OAAO,eAAe,OAAO,CAAC,kBAAkB;;IAElD,QAAQ;IACR,IAAI;QACF,OAAO,mBAAmB;MAC1B,OAAO,GAAG;QACV,OAAO;;AAEX;AAEA,MAAM,QAAQ;AAEP,MAAM,SAMC,CAAC,KAAK,iBAAiB,SAAS,OAAO;IACnD,0FAA0F;IAC1F,8DAA8D;IAC9D,IAAI,IAAI,MAAM,KAAK,GAAG;QACpB,OAAO;;IAGT,IAAI,SAAS;IACb,IAAI,OAAO,QAAQ,UAAU;QAC3B,SAAS,OAAO,SAAS,CAAC,QAAQ,CAAC,IAAI,CAAC;WACnC,IAAI,OAAO,QAAQ,UAAU;QAClC,SAAS,OAAO;;IAGlB,IAAI,YAAY,cAAc;QAC5B,OAAO,OAAO,QAAQ,OAAO,CAAC,mBAAmB,SAAU,EAAE;YAC3D,OAAO,WAAW,SAAS,GAAG,KAAK,CAAC,IAAI,MAAM;QAChD;;IAGF,IAAI,MAAM;IACV,IAAK,IAAI,IAAI,GAAG,IAAI,OAAO,MAAM,EAAE,KAAK,MAAO;QAC7C,MAAM,UAAU,OAAO,MAAM,IAAI,QAAQ,OAAO,KAAK,CAAC,GAAG,IAAI,SAAS;QACtE,MAAM,MAAM,EAAE;QAEd,IAAK,IAAI,IAAI,GAAG,IAAI,QAAQ,MAAM,EAAE,EAAE,EAAG;YACvC,IAAI,IAAI,QAAQ,UAAU,CAAC;YAC3B,IACE,MAAM,QAAQ,IAAI;YAClB,MAAM,QAAQ,IAAI;YAClB,MAAM,QAAQ,IAAI;YAClB,MAAM,QACL,KAAK,QAAQ,KAAK,QAClB,KAAK,QAAQ,KAAK,QAClB,KAAK,QAAQ,KAAK,QAClB,WAAW,sJAAA,CAAA,UAAO,IAAI,CAAC,MAAM,QAAQ,MAAM,IAAI,EAAG,MAAM;cACzD;gBACA,GAAG,CAAC,IAAI,MAAM,CAAC,GAAG,QAAQ,MAAM,CAAC;gBACjC;;YAGF,IAAI,IAAI,MAAM;gBACZ,GAAG,CAAC,IAAI,MAAM,CAAC,GAAG,SAAS,CAAC,EAAE;gBAC9B;;YAGF,IAAI,IAAI,OAAO;gBACb,GAAG,CAAC,IAAI,MAAM,CAAC,GAAG,SAAS,CAAC,OAAQ,KAAK,EAAI,GAAG,SAAS,CAAC,OAAQ,IAAI,KAAM;gBAC5E;;YAGF,IAAI,IAAI,UAAU,KAAK,QAAQ;gBAC7B,GAAG,CAAC,IAAI,MAAM,CAAC,GACb,SAAS,CAAC,OAAQ,KAAK,GAAK,GAAG,SAAS,CAAC,OAAQ,AAAC,KAAK,IAAK,KAAM,GAAG,SAAS,CAAC,OAAQ,IAAI,KAAM;gBACnG;;YAGF,KAAK;YACL,IAAI,UAAU,CAAC,AAAC,CAAC,IAAI,KAAK,KAAK,KAAO,QAAQ,UAAU,CAAC,KAAK,KAAM;YAEpE,GAAG,CAAC,IAAI,MAAM,CAAC,GACb,SAAS,CAAC,OAAQ,KAAK,GAAK,GAC5B,SAAS,CAAC,OAAQ,AAAC,KAAK,KAAM,KAAM,GACpC,SAAS,CAAC,OAAQ,AAAC,KAAK,IAAK,KAAM,GACnC,SAAS,CAAC,OAAQ,IAAI,KAAM;;QAGhC,OAAO,IAAI,IAAI,CAAC;;IAGlB,OAAO;AACT;AAEM,SAAU,QAAQ,KAAU;IAChC,MAAM,QAAQ;QAAC;YAAE,KAAK;gBAAE,GAAG;YAAK;YAAI,MAAM;QAAG;KAAG;IAChD,MAAM,OAAO,EAAE;IAEf,IAAK,IAAI,IAAI,GAAG,IAAI,MAAM,MAAM,EAAE,EAAE,EAAG;QACrC,MAAM,OAAO,KAAK,CAAC,EAAE;QACrB,aAAa;QACb,MAAM,MAAM,KAAK,GAAG,CAAC,KAAK,IAAI,CAAC;QAE/B,MAAM,OAAO,OAAO,IAAI,CAAC;QACzB,IAAK,IAAI,IAAI,GAAG,IAAI,KAAK,MAAM,EAAE,EAAE,EAAG;YACpC,MAAM,MAAM,IAAI,CAAC,EAAG;YACpB,MAAM,MAAM,GAAG,CAAC,IAAI;YACpB,IAAI,OAAO,QAAQ,YAAY,QAAQ,QAAQ,KAAK,OAAO,CAAC,SAAS,CAAC,GAAG;gBACvE,MAAM,IAAI,CAAC;oBAAE,KAAK;oBAAK,MAAM;gBAAG;gBAChC,KAAK,IAAI,CAAC;;;;IAKhB,cAAc;IAEd,OAAO;AACT;AAEM,SAAU,UAAU,GAAQ;IAChC,OAAO,OAAO,SAAS,CAAC,QAAQ,CAAC,IAAI,CAAC,SAAS;AACjD;AAEM,SAAU,UAAU,GAAQ;IAChC,IAAI,CAAC,OAAO,OAAO,QAAQ,UAAU;QACnC,OAAO;;IAGT,OAAO,CAAC,CAAC,CAAC,IAAI,WAAW,IAAI,IAAI,WAAW,CAAC,QAAQ,IAAI,IAAI,WAAW,CAAC,QAAQ,CAAC,IAAI;AACxF;AAEM,SAAU,QAAQ,CAAM,EAAE,CAAM;IACpC,OAAO,EAAE,CAAC,MAAM,CAAC,GAAG;AACtB;AAEM,SAAU,UAAa,GAAQ,EAAE,EAAe;IACpD,IAAI,SAAS,MAAM;QACjB,MAAM,SAAS,EAAE;QACjB,IAAK,IAAI,IAAI,GAAG,IAAI,IAAI,MAAM,EAAE,KAAK,EAAG;YACtC,OAAO,IAAI,CAAC,GAAG,GAAG,CAAC,EAAG;;QAExB,OAAO;;IAET,OAAO,GAAG;AACZ"}},
    {"offset": {"line": 2199, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 2204, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/internal/qs/stringify.ts"],"sourcesContent":["import { encode, is_buffer, maybe_map } from './utils';\nimport { default_format, formatters } from './formats';\nimport type { NonNullableProperties, StringifyOptions } from './types';\n\nconst has = Object.prototype.hasOwnProperty;\n\nconst array_prefix_generators = {\n  brackets(prefix: PropertyKey) {\n    return String(prefix) + '[]';\n  },\n  comma: 'comma',\n  indices(prefix: PropertyKey, key: string) {\n    return String(prefix) + '[' + key + ']';\n  },\n  repeat(prefix: PropertyKey) {\n    return String(prefix);\n  },\n};\n\nconst is_array = Array.isArray;\nconst push = Array.prototype.push;\nconst push_to_array = function (arr: any[], value_or_array: any) {\n  push.apply(arr, is_array(value_or_array) ? value_or_array : [value_or_array]);\n};\n\nconst to_ISO = Date.prototype.toISOString;\n\nconst defaults = {\n  addQueryPrefix: false,\n  allowDots: false,\n  allowEmptyArrays: false,\n  arrayFormat: 'indices',\n  charset: 'utf-8',\n  charsetSentinel: false,\n  delimiter: '&',\n  encode: true,\n  encodeDotInKeys: false,\n  encoder: encode,\n  encodeValuesOnly: false,\n  format: default_format,\n  formatter: formatters[default_format],\n  /** @deprecated */\n  indices: false,\n  serializeDate(date) {\n    return to_ISO.call(date);\n  },\n  skipNulls: false,\n  strictNullHandling: false,\n} as NonNullableProperties<StringifyOptions & { formatter: (typeof formatters)['RFC1738'] }>;\n\nfunction is_non_nullish_primitive(v: unknown): v is string | number | boolean | symbol | bigint {\n  return (\n    typeof v === 'string' ||\n    typeof v === 'number' ||\n    typeof v === 'boolean' ||\n    typeof v === 'symbol' ||\n    typeof v === 'bigint'\n  );\n}\n\nconst sentinel = {};\n\nfunction inner_stringify(\n  object: any,\n  prefix: PropertyKey,\n  generateArrayPrefix: StringifyOptions['arrayFormat'] | ((prefix: string, key: string) => string),\n  commaRoundTrip: boolean,\n  allowEmptyArrays: boolean,\n  strictNullHandling: boolean,\n  skipNulls: boolean,\n  encodeDotInKeys: boolean,\n  encoder: StringifyOptions['encoder'],\n  filter: StringifyOptions['filter'],\n  sort: StringifyOptions['sort'],\n  allowDots: StringifyOptions['allowDots'],\n  serializeDate: StringifyOptions['serializeDate'],\n  format: StringifyOptions['format'],\n  formatter: StringifyOptions['formatter'],\n  encodeValuesOnly: boolean,\n  charset: StringifyOptions['charset'],\n  sideChannel: WeakMap<any, any>,\n) {\n  let obj = object;\n\n  let tmp_sc = sideChannel;\n  let step = 0;\n  let find_flag = false;\n  while ((tmp_sc = tmp_sc.get(sentinel)) !== void undefined && !find_flag) {\n    // Where object last appeared in the ref tree\n    const pos = tmp_sc.get(object);\n    step += 1;\n    if (typeof pos !== 'undefined') {\n      if (pos === step) {\n        throw new RangeError('Cyclic object value');\n      } else {\n        find_flag = true; // Break while\n      }\n    }\n    if (typeof tmp_sc.get(sentinel) === 'undefined') {\n      step = 0;\n    }\n  }\n\n  if (typeof filter === 'function') {\n    obj = filter(prefix, obj);\n  } else if (obj instanceof Date) {\n    obj = serializeDate?.(obj);\n  } else if (generateArrayPrefix === 'comma' && is_array(obj)) {\n    obj = maybe_map(obj, function (value) {\n      if (value instanceof Date) {\n        return serializeDate?.(value);\n      }\n      return value;\n    });\n  }\n\n  if (obj === null) {\n    if (strictNullHandling) {\n      return encoder && !encodeValuesOnly ?\n          // @ts-expect-error\n          encoder(prefix, defaults.encoder, charset, 'key', format)\n        : prefix;\n    }\n\n    obj = '';\n  }\n\n  if (is_non_nullish_primitive(obj) || is_buffer(obj)) {\n    if (encoder) {\n      const key_value =\n        encodeValuesOnly ? prefix\n          // @ts-expect-error\n        : encoder(prefix, defaults.encoder, charset, 'key', format);\n      return [\n        formatter?.(key_value) +\n          '=' +\n          // @ts-expect-error\n          formatter?.(encoder(obj, defaults.encoder, charset, 'value', format)),\n      ];\n    }\n    return [formatter?.(prefix) + '=' + formatter?.(String(obj))];\n  }\n\n  const values: string[] = [];\n\n  if (typeof obj === 'undefined') {\n    return values;\n  }\n\n  let obj_keys;\n  if (generateArrayPrefix === 'comma' && is_array(obj)) {\n    // we need to join elements in\n    if (encodeValuesOnly && encoder) {\n      // @ts-expect-error values only\n      obj = maybe_map(obj, encoder);\n    }\n    obj_keys = [{ value: obj.length > 0 ? obj.join(',') || null : void undefined }];\n  } else if (is_array(filter)) {\n    obj_keys = filter;\n  } else {\n    const keys = Object.keys(obj);\n    obj_keys = sort ? keys.sort(sort) : keys;\n  }\n\n  const encoded_prefix = encodeDotInKeys ? String(prefix).replace(/\\./g, '%2E') : String(prefix);\n\n  const adjusted_prefix =\n    commaRoundTrip && is_array(obj) && obj.length === 1 ? encoded_prefix + '[]' : encoded_prefix;\n\n  if (allowEmptyArrays && is_array(obj) && obj.length === 0) {\n    return adjusted_prefix + '[]';\n  }\n\n  for (let j = 0; j < obj_keys.length; ++j) {\n    const key = obj_keys[j];\n    const value =\n      // @ts-ignore\n      typeof key === 'object' && typeof key.value !== 'undefined' ? key.value : obj[key as any];\n\n    if (skipNulls && value === null) {\n      continue;\n    }\n\n    // @ts-ignore\n    const encoded_key = allowDots && encodeDotInKeys ? (key as any).replace(/\\./g, '%2E') : key;\n    const key_prefix =\n      is_array(obj) ?\n        typeof generateArrayPrefix === 'function' ?\n          generateArrayPrefix(adjusted_prefix, encoded_key)\n        : adjusted_prefix\n      : adjusted_prefix + (allowDots ? '.' + encoded_key : '[' + encoded_key + ']');\n\n    sideChannel.set(object, step);\n    const valueSideChannel = new WeakMap();\n    valueSideChannel.set(sentinel, sideChannel);\n    push_to_array(\n      values,\n      inner_stringify(\n        value,\n        key_prefix,\n        generateArrayPrefix,\n        commaRoundTrip,\n        allowEmptyArrays,\n        strictNullHandling,\n        skipNulls,\n        encodeDotInKeys,\n        // @ts-ignore\n        generateArrayPrefix === 'comma' && encodeValuesOnly && is_array(obj) ? null : encoder,\n        filter,\n        sort,\n        allowDots,\n        serializeDate,\n        format,\n        formatter,\n        encodeValuesOnly,\n        charset,\n        valueSideChannel,\n      ),\n    );\n  }\n\n  return values;\n}\n\nfunction normalize_stringify_options(\n  opts: StringifyOptions = defaults,\n): NonNullableProperties<Omit<StringifyOptions, 'indices'>> & { indices?: boolean } {\n  if (typeof opts.allowEmptyArrays !== 'undefined' && typeof opts.allowEmptyArrays !== 'boolean') {\n    throw new TypeError('`allowEmptyArrays` option can only be `true` or `false`, when provided');\n  }\n\n  if (typeof opts.encodeDotInKeys !== 'undefined' && typeof opts.encodeDotInKeys !== 'boolean') {\n    throw new TypeError('`encodeDotInKeys` option can only be `true` or `false`, when provided');\n  }\n\n  if (opts.encoder !== null && typeof opts.encoder !== 'undefined' && typeof opts.encoder !== 'function') {\n    throw new TypeError('Encoder has to be a function.');\n  }\n\n  const charset = opts.charset || defaults.charset;\n  if (typeof opts.charset !== 'undefined' && opts.charset !== 'utf-8' && opts.charset !== 'iso-8859-1') {\n    throw new TypeError('The charset option must be either utf-8, iso-8859-1, or undefined');\n  }\n\n  let format = default_format;\n  if (typeof opts.format !== 'undefined') {\n    if (!has.call(formatters, opts.format)) {\n      throw new TypeError('Unknown format option provided.');\n    }\n    format = opts.format;\n  }\n  const formatter = formatters[format];\n\n  let filter = defaults.filter;\n  if (typeof opts.filter === 'function' || is_array(opts.filter)) {\n    filter = opts.filter;\n  }\n\n  let arrayFormat: StringifyOptions['arrayFormat'];\n  if (opts.arrayFormat && opts.arrayFormat in array_prefix_generators) {\n    arrayFormat = opts.arrayFormat;\n  } else if ('indices' in opts) {\n    arrayFormat = opts.indices ? 'indices' : 'repeat';\n  } else {\n    arrayFormat = defaults.arrayFormat;\n  }\n\n  if ('commaRoundTrip' in opts && typeof opts.commaRoundTrip !== 'boolean') {\n    throw new TypeError('`commaRoundTrip` must be a boolean, or absent');\n  }\n\n  const allowDots =\n    typeof opts.allowDots === 'undefined' ?\n      !!opts.encodeDotInKeys === true ?\n        true\n      : defaults.allowDots\n    : !!opts.allowDots;\n\n  return {\n    addQueryPrefix: typeof opts.addQueryPrefix === 'boolean' ? opts.addQueryPrefix : defaults.addQueryPrefix,\n    // @ts-ignore\n    allowDots: allowDots,\n    allowEmptyArrays:\n      typeof opts.allowEmptyArrays === 'boolean' ? !!opts.allowEmptyArrays : defaults.allowEmptyArrays,\n    arrayFormat: arrayFormat,\n    charset: charset,\n    charsetSentinel:\n      typeof opts.charsetSentinel === 'boolean' ? opts.charsetSentinel : defaults.charsetSentinel,\n    commaRoundTrip: !!opts.commaRoundTrip,\n    delimiter: typeof opts.delimiter === 'undefined' ? defaults.delimiter : opts.delimiter,\n    encode: typeof opts.encode === 'boolean' ? opts.encode : defaults.encode,\n    encodeDotInKeys:\n      typeof opts.encodeDotInKeys === 'boolean' ? opts.encodeDotInKeys : defaults.encodeDotInKeys,\n    encoder: typeof opts.encoder === 'function' ? opts.encoder : defaults.encoder,\n    encodeValuesOnly:\n      typeof opts.encodeValuesOnly === 'boolean' ? opts.encodeValuesOnly : defaults.encodeValuesOnly,\n    filter: filter,\n    format: format,\n    formatter: formatter,\n    serializeDate: typeof opts.serializeDate === 'function' ? opts.serializeDate : defaults.serializeDate,\n    skipNulls: typeof opts.skipNulls === 'boolean' ? opts.skipNulls : defaults.skipNulls,\n    // @ts-ignore\n    sort: typeof opts.sort === 'function' ? opts.sort : null,\n    strictNullHandling:\n      typeof opts.strictNullHandling === 'boolean' ? opts.strictNullHandling : defaults.strictNullHandling,\n  };\n}\n\nexport function stringify(object: any, opts: StringifyOptions = {}) {\n  let obj = object;\n  const options = normalize_stringify_options(opts);\n\n  let obj_keys: PropertyKey[] | undefined;\n  let filter;\n\n  if (typeof options.filter === 'function') {\n    filter = options.filter;\n    obj = filter('', obj);\n  } else if (is_array(options.filter)) {\n    filter = options.filter;\n    obj_keys = filter;\n  }\n\n  const keys: string[] = [];\n\n  if (typeof obj !== 'object' || obj === null) {\n    return '';\n  }\n\n  const generateArrayPrefix = array_prefix_generators[options.arrayFormat];\n  const commaRoundTrip = generateArrayPrefix === 'comma' && options.commaRoundTrip;\n\n  if (!obj_keys) {\n    obj_keys = Object.keys(obj);\n  }\n\n  if (options.sort) {\n    obj_keys.sort(options.sort);\n  }\n\n  const sideChannel = new WeakMap();\n  for (let i = 0; i < obj_keys.length; ++i) {\n    const key = obj_keys[i]!;\n\n    if (options.skipNulls && obj[key] === null) {\n      continue;\n    }\n    push_to_array(\n      keys,\n      inner_stringify(\n        obj[key],\n        key,\n        // @ts-expect-error\n        generateArrayPrefix,\n        commaRoundTrip,\n        options.allowEmptyArrays,\n        options.strictNullHandling,\n        options.skipNulls,\n        options.encodeDotInKeys,\n        options.encode ? options.encoder : null,\n        options.filter,\n        options.sort,\n        options.allowDots,\n        options.serializeDate,\n        options.format,\n        options.formatter,\n        options.encodeValuesOnly,\n        options.charset,\n        sideChannel,\n      ),\n    );\n  }\n\n  const joined = keys.join(options.delimiter);\n  let prefix = options.addQueryPrefix === true ? '?' : '';\n\n  if (options.charsetSentinel) {\n    if (options.charset === 'iso-8859-1') {\n      // encodeURIComponent('&#10003;'), the \"numeric entity\" representation of a checkmark\n      prefix += 'utf8=%26%2310003%3B&';\n    } else {\n      // encodeURIComponent('✓')\n      prefix += 'utf8=%E2%9C%93&';\n    }\n  }\n\n  return joined.length > 0 ? prefix + joined : '';\n}\n"],"names":[],"mappings":";;;;;;;;AAIA,MAAM,MAAM,OAAO,SAAS,CAAC,cAAc;AAE3C,MAAM,0BAA0B;IAC9B,UAAS,MAAmB;QAC1B,OAAO,OAAO,UAAU;IAC1B;IACA,OAAO;IACP,SAAQ,MAAmB,EAAE,GAAW;QACtC,OAAO,OAAO,UAAU,MAAM,MAAM;IACtC;IACA,QAAO,MAAmB;QACxB,OAAO,OAAO;IAChB;;AAGF,MAAM,WAAW,MAAM,OAAO;AAC9B,MAAM,OAAO,MAAM,SAAS,CAAC,IAAI;AACjC,MAAM,gBAAgB,SAAU,GAAU,EAAE,cAAmB;IAC7D,KAAK,KAAK,CAAC,KAAK,SAAS,kBAAkB,iBAAiB;QAAC;KAAe;AAC9E;AAEA,MAAM,SAAS,KAAK,SAAS,CAAC,WAAW;AAEzC,MAAM,WAAW;IACf,gBAAgB;IAChB,WAAW;IACX,kBAAkB;IAClB,aAAa;IACb,SAAS;IACT,iBAAiB;IACjB,WAAW;IACX,QAAQ;IACR,iBAAiB;IACjB,SAAS,oJAAA,CAAA,SAAM;IACf,kBAAkB;IAClB,QAAQ,sJAAA,CAAA,iBAAc;IACtB,WAAW,sJAAA,CAAA,aAAU,CAAC,sJAAA,CAAA,iBAAc,CAAC;IACrC,gBAAA,GACA,SAAS;IACT,eAAc,IAAI;QAChB,OAAO,OAAO,IAAI,CAAC;IACrB;IACA,WAAW;IACX,oBAAoB;;AAGtB,SAAS,yBAAyB,CAAU;IAC1C,OACE,OAAO,MAAM,YACb,OAAO,MAAM,YACb,OAAO,MAAM,aACb,OAAO,MAAM,YACb,OAAO,MAAM;AAEjB;AAEA,MAAM,WAAW,CAAA;AAEjB,SAAS,gBACP,MAAW,EACX,MAAmB,EACnB,mBAAgG,EAChG,cAAuB,EACvB,gBAAyB,EACzB,kBAA2B,EAC3B,SAAkB,EAClB,eAAwB,EACxB,OAAoC,EACpC,MAAkC,EAClC,IAA8B,EAC9B,SAAwC,EACxC,aAAgD,EAChD,MAAkC,EAClC,SAAwC,EACxC,gBAAyB,EACzB,OAAoC,EACpC,WAA8B;IAE9B,IAAI,MAAM;IAEV,IAAI,SAAS;IACb,IAAI,OAAO;IACX,IAAI,YAAY;IAChB,MAAO,CAAC,SAAS,OAAO,GAAG,CAAC,SAAS,MAAM,KAAK,aAAa,CAAC,UAAW;QACvE,6CAA6C;QAC7C,MAAM,MAAM,OAAO,GAAG,CAAC;QACvB,QAAQ;QACR,IAAI,OAAO,QAAQ,aAAa;YAC9B,IAAI,QAAQ,MAAM;gBAChB,MAAM,IAAI,WAAW;mBAChB;gBACL,YAAY,MAAM,cAAc;;;QAGpC,IAAI,OAAO,OAAO,GAAG,CAAC,cAAc,aAAa;YAC/C,OAAO;;;IAIX,IAAI,OAAO,WAAW,YAAY;QAChC,MAAM,OAAO,QAAQ;WAChB,IAAI,eAAe,MAAM;QAC9B,MAAM,gBAAgB;WACjB,IAAI,wBAAwB,WAAW,SAAS,MAAM;QAC3D,MAAM,CAAA,GAAA,oJAAA,CAAA,YAAS,AAAT,EAAU,KAAK,SAAU,KAAK;YAClC,IAAI,iBAAiB,MAAM;gBACzB,OAAO,gBAAgB;;YAEzB,OAAO;QACT;;IAGF,IAAI,QAAQ,MAAM;QAChB,IAAI,oBAAoB;YACtB,OAAO,WAAW,CAAC,mBACf,mBAAmB;YACnB,QAAQ,QAAQ,SAAS,OAAO,EAAE,SAAS,OAAO,UAClD;;QAGN,MAAM;;IAGR,IAAI,yBAAyB,QAAQ,CAAA,GAAA,oJAAA,CAAA,YAAS,AAAT,EAAU,MAAM;QACnD,IAAI,SAAS;YACX,MAAM,YACJ,mBAAmB,SAEjB,QAAQ,QAAQ,SAAS,OAAO,EAAE,SAAS,OAAO;YACtD,OAAO;gBACL,YAAY,aACV,MACA,mBAAmB;gBACnB,YAAY,QAAQ,KAAK,SAAS,OAAO,EAAE,SAAS,SAAS;aAChE;;QAEH,OAAO;YAAC,YAAY,UAAU,MAAM,YAAY,OAAO;SAAM;;IAG/D,MAAM,SAAmB,EAAE;IAE3B,IAAI,OAAO,QAAQ,aAAa;QAC9B,OAAO;;IAGT,IAAI;IACJ,IAAI,wBAAwB,WAAW,SAAS,MAAM;QACpD,8BAA8B;QAC9B,IAAI,oBAAoB,SAAS;YAC/B,+BAA+B;YAC/B,MAAM,CAAA,GAAA,oJAAA,CAAA,YAAS,AAAT,EAAU,KAAK;;QAEvB,WAAW;YAAC;gBAAE,OAAO,IAAI,MAAM,GAAG,IAAI,IAAI,IAAI,CAAC,QAAQ,OAAO,KAAK;YAAS;SAAG;WAC1E,IAAI,SAAS,SAAS;QAC3B,WAAW;WACN;QACL,MAAM,OAAO,OAAO,IAAI,CAAC;QACzB,WAAW,OAAO,KAAK,IAAI,CAAC,QAAQ;;IAGtC,MAAM,iBAAiB,kBAAkB,OAAO,QAAQ,OAAO,CAAC,OAAO,SAAS,OAAO;IAEvF,MAAM,kBACJ,kBAAkB,SAAS,QAAQ,IAAI,MAAM,KAAK,IAAI,iBAAiB,OAAO;IAEhF,IAAI,oBAAoB,SAAS,QAAQ,IAAI,MAAM,KAAK,GAAG;QACzD,OAAO,kBAAkB;;IAG3B,IAAK,IAAI,IAAI,GAAG,IAAI,SAAS,MAAM,EAAE,EAAE,EAAG;QACxC,MAAM,MAAM,QAAQ,CAAC,EAAE;QACvB,MAAM,QACJ,aAAa;QACb,OAAO,QAAQ,YAAY,OAAO,IAAI,KAAK,KAAK,cAAc,IAAI,KAAK,GAAG,GAAG,CAAC,IAAW;QAE3F,IAAI,aAAa,UAAU,MAAM;YAC/B;;QAGF,aAAa;QACb,MAAM,cAAc,aAAa,kBAAmB,IAAY,OAAO,CAAC,OAAO,SAAS;QACxF,MAAM,aACJ,SAAS,OACP,OAAO,wBAAwB,aAC7B,oBAAoB,iBAAiB,eACrC,kBACF,kBAAkB,CAAC,YAAY,MAAM,cAAc,MAAM,cAAc,GAAG;QAE9E,YAAY,GAAG,CAAC,QAAQ;QACxB,MAAM,mBAAmB,IAAI;QAC7B,iBAAiB,GAAG,CAAC,UAAU;QAC/B,cACE,QACA,gBACE,OACA,YACA,qBACA,gBACA,kBACA,oBACA,WACA,iBACA,aAAa;QACb,wBAAwB,WAAW,oBAAoB,SAAS,OAAO,OAAO,SAC9E,QACA,MACA,WACA,eACA,QACA,WACA,kBACA,SACA;;IAKN,OAAO;AACT;AAEA,SAAS,4BACP,OAAyB,QAAQ;IAEjC,IAAI,OAAO,KAAK,gBAAgB,KAAK,eAAe,OAAO,KAAK,gBAAgB,KAAK,WAAW;QAC9F,MAAM,IAAI,UAAU;;IAGtB,IAAI,OAAO,KAAK,eAAe,KAAK,eAAe,OAAO,KAAK,eAAe,KAAK,WAAW;QAC5F,MAAM,IAAI,UAAU;;IAGtB,IAAI,KAAK,OAAO,KAAK,QAAQ,OAAO,KAAK,OAAO,KAAK,eAAe,OAAO,KAAK,OAAO,KAAK,YAAY;QACtG,MAAM,IAAI,UAAU;;IAGtB,MAAM,UAAU,KAAK,OAAO,IAAI,SAAS,OAAO;IAChD,IAAI,OAAO,KAAK,OAAO,KAAK,eAAe,KAAK,OAAO,KAAK,WAAW,KAAK,OAAO,KAAK,cAAc;QACpG,MAAM,IAAI,UAAU;;IAGtB,IAAI,SAAS,sJAAA,CAAA,iBAAc;IAC3B,IAAI,OAAO,KAAK,MAAM,KAAK,aAAa;QACtC,IAAI,CAAC,IAAI,IAAI,CAAC,sJAAA,CAAA,aAAU,EAAE,KAAK,MAAM,GAAG;YACtC,MAAM,IAAI,UAAU;;QAEtB,SAAS,KAAK,MAAM;;IAEtB,MAAM,YAAY,sJAAA,CAAA,aAAU,CAAC,OAAO;IAEpC,IAAI,SAAS,SAAS,MAAM;IAC5B,IAAI,OAAO,KAAK,MAAM,KAAK,cAAc,SAAS,KAAK,MAAM,GAAG;QAC9D,SAAS,KAAK,MAAM;;IAGtB,IAAI;IACJ,IAAI,KAAK,WAAW,IAAI,KAAK,WAAW,IAAI,yBAAyB;QACnE,cAAc,KAAK,WAAW;WACzB,IAAI,aAAa,MAAM;QAC5B,cAAc,KAAK,OAAO,GAAG,YAAY;WACpC;QACL,cAAc,SAAS,WAAW;;IAGpC,IAAI,oBAAoB,QAAQ,OAAO,KAAK,cAAc,KAAK,WAAW;QACxE,MAAM,IAAI,UAAU;;IAGtB,MAAM,YACJ,OAAO,KAAK,SAAS,KAAK,cACxB,CAAC,CAAC,KAAK,eAAe,KAAK,OACzB,OACA,SAAS,SAAS,GACpB,CAAC,CAAC,KAAK,SAAS;IAEpB,OAAO;QACL,gBAAgB,OAAO,KAAK,cAAc,KAAK,YAAY,KAAK,cAAc,GAAG,SAAS,cAAc;QACxG,aAAa;QACb,WAAW;QACX,kBACE,OAAO,KAAK,gBAAgB,KAAK,YAAY,CAAC,CAAC,KAAK,gBAAgB,GAAG,SAAS,gBAAgB;QAClG,aAAa;QACb,SAAS;QACT,iBACE,OAAO,KAAK,eAAe,KAAK,YAAY,KAAK,eAAe,GAAG,SAAS,eAAe;QAC7F,gBAAgB,CAAC,CAAC,KAAK,cAAc;QACrC,WAAW,OAAO,KAAK,SAAS,KAAK,cAAc,SAAS,SAAS,GAAG,KAAK,SAAS;QACtF,QAAQ,OAAO,KAAK,MAAM,KAAK,YAAY,KAAK,MAAM,GAAG,SAAS,MAAM;QACxE,iBACE,OAAO,KAAK,eAAe,KAAK,YAAY,KAAK,eAAe,GAAG,SAAS,eAAe;QAC7F,SAAS,OAAO,KAAK,OAAO,KAAK,aAAa,KAAK,OAAO,GAAG,SAAS,OAAO;QAC7E,kBACE,OAAO,KAAK,gBAAgB,KAAK,YAAY,KAAK,gBAAgB,GAAG,SAAS,gBAAgB;QAChG,QAAQ;QACR,QAAQ;QACR,WAAW;QACX,eAAe,OAAO,KAAK,aAAa,KAAK,aAAa,KAAK,aAAa,GAAG,SAAS,aAAa;QACrG,WAAW,OAAO,KAAK,SAAS,KAAK,YAAY,KAAK,SAAS,GAAG,SAAS,SAAS;QACpF,aAAa;QACb,MAAM,OAAO,KAAK,IAAI,KAAK,aAAa,KAAK,IAAI,GAAG;QACpD,oBACE,OAAO,KAAK,kBAAkB,KAAK,YAAY,KAAK,kBAAkB,GAAG,SAAS,kBAAkB;;AAE1G;AAEM,SAAU,UAAU,MAAW,EAAE,OAAyB,CAAA,CAAE;IAChE,IAAI,MAAM;IACV,MAAM,UAAU,4BAA4B;IAE5C,IAAI;IACJ,IAAI;IAEJ,IAAI,OAAO,QAAQ,MAAM,KAAK,YAAY;QACxC,SAAS,QAAQ,MAAM;QACvB,MAAM,OAAO,IAAI;WACZ,IAAI,SAAS,QAAQ,MAAM,GAAG;QACnC,SAAS,QAAQ,MAAM;QACvB,WAAW;;IAGb,MAAM,OAAiB,EAAE;IAEzB,IAAI,OAAO,QAAQ,YAAY,QAAQ,MAAM;QAC3C,OAAO;;IAGT,MAAM,sBAAsB,uBAAuB,CAAC,QAAQ,WAAW,CAAC;IACxE,MAAM,iBAAiB,wBAAwB,WAAW,QAAQ,cAAc;IAEhF,IAAI,CAAC,UAAU;QACb,WAAW,OAAO,IAAI,CAAC;;IAGzB,IAAI,QAAQ,IAAI,EAAE;QAChB,SAAS,IAAI,CAAC,QAAQ,IAAI;;IAG5B,MAAM,cAAc,IAAI;IACxB,IAAK,IAAI,IAAI,GAAG,IAAI,SAAS,MAAM,EAAE,EAAE,EAAG;QACxC,MAAM,MAAM,QAAQ,CAAC,EAAG;QAExB,IAAI,QAAQ,SAAS,IAAI,GAAG,CAAC,IAAI,KAAK,MAAM;YAC1C;;QAEF,cACE,MACA,gBACE,GAAG,CAAC,IAAI,EACR,KACA,mBAAmB;QACnB,qBACA,gBACA,QAAQ,gBAAgB,EACxB,QAAQ,kBAAkB,EAC1B,QAAQ,SAAS,EACjB,QAAQ,eAAe,EACvB,QAAQ,MAAM,GAAG,QAAQ,OAAO,GAAG,MACnC,QAAQ,MAAM,EACd,QAAQ,IAAI,EACZ,QAAQ,SAAS,EACjB,QAAQ,aAAa,EACrB,QAAQ,MAAM,EACd,QAAQ,SAAS,EACjB,QAAQ,gBAAgB,EACxB,QAAQ,OAAO,EACf;;IAKN,MAAM,SAAS,KAAK,IAAI,CAAC,QAAQ,SAAS;IAC1C,IAAI,SAAS,QAAQ,cAAc,KAAK,OAAO,MAAM;IAErD,IAAI,QAAQ,eAAe,EAAE;QAC3B,IAAI,QAAQ,OAAO,KAAK,cAAc;YACpC,qFAAqF;YACrF,UAAU;eACL;YACL,0BAA0B;YAC1B,UAAU;;;IAId,OAAO,OAAO,MAAM,GAAG,IAAI,SAAS,SAAS;AAC/C"}},
    {"offset": {"line": 2462, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 2578, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/pagination.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { AbstractPage, Response, APIClient, FinalRequestOptions, PageInfo } from './core';\n\nexport interface PageResponse<Item> {\n  data: Array<Item>;\n\n  object: string;\n}\n\n/**\n * Note: no pagination actually occurs yet, this is for forwards-compatibility.\n */\nexport class Page<Item> extends AbstractPage<Item> implements PageResponse<Item> {\n  data: Array<Item>;\n\n  object: string;\n\n  constructor(client: APIClient, response: Response, body: PageResponse<Item>, options: FinalRequestOptions) {\n    super(client, response, body, options);\n\n    this.data = body.data || [];\n    this.object = body.object;\n  }\n\n  getPaginatedItems(): Item[] {\n    return this.data ?? [];\n  }\n\n  // @deprecated Please use `nextPageInfo()` instead\n  /**\n   * This page represents a response that isn't actually paginated at the API level\n   * so there will never be any next page params.\n   */\n  nextPageParams(): null {\n    return null;\n  }\n\n  nextPageInfo(): null {\n    return null;\n  }\n}\n\nexport interface CursorPageResponse<Item> {\n  data: Array<Item>;\n}\n\nexport interface CursorPageParams {\n  after?: string;\n\n  limit?: number;\n}\n\nexport class CursorPage<Item extends { id: string }>\n  extends AbstractPage<Item>\n  implements CursorPageResponse<Item>\n{\n  data: Array<Item>;\n\n  constructor(\n    client: APIClient,\n    response: Response,\n    body: CursorPageResponse<Item>,\n    options: FinalRequestOptions,\n  ) {\n    super(client, response, body, options);\n\n    this.data = body.data || [];\n  }\n\n  getPaginatedItems(): Item[] {\n    return this.data ?? [];\n  }\n\n  // @deprecated Please use `nextPageInfo()` instead\n  nextPageParams(): Partial<CursorPageParams> | null {\n    const info = this.nextPageInfo();\n    if (!info) return null;\n    if ('params' in info) return info.params;\n    const params = Object.fromEntries(info.url.searchParams);\n    if (!Object.keys(params).length) return null;\n    return params;\n  }\n\n  nextPageInfo(): PageInfo | null {\n    const data = this.getPaginatedItems();\n    if (!data.length) {\n      return null;\n    }\n\n    const id = data[data.length - 1]?.id;\n    if (!id) {\n      return null;\n    }\n\n    return { params: { after: id } };\n  }\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;AAahF,MAAO,aAAmB,iJAAA,CAAA,eAAkB;IAKhD,YAAY,MAAiB,EAAE,QAAkB,EAAE,IAAwB,EAAE,OAA4B,CAAA;QACvG,KAAK,CAAC,QAAQ,UAAU,MAAM;QAE9B,IAAI,CAAC,IAAI,GAAG,KAAK,IAAI,IAAI,EAAE;QAC3B,IAAI,CAAC,MAAM,GAAG,KAAK,MAAM;IAC3B;IAEA,oBAAiB;QACf,OAAO,IAAI,CAAC,IAAI,IAAI,EAAE;IACxB;IAEA,kDAAkD;IAClD;;;QAIA,iBAAc;QACZ,OAAO;IACT;IAEA,eAAY;QACV,OAAO;IACT;;AAaI,MAAO,mBACH,iJAAA,CAAA,eAAkB;IAK1B,YACE,MAAiB,EACjB,QAAkB,EAClB,IAA8B,EAC9B,OAA4B,CAAA;QAE5B,KAAK,CAAC,QAAQ,UAAU,MAAM;QAE9B,IAAI,CAAC,IAAI,GAAG,KAAK,IAAI,IAAI,EAAE;IAC7B;IAEA,oBAAiB;QACf,OAAO,IAAI,CAAC,IAAI,IAAI,EAAE;IACxB;IAEA,kDAAkD;IAClD,iBAAc;QACZ,MAAM,OAAO,IAAI,CAAC,YAAY;QAC9B,IAAI,CAAC,MAAM,OAAO;QAClB,IAAI,YAAY,MAAM,OAAO,KAAK,MAAM;QACxC,MAAM,SAAS,OAAO,WAAW,CAAC,KAAK,GAAG,CAAC,YAAY;QACvD,IAAI,CAAC,OAAO,IAAI,CAAC,QAAQ,MAAM,EAAE,OAAO;QACxC,OAAO;IACT;IAEA,eAAY;QACV,MAAM,OAAO,IAAI,CAAC,iBAAiB;QACnC,IAAI,CAAC,KAAK,MAAM,EAAE;YAChB,OAAO;;QAGT,MAAM,KAAK,IAAI,CAAC,KAAK,MAAM,GAAG,EAAE,EAAE;QAClC,IAAI,CAAC,IAAI;YACP,OAAO;;QAGT,OAAO;YAAE,QAAQ;gBAAE,OAAO;YAAE;QAAE;IAChC"}},
    {"offset": {"line": 2639, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 2644, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/index.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nexport * from './chat/index';\nexport * from './shared';\nexport { AudioModel, AudioResponseFormat, Audio } from './audio/audio';\nexport {\n  Batch,\n  BatchError,\n  BatchRequestCounts,\n  BatchCreateParams,\n  BatchListParams,\n  BatchesPage,\n  Batches,\n} from './batches';\nexport { Beta } from './beta/beta';\nexport {\n  Completion,\n  CompletionChoice,\n  CompletionUsage,\n  CompletionCreateParams,\n  CompletionCreateParamsNonStreaming,\n  CompletionCreateParamsStreaming,\n  Completions,\n} from './completions';\nexport {\n  CreateEmbeddingResponse,\n  Embedding,\n  EmbeddingModel,\n  EmbeddingCreateParams,\n  Embeddings,\n} from './embeddings';\nexport {\n  FileContent,\n  FileDeleted,\n  FileObject,\n  FilePurpose,\n  FileCreateParams,\n  FileListParams,\n  FileObjectsPage,\n  Files,\n} from './files';\nexport { FineTuning } from './fine-tuning/fine-tuning';\nexport {\n  Image,\n  ImageModel,\n  ImagesResponse,\n  ImageCreateVariationParams,\n  ImageEditParams,\n  ImageGenerateParams,\n  Images,\n} from './images';\nexport { Model, ModelDeleted, ModelsPage, Models } from './models';\nexport {\n  Moderation,\n  ModerationImageURLInput,\n  ModerationModel,\n  ModerationMultiModalInput,\n  ModerationTextInput,\n  ModerationCreateResponse,\n  ModerationCreateParams,\n  Moderations,\n} from './moderations';\nexport { Upload, UploadCreateParams, UploadCompleteParams, Uploads } from './uploads/uploads';\n"],"names":[],"mappings":"AAAA,sFAAsF"}},
    {"offset": {"line": 2660, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 2673, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resource.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport type { OpenAI } from './index';\n\nexport class APIResource {\n  protected _client: OpenAI;\n\n  constructor(client: OpenAI) {\n    this._client = client;\n  }\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;AAIhF,MAAO;IAGX,YAAY,MAAc,CAAA;QACxB,IAAI,CAAC,OAAO,GAAG;IACjB"}},
    {"offset": {"line": 2682, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 2687, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/audio/speech.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as Core from '../../core';\nimport * as SpeechAPI from './speech';\nimport { type Response } from '../../_shims/index';\n\nexport class Speech extends APIResource {\n  /**\n   * Generates audio from the input text.\n   */\n  create(body: SpeechCreateParams, options?: Core.RequestOptions): Core.APIPromise<Response> {\n    return this._client.post('/audio/speech', { body, ...options, __binaryResponse: true });\n  }\n}\n\nexport type SpeechModel = 'tts-1' | 'tts-1-hd';\n\nexport interface SpeechCreateParams {\n  /**\n   * The text to generate audio for. The maximum length is 4096 characters.\n   */\n  input: string;\n\n  /**\n   * One of the available [TTS models](https://platform.openai.com/docs/models/tts):\n   * `tts-1` or `tts-1-hd`\n   */\n  model: (string & {}) | SpeechModel;\n\n  /**\n   * The voice to use when generating the audio. Supported voices are `alloy`,\n   * `echo`, `fable`, `onyx`, `nova`, and `shimmer`. Previews of the voices are\n   * available in the\n   * [Text to speech guide](https://platform.openai.com/docs/guides/text-to-speech/voice-options).\n   */\n  voice: 'alloy' | 'echo' | 'fable' | 'onyx' | 'nova' | 'shimmer';\n\n  /**\n   * The format to audio in. Supported formats are `mp3`, `opus`, `aac`, `flac`,\n   * `wav`, and `pcm`.\n   */\n  response_format?: 'mp3' | 'opus' | 'aac' | 'flac' | 'wav' | 'pcm';\n\n  /**\n   * The speed of the generated audio. Select a value from `0.25` to `4.0`. `1.0` is\n   * the default.\n   */\n  speed?: number;\n}\n\nexport namespace Speech {\n  export import SpeechModel = SpeechAPI.SpeechModel;\n  export import SpeechCreateParams = SpeechAPI.SpeechCreateParams;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;AAOhF,MAAO,eAAe,qIAAA,CAAA,cAAW;IACrC;;QAGA,OAAO,IAAwB,EAAE,OAA6B,EAAA;QAC5D,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,iBAAiB;YAAE;YAAM,GAAG,OAAO;YAAE,kBAAkB;QAAI;IACtF;;AAsCF,CAAA,SAAiB,MAAM,GAGvB,CAAC,EAHgB,UAAM,CAAN,SAAM,CAAA,CAAA"}},
    {"offset": {"line": 2706, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 2711, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/audio/transcriptions.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as Core from '../../core';\nimport * as TranscriptionsAPI from './transcriptions';\nimport * as AudioAPI from './audio';\n\nexport class Transcriptions extends APIResource {\n  /**\n   * Transcribes audio into the input language.\n   */\n  create(\n    body: TranscriptionCreateParams<'json' | undefined>,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Transcription>;\n  create(\n    body: TranscriptionCreateParams<'verbose_json'>,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<TranscriptionVerbose>;\n  create(\n    body: TranscriptionCreateParams<'srt' | 'vtt' | 'text'>,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<string>;\n  create(body: TranscriptionCreateParams, options?: Core.RequestOptions): Core.APIPromise<Transcription>;\n  create(\n    body: TranscriptionCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<TranscriptionCreateResponse | string> {\n    return this._client.post('/audio/transcriptions', Core.multipartFormRequestOptions({ body, ...options }));\n  }\n}\n\n/**\n * Represents a transcription response returned by model, based on the provided\n * input.\n */\nexport interface Transcription {\n  /**\n   * The transcribed text.\n   */\n  text: string;\n}\n\nexport interface TranscriptionSegment {\n  /**\n   * Unique identifier of the segment.\n   */\n  id: number;\n\n  /**\n   * Average logprob of the segment. If the value is lower than -1, consider the\n   * logprobs failed.\n   */\n  avg_logprob: number;\n\n  /**\n   * Compression ratio of the segment. If the value is greater than 2.4, consider the\n   * compression failed.\n   */\n  compression_ratio: number;\n\n  /**\n   * End time of the segment in seconds.\n   */\n  end: number;\n\n  /**\n   * Probability of no speech in the segment. If the value is higher than 1.0 and the\n   * `avg_logprob` is below -1, consider this segment silent.\n   */\n  no_speech_prob: number;\n\n  /**\n   * Seek offset of the segment.\n   */\n  seek: number;\n\n  /**\n   * Start time of the segment in seconds.\n   */\n  start: number;\n\n  /**\n   * Temperature parameter used for generating the segment.\n   */\n  temperature: number;\n\n  /**\n   * Text content of the segment.\n   */\n  text: string;\n\n  /**\n   * Array of token IDs for the text content.\n   */\n  tokens: Array<number>;\n}\n\n/**\n * Represents a verbose json transcription response returned by model, based on the\n * provided input.\n */\nexport interface TranscriptionVerbose {\n  /**\n   * The duration of the input audio.\n   */\n  duration: string;\n\n  /**\n   * The language of the input audio.\n   */\n  language: string;\n\n  /**\n   * The transcribed text.\n   */\n  text: string;\n\n  /**\n   * Segments of the transcribed text and their corresponding details.\n   */\n  segments?: Array<TranscriptionSegment>;\n\n  /**\n   * Extracted words and their corresponding timestamps.\n   */\n  words?: Array<TranscriptionWord>;\n}\n\nexport interface TranscriptionWord {\n  /**\n   * End time of the word in seconds.\n   */\n  end: number;\n\n  /**\n   * Start time of the word in seconds.\n   */\n  start: number;\n\n  /**\n   * The text content of the word.\n   */\n  word: string;\n}\n\n/**\n * Represents a transcription response returned by model, based on the provided\n * input.\n */\nexport type TranscriptionCreateResponse = Transcription | TranscriptionVerbose;\n\nexport interface TranscriptionCreateParams<\n  ResponseFormat extends AudioAPI.AudioResponseFormat | undefined = AudioAPI.AudioResponseFormat | undefined,\n> {\n  /**\n   * The audio file object (not file name) to transcribe, in one of these formats:\n   * flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n   */\n  file: Core.Uploadable;\n\n  /**\n   * ID of the model to use. Only `whisper-1` (which is powered by our open source\n   * Whisper V2 model) is currently available.\n   */\n  model: (string & {}) | AudioAPI.AudioModel;\n\n  /**\n   * The language of the input audio. Supplying the input language in\n   * [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will\n   * improve accuracy and latency.\n   */\n  language?: string;\n\n  /**\n   * An optional text to guide the model's style or continue a previous audio\n   * segment. The\n   * [prompt](https://platform.openai.com/docs/guides/speech-to-text/prompting)\n   * should match the audio language.\n   */\n  prompt?: string;\n\n  /**\n   * The format of the output, in one of these options: `json`, `text`, `srt`,\n   * `verbose_json`, or `vtt`.\n   */\n  response_format?: ResponseFormat;\n\n  /**\n   * The sampling temperature, between 0 and 1. Higher values like 0.8 will make the\n   * output more random, while lower values like 0.2 will make it more focused and\n   * deterministic. If set to 0, the model will use\n   * [log probability](https://en.wikipedia.org/wiki/Log_probability) to\n   * automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n\n  /**\n   * The timestamp granularities to populate for this transcription.\n   * `response_format` must be set `verbose_json` to use timestamp granularities.\n   * Either or both of these options are supported: `word`, or `segment`. Note: There\n   * is no additional latency for segment timestamps, but generating word timestamps\n   * incurs additional latency.\n   */\n  timestamp_granularities?: Array<'word' | 'segment'>;\n}\n\nexport namespace Transcriptions {\n  export import Transcription = TranscriptionsAPI.Transcription;\n  export import TranscriptionSegment = TranscriptionsAPI.TranscriptionSegment;\n  export import TranscriptionVerbose = TranscriptionsAPI.TranscriptionVerbose;\n  export import TranscriptionWord = TranscriptionsAPI.TranscriptionWord;\n  export import TranscriptionCreateResponse = TranscriptionsAPI.TranscriptionCreateResponse;\n  export type TranscriptionCreateParams<\n    ResponseFormat extends AudioAPI.AudioResponseFormat | undefined =\n      | AudioAPI.AudioResponseFormat\n      | undefined,\n  > = TranscriptionsAPI.TranscriptionCreateParams<ResponseFormat>;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;AAOhF,MAAO,uBAAuB,qIAAA,CAAA,cAAW;IAiB7C,OACE,IAA+B,EAC/B,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,yBAAyB,kJAAK,2BAA2B,CAAC;YAAE;YAAM,GAAG,OAAO;QAAA;IACvG;;AAkLF,CAAA,SAAiB,cAAc,GAW/B,CAAC,EAXgB,kBAAc,CAAd,iBAAc,CAAA,CAAA"}},
    {"offset": {"line": 2729, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 2734, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/audio/translations.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as Core from '../../core';\nimport * as TranslationsAPI from './translations';\nimport * as AudioAPI from './audio';\nimport * as TranscriptionsAPI from './transcriptions';\n\nexport class Translations extends APIResource {\n  /**\n   * Translates audio into English.\n   */\n  create(\n    body: TranslationCreateParams<'json' | undefined>,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Translation>;\n  create(\n    body: TranslationCreateParams<'verbose_json'>,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<TranslationVerbose>;\n  create(\n    body: TranslationCreateParams<'text' | 'srt' | 'vtt'>,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<string>;\n  create(body: TranslationCreateParams, options?: Core.RequestOptions): Core.APIPromise<Translation>;\n  create(\n    body: TranslationCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<TranslationCreateResponse | string> {\n    return this._client.post('/audio/translations', Core.multipartFormRequestOptions({ body, ...options }));\n  }\n}\n\nexport interface Translation {\n  text: string;\n}\n\nexport interface TranslationVerbose {\n  /**\n   * The duration of the input audio.\n   */\n  duration: string;\n\n  /**\n   * The language of the output translation (always `english`).\n   */\n  language: string;\n\n  /**\n   * The translated text.\n   */\n  text: string;\n\n  /**\n   * Segments of the translated text and their corresponding details.\n   */\n  segments?: Array<TranscriptionsAPI.TranscriptionSegment>;\n}\n\nexport type TranslationCreateResponse = Translation | TranslationVerbose;\n\nexport interface TranslationCreateParams<\n  ResponseFormat extends AudioAPI.AudioResponseFormat | undefined = AudioAPI.AudioResponseFormat | undefined,\n> {\n  /**\n   * The audio file object (not file name) translate, in one of these formats: flac,\n   * mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.\n   */\n  file: Core.Uploadable;\n\n  /**\n   * ID of the model to use. Only `whisper-1` (which is powered by our open source\n   * Whisper V2 model) is currently available.\n   */\n  model: (string & {}) | AudioAPI.AudioModel;\n\n  /**\n   * An optional text to guide the model's style or continue a previous audio\n   * segment. The\n   * [prompt](https://platform.openai.com/docs/guides/speech-to-text/prompting)\n   * should be in English.\n   */\n  prompt?: string;\n\n  /**\n   * The format of the output, in one of these options: `json`, `text`, `srt`,\n   * `verbose_json`, or `vtt`.\n   */\n  response_format?: ResponseFormat;\n\n  /**\n   * The sampling temperature, between 0 and 1. Higher values like 0.8 will make the\n   * output more random, while lower values like 0.2 will make it more focused and\n   * deterministic. If set to 0, the model will use\n   * [log probability](https://en.wikipedia.org/wiki/Log_probability) to\n   * automatically increase the temperature until certain thresholds are hit.\n   */\n  temperature?: number;\n}\n\nexport namespace Translations {\n  export import Translation = TranslationsAPI.Translation;\n  export import TranslationVerbose = TranslationsAPI.TranslationVerbose;\n  export import TranslationCreateResponse = TranslationsAPI.TranslationCreateResponse;\n  export type TranslationCreateParams<\n    ResponseFormat extends AudioAPI.AudioResponseFormat | undefined =\n      | AudioAPI.AudioResponseFormat\n      | undefined,\n  > = TranslationsAPI.TranslationCreateParams<ResponseFormat>;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;AAQhF,MAAO,qBAAqB,qIAAA,CAAA,cAAW;IAiB3C,OACE,IAA6B,EAC7B,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,uBAAuB,kJAAK,2BAA2B,CAAC;YAAE;YAAM,GAAG,OAAO;QAAA;IACrG;;AAsEF,CAAA,SAAiB,YAAY,GAS7B,CAAC,EATgB,gBAAY,CAAZ,eAAY,CAAA,CAAA"}},
    {"offset": {"line": 2752, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 2757, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/audio/audio.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as AudioAPI from './audio';\nimport * as SpeechAPI from './speech';\nimport * as TranscriptionsAPI from './transcriptions';\nimport * as TranslationsAPI from './translations';\n\nexport class Audio extends APIResource {\n  transcriptions: TranscriptionsAPI.Transcriptions = new TranscriptionsAPI.Transcriptions(this._client);\n  translations: TranslationsAPI.Translations = new TranslationsAPI.Translations(this._client);\n  speech: SpeechAPI.Speech = new SpeechAPI.Speech(this._client);\n}\n\nexport type AudioModel = 'whisper-1';\n\n/**\n * The format of the output, in one of these options: `json`, `text`, `srt`,\n * `verbose_json`, or `vtt`.\n */\nexport type AudioResponseFormat = 'json' | 'text' | 'srt' | 'verbose_json' | 'vtt';\n\nexport namespace Audio {\n  export import AudioModel = AudioAPI.AudioModel;\n  export import AudioResponseFormat = AudioAPI.AudioResponseFormat;\n  export import Transcriptions = TranscriptionsAPI.Transcriptions;\n  export import Transcription = TranscriptionsAPI.Transcription;\n  export import TranscriptionSegment = TranscriptionsAPI.TranscriptionSegment;\n  export import TranscriptionVerbose = TranscriptionsAPI.TranscriptionVerbose;\n  export import TranscriptionWord = TranscriptionsAPI.TranscriptionWord;\n  export import TranscriptionCreateResponse = TranscriptionsAPI.TranscriptionCreateResponse;\n  export type TranscriptionCreateParams<\n    ResponseFormat extends AudioAPI.AudioResponseFormat | undefined =\n      | AudioAPI.AudioResponseFormat\n      | undefined,\n  > = TranscriptionsAPI.TranscriptionCreateParams<ResponseFormat>;\n  export import Translations = TranslationsAPI.Translations;\n  export import Translation = TranslationsAPI.Translation;\n  export import TranslationVerbose = TranslationsAPI.TranslationVerbose;\n  export import TranslationCreateResponse = TranslationsAPI.TranslationCreateResponse;\n  export type TranslationCreateParams<\n    ResponseFormat extends AudioAPI.AudioResponseFormat | undefined =\n      | AudioAPI.AudioResponseFormat\n      | undefined,\n  > = TranslationsAPI.TranslationCreateParams<ResponseFormat>;\n  export import Speech = SpeechAPI.Speech;\n  export import SpeechModel = SpeechAPI.SpeechModel;\n  export import SpeechCreateParams = SpeechAPI.SpeechCreateParams;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;;;;;AAQhF,MAAO,cAAc,qIAAA,CAAA,cAAW;IAAtC,aAAA;;QACE,IAAA,CAAA,cAAc,GAAqC,IAAI,kKAAkB,cAAc,CAAC,IAAI,CAAC,OAAO;QACpG,IAAA,CAAA,YAAY,GAAiC,IAAI,gKAAgB,YAAY,CAAC,IAAI,CAAC,OAAO;QAC1F,IAAA,CAAA,MAAM,GAAqB,IAAI,0JAAU,MAAM,CAAC,IAAI,CAAC,OAAO;IAC9D;;AAUA,CAAA,SAAiB,KAAK;IAGN,MAAA,cAAc,GAAG,kKAAkB,cAAc;IAWjD,MAAA,YAAY,GAAG,gKAAgB,YAAY;IAS3C,MAAA,MAAM,GAAG,0JAAU,MAAM;AAGzC,CAAC,EA1BgB,SAAK,CAAL,QAAK,CAAA,CAAA"}},
    {"offset": {"line": 2783, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 2788, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/batches.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport { isRequestOptions } from '../core';\nimport * as Core from '../core';\nimport * as BatchesAPI from './batches';\nimport { CursorPage, type CursorPageParams } from '../pagination';\n\nexport class Batches extends APIResource {\n  /**\n   * Creates and executes a batch from an uploaded file of requests\n   */\n  create(body: BatchCreateParams, options?: Core.RequestOptions): Core.APIPromise<Batch> {\n    return this._client.post('/batches', { body, ...options });\n  }\n\n  /**\n   * Retrieves a batch.\n   */\n  retrieve(batchId: string, options?: Core.RequestOptions): Core.APIPromise<Batch> {\n    return this._client.get(`/batches/${batchId}`, options);\n  }\n\n  /**\n   * List your organization's batches.\n   */\n  list(query?: BatchListParams, options?: Core.RequestOptions): Core.PagePromise<BatchesPage, Batch>;\n  list(options?: Core.RequestOptions): Core.PagePromise<BatchesPage, Batch>;\n  list(\n    query: BatchListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<BatchesPage, Batch> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/batches', BatchesPage, { query, ...options });\n  }\n\n  /**\n   * Cancels an in-progress batch. The batch will be in status `cancelling` for up to\n   * 10 minutes, before changing to `cancelled`, where it will have partial results\n   * (if any) available in the output file.\n   */\n  cancel(batchId: string, options?: Core.RequestOptions): Core.APIPromise<Batch> {\n    return this._client.post(`/batches/${batchId}/cancel`, options);\n  }\n}\n\nexport class BatchesPage extends CursorPage<Batch> {}\n\nexport interface Batch {\n  id: string;\n\n  /**\n   * The time frame within which the batch should be processed.\n   */\n  completion_window: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was created.\n   */\n  created_at: number;\n\n  /**\n   * The OpenAI API endpoint used by the batch.\n   */\n  endpoint: string;\n\n  /**\n   * The ID of the input file for the batch.\n   */\n  input_file_id: string;\n\n  /**\n   * The object type, which is always `batch`.\n   */\n  object: 'batch';\n\n  /**\n   * The current status of the batch.\n   */\n  status:\n    | 'validating'\n    | 'failed'\n    | 'in_progress'\n    | 'finalizing'\n    | 'completed'\n    | 'expired'\n    | 'cancelling'\n    | 'cancelled';\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was cancelled.\n   */\n  cancelled_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started cancelling.\n   */\n  cancelling_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch was completed.\n   */\n  completed_at?: number;\n\n  /**\n   * The ID of the file containing the outputs of requests with errors.\n   */\n  error_file_id?: string;\n\n  errors?: Batch.Errors;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch expired.\n   */\n  expired_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch will expire.\n   */\n  expires_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch failed.\n   */\n  failed_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started finalizing.\n   */\n  finalizing_at?: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the batch started processing.\n   */\n  in_progress_at?: number;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the file containing the outputs of successfully executed requests.\n   */\n  output_file_id?: string;\n\n  /**\n   * The request counts for different statuses within the batch.\n   */\n  request_counts?: BatchRequestCounts;\n}\n\nexport namespace Batch {\n  export interface Errors {\n    data?: Array<BatchesAPI.BatchError>;\n\n    /**\n     * The object type, which is always `list`.\n     */\n    object?: string;\n  }\n}\n\nexport interface BatchError {\n  /**\n   * An error code identifying the error type.\n   */\n  code?: string;\n\n  /**\n   * The line number of the input file where the error occurred, if applicable.\n   */\n  line?: number | null;\n\n  /**\n   * A human-readable message providing more details about the error.\n   */\n  message?: string;\n\n  /**\n   * The name of the parameter that caused the error, if applicable.\n   */\n  param?: string | null;\n}\n\n/**\n * The request counts for different statuses within the batch.\n */\nexport interface BatchRequestCounts {\n  /**\n   * Number of requests that have been completed successfully.\n   */\n  completed: number;\n\n  /**\n   * Number of requests that have failed.\n   */\n  failed: number;\n\n  /**\n   * Total number of requests in the batch.\n   */\n  total: number;\n}\n\nexport interface BatchCreateParams {\n  /**\n   * The time frame within which the batch should be processed. Currently only `24h`\n   * is supported.\n   */\n  completion_window: '24h';\n\n  /**\n   * The endpoint to be used for all requests in the batch. Currently\n   * `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are supported.\n   * Note that `/v1/embeddings` batches are also restricted to a maximum of 50,000\n   * embedding inputs across all requests in the batch.\n   */\n  endpoint: '/v1/chat/completions' | '/v1/embeddings' | '/v1/completions';\n\n  /**\n   * The ID of an uploaded file that contains requests for the new batch.\n   *\n   * See [upload file](https://platform.openai.com/docs/api-reference/files/create)\n   * for how to upload a file.\n   *\n   * Your input file must be formatted as a\n   * [JSONL file](https://platform.openai.com/docs/api-reference/batch/request-input),\n   * and must be uploaded with the purpose `batch`. The file can contain up to 50,000\n   * requests, and can be up to 100 MB in size.\n   */\n  input_file_id: string;\n\n  /**\n   * Optional custom metadata for the batch.\n   */\n  metadata?: Record<string, string> | null;\n}\n\nexport interface BatchListParams extends CursorPageParams {}\n\nexport namespace Batches {\n  export import Batch = BatchesAPI.Batch;\n  export import BatchError = BatchesAPI.BatchError;\n  export import BatchRequestCounts = BatchesAPI.BatchRequestCounts;\n  export import BatchesPage = BatchesAPI.BatchesPage;\n  export import BatchCreateParams = BatchesAPI.BatchCreateParams;\n  export import BatchListParams = BatchesAPI.BatchListParams;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;;;;;;AAQhF,MAAO,gBAAgB,qIAAA,CAAA,cAAW;IACtC;;QAGA,OAAO,IAAuB,EAAE,OAA6B,EAAA;QAC3D,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,YAAY;YAAE;YAAM,GAAG,OAAO;QAAA;IACzD;IAEA;;QAGA,SAAS,OAAe,EAAE,OAA6B,EAAA;QACrD,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,CAAA,SAAA,EAAY,QAAO,CAAE,EAAE;IACjD;IAOA,KACE,QAA+C,CAAA,CAAE,EACjD,OAA6B,EAAA;QAE7B,IAAI,CAAA,GAAA,iJAAA,CAAA,mBAAgB,AAAhB,EAAiB,QAAQ;YAC3B,OAAO,IAAI,CAAC,IAAI,CAAC,CAAA,GAAI;;QAEvB,OAAO,IAAI,CAAC,OAAO,CAAC,UAAU,CAAC,YAAY,aAAa;YAAE;YAAO,GAAG,OAAO;QAAA;IAC7E;IAEA;;;;QAKA,OAAO,OAAe,EAAE,OAA6B,EAAA;QACnD,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,CAAA,SAAA,EAAY,QAAO,OAAA,CAAS,EAAE;IACzD;;AAGI,MAAO,oBAAoB,uIAAA,CAAA,aAAiB;;AAsMlD,CAAA,SAAiB,OAAO;IAIR,QAAA,WAAW,GAAG,kJAAW,WAAW;AAGpD,CAAC,EAPgB,WAAO,CAAP,UAAO,CAAA,CAAA"}},
    {"offset": {"line": 2838, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 2843, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/beta/assistants.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport { isRequestOptions } from '../../core';\nimport * as Core from '../../core';\nimport * as AssistantsAPI from './assistants';\nimport * as Shared from '../shared';\nimport * as ChatAPI from '../chat/chat';\nimport * as MessagesAPI from './threads/messages';\nimport * as ThreadsAPI from './threads/threads';\nimport * as VectorStoresAPI from './vector-stores/vector-stores';\nimport * as RunsAPI from './threads/runs/runs';\nimport * as StepsAPI from './threads/runs/steps';\nimport { CursorPage, type CursorPageParams } from '../../pagination';\n\nexport class Assistants extends APIResource {\n  /**\n   * Create an assistant with a model and instructions.\n   */\n  create(body: AssistantCreateParams, options?: Core.RequestOptions): Core.APIPromise<Assistant> {\n    return this._client.post('/assistants', {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves an assistant.\n   */\n  retrieve(assistantId: string, options?: Core.RequestOptions): Core.APIPromise<Assistant> {\n    return this._client.get(`/assistants/${assistantId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Modifies an assistant.\n   */\n  update(\n    assistantId: string,\n    body: AssistantUpdateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Assistant> {\n    return this._client.post(`/assistants/${assistantId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of assistants.\n   */\n  list(\n    query?: AssistantListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<AssistantsPage, Assistant>;\n  list(options?: Core.RequestOptions): Core.PagePromise<AssistantsPage, Assistant>;\n  list(\n    query: AssistantListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<AssistantsPage, Assistant> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/assistants', AssistantsPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Delete an assistant.\n   */\n  del(assistantId: string, options?: Core.RequestOptions): Core.APIPromise<AssistantDeleted> {\n    return this._client.delete(`/assistants/${assistantId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n}\n\nexport class AssistantsPage extends CursorPage<Assistant> {}\n\n/**\n * Represents an `assistant` that can call the model and use tools.\n */\nexport interface Assistant {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the assistant was created.\n   */\n  created_at: number;\n\n  /**\n   * The description of the assistant. The maximum length is 512 characters.\n   */\n  description: string | null;\n\n  /**\n   * The system instructions that the assistant uses. The maximum length is 256,000\n   * characters.\n   */\n  instructions: string | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata: unknown | null;\n\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models/overview) for\n   * descriptions of them.\n   */\n  model: string;\n\n  /**\n   * The name of the assistant. The maximum length is 256 characters.\n   */\n  name: string | null;\n\n  /**\n   * The object type, which is always `assistant`.\n   */\n  object: 'assistant';\n\n  /**\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\n   * assistant. Tools can be of types `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tools: Array<AssistantTool>;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: Assistant.ToolResources | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n}\n\nexport namespace Assistant {\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter`` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport interface AssistantDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'assistant.deleted';\n}\n\n/**\n * Represents an event emitted when streaming a Run.\n *\n * Each event in a server-sent events stream has an `event` and `data` property:\n *\n * ```\n * event: thread.created\n * data: {\"id\": \"thread_123\", \"object\": \"thread\", ...}\n * ```\n *\n * We emit events whenever a new object is created, transitions to a new state, or\n * is being streamed in parts (deltas). For example, we emit `thread.run.created`\n * when a new run is created, `thread.run.completed` when a run completes, and so\n * on. When an Assistant chooses to create a message during a run, we emit a\n * `thread.message.created event`, a `thread.message.in_progress` event, many\n * `thread.message.delta` events, and finally a `thread.message.completed` event.\n *\n * We may add additional events over time, so we recommend handling unknown events\n * gracefully in your code. See the\n * [Assistants API quickstart](https://platform.openai.com/docs/assistants/overview)\n * to learn how to integrate the Assistants API with streaming.\n */\nexport type AssistantStreamEvent =\n  | AssistantStreamEvent.ThreadCreated\n  | AssistantStreamEvent.ThreadRunCreated\n  | AssistantStreamEvent.ThreadRunQueued\n  | AssistantStreamEvent.ThreadRunInProgress\n  | AssistantStreamEvent.ThreadRunRequiresAction\n  | AssistantStreamEvent.ThreadRunCompleted\n  | AssistantStreamEvent.ThreadRunIncomplete\n  | AssistantStreamEvent.ThreadRunFailed\n  | AssistantStreamEvent.ThreadRunCancelling\n  | AssistantStreamEvent.ThreadRunCancelled\n  | AssistantStreamEvent.ThreadRunExpired\n  | AssistantStreamEvent.ThreadRunStepCreated\n  | AssistantStreamEvent.ThreadRunStepInProgress\n  | AssistantStreamEvent.ThreadRunStepDelta\n  | AssistantStreamEvent.ThreadRunStepCompleted\n  | AssistantStreamEvent.ThreadRunStepFailed\n  | AssistantStreamEvent.ThreadRunStepCancelled\n  | AssistantStreamEvent.ThreadRunStepExpired\n  | AssistantStreamEvent.ThreadMessageCreated\n  | AssistantStreamEvent.ThreadMessageInProgress\n  | AssistantStreamEvent.ThreadMessageDelta\n  | AssistantStreamEvent.ThreadMessageCompleted\n  | AssistantStreamEvent.ThreadMessageIncomplete\n  | AssistantStreamEvent.ErrorEvent;\n\nexport namespace AssistantStreamEvent {\n  /**\n   * Occurs when a new\n   * [thread](https://platform.openai.com/docs/api-reference/threads/object) is\n   * created.\n   */\n  export interface ThreadCreated {\n    /**\n     * Represents a thread that contains\n     * [messages](https://platform.openai.com/docs/api-reference/messages).\n     */\n    data: ThreadsAPI.Thread;\n\n    event: 'thread.created';\n  }\n\n  /**\n   * Occurs when a new\n   * [run](https://platform.openai.com/docs/api-reference/runs/object) is created.\n   */\n  export interface ThreadRunCreated {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.created';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `queued` status.\n   */\n  export interface ThreadRunQueued {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.queued';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to an `in_progress` status.\n   */\n  export interface ThreadRunInProgress {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.in_progress';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `requires_action` status.\n   */\n  export interface ThreadRunRequiresAction {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.requires_action';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is completed.\n   */\n  export interface ThreadRunCompleted {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.completed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * ends with status `incomplete`.\n   */\n  export interface ThreadRunIncomplete {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.incomplete';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * fails.\n   */\n  export interface ThreadRunFailed {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.failed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `cancelling` status.\n   */\n  export interface ThreadRunCancelling {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelling';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is cancelled.\n   */\n  export interface ThreadRunCancelled {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelled';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * expires.\n   */\n  export interface ThreadRunExpired {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.expired';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is created.\n   */\n  export interface ThreadRunStepCreated {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.created';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * moves to an `in_progress` state.\n   */\n  export interface ThreadRunStepInProgress {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * are being streamed.\n   */\n  export interface ThreadRunStepDelta {\n    /**\n     * Represents a run step delta i.e. any changed fields on a run step during\n     * streaming.\n     */\n    data: StepsAPI.RunStepDeltaEvent;\n\n    event: 'thread.run.step.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is completed.\n   */\n  export interface ThreadRunStepCompleted {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * fails.\n   */\n  export interface ThreadRunStepFailed {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.failed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is cancelled.\n   */\n  export interface ThreadRunStepCancelled {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.cancelled';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * expires.\n   */\n  export interface ThreadRunStepExpired {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.expired';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * created.\n   */\n  export interface ThreadMessageCreated {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.created';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) moves\n   * to an `in_progress` state.\n   */\n  export interface ThreadMessageInProgress {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [Message](https://platform.openai.com/docs/api-reference/messages/object) are\n   * being streamed.\n   */\n  export interface ThreadMessageDelta {\n    /**\n     * Represents a message delta i.e. any changed fields on a message during\n     * streaming.\n     */\n    data: MessagesAPI.MessageDeltaEvent;\n\n    event: 'thread.message.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * completed.\n   */\n  export interface ThreadMessageCompleted {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) ends\n   * before it is completed.\n   */\n  export interface ThreadMessageIncomplete {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.incomplete';\n  }\n\n  /**\n   * Occurs when an\n   * [error](https://platform.openai.com/docs/guides/error-codes/api-errors) occurs.\n   * This can happen due to an internal server error or a timeout.\n   */\n  export interface ErrorEvent {\n    data: Shared.ErrorObject;\n\n    event: 'error';\n  }\n}\n\nexport type AssistantTool = CodeInterpreterTool | FileSearchTool | FunctionTool;\n\nexport interface CodeInterpreterTool {\n  /**\n   * The type of tool being defined: `code_interpreter`\n   */\n  type: 'code_interpreter';\n}\n\nexport interface FileSearchTool {\n  /**\n   * The type of tool being defined: `file_search`\n   */\n  type: 'file_search';\n\n  /**\n   * Overrides for the file search tool.\n   */\n  file_search?: FileSearchTool.FileSearch;\n}\n\nexport namespace FileSearchTool {\n  /**\n   * Overrides for the file search tool.\n   */\n  export interface FileSearch {\n    /**\n     * The maximum number of results the file search tool should output. The default is\n     * 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between\n     * 1 and 50 inclusive.\n     *\n     * Note that the file search tool may output fewer than `max_num_results` results.\n     * See the\n     * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search/customizing-file-search-settings)\n     * for more information.\n     */\n    max_num_results?: number;\n\n    /**\n     * The ranking options for the file search. If not specified, the file search tool\n     * will use the `auto` ranker and a score_threshold of 0.\n     *\n     * See the\n     * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search/customizing-file-search-settings)\n     * for more information.\n     */\n    ranking_options?: FileSearch.RankingOptions;\n  }\n\n  export namespace FileSearch {\n    /**\n     * The ranking options for the file search. If not specified, the file search tool\n     * will use the `auto` ranker and a score_threshold of 0.\n     *\n     * See the\n     * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search/customizing-file-search-settings)\n     * for more information.\n     */\n    export interface RankingOptions {\n      /**\n       * The score threshold for the file search. All values must be a floating point\n       * number between 0 and 1.\n       */\n      score_threshold: number;\n\n      /**\n       * The ranker to use for the file search. If not specified will use the `auto`\n       * ranker.\n       */\n      ranker?: 'auto' | 'default_2024_08_21';\n    }\n  }\n}\n\nexport interface FunctionTool {\n  function: Shared.FunctionDefinition;\n\n  /**\n   * The type of tool being defined: `function`\n   */\n  type: 'function';\n}\n\n/**\n * Occurs when a\n * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n * created.\n */\nexport type MessageStreamEvent =\n  | MessageStreamEvent.ThreadMessageCreated\n  | MessageStreamEvent.ThreadMessageInProgress\n  | MessageStreamEvent.ThreadMessageDelta\n  | MessageStreamEvent.ThreadMessageCompleted\n  | MessageStreamEvent.ThreadMessageIncomplete;\n\nexport namespace MessageStreamEvent {\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * created.\n   */\n  export interface ThreadMessageCreated {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.created';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) moves\n   * to an `in_progress` state.\n   */\n  export interface ThreadMessageInProgress {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [Message](https://platform.openai.com/docs/api-reference/messages/object) are\n   * being streamed.\n   */\n  export interface ThreadMessageDelta {\n    /**\n     * Represents a message delta i.e. any changed fields on a message during\n     * streaming.\n     */\n    data: MessagesAPI.MessageDeltaEvent;\n\n    event: 'thread.message.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) is\n   * completed.\n   */\n  export interface ThreadMessageCompleted {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [message](https://platform.openai.com/docs/api-reference/messages/object) ends\n   * before it is completed.\n   */\n  export interface ThreadMessageIncomplete {\n    /**\n     * Represents a message within a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: MessagesAPI.Message;\n\n    event: 'thread.message.incomplete';\n  }\n}\n\n/**\n * Occurs when a\n * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n * is created.\n */\nexport type RunStepStreamEvent =\n  | RunStepStreamEvent.ThreadRunStepCreated\n  | RunStepStreamEvent.ThreadRunStepInProgress\n  | RunStepStreamEvent.ThreadRunStepDelta\n  | RunStepStreamEvent.ThreadRunStepCompleted\n  | RunStepStreamEvent.ThreadRunStepFailed\n  | RunStepStreamEvent.ThreadRunStepCancelled\n  | RunStepStreamEvent.ThreadRunStepExpired;\n\nexport namespace RunStepStreamEvent {\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is created.\n   */\n  export interface ThreadRunStepCreated {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.created';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * moves to an `in_progress` state.\n   */\n  export interface ThreadRunStepInProgress {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.in_progress';\n  }\n\n  /**\n   * Occurs when parts of a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * are being streamed.\n   */\n  export interface ThreadRunStepDelta {\n    /**\n     * Represents a run step delta i.e. any changed fields on a run step during\n     * streaming.\n     */\n    data: StepsAPI.RunStepDeltaEvent;\n\n    event: 'thread.run.step.delta';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is completed.\n   */\n  export interface ThreadRunStepCompleted {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.completed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * fails.\n   */\n  export interface ThreadRunStepFailed {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.failed';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * is cancelled.\n   */\n  export interface ThreadRunStepCancelled {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.cancelled';\n  }\n\n  /**\n   * Occurs when a\n   * [run step](https://platform.openai.com/docs/api-reference/run-steps/step-object)\n   * expires.\n   */\n  export interface ThreadRunStepExpired {\n    /**\n     * Represents a step in execution of a run.\n     */\n    data: StepsAPI.RunStep;\n\n    event: 'thread.run.step.expired';\n  }\n}\n\n/**\n * Occurs when a new\n * [run](https://platform.openai.com/docs/api-reference/runs/object) is created.\n */\nexport type RunStreamEvent =\n  | RunStreamEvent.ThreadRunCreated\n  | RunStreamEvent.ThreadRunQueued\n  | RunStreamEvent.ThreadRunInProgress\n  | RunStreamEvent.ThreadRunRequiresAction\n  | RunStreamEvent.ThreadRunCompleted\n  | RunStreamEvent.ThreadRunIncomplete\n  | RunStreamEvent.ThreadRunFailed\n  | RunStreamEvent.ThreadRunCancelling\n  | RunStreamEvent.ThreadRunCancelled\n  | RunStreamEvent.ThreadRunExpired;\n\nexport namespace RunStreamEvent {\n  /**\n   * Occurs when a new\n   * [run](https://platform.openai.com/docs/api-reference/runs/object) is created.\n   */\n  export interface ThreadRunCreated {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.created';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `queued` status.\n   */\n  export interface ThreadRunQueued {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.queued';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to an `in_progress` status.\n   */\n  export interface ThreadRunInProgress {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.in_progress';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `requires_action` status.\n   */\n  export interface ThreadRunRequiresAction {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.requires_action';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is completed.\n   */\n  export interface ThreadRunCompleted {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.completed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * ends with status `incomplete`.\n   */\n  export interface ThreadRunIncomplete {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.incomplete';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * fails.\n   */\n  export interface ThreadRunFailed {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.failed';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * moves to a `cancelling` status.\n   */\n  export interface ThreadRunCancelling {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelling';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * is cancelled.\n   */\n  export interface ThreadRunCancelled {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.cancelled';\n  }\n\n  /**\n   * Occurs when a [run](https://platform.openai.com/docs/api-reference/runs/object)\n   * expires.\n   */\n  export interface ThreadRunExpired {\n    /**\n     * Represents an execution run on a\n     * [thread](https://platform.openai.com/docs/api-reference/threads).\n     */\n    data: RunsAPI.Run;\n\n    event: 'thread.run.expired';\n  }\n}\n\n/**\n * Occurs when a new\n * [thread](https://platform.openai.com/docs/api-reference/threads/object) is\n * created.\n */\nexport interface ThreadStreamEvent {\n  /**\n   * Represents a thread that contains\n   * [messages](https://platform.openai.com/docs/api-reference/messages).\n   */\n  data: ThreadsAPI.Thread;\n\n  event: 'thread.created';\n}\n\nexport interface AssistantCreateParams {\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models/overview) for\n   * descriptions of them.\n   */\n  model: (string & {}) | ChatAPI.ChatModel;\n\n  /**\n   * The description of the assistant. The maximum length is 512 characters.\n   */\n  description?: string | null;\n\n  /**\n   * The system instructions that the assistant uses. The maximum length is 256,000\n   * characters.\n   */\n  instructions?: string | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The name of the assistant. The maximum length is 256 characters.\n   */\n  name?: string | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: AssistantCreateParams.ToolResources | null;\n\n  /**\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\n   * assistant. Tools can be of types `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tools?: Array<AssistantTool>;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n}\n\nexport namespace AssistantCreateParams {\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n\n      /**\n       * A helper to create a\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * with file_ids and attach it to this assistant. There can be a maximum of 1\n       * vector store attached to the assistant.\n       */\n      vector_stores?: Array<FileSearch.VectorStore>;\n    }\n\n    export namespace FileSearch {\n      export interface VectorStore {\n        /**\n         * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n         * strategy. Only applicable if `file_ids` is non-empty.\n         */\n        chunking_strategy?: VectorStoresAPI.FileChunkingStrategyParam;\n\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n         * add to the vector store. There can be a maximum of 10000 files in a vector\n         * store.\n         */\n        file_ids?: Array<string>;\n\n        /**\n         * Set of 16 key-value pairs that can be attached to a vector store. This can be\n         * useful for storing additional information about the vector store in a structured\n         * format. Keys can be a maximum of 64 characters long and values can be a maxium\n         * of 512 characters long.\n         */\n        metadata?: unknown;\n      }\n    }\n  }\n}\n\nexport interface AssistantUpdateParams {\n  /**\n   * The description of the assistant. The maximum length is 512 characters.\n   */\n  description?: string | null;\n\n  /**\n   * The system instructions that the assistant uses. The maximum length is 256,000\n   * characters.\n   */\n  instructions?: string | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models/overview) for\n   * descriptions of them.\n   */\n  model?: string;\n\n  /**\n   * The name of the assistant. The maximum length is 256 characters.\n   */\n  name?: string | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: AssistantUpdateParams.ToolResources | null;\n\n  /**\n   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per\n   * assistant. Tools can be of types `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tools?: Array<AssistantTool>;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n}\n\nexport namespace AssistantUpdateParams {\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * Overrides the list of\n       * [file](https://platform.openai.com/docs/api-reference/files) IDs made available\n       * to the `code_interpreter` tool. There can be a maximum of 20 files associated\n       * with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * Overrides the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport interface AssistantListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\n   * fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport namespace Assistants {\n  export import Assistant = AssistantsAPI.Assistant;\n  export import AssistantDeleted = AssistantsAPI.AssistantDeleted;\n  export import AssistantStreamEvent = AssistantsAPI.AssistantStreamEvent;\n  export import AssistantTool = AssistantsAPI.AssistantTool;\n  export import CodeInterpreterTool = AssistantsAPI.CodeInterpreterTool;\n  export import FileSearchTool = AssistantsAPI.FileSearchTool;\n  export import FunctionTool = AssistantsAPI.FunctionTool;\n  export import MessageStreamEvent = AssistantsAPI.MessageStreamEvent;\n  export import RunStepStreamEvent = AssistantsAPI.RunStepStreamEvent;\n  export import RunStreamEvent = AssistantsAPI.RunStreamEvent;\n  export import ThreadStreamEvent = AssistantsAPI.ThreadStreamEvent;\n  export import AssistantsPage = AssistantsAPI.AssistantsPage;\n  export import AssistantCreateParams = AssistantsAPI.AssistantCreateParams;\n  export import AssistantUpdateParams = AssistantsAPI.AssistantUpdateParams;\n  export import AssistantListParams = AssistantsAPI.AssistantListParams;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;;;;;;AAehF,MAAO,mBAAmB,qIAAA,CAAA,cAAW;IACzC;;QAGA,OAAO,IAA2B,EAAE,OAA6B,EAAA;QAC/D,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,eAAe;YACtC;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;QAGA,SAAS,WAAmB,EAAE,OAA6B,EAAA;QACzD,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,CAAA,YAAA,EAAe,YAAW,CAAE,EAAE;YACpD,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;QAGA,OACE,WAAmB,EACnB,IAA2B,EAC3B,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,CAAA,YAAA,EAAe,YAAW,CAAE,EAAE;YACrD;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAUA,KACE,QAAmD,CAAA,CAAE,EACrD,OAA6B,EAAA;QAE7B,IAAI,CAAA,GAAA,iJAAA,CAAA,mBAAgB,AAAhB,EAAiB,QAAQ;YAC3B,OAAO,IAAI,CAAC,IAAI,CAAC,CAAA,GAAI;;QAEvB,OAAO,IAAI,CAAC,OAAO,CAAC,UAAU,CAAC,eAAe,gBAAgB;YAC5D;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;QAGA,IAAI,WAAmB,EAAE,OAA6B,EAAA;QACpD,OAAO,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,CAAA,YAAA,EAAe,YAAW,CAAE,EAAE;YACvD,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;;AAGI,MAAO,uBAAuB,uIAAA,CAAA,aAAqB;;AAuxCzD,CAAA,SAAiB,UAAU;IAYX,WAAA,cAAc,GAAG,6JAAc,cAAc;AAI7D,CAAC,EAhBgB,cAAU,CAAV,aAAU,CAAA,CAAA"}},
    {"offset": {"line": 2923, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 2928, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/lib/parser.ts"],"sourcesContent":["import {\n  ChatCompletion,\n  ChatCompletionCreateParams,\n  ChatCompletionMessageToolCall,\n  ChatCompletionTool,\n} from '../resources/chat/completions';\nimport {\n  ChatCompletionStreamingToolRunnerParams,\n  ChatCompletionStreamParams,\n  ChatCompletionToolRunnerParams,\n  ParsedChatCompletion,\n  ParsedChoice,\n  ParsedFunctionToolCall,\n} from '../resources/beta/chat/completions';\nimport { ResponseFormatJSONSchema } from '../resources/shared';\nimport { ContentFilterFinishReasonError, LengthFinishReasonError, OpenAIError } from \"../error\";\n\ntype AnyChatCompletionCreateParams =\n  | ChatCompletionCreateParams\n  | ChatCompletionToolRunnerParams<any>\n  | ChatCompletionStreamingToolRunnerParams<any>\n  | ChatCompletionStreamParams;\n\nexport type ExtractParsedContentFromParams<Params extends AnyChatCompletionCreateParams> =\n  Params['response_format'] extends AutoParseableResponseFormat<infer P> ? P : null;\n\nexport type AutoParseableResponseFormat<ParsedT> = ResponseFormatJSONSchema & {\n  __output: ParsedT; // type-level only\n\n  $brand: 'auto-parseable-response-format';\n  $parseRaw(content: string): ParsedT;\n};\n\nexport function makeParseableResponseFormat<ParsedT>(\n  response_format: ResponseFormatJSONSchema,\n  parser: (content: string) => ParsedT,\n): AutoParseableResponseFormat<ParsedT> {\n  const obj = { ...response_format };\n\n  Object.defineProperties(obj, {\n    $brand: {\n      value: 'auto-parseable-response-format',\n      enumerable: false,\n    },\n    $parseRaw: {\n      value: parser,\n      enumerable: false,\n    },\n  });\n\n  return obj as AutoParseableResponseFormat<ParsedT>;\n}\n\nexport function isAutoParsableResponseFormat<ParsedT>(\n  response_format: any,\n): response_format is AutoParseableResponseFormat<ParsedT> {\n  return response_format?.['$brand'] === 'auto-parseable-response-format';\n}\n\ntype ToolOptions = {\n  name: string;\n  arguments: any;\n  function?: ((args: any) => any) | undefined;\n};\n\nexport type AutoParseableTool<\n  OptionsT extends ToolOptions,\n  HasFunction = OptionsT['function'] extends Function ? true : false,\n> = ChatCompletionTool & {\n  __arguments: OptionsT['arguments']; // type-level only\n  __name: OptionsT['name']; // type-level only\n  __hasFunction: HasFunction; // type-level only\n\n  $brand: 'auto-parseable-tool';\n  $callback: ((args: OptionsT['arguments']) => any) | undefined;\n  $parseRaw(args: string): OptionsT['arguments'];\n};\n\nexport function makeParseableTool<OptionsT extends ToolOptions>(\n  tool: ChatCompletionTool,\n  {\n    parser,\n    callback,\n  }: {\n    parser: (content: string) => OptionsT['arguments'];\n    callback: ((args: any) => any) | undefined;\n  },\n): AutoParseableTool<OptionsT['arguments']> {\n  const obj = { ...tool };\n\n  Object.defineProperties(obj, {\n    $brand: {\n      value: 'auto-parseable-tool',\n      enumerable: false,\n    },\n    $parseRaw: {\n      value: parser,\n      enumerable: false,\n    },\n    $callback: {\n      value: callback,\n      enumerable: false,\n    },\n  });\n\n  return obj as AutoParseableTool<OptionsT['arguments']>;\n}\n\nexport function isAutoParsableTool(tool: any): tool is AutoParseableTool<any> {\n  return tool?.['$brand'] === 'auto-parseable-tool';\n}\n\nexport function maybeParseChatCompletion<\n  Params extends ChatCompletionCreateParams | null,\n  ParsedT = Params extends null ? null : ExtractParsedContentFromParams<NonNullable<Params>>,\n>(completion: ChatCompletion, params: Params): ParsedChatCompletion<ParsedT> {\n  if (!params || !hasAutoParseableInput(params)) {\n    return {\n      ...completion,\n      choices: completion.choices.map((choice) => ({\n        ...choice,\n        message: { ...choice.message, parsed: null, tool_calls: choice.message.tool_calls ?? [] },\n      })),\n    };\n  }\n\n  return parseChatCompletion(completion, params);\n}\n\nexport function parseChatCompletion<\n  Params extends ChatCompletionCreateParams,\n  ParsedT = ExtractParsedContentFromParams<Params>,\n>(completion: ChatCompletion, params: Params): ParsedChatCompletion<ParsedT> {\n  const choices: Array<ParsedChoice<ParsedT>> = completion.choices.map((choice): ParsedChoice<ParsedT> => {\n    if (choice.finish_reason === 'length') {\n      throw new LengthFinishReasonError();\n    }\n\n    if (choice.finish_reason === 'content_filter') {\n      throw new ContentFilterFinishReasonError();\n    }\n\n    return {\n      ...choice,\n      message: {\n        ...choice.message,\n        tool_calls: choice.message.tool_calls?.map((toolCall) => parseToolCall(params, toolCall)) ?? [],\n        parsed:\n          choice.message.content && !choice.message.refusal ?\n            parseResponseFormat(params, choice.message.content)\n          : null,\n      },\n    };\n  });\n\n  return { ...completion, choices };\n}\n\nfunction parseResponseFormat<\n  Params extends ChatCompletionCreateParams,\n  ParsedT = ExtractParsedContentFromParams<Params>,\n>(params: Params, content: string): ParsedT | null {\n  if (params.response_format?.type !== 'json_schema') {\n    return null;\n  }\n\n  if (params.response_format?.type === 'json_schema') {\n    if ('$parseRaw' in params.response_format) {\n      const response_format = params.response_format as AutoParseableResponseFormat<ParsedT>;\n\n      return response_format.$parseRaw(content);\n    }\n\n    return JSON.parse(content);\n  }\n\n  return null;\n}\n\nfunction parseToolCall<Params extends ChatCompletionCreateParams>(\n  params: Params,\n  toolCall: ChatCompletionMessageToolCall,\n): ParsedFunctionToolCall {\n  const inputTool = params.tools?.find((inputTool) => inputTool.function?.name === toolCall.function.name);\n  return {\n    ...toolCall,\n    function: {\n      ...toolCall.function,\n      parsed_arguments:\n        isAutoParsableTool(inputTool) ? inputTool.$parseRaw(toolCall.function.arguments)\n        : inputTool?.function.strict ? JSON.parse(toolCall.function.arguments)\n        : null,\n    },\n  };\n}\n\nexport function shouldParseToolCall(\n  params: ChatCompletionCreateParams | null | undefined,\n  toolCall: ChatCompletionMessageToolCall,\n): boolean {\n  if (!params) {\n    return false;\n  }\n\n  const inputTool = params.tools?.find((inputTool) => inputTool.function?.name === toolCall.function.name);\n  return isAutoParsableTool(inputTool) || inputTool?.function.strict || false;\n}\n\nexport function hasAutoParseableInput(params: AnyChatCompletionCreateParams): boolean {\n  if (isAutoParsableResponseFormat(params.response_format)) {\n    return true;\n  }\n\n  return (\n    params.tools?.some(\n      (t) => isAutoParsableTool(t) || (t.type === 'function' && t.function.strict === true),\n    ) ?? false\n  );\n}\n\nexport function validateInputTools(tools: ChatCompletionTool[] | undefined) {\n  for (const tool of tools ?? []) {\n    if (tool.type !== 'function') {\n      throw new OpenAIError(\n        `Currently only \\`function\\` tool types support auto-parsing; Received \\`${tool.type}\\``,\n      );\n    }\n\n    if (tool.function.strict !== true) {\n      throw new OpenAIError(\n        `The \\`${tool.function.name}\\` tool is not marked with \\`strict: true\\`. Only strict function tools can be auto-parsed`,\n      );\n    }\n  }\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;AAiCM,SAAU,4BACd,eAAyC,EACzC,MAAoC;IAEpC,MAAM,MAAM;QAAE,GAAG,eAAe;IAAA;IAEhC,OAAO,gBAAgB,CAAC,KAAK;QAC3B,QAAQ;YACN,OAAO;YACP,YAAY;;QAEd,WAAW;YACT,OAAO;YACP,YAAY;;;IAIhB,OAAO;AACT;AAEM,SAAU,6BACd,eAAoB;IAEpB,OAAO,iBAAiB,CAAC,SAAS,KAAK;AACzC;AAqBM,SAAU,kBACd,IAAwB,EACxB,EACE,MAAM,EACN,QAAQ,EAIT;IAED,MAAM,MAAM;QAAE,GAAG,IAAI;IAAA;IAErB,OAAO,gBAAgB,CAAC,KAAK;QAC3B,QAAQ;YACN,OAAO;YACP,YAAY;;QAEd,WAAW;YACT,OAAO;YACP,YAAY;;QAEd,WAAW;YACT,OAAO;YACP,YAAY;;;IAIhB,OAAO;AACT;AAEM,SAAU,mBAAmB,IAAS;IAC1C,OAAO,MAAM,CAAC,SAAS,KAAK;AAC9B;AAEM,SAAU,yBAGd,UAA0B,EAAE,MAAc;IAC1C,IAAI,CAAC,UAAU,CAAC,sBAAsB,SAAS;QAC7C,OAAO;YACL,GAAG,UAAU;YACb,SAAS,WAAW,OAAO,CAAC,GAAG,CAAC,CAAC,SAAW,CAAC;oBAC3C,GAAG,MAAM;oBACT,SAAS;wBAAE,GAAG,OAAO,OAAO;wBAAE,QAAQ;wBAAM,YAAY,OAAO,OAAO,CAAC,UAAU,IAAI,EAAE;oBAAA;iBACxF;;;IAIL,OAAO,oBAAoB,YAAY;AACzC;AAEM,SAAU,oBAGd,UAA0B,EAAE,MAAc;IAC1C,MAAM,UAAwC,WAAW,OAAO,CAAC,GAAG,CAAC,CAAC;QACpE,IAAI,OAAO,aAAa,KAAK,UAAU;YACrC,MAAM,IAAI,kIAAA,CAAA,0BAAuB;;QAGnC,IAAI,OAAO,aAAa,KAAK,kBAAkB;YAC7C,MAAM,IAAI,kIAAA,CAAA,iCAA8B;;QAG1C,OAAO;YACL,GAAG,MAAM;YACT,SAAS;gBACP,GAAG,OAAO,OAAO;gBACjB,YAAY,OAAO,OAAO,CAAC,UAAU,EAAE,IAAI,CAAC,WAAa,cAAc,QAAQ,cAAc,EAAE;gBAC/F,QACE,OAAO,OAAO,CAAC,OAAO,IAAI,CAAC,OAAO,OAAO,CAAC,OAAO,GAC/C,oBAAoB,QAAQ,OAAO,OAAO,CAAC,OAAO,IAClD;;;IAGV;IAEA,OAAO;QAAE,GAAG,UAAU;QAAE;IAAO;AACjC;AAEA,SAAS,oBAGP,MAAc,EAAE,OAAe;IAC/B,IAAI,OAAO,eAAe,EAAE,SAAS,eAAe;QAClD,OAAO;;IAGT,IAAI,OAAO,eAAe,EAAE,SAAS,eAAe;QAClD,IAAI,eAAe,OAAO,eAAe,EAAE;YACzC,MAAM,kBAAkB,OAAO,eAAuD;YAEtF,OAAO,gBAAgB,SAAS,CAAC;;QAGnC,OAAO,KAAK,KAAK,CAAC;;IAGpB,OAAO;AACT;AAEA,SAAS,cACP,MAAc,EACd,QAAuC;IAEvC,MAAM,YAAY,OAAO,KAAK,EAAE,KAAK,CAAC,YAAc,UAAU,QAAQ,EAAE,SAAS,SAAS,QAAQ,CAAC,IAAI;IACvG,OAAO;QACL,GAAG,QAAQ;QACX,UAAU;YACR,GAAG,SAAS,QAAQ;YACpB,kBACE,mBAAmB,aAAa,UAAU,SAAS,CAAC,SAAS,QAAQ,CAAC,SAAS,IAC7E,WAAW,SAAS,SAAS,KAAK,KAAK,CAAC,SAAS,QAAQ,CAAC,SAAS,IACnE;;;AAGV;AAEM,SAAU,oBACd,MAAqD,EACrD,QAAuC;IAEvC,IAAI,CAAC,QAAQ;QACX,OAAO;;IAGT,MAAM,YAAY,OAAO,KAAK,EAAE,KAAK,CAAC,YAAc,UAAU,QAAQ,EAAE,SAAS,SAAS,QAAQ,CAAC,IAAI;IACvG,OAAO,mBAAmB,cAAc,WAAW,SAAS,UAAU;AACxE;AAEM,SAAU,sBAAsB,MAAqC;IACzE,IAAI,6BAA6B,OAAO,eAAe,GAAG;QACxD,OAAO;;IAGT,OACE,OAAO,KAAK,EAAE,KACZ,CAAC,IAAM,mBAAmB,MAAO,EAAE,IAAI,KAAK,cAAc,EAAE,QAAQ,CAAC,MAAM,KAAK,SAC7E;AAET;AAEM,SAAU,mBAAmB,KAAuC;IACxE,KAAK,MAAM,QAAQ,SAAS,EAAE,CAAE;QAC9B,IAAI,KAAK,IAAI,KAAK,YAAY;YAC5B,MAAM,IAAI,kIAAA,CAAA,cAAW,CACnB,CAAA,wEAAA,EAA2E,KAAK,IAAI,CAAA,EAAA,CAAI;;QAI5F,IAAI,KAAK,QAAQ,CAAC,MAAM,KAAK,MAAM;YACjC,MAAM,IAAI,kIAAA,CAAA,cAAW,CACnB,CAAA,MAAA,EAAS,KAAK,QAAQ,CAAC,IAAI,CAAA,0FAAA,CAA4F;;;AAI/H"}},
    {"offset": {"line": 3068, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 3073, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/lib/RunnableFunction.ts"],"sourcesContent":["import { type ChatCompletionRunner } from './ChatCompletionRunner';\nimport { type ChatCompletionStreamingRunner } from './ChatCompletionStreamingRunner';\nimport { JSONSchema } from './jsonschema';\n\ntype PromiseOrValue<T> = T | Promise<T>;\n\nexport type RunnableFunctionWithParse<Args extends object> = {\n  /**\n   * @param args the return value from `parse`.\n   * @param runner the runner evaluating this callback.\n   * @returns a string to send back to OpenAI.\n   */\n  function: (\n    args: Args,\n    runner: ChatCompletionRunner<unknown> | ChatCompletionStreamingRunner<unknown>,\n  ) => PromiseOrValue<unknown>;\n  /**\n   * @param input the raw args from the OpenAI function call.\n   * @returns the parsed arguments to pass to `function`\n   */\n  parse: (input: string) => PromiseOrValue<Args>;\n  /**\n   * The parameters the function accepts, describes as a JSON Schema object.\n   */\n  parameters: JSONSchema;\n  /**\n   * A description of what the function does, used by the model to choose when and how to call the function.\n   */\n  description: string;\n  /**\n   * The name of the function to be called. Will default to function.name if omitted.\n   */\n  name?: string | undefined;\n  strict?: boolean | undefined;\n};\n\nexport type RunnableFunctionWithoutParse = {\n  /**\n   * @param args the raw args from the OpenAI function call.\n   * @returns a string to send back to OpenAI\n   */\n  function: (\n    args: string,\n    runner: ChatCompletionRunner<unknown> | ChatCompletionStreamingRunner<unknown>,\n  ) => PromiseOrValue<unknown>;\n  /**\n   * The parameters the function accepts, describes as a JSON Schema object.\n   */\n  parameters: JSONSchema;\n  /**\n   * A description of what the function does, used by the model to choose when and how to call the function.\n   */\n  description: string;\n  /**\n   * The name of the function to be called. Will default to function.name if omitted.\n   */\n  name?: string | undefined;\n  strict?: boolean | undefined;\n};\n\nexport type RunnableFunction<Args extends object | string> =\n  Args extends string ? RunnableFunctionWithoutParse\n  : Args extends object ? RunnableFunctionWithParse<Args>\n  : never;\n\nexport type RunnableToolFunction<Args extends object | string> =\n  Args extends string ? RunnableToolFunctionWithoutParse\n  : Args extends object ? RunnableToolFunctionWithParse<Args>\n  : never;\n\nexport type RunnableToolFunctionWithoutParse = {\n  type: 'function';\n  function: RunnableFunctionWithoutParse;\n};\nexport type RunnableToolFunctionWithParse<Args extends object> = {\n  type: 'function';\n  function: RunnableFunctionWithParse<Args>;\n};\n\nexport function isRunnableFunctionWithParse<Args extends object>(\n  fn: any,\n): fn is RunnableFunctionWithParse<Args> {\n  return typeof (fn as any).parse === 'function';\n}\n\nexport type BaseFunctionsArgs = readonly (object | string)[];\n\nexport type RunnableFunctions<FunctionsArgs extends BaseFunctionsArgs> =\n  [any[]] extends [FunctionsArgs] ? readonly RunnableFunction<any>[]\n  : {\n      [Index in keyof FunctionsArgs]: Index extends number ? RunnableFunction<FunctionsArgs[Index]>\n      : FunctionsArgs[Index];\n    };\n\nexport type RunnableTools<FunctionsArgs extends BaseFunctionsArgs> =\n  [any[]] extends [FunctionsArgs] ? readonly RunnableToolFunction<any>[]\n  : {\n      [Index in keyof FunctionsArgs]: Index extends number ? RunnableToolFunction<FunctionsArgs[Index]>\n      : FunctionsArgs[Index];\n    };\n\n/**\n * This is helper class for passing a `function` and `parse` where the `function`\n * argument type matches the `parse` return type.\n *\n * @deprecated - please use ParsingToolFunction instead.\n */\nexport class ParsingFunction<Args extends object> {\n  function: RunnableFunctionWithParse<Args>['function'];\n  parse: RunnableFunctionWithParse<Args>['parse'];\n  parameters: RunnableFunctionWithParse<Args>['parameters'];\n  description: RunnableFunctionWithParse<Args>['description'];\n  name?: RunnableFunctionWithParse<Args>['name'];\n\n  constructor(input: RunnableFunctionWithParse<Args>) {\n    this.function = input.function;\n    this.parse = input.parse;\n    this.parameters = input.parameters;\n    this.description = input.description;\n    this.name = input.name;\n  }\n}\n\n/**\n * This is helper class for passing a `function` and `parse` where the `function`\n * argument type matches the `parse` return type.\n */\nexport class ParsingToolFunction<Args extends object> {\n  type: 'function';\n  function: RunnableFunctionWithParse<Args>;\n\n  constructor(input: RunnableFunctionWithParse<Args>) {\n    this.type = 'function';\n    this.function = input;\n  }\n}\n"],"names":[],"mappings":";;;;;AA+EM,SAAU,4BACd,EAAO;IAEP,OAAO,OAAQ,GAAW,KAAK,KAAK;AACtC;AAwBM,MAAO;IAOX,YAAY,KAAsC,CAAA;QAChD,IAAI,CAAC,QAAQ,GAAG,MAAM,QAAQ;QAC9B,IAAI,CAAC,KAAK,GAAG,MAAM,KAAK;QACxB,IAAI,CAAC,UAAU,GAAG,MAAM,UAAU;QAClC,IAAI,CAAC,WAAW,GAAG,MAAM,WAAW;QACpC,IAAI,CAAC,IAAI,GAAG,MAAM,IAAI;IACxB;;AAOI,MAAO;IAIX,YAAY,KAAsC,CAAA;QAChD,IAAI,CAAC,IAAI,GAAG;QACZ,IAAI,CAAC,QAAQ,GAAG;IAClB"}},
    {"offset": {"line": 3096, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 3101, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/lib/chatCompletionUtils.ts"],"sourcesContent":["import {\n  type ChatCompletionAssistantMessageParam,\n  type ChatCompletionFunctionMessageParam,\n  type ChatCompletionMessageParam,\n  type ChatCompletionToolMessageParam,\n} from \"../resources\";\n\nexport const isAssistantMessage = (\n  message: ChatCompletionMessageParam | null | undefined,\n): message is ChatCompletionAssistantMessageParam => {\n  return message?.role === 'assistant';\n};\n\nexport const isFunctionMessage = (\n  message: ChatCompletionMessageParam | null | undefined,\n): message is ChatCompletionFunctionMessageParam => {\n  return message?.role === 'function';\n};\n\nexport const isToolMessage = (\n  message: ChatCompletionMessageParam | null | undefined,\n): message is ChatCompletionToolMessageParam => {\n  return message?.role === 'tool';\n};\n\nexport function isPresent<T>(obj: T | null | undefined): obj is T {\n  return obj != null;\n}\n"],"names":[],"mappings":";;;;;;AAOO,MAAM,qBAAqB,CAChC;IAEA,OAAO,SAAS,SAAS;AAC3B;AAEO,MAAM,oBAAoB,CAC/B;IAEA,OAAO,SAAS,SAAS;AAC3B;AAEO,MAAM,gBAAgB,CAC3B;IAEA,OAAO,SAAS,SAAS;AAC3B;AAEM,SAAU,UAAa,GAAyB;IACpD,OAAO,OAAO;AAChB"}},
    {"offset": {"line": 3119, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 3124, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/lib/EventStream.ts"],"sourcesContent":["import { APIUserAbortError, OpenAIError } from \"../error\";\n\nexport class EventStream<EventTypes extends BaseEvents> {\n  controller: AbortController = new AbortController();\n\n  #connectedPromise: Promise<void>;\n  #resolveConnectedPromise: () => void = () => {};\n  #rejectConnectedPromise: (error: OpenAIError) => void = () => {};\n\n  #endPromise: Promise<void>;\n  #resolveEndPromise: () => void = () => {};\n  #rejectEndPromise: (error: OpenAIError) => void = () => {};\n\n  #listeners: {\n    [Event in keyof EventTypes]?: EventListeners<EventTypes, Event>;\n  } = {};\n\n  #ended = false;\n  #errored = false;\n  #aborted = false;\n  #catchingPromiseCreated = false;\n\n  constructor() {\n    this.#connectedPromise = new Promise<void>((resolve, reject) => {\n      this.#resolveConnectedPromise = resolve;\n      this.#rejectConnectedPromise = reject;\n    });\n\n    this.#endPromise = new Promise<void>((resolve, reject) => {\n      this.#resolveEndPromise = resolve;\n      this.#rejectEndPromise = reject;\n    });\n\n    // Don't let these promises cause unhandled rejection errors.\n    // we will manually cause an unhandled rejection error later\n    // if the user hasn't registered any error listener or called\n    // any promise-returning method.\n    this.#connectedPromise.catch(() => {});\n    this.#endPromise.catch(() => {});\n  }\n\n  protected _run(this: EventStream<EventTypes>, executor: () => Promise<any>) {\n    // Unfortunately if we call `executor()` immediately we get runtime errors about\n    // references to `this` before the `super()` constructor call returns.\n    setTimeout(() => {\n      executor().then(() => {\n        this._emitFinal();\n        this._emit('end');\n      }, this.#handleError.bind(this));\n    }, 0);\n  }\n\n  protected _connected(this: EventStream<EventTypes>) {\n    if (this.ended) return;\n    this.#resolveConnectedPromise();\n    this._emit('connect');\n  }\n\n  get ended(): boolean {\n    return this.#ended;\n  }\n\n  get errored(): boolean {\n    return this.#errored;\n  }\n\n  get aborted(): boolean {\n    return this.#aborted;\n  }\n\n  abort() {\n    this.controller.abort();\n  }\n\n  /**\n   * Adds the listener function to the end of the listeners array for the event.\n   * No checks are made to see if the listener has already been added. Multiple calls passing\n   * the same combination of event and listener will result in the listener being added, and\n   * called, multiple times.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  on<Event extends keyof EventTypes>(event: Event, listener: EventListener<EventTypes, Event>): this {\n    const listeners: EventListeners<EventTypes, Event> =\n      this.#listeners[event] || (this.#listeners[event] = []);\n    listeners.push({ listener });\n    return this;\n  }\n\n  /**\n   * Removes the specified listener from the listener array for the event.\n   * off() will remove, at most, one instance of a listener from the listener array. If any single\n   * listener has been added multiple times to the listener array for the specified event, then\n   * off() must be called multiple times to remove each instance.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  off<Event extends keyof EventTypes>(event: Event, listener: EventListener<EventTypes, Event>): this {\n    const listeners = this.#listeners[event];\n    if (!listeners) return this;\n    const index = listeners.findIndex((l) => l.listener === listener);\n    if (index >= 0) listeners.splice(index, 1);\n    return this;\n  }\n\n  /**\n   * Adds a one-time listener function for the event. The next time the event is triggered,\n   * this listener is removed and then invoked.\n   * @returns this ChatCompletionStream, so that calls can be chained\n   */\n  once<Event extends keyof EventTypes>(event: Event, listener: EventListener<EventTypes, Event>): this {\n    const listeners: EventListeners<EventTypes, Event> =\n      this.#listeners[event] || (this.#listeners[event] = []);\n    listeners.push({ listener, once: true });\n    return this;\n  }\n\n  /**\n   * This is similar to `.once()`, but returns a Promise that resolves the next time\n   * the event is triggered, instead of calling a listener callback.\n   * @returns a Promise that resolves the next time given event is triggered,\n   * or rejects if an error is emitted.  (If you request the 'error' event,\n   * returns a promise that resolves with the error).\n   *\n   * Example:\n   *\n   *   const message = await stream.emitted('message') // rejects if the stream errors\n   */\n  emitted<Event extends keyof EventTypes>(\n    event: Event,\n  ): Promise<\n    EventParameters<EventTypes, Event> extends [infer Param] ? Param\n    : EventParameters<EventTypes, Event> extends [] ? void\n    : EventParameters<EventTypes, Event>\n  > {\n    return new Promise((resolve, reject) => {\n      this.#catchingPromiseCreated = true;\n      if (event !== 'error') this.once('error', reject);\n      this.once(event, resolve as any);\n    });\n  }\n\n  async done(): Promise<void> {\n    this.#catchingPromiseCreated = true;\n    await this.#endPromise;\n  }\n\n  #handleError(this: EventStream<EventTypes>, error: unknown) {\n    this.#errored = true;\n    if (error instanceof Error && error.name === 'AbortError') {\n      error = new APIUserAbortError();\n    }\n    if (error instanceof APIUserAbortError) {\n      this.#aborted = true;\n      return this._emit('abort', error);\n    }\n    if (error instanceof OpenAIError) {\n      return this._emit('error', error);\n    }\n    if (error instanceof Error) {\n      const openAIError: OpenAIError = new OpenAIError(error.message);\n      // @ts-ignore\n      openAIError.cause = error;\n      return this._emit('error', openAIError);\n    }\n    return this._emit('error', new OpenAIError(String(error)));\n  }\n\n  _emit<Event extends keyof BaseEvents>(event: Event, ...args: EventParameters<BaseEvents, Event>): void;\n  _emit<Event extends keyof EventTypes>(event: Event, ...args: EventParameters<EventTypes, Event>): void;\n  _emit<Event extends keyof EventTypes>(\n    this: EventStream<EventTypes>,\n    event: Event,\n    ...args: EventParameters<EventTypes, Event>\n  ) {\n    // make sure we don't emit any events after end\n    if (this.#ended) {\n      return;\n    }\n\n    if (event === 'end') {\n      this.#ended = true;\n      this.#resolveEndPromise();\n    }\n\n    const listeners: EventListeners<EventTypes, Event> | undefined = this.#listeners[event];\n    if (listeners) {\n      this.#listeners[event] = listeners.filter((l) => !l.once) as any;\n      listeners.forEach(({ listener }: any) => listener(...(args as any)));\n    }\n\n    if (event === 'abort') {\n      const error = args[0] as APIUserAbortError;\n      if (!this.#catchingPromiseCreated && !listeners?.length) {\n        Promise.reject(error);\n      }\n      this.#rejectConnectedPromise(error);\n      this.#rejectEndPromise(error);\n      this._emit('end');\n      return;\n    }\n\n    if (event === 'error') {\n      // NOTE: _emit('error', error) should only be called from #handleError().\n\n      const error = args[0] as OpenAIError;\n      if (!this.#catchingPromiseCreated && !listeners?.length) {\n        // Trigger an unhandled rejection if the user hasn't registered any error handlers.\n        // If you are seeing stack traces here, make sure to handle errors via either:\n        // - runner.on('error', () => ...)\n        // - await runner.done()\n        // - await runner.finalChatCompletion()\n        // - etc.\n        Promise.reject(error);\n      }\n      this.#rejectConnectedPromise(error);\n      this.#rejectEndPromise(error);\n      this._emit('end');\n    }\n  }\n\n  protected _emitFinal(): void {}\n}\n\ntype EventListener<Events, EventType extends keyof Events> = Events[EventType];\n\ntype EventListeners<Events, EventType extends keyof Events> = Array<{\n  listener: EventListener<Events, EventType>;\n  once?: boolean;\n}>;\n\nexport type EventParameters<Events, EventType extends keyof Events> = {\n  [Event in EventType]: EventListener<Events, EventType> extends (...args: infer P) => any ? P : never;\n}[EventType];\n\nexport interface BaseEvents {\n  connect: () => void;\n  error: (error: OpenAIError) => void;\n  abort: (error: APIUserAbortError) => void;\n  end: () => void;\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;AAEM,MAAO;IAoBX,aAAA;;QAnBA,IAAA,CAAA,UAAU,GAAoB,IAAI;QAElC,8BAAA,GAAA,CAAA,IAAA,EAAA,KAAA;QACA,qCAAA,GAAA,CAAA,IAAA,EAAuC,KAAO;QAC9C,oCAAA,GAAA,CAAA,IAAA,EAAwD,KAAO;QAE/D,wBAAA,GAAA,CAAA,IAAA,EAAA,KAAA;QACA,+BAAA,GAAA,CAAA,IAAA,EAAiC,KAAO;QACxC,8BAAA,GAAA,CAAA,IAAA,EAAkD,KAAO;QAEzD,uBAAA,GAAA,CAAA,IAAA,EAEI,CAAA;QAEJ,mBAAA,GAAA,CAAA,IAAA,EAAS;QACT,qBAAA,GAAA,CAAA,IAAA,EAAW;QACX,qBAAA,GAAA,CAAA,IAAA,EAAW;QACX,oCAAA,GAAA,CAAA,IAAA,EAA0B;QAGxB,uBAAA,IAAI,EAAA,+BAAqB,IAAI,QAAc,CAAC,SAAS;YACnD,uBAAA,IAAI,EAAA,sCAA4B,SAAO;YACvC,uBAAA,IAAI,EAAA,qCAA2B,QAAM;QACvC,IAAE;QAEF,uBAAA,IAAI,EAAA,yBAAe,IAAI,QAAc,CAAC,SAAS;YAC7C,uBAAA,IAAI,EAAA,gCAAsB,SAAO;YACjC,uBAAA,IAAI,EAAA,+BAAqB,QAAM;QACjC,IAAE;QAEF,6DAA6D;QAC7D,4DAA4D;QAC5D,6DAA6D;QAC7D,gCAAgC;QAChC,uBAAA,IAAI,EAAA,+BAAA,KAAmB,KAAK,CAAC,KAAO;QACpC,uBAAA,IAAI,EAAA,yBAAA,KAAa,KAAK,CAAC,KAAO;IAChC;IAEU,KAAoC,QAA4B,EAAA;QACxE,gFAAgF;QAChF,sEAAsE;QACtE,WAAW;YACT,WAAW,IAAI,CAAC;gBACd,IAAI,CAAC,UAAU;gBACf,IAAI,CAAC,KAAK,CAAC;YACb,GAAG,uBAAA,IAAI,EAAA,wBAAA,KAAA,0BAAc,IAAI,CAAC,IAAI;QAChC,GAAG;IACL;IAEU,aAAU;QAClB,IAAI,IAAI,CAAC,KAAK,EAAE;QAChB,uBAAA,IAAI,EAAA,sCAAA,KAAyB,IAAA,CAA7B,IAAI;QACJ,IAAI,CAAC,KAAK,CAAC;IACb;IAEA,IAAI,QAAK;QACP,OAAO,uBAAA,IAAI,EAAA,oBAAA;IACb;IAEA,IAAI,UAAO;QACT,OAAO,uBAAA,IAAI,EAAA,sBAAA;IACb;IAEA,IAAI,UAAO;QACT,OAAO,uBAAA,IAAI,EAAA,sBAAA;IACb;IAEA,QAAK;QACH,IAAI,CAAC,UAAU,CAAC,KAAK;IACvB;IAEA;;;;;;QAOA,GAAmC,KAAY,EAAE,QAA0C,EAAA;QACzF,MAAM,YACJ,uBAAA,IAAI,EAAA,wBAAA,IAAW,CAAC,MAAM,IAAI,CAAC,uBAAA,IAAI,EAAA,wBAAA,IAAW,CAAC,MAAM,GAAG,EAAE;QACxD,UAAU,IAAI,CAAC;YAAE;QAAQ;QACzB,OAAO,IAAI;IACb;IAEA;;;;;;QAOA,IAAoC,KAAY,EAAE,QAA0C,EAAA;QAC1F,MAAM,YAAY,uBAAA,IAAI,EAAA,wBAAA,IAAW,CAAC,MAAM;QACxC,IAAI,CAAC,WAAW,OAAO,IAAI;QAC3B,MAAM,QAAQ,UAAU,SAAS,CAAC,CAAC,IAAM,EAAE,QAAQ,KAAK;QACxD,IAAI,SAAS,GAAG,UAAU,MAAM,CAAC,OAAO;QACxC,OAAO,IAAI;IACb;IAEA;;;;QAKA,KAAqC,KAAY,EAAE,QAA0C,EAAA;QAC3F,MAAM,YACJ,uBAAA,IAAI,EAAA,wBAAA,IAAW,CAAC,MAAM,IAAI,CAAC,uBAAA,IAAI,EAAA,wBAAA,IAAW,CAAC,MAAM,GAAG,EAAE;QACxD,UAAU,IAAI,CAAC;YAAE;YAAU,MAAM;QAAI;QACrC,OAAO,IAAI;IACb;IAEA;;;;;;;;;;QAWA,QACE,KAAY,EAAA;QAMZ,OAAO,IAAI,QAAQ,CAAC,SAAS;YAC3B,uBAAA,IAAI,EAAA,qCAA2B,MAAI;YACnC,IAAI,UAAU,SAAS,IAAI,CAAC,IAAI,CAAC,SAAS;YAC1C,IAAI,CAAC,IAAI,CAAC,OAAO;QACnB;IACF;IAEA,MAAM,OAAI;QACR,uBAAA,IAAI,EAAA,qCAA2B,MAAI;QACnC,MAAM,uBAAA,IAAI,EAAA,yBAAA;IACZ;IAyBA,MAEE,KAAY,EACZ,GAAG,IAAwC,EAAA;QAE3C,+CAA+C;QAC/C,IAAI,uBAAA,IAAI,EAAA,oBAAA,MAAS;YACf;;QAGF,IAAI,UAAU,OAAO;YACnB,uBAAA,IAAI,EAAA,oBAAU,MAAI;YAClB,uBAAA,IAAI,EAAA,gCAAA,KAAmB,IAAA,CAAvB,IAAI;;QAGN,MAAM,YAA2D,uBAAA,IAAI,EAAA,wBAAA,IAAW,CAAC,MAAM;QACvF,IAAI,WAAW;YACb,uBAAA,IAAI,EAAA,wBAAA,IAAW,CAAC,MAAM,GAAG,UAAU,MAAM,CAAC,CAAC,IAAM,CAAC,EAAE,IAAI;YACxD,UAAU,OAAO,CAAC,CAAC,EAAE,QAAQ,EAAO,GAAK,YAAa;;QAGxD,IAAI,UAAU,SAAS;YACrB,MAAM,QAAQ,IAAI,CAAC,EAAuB;YAC1C,IAAI,CAAC,uBAAA,IAAI,EAAA,qCAAA,QAA4B,CAAC,WAAW,QAAQ;gBACvD,QAAQ,MAAM,CAAC;;YAEjB,uBAAA,IAAI,EAAA,qCAAA,KAAwB,IAAA,CAA5B,IAAI,EAAyB;YAC7B,uBAAA,IAAI,EAAA,+BAAA,KAAkB,IAAA,CAAtB,IAAI,EAAmB;YACvB,IAAI,CAAC,KAAK,CAAC;YACX;;QAGF,IAAI,UAAU,SAAS;YACrB,yEAAyE;YAEzE,MAAM,QAAQ,IAAI,CAAC,EAAiB;YACpC,IAAI,CAAC,uBAAA,IAAI,EAAA,qCAAA,QAA4B,CAAC,WAAW,QAAQ;gBACvD,mFAAmF;gBACnF,8EAA8E;gBAC9E,kCAAkC;gBAClC,wBAAwB;gBACxB,uCAAuC;gBACvC,SAAS;gBACT,QAAQ,MAAM,CAAC;;YAEjB,uBAAA,IAAI,EAAA,qCAAA,KAAwB,IAAA,CAA5B,IAAI,EAAyB;YAC7B,uBAAA,IAAI,EAAA,+BAAA,KAAkB,IAAA,CAAtB,IAAI,EAAmB;YACvB,IAAI,CAAC,KAAK,CAAC;;IAEf;IAEU,aAAU,CAAU;;olBA1Ec,KAAc;IACxD,uBAAA,IAAI,EAAA,sBAAY,MAAI;IACpB,IAAI,iBAAiB,SAAS,MAAM,IAAI,KAAK,cAAc;QACzD,QAAQ,IAAI,kIAAA,CAAA,oBAAiB;;IAE/B,IAAI,iBAAiB,kIAAA,CAAA,oBAAiB,EAAE;QACtC,uBAAA,IAAI,EAAA,sBAAY,MAAI;QACpB,OAAO,IAAI,CAAC,KAAK,CAAC,SAAS;;IAE7B,IAAI,iBAAiB,kIAAA,CAAA,cAAW,EAAE;QAChC,OAAO,IAAI,CAAC,KAAK,CAAC,SAAS;;IAE7B,IAAI,iBAAiB,OAAO;QAC1B,MAAM,cAA2B,IAAI,kIAAA,CAAA,cAAW,CAAC,MAAM,OAAO;QAC9D,aAAa;QACb,YAAY,KAAK,GAAG;QACpB,OAAO,IAAI,CAAC,KAAK,CAAC,SAAS;;IAE7B,OAAO,IAAI,CAAC,KAAK,CAAC,SAAS,IAAI,kIAAA,CAAA,cAAW,CAAC,OAAO;AACpD"}},
    {"offset": {"line": 3321, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 3326, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/lib/AbstractChatCompletionRunner.ts"],"sourcesContent":["import * as Core from \"../core\";\nimport { type CompletionUsage } from \"../resources/completions\";\nimport {\n  type ChatCompletion,\n  type ChatCompletionMessage,\n  type ChatCompletionMessageParam,\n  type ChatCompletionCreateParams,\n  type ChatCompletionTool,\n} from \"../resources/chat/completions\";\nimport { OpenAIError } from \"../error\";\nimport {\n  type RunnableFunction,\n  isRunnableFunctionWithParse,\n  type BaseFunctionsArgs,\n  RunnableToolFunction,\n} from './RunnableFunction';\nimport { ChatCompletionFunctionRunnerParams, ChatCompletionToolRunnerParams } from './ChatCompletionRunner';\nimport {\n  ChatCompletionStreamingFunctionRunnerParams,\n  ChatCompletionStreamingToolRunnerParams,\n} from './ChatCompletionStreamingRunner';\nimport { isAssistantMessage, isFunctionMessage, isToolMessage } from './chatCompletionUtils';\nimport { BaseEvents, EventStream } from './EventStream';\nimport { ParsedChatCompletion } from '../resources/beta/chat/completions';\nimport OpenAI from '../index';\nimport { isAutoParsableTool, parseChatCompletion } from \"./parser\";\n\nconst DEFAULT_MAX_CHAT_COMPLETIONS = 10;\nexport interface RunnerOptions extends Core.RequestOptions {\n  /** How many requests to make before canceling. Default 10. */\n  maxChatCompletions?: number;\n}\n\nexport class AbstractChatCompletionRunner<\n  EventTypes extends AbstractChatCompletionRunnerEvents,\n  ParsedT,\n> extends EventStream<EventTypes> {\n  protected _chatCompletions: ParsedChatCompletion<ParsedT>[] = [];\n  messages: ChatCompletionMessageParam[] = [];\n\n  protected _addChatCompletion(\n    this: AbstractChatCompletionRunner<AbstractChatCompletionRunnerEvents, ParsedT>,\n    chatCompletion: ParsedChatCompletion<ParsedT>,\n  ): ParsedChatCompletion<ParsedT> {\n    this._chatCompletions.push(chatCompletion);\n    this._emit('chatCompletion', chatCompletion);\n    const message = chatCompletion.choices[0]?.message;\n    if (message) this._addMessage(message as ChatCompletionMessageParam);\n    return chatCompletion;\n  }\n\n  protected _addMessage(\n    this: AbstractChatCompletionRunner<AbstractChatCompletionRunnerEvents, ParsedT>,\n    message: ChatCompletionMessageParam,\n    emit = true,\n  ) {\n    if (!('content' in message)) message.content = null;\n\n    this.messages.push(message);\n\n    if (emit) {\n      this._emit('message', message);\n      if ((isFunctionMessage(message) || isToolMessage(message)) && message.content) {\n        // Note, this assumes that {role: 'tool', content: …} is always the result of a call of tool of type=function.\n        this._emit('functionCallResult', message.content as string);\n      } else if (isAssistantMessage(message) && message.function_call) {\n        this._emit('functionCall', message.function_call);\n      } else if (isAssistantMessage(message) && message.tool_calls) {\n        for (const tool_call of message.tool_calls) {\n          if (tool_call.type === 'function') {\n            this._emit('functionCall', tool_call.function);\n          }\n        }\n      }\n    }\n  }\n\n  /**\n   * @returns a promise that resolves with the final ChatCompletion, or rejects\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletion.\n   */\n  async finalChatCompletion(): Promise<ParsedChatCompletion<ParsedT>> {\n    await this.done();\n    const completion = this._chatCompletions[this._chatCompletions.length - 1];\n    if (!completion) throw new OpenAIError('stream ended without producing a ChatCompletion');\n    return completion;\n  }\n\n  #getFinalContent(): string | null {\n    return this.#getFinalMessage().content ?? null;\n  }\n\n  /**\n   * @returns a promise that resolves with the content of the final ChatCompletionMessage, or rejects\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n   */\n  async finalContent(): Promise<string | null> {\n    await this.done();\n    return this.#getFinalContent();\n  }\n\n  #getFinalMessage(): ChatCompletionMessage {\n    let i = this.messages.length;\n    while (i-- > 0) {\n      const message = this.messages[i];\n      if (isAssistantMessage(message)) {\n        const { function_call, ...rest } = message;\n        const ret: ChatCompletionMessage = {\n          ...rest,\n          content: (message as ChatCompletionMessage).content ?? null,\n          refusal: (message as ChatCompletionMessage).refusal ?? null,\n        };\n        if (function_call) {\n          ret.function_call = function_call;\n        }\n        return ret;\n      }\n    }\n    throw new OpenAIError('stream ended without producing a ChatCompletionMessage with role=assistant');\n  }\n\n  /**\n   * @returns a promise that resolves with the the final assistant ChatCompletionMessage response,\n   * or rejects if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n   */\n  async finalMessage(): Promise<ChatCompletionMessage> {\n    await this.done();\n    return this.#getFinalMessage();\n  }\n\n  #getFinalFunctionCall(): ChatCompletionMessage.FunctionCall | undefined {\n    for (let i = this.messages.length - 1; i >= 0; i--) {\n      const message = this.messages[i];\n      if (isAssistantMessage(message) && message?.function_call) {\n        return message.function_call;\n      }\n      if (isAssistantMessage(message) && message?.tool_calls?.length) {\n        return message.tool_calls.at(-1)?.function;\n      }\n    }\n\n    return;\n  }\n\n  /**\n   * @returns a promise that resolves with the content of the final FunctionCall, or rejects\n   * if an error occurred or the stream ended prematurely without producing a ChatCompletionMessage.\n   */\n  async finalFunctionCall(): Promise<ChatCompletionMessage.FunctionCall | undefined> {\n    await this.done();\n    return this.#getFinalFunctionCall();\n  }\n\n  #getFinalFunctionCallResult(): string | undefined {\n    for (let i = this.messages.length - 1; i >= 0; i--) {\n      const message = this.messages[i];\n      if (isFunctionMessage(message) && message.content != null) {\n        return message.content;\n      }\n      if (\n        isToolMessage(message) &&\n        message.content != null &&\n        typeof message.content === 'string' &&\n        this.messages.some(\n          (x) =>\n            x.role === 'assistant' &&\n            x.tool_calls?.some((y) => y.type === 'function' && y.id === message.tool_call_id),\n        )\n      ) {\n        return message.content;\n      }\n    }\n\n    return;\n  }\n\n  async finalFunctionCallResult(): Promise<string | undefined> {\n    await this.done();\n    return this.#getFinalFunctionCallResult();\n  }\n\n  #calculateTotalUsage(): CompletionUsage {\n    const total: CompletionUsage = {\n      completion_tokens: 0,\n      prompt_tokens: 0,\n      total_tokens: 0,\n    };\n    for (const { usage } of this._chatCompletions) {\n      if (usage) {\n        total.completion_tokens += usage.completion_tokens;\n        total.prompt_tokens += usage.prompt_tokens;\n        total.total_tokens += usage.total_tokens;\n      }\n    }\n    return total;\n  }\n\n  async totalUsage(): Promise<CompletionUsage> {\n    await this.done();\n    return this.#calculateTotalUsage();\n  }\n\n  allChatCompletions(): ChatCompletion[] {\n    return [...this._chatCompletions];\n  }\n\n  protected override _emitFinal(\n    this: AbstractChatCompletionRunner<AbstractChatCompletionRunnerEvents, ParsedT>,\n  ) {\n    const completion = this._chatCompletions[this._chatCompletions.length - 1];\n    if (completion) this._emit('finalChatCompletion', completion);\n    const finalMessage = this.#getFinalMessage();\n    if (finalMessage) this._emit('finalMessage', finalMessage);\n    const finalContent = this.#getFinalContent();\n    if (finalContent) this._emit('finalContent', finalContent);\n\n    const finalFunctionCall = this.#getFinalFunctionCall();\n    if (finalFunctionCall) this._emit('finalFunctionCall', finalFunctionCall);\n\n    const finalFunctionCallResult = this.#getFinalFunctionCallResult();\n    if (finalFunctionCallResult != null) this._emit('finalFunctionCallResult', finalFunctionCallResult);\n\n    if (this._chatCompletions.some((c) => c.usage)) {\n      this._emit('totalUsage', this.#calculateTotalUsage());\n    }\n  }\n\n  #validateParams(params: ChatCompletionCreateParams): void {\n    if (params.n != null && params.n > 1) {\n      throw new OpenAIError(\n        'ChatCompletion convenience helpers only support n=1 at this time. To use n>1, please use chat.completions.create() directly.',\n      );\n    }\n  }\n\n  protected async _createChatCompletion(\n    client: OpenAI,\n    params: ChatCompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): Promise<ParsedChatCompletion<ParsedT>> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#validateParams(params);\n\n    const chatCompletion = await client.chat.completions.create(\n      { ...params, stream: false },\n      { ...options, signal: this.controller.signal },\n    );\n    this._connected();\n    return this._addChatCompletion(parseChatCompletion(chatCompletion, params));\n  }\n\n  protected async _runChatCompletion(\n    client: OpenAI,\n    params: ChatCompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): Promise<ChatCompletion> {\n    for (const message of params.messages) {\n      this._addMessage(message, false);\n    }\n    return await this._createChatCompletion(client, params, options);\n  }\n\n  protected async _runFunctions<FunctionsArgs extends BaseFunctionsArgs>(\n    client: OpenAI,\n    params:\n      | ChatCompletionFunctionRunnerParams<FunctionsArgs>\n      | ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs>,\n    options?: RunnerOptions,\n  ) {\n    const role = 'function' as const;\n    const { function_call = 'auto', stream, ...restParams } = params;\n    const singleFunctionToCall = typeof function_call !== 'string' && function_call?.name;\n    const { maxChatCompletions = DEFAULT_MAX_CHAT_COMPLETIONS } = options || {};\n\n    const functionsByName: Record<string, RunnableFunction<any>> = {};\n    for (const f of params.functions) {\n      functionsByName[f.name || f.function.name] = f;\n    }\n\n    const functions: ChatCompletionCreateParams.Function[] = params.functions.map(\n      (f): ChatCompletionCreateParams.Function => ({\n        name: f.name || f.function.name,\n        parameters: f.parameters as Record<string, unknown>,\n        description: f.description,\n      }),\n    );\n\n    for (const message of params.messages) {\n      this._addMessage(message, false);\n    }\n\n    for (let i = 0; i < maxChatCompletions; ++i) {\n      const chatCompletion: ChatCompletion = await this._createChatCompletion(\n        client,\n        {\n          ...restParams,\n          function_call,\n          functions,\n          messages: [...this.messages],\n        },\n        options,\n      );\n      const message = chatCompletion.choices[0]?.message;\n      if (!message) {\n        throw new OpenAIError(`missing message in ChatCompletion response`);\n      }\n      if (!message.function_call) return;\n      const { name, arguments: args } = message.function_call;\n      const fn = functionsByName[name];\n      if (!fn) {\n        const content = `Invalid function_call: ${JSON.stringify(name)}. Available options are: ${functions\n          .map((f) => JSON.stringify(f.name))\n          .join(', ')}. Please try again`;\n\n        this._addMessage({ role, name, content });\n        continue;\n      } else if (singleFunctionToCall && singleFunctionToCall !== name) {\n        const content = `Invalid function_call: ${JSON.stringify(name)}. ${JSON.stringify(\n          singleFunctionToCall,\n        )} requested. Please try again`;\n\n        this._addMessage({ role, name, content });\n        continue;\n      }\n\n      let parsed;\n      try {\n        parsed = isRunnableFunctionWithParse(fn) ? await fn.parse(args) : args;\n      } catch (error) {\n        this._addMessage({\n          role,\n          name,\n          content: error instanceof Error ? error.message : String(error),\n        });\n        continue;\n      }\n\n      // @ts-expect-error it can't rule out `never` type.\n      const rawContent = await fn.function(parsed, this);\n      const content = this.#stringifyFunctionCallResult(rawContent);\n\n      this._addMessage({ role, name, content });\n\n      if (singleFunctionToCall) return;\n    }\n  }\n\n  protected async _runTools<FunctionsArgs extends BaseFunctionsArgs>(\n    client: OpenAI,\n    params:\n      | ChatCompletionToolRunnerParams<FunctionsArgs>\n      | ChatCompletionStreamingToolRunnerParams<FunctionsArgs>,\n    options?: RunnerOptions,\n  ) {\n    const role = 'tool' as const;\n    const { tool_choice = 'auto', stream, ...restParams } = params;\n    const singleFunctionToCall = typeof tool_choice !== 'string' && tool_choice?.function?.name;\n    const { maxChatCompletions = DEFAULT_MAX_CHAT_COMPLETIONS } = options || {};\n\n    // TODO(someday): clean this logic up\n    const inputTools = params.tools.map((tool): RunnableToolFunction<any> => {\n      if (isAutoParsableTool(tool)) {\n        if (!tool.$callback) {\n          throw new OpenAIError('Tool given to `.runTools()` that does not have an associated function');\n        }\n\n        return {\n          type: 'function',\n          function: {\n            function: tool.$callback,\n            name: tool.function.name,\n            description: tool.function.description || '',\n            parameters: tool.function.parameters as any,\n            parse: tool.$parseRaw,\n            strict: true,\n          },\n        };\n      }\n\n      return tool as any as RunnableToolFunction<any>;\n    });\n\n    const functionsByName: Record<string, RunnableFunction<any>> = {};\n    for (const f of inputTools) {\n      if (f.type === 'function') {\n        functionsByName[f.function.name || f.function.function.name] = f.function;\n      }\n    }\n\n    const tools: ChatCompletionTool[] =\n      'tools' in params ?\n        inputTools.map((t) =>\n          t.type === 'function' ?\n            {\n              type: 'function',\n              function: {\n                name: t.function.name || t.function.function.name,\n                parameters: t.function.parameters as Record<string, unknown>,\n                description: t.function.description,\n                strict: t.function.strict,\n              },\n            }\n          : (t as unknown as ChatCompletionTool),\n        )\n      : (undefined as any);\n\n    for (const message of params.messages) {\n      this._addMessage(message, false);\n    }\n\n    for (let i = 0; i < maxChatCompletions; ++i) {\n      const chatCompletion: ChatCompletion = await this._createChatCompletion(\n        client,\n        {\n          ...restParams,\n          tool_choice,\n          tools,\n          messages: [...this.messages],\n        },\n        options,\n      );\n      const message = chatCompletion.choices[0]?.message;\n      if (!message) {\n        throw new OpenAIError(`missing message in ChatCompletion response`);\n      }\n      if (!message.tool_calls?.length) {\n        return;\n      }\n\n      for (const tool_call of message.tool_calls) {\n        if (tool_call.type !== 'function') continue;\n        const tool_call_id = tool_call.id;\n        const { name, arguments: args } = tool_call.function;\n        const fn = functionsByName[name];\n\n        if (!fn) {\n          const content = `Invalid tool_call: ${JSON.stringify(name)}. Available options are: ${Object.keys(\n            functionsByName,\n          )\n            .map((name) => JSON.stringify(name))\n            .join(', ')}. Please try again`;\n\n          this._addMessage({ role, tool_call_id, content });\n          continue;\n        } else if (singleFunctionToCall && singleFunctionToCall !== name) {\n          const content = `Invalid tool_call: ${JSON.stringify(name)}. ${JSON.stringify(\n            singleFunctionToCall,\n          )} requested. Please try again`;\n\n          this._addMessage({ role, tool_call_id, content });\n          continue;\n        }\n\n        let parsed;\n        try {\n          parsed = isRunnableFunctionWithParse(fn) ? await fn.parse(args) : args;\n        } catch (error) {\n          const content = error instanceof Error ? error.message : String(error);\n          this._addMessage({ role, tool_call_id, content });\n          continue;\n        }\n\n        // @ts-expect-error it can't rule out `never` type.\n        const rawContent = await fn.function(parsed, this);\n        const content = this.#stringifyFunctionCallResult(rawContent);\n        this._addMessage({ role, tool_call_id, content });\n\n        if (singleFunctionToCall) {\n          return;\n        }\n      }\n    }\n\n    return;\n  }\n\n  #stringifyFunctionCallResult(rawContent: unknown): string {\n    return (\n      typeof rawContent === 'string' ? rawContent\n      : rawContent === undefined ? 'undefined'\n      : JSON.stringify(rawContent)\n    );\n  }\n}\n\nexport interface AbstractChatCompletionRunnerEvents extends BaseEvents {\n  functionCall: (functionCall: ChatCompletionMessage.FunctionCall) => void;\n  message: (message: ChatCompletionMessageParam) => void;\n  chatCompletion: (completion: ChatCompletion) => void;\n  finalContent: (contentSnapshot: string) => void;\n  finalMessage: (message: ChatCompletionMessageParam) => void;\n  finalChatCompletion: (completion: ChatCompletion) => void;\n  finalFunctionCall: (functionCall: ChatCompletionMessage.FunctionCall) => void;\n  functionCallResult: (content: string) => void;\n  finalFunctionCallResult: (content: string) => void;\n  totalUsage: (usage: CompletionUsage) => void;\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;AA2BA,MAAM,+BAA+B;AAM/B,MAAO,qCAGH,+IAAA,CAAA,cAAuB;IAHjC,aAAA;;;QAIY,IAAA,CAAA,gBAAgB,GAAoC,EAAE;QAChE,IAAA,CAAA,QAAQ,GAAiC,EAAE;IAic7C;IA/bY,mBAER,cAA6C,EAAA;QAE7C,IAAI,CAAC,gBAAgB,CAAC,IAAI,CAAC;QAC3B,IAAI,CAAC,KAAK,CAAC,kBAAkB;QAC7B,MAAM,UAAU,eAAe,OAAO,CAAC,EAAE,EAAE;QAC3C,IAAI,SAAS,IAAI,CAAC,WAAW,CAAC;QAC9B,OAAO;IACT;IAEU,YAER,OAAmC,EACnC,OAAO,IAAI,EAAA;QAEX,IAAI,CAAC,CAAC,aAAa,OAAO,GAAG,QAAQ,OAAO,GAAG;QAE/C,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC;QAEnB,IAAI,MAAM;YACR,IAAI,CAAC,KAAK,CAAC,WAAW;YACtB,IAAI,CAAC,CAAA,GAAA,uJAAA,CAAA,oBAAiB,AAAjB,EAAkB,YAAY,CAAA,GAAA,uJAAA,CAAA,gBAAa,AAAb,EAAc,QAAQ,KAAK,QAAQ,OAAO,EAAE;gBAC7E,8GAA8G;gBAC9G,IAAI,CAAC,KAAK,CAAC,sBAAsB,QAAQ,OAAiB;mBACrD,IAAI,CAAA,GAAA,uJAAA,CAAA,qBAAkB,AAAlB,EAAmB,YAAY,QAAQ,aAAa,EAAE;gBAC/D,IAAI,CAAC,KAAK,CAAC,gBAAgB,QAAQ,aAAa;mBAC3C,IAAI,CAAA,GAAA,uJAAA,CAAA,qBAAkB,AAAlB,EAAmB,YAAY,QAAQ,UAAU,EAAE;gBAC5D,KAAK,MAAM,aAAa,QAAQ,UAAU,CAAE;oBAC1C,IAAI,UAAU,IAAI,KAAK,YAAY;wBACjC,IAAI,CAAC,KAAK,CAAC,gBAAgB,UAAU,QAAQ;;;;;IAKvD;IAEA;;;QAIA,MAAM,sBAAmB;QACvB,MAAM,IAAI,CAAC,IAAI;QACf,MAAM,aAAa,IAAI,CAAC,gBAAgB,CAAC,IAAI,CAAC,gBAAgB,CAAC,MAAM,GAAG,EAAE;QAC1E,IAAI,CAAC,YAAY,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC;QACvC,OAAO;IACT;IAMA;;;QAIA,MAAM,eAAY;QAChB,MAAM,IAAI,CAAC,IAAI;QACf,OAAO,uBAAA,IAAI,EAAA,yCAAA,KAAA,+CAAiB,IAAA,CAArB,IAAI;IACb;IAsBA;;;QAIA,MAAM,eAAY;QAChB,MAAM,IAAI,CAAC,IAAI;QACf,OAAO,uBAAA,IAAI,EAAA,yCAAA,KAAA,+CAAiB,IAAA,CAArB,IAAI;IACb;IAgBA;;;QAIA,MAAM,oBAAiB;QACrB,MAAM,IAAI,CAAC,IAAI;QACf,OAAO,uBAAA,IAAI,EAAA,yCAAA,KAAA,oDAAsB,IAAA,CAA1B,IAAI;IACb;IAyBA,MAAM,0BAAuB;QAC3B,MAAM,IAAI,CAAC,IAAI;QACf,OAAO,uBAAA,IAAI,EAAA,yCAAA,KAAA,0DAA4B,IAAA,CAAhC,IAAI;IACb;IAkBA,MAAM,aAAU;QACd,MAAM,IAAI,CAAC,IAAI;QACf,OAAO,uBAAA,IAAI,EAAA,yCAAA,KAAA,mDAAqB,IAAA,CAAzB,IAAI;IACb;IAEA,qBAAkB;QAChB,OAAO;eAAI,IAAI,CAAC,gBAAgB;SAAC;IACnC;IAEmB,aAAU;QAG3B,MAAM,aAAa,IAAI,CAAC,gBAAgB,CAAC,IAAI,CAAC,gBAAgB,CAAC,MAAM,GAAG,EAAE;QAC1E,IAAI,YAAY,IAAI,CAAC,KAAK,CAAC,uBAAuB;QAClD,MAAM,eAAe,uBAAA,IAAI,EAAA,yCAAA,KAAA,+CAAiB,IAAA,CAArB,IAAI;QACzB,IAAI,cAAc,IAAI,CAAC,KAAK,CAAC,gBAAgB;QAC7C,MAAM,eAAe,uBAAA,IAAI,EAAA,yCAAA,KAAA,+CAAiB,IAAA,CAArB,IAAI;QACzB,IAAI,cAAc,IAAI,CAAC,KAAK,CAAC,gBAAgB;QAE7C,MAAM,oBAAoB,uBAAA,IAAI,EAAA,yCAAA,KAAA,oDAAsB,IAAA,CAA1B,IAAI;QAC9B,IAAI,mBAAmB,IAAI,CAAC,KAAK,CAAC,qBAAqB;QAEvD,MAAM,0BAA0B,uBAAA,IAAI,EAAA,yCAAA,KAAA,0DAA4B,IAAA,CAAhC,IAAI;QACpC,IAAI,2BAA2B,MAAM,IAAI,CAAC,KAAK,CAAC,2BAA2B;QAE3E,IAAI,IAAI,CAAC,gBAAgB,CAAC,IAAI,CAAC,CAAC,IAAM,EAAE,KAAK,GAAG;YAC9C,IAAI,CAAC,KAAK,CAAC,cAAc,uBAAA,IAAI,EAAA,yCAAA,KAAA,mDAAqB,IAAA,CAAzB,IAAI;;IAEjC;IAUU,MAAM,sBACd,MAAc,EACd,MAAkC,EAClC,OAA6B,EAAA;QAE7B,MAAM,SAAS,SAAS;QACxB,IAAI,QAAQ;YACV,IAAI,OAAO,OAAO,EAAE,IAAI,CAAC,UAAU,CAAC,KAAK;YACzC,OAAO,gBAAgB,CAAC,SAAS,IAAM,IAAI,CAAC,UAAU,CAAC,KAAK;;QAE9D,uBAAA,IAAI,EAAA,yCAAA,KAAA,8CAAgB,IAAA,CAApB,IAAI,EAAiB;QAErB,MAAM,iBAAiB,MAAM,OAAO,IAAI,CAAC,WAAW,CAAC,MAAM,CACzD;YAAE,GAAG,MAAM;YAAE,QAAQ;QAAK,GAC1B;YAAE,GAAG,OAAO;YAAE,QAAQ,IAAI,CAAC,UAAU,CAAC,MAAM;QAAA;QAE9C,IAAI,CAAC,UAAU;QACf,OAAO,IAAI,CAAC,kBAAkB,CAAC,CAAA,GAAA,0IAAA,CAAA,sBAAmB,AAAnB,EAAoB,gBAAgB;IACrE;IAEU,MAAM,mBACd,MAAc,EACd,MAAkC,EAClC,OAA6B,EAAA;QAE7B,KAAK,MAAM,WAAW,OAAO,QAAQ,CAAE;YACrC,IAAI,CAAC,WAAW,CAAC,SAAS;;QAE5B,OAAO,MAAM,IAAI,CAAC,qBAAqB,CAAC,QAAQ,QAAQ;IAC1D;IAEU,MAAM,cACd,MAAc,EACd,MAE8D,EAC9D,OAAuB,EAAA;QAEvB,MAAM,OAAO;QACb,MAAM,EAAE,gBAAgB,MAAM,EAAE,MAAM,EAAE,GAAG,YAAY,GAAG;QAC1D,MAAM,uBAAuB,OAAO,kBAAkB,YAAY,eAAe;QACjF,MAAM,EAAE,qBAAqB,4BAA4B,EAAE,GAAG,WAAW,CAAA;QAEzE,MAAM,kBAAyD,CAAA;QAC/D,KAAK,MAAM,KAAK,OAAO,SAAS,CAAE;YAChC,eAAe,CAAC,EAAE,IAAI,IAAI,EAAE,QAAQ,CAAC,IAAI,CAAC,GAAG;;QAG/C,MAAM,YAAmD,OAAO,SAAS,CAAC,GAAG,CAC3E,CAAC,IAA2C,CAAC;gBAC3C,MAAM,EAAE,IAAI,IAAI,EAAE,QAAQ,CAAC,IAAI;gBAC/B,YAAY,EAAE,UAAqC;gBACnD,aAAa,EAAE,WAAW;aAC3B;QAGH,KAAK,MAAM,WAAW,OAAO,QAAQ,CAAE;YACrC,IAAI,CAAC,WAAW,CAAC,SAAS;;QAG5B,IAAK,IAAI,IAAI,GAAG,IAAI,oBAAoB,EAAE,EAAG;YAC3C,MAAM,iBAAiC,MAAM,IAAI,CAAC,qBAAqB,CACrE,QACA;gBACE,GAAG,UAAU;gBACb;gBACA;gBACA,UAAU;uBAAI,IAAI,CAAC,QAAQ;iBAAC;eAE9B;YAEF,MAAM,UAAU,eAAe,OAAO,CAAC,EAAE,EAAE;YAC3C,IAAI,CAAC,SAAS;gBACZ,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC,CAAA,0CAAA,CAA4C;;YAEpE,IAAI,CAAC,QAAQ,aAAa,EAAE;YAC5B,MAAM,EAAE,IAAI,EAAE,WAAW,IAAI,EAAE,GAAG,QAAQ,aAAa;YACvD,MAAM,KAAK,eAAe,CAAC,KAAK;YAChC,IAAI,CAAC,IAAI;gBACP,MAAM,UAAU,CAAA,uBAAA,EAA0B,KAAK,SAAS,CAAC,MAAK,yBAAA,EAA4B,UACvF,GAAG,CAAC,CAAC,IAAM,KAAK,SAAS,CAAC,EAAE,IAAI,GAChC,IAAI,CAAC,MAAK,kBAAA,CAAoB;gBAEjC,IAAI,CAAC,WAAW,CAAC;oBAAE;oBAAM;oBAAM;gBAAO;gBACtC;mBACK,IAAI,wBAAwB,yBAAyB,MAAM;gBAChE,MAAM,UAAU,CAAA,uBAAA,EAA0B,KAAK,SAAS,CAAC,MAAK,EAAA,EAAK,KAAK,SAAS,CAC/E,sBACD,4BAAA,CAA8B;gBAE/B,IAAI,CAAC,WAAW,CAAC;oBAAE;oBAAM;oBAAM;gBAAO;gBACtC;;YAGF,IAAI;YACJ,IAAI;gBACF,SAAS,CAAA,GAAA,oJAAA,CAAA,8BAA2B,AAA3B,EAA4B,MAAM,MAAM,GAAG,KAAK,CAAC,QAAQ;cAClE,OAAO,OAAO;gBACd,IAAI,CAAC,WAAW,CAAC;oBACf;oBACA;oBACA,SAAS,iBAAiB,QAAQ,MAAM,OAAO,GAAG,OAAO;;gBAE3D;;YAGF,mDAAmD;YACnD,MAAM,aAAa,MAAM,GAAG,QAAQ,CAAC,QAAQ,IAAI;YACjD,MAAM,UAAU,uBAAA,IAAI,EAAA,yCAAA,KAAA,2DAA6B,IAAA,CAAjC,IAAI,EAA8B;YAElD,IAAI,CAAC,WAAW,CAAC;gBAAE;gBAAM;gBAAM;YAAO;YAEtC,IAAI,sBAAsB;;IAE9B;IAEU,MAAM,UACd,MAAc,EACd,MAE0D,EAC1D,OAAuB,EAAA;QAEvB,MAAM,OAAO;QACb,MAAM,EAAE,cAAc,MAAM,EAAE,MAAM,EAAE,GAAG,YAAY,GAAG;QACxD,MAAM,uBAAuB,OAAO,gBAAgB,YAAY,aAAa,UAAU;QACvF,MAAM,EAAE,qBAAqB,4BAA4B,EAAE,GAAG,WAAW,CAAA;QAEzE,qCAAqC;QACrC,MAAM,aAAa,OAAO,KAAK,CAAC,GAAG,CAAC,CAAC;YACnC,IAAI,CAAA,GAAA,0IAAA,CAAA,qBAAkB,AAAlB,EAAmB,OAAO;gBAC5B,IAAI,CAAC,KAAK,SAAS,EAAE;oBACnB,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC;;gBAGxB,OAAO;oBACL,MAAM;oBACN,UAAU;wBACR,UAAU,KAAK,SAAS;wBACxB,MAAM,KAAK,QAAQ,CAAC,IAAI;wBACxB,aAAa,KAAK,QAAQ,CAAC,WAAW,IAAI;wBAC1C,YAAY,KAAK,QAAQ,CAAC,UAAiB;wBAC3C,OAAO,KAAK,SAAS;wBACrB,QAAQ;;;;YAKd,OAAO;QACT;QAEA,MAAM,kBAAyD,CAAA;QAC/D,KAAK,MAAM,KAAK,WAAY;YAC1B,IAAI,EAAE,IAAI,KAAK,YAAY;gBACzB,eAAe,CAAC,EAAE,QAAQ,CAAC,IAAI,IAAI,EAAE,QAAQ,CAAC,QAAQ,CAAC,IAAI,CAAC,GAAG,EAAE,QAAQ;;;QAI7E,MAAM,QACJ,WAAW,SACT,WAAW,GAAG,CAAC,CAAC,IACd,EAAE,IAAI,KAAK,aACT;gBACE,MAAM;gBACN,UAAU;oBACR,MAAM,EAAE,QAAQ,CAAC,IAAI,IAAI,EAAE,QAAQ,CAAC,QAAQ,CAAC,IAAI;oBACjD,YAAY,EAAE,QAAQ,CAAC,UAAqC;oBAC5D,aAAa,EAAE,QAAQ,CAAC,WAAW;oBACnC,QAAQ,EAAE,QAAQ,CAAC,MAAM;;gBAG5B,KAEJ;QAEL,KAAK,MAAM,WAAW,OAAO,QAAQ,CAAE;YACrC,IAAI,CAAC,WAAW,CAAC,SAAS;;QAG5B,IAAK,IAAI,IAAI,GAAG,IAAI,oBAAoB,EAAE,EAAG;YAC3C,MAAM,iBAAiC,MAAM,IAAI,CAAC,qBAAqB,CACrE,QACA;gBACE,GAAG,UAAU;gBACb;gBACA;gBACA,UAAU;uBAAI,IAAI,CAAC,QAAQ;iBAAC;eAE9B;YAEF,MAAM,UAAU,eAAe,OAAO,CAAC,EAAE,EAAE;YAC3C,IAAI,CAAC,SAAS;gBACZ,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC,CAAA,0CAAA,CAA4C;;YAEpE,IAAI,CAAC,QAAQ,UAAU,EAAE,QAAQ;gBAC/B;;YAGF,KAAK,MAAM,aAAa,QAAQ,UAAU,CAAE;gBAC1C,IAAI,UAAU,IAAI,KAAK,YAAY;gBACnC,MAAM,eAAe,UAAU,EAAE;gBACjC,MAAM,EAAE,IAAI,EAAE,WAAW,IAAI,EAAE,GAAG,UAAU,QAAQ;gBACpD,MAAM,KAAK,eAAe,CAAC,KAAK;gBAEhC,IAAI,CAAC,IAAI;oBACP,MAAM,UAAU,CAAA,mBAAA,EAAsB,KAAK,SAAS,CAAC,MAAK,yBAAA,EAA4B,OAAO,IAAI,CAC/F,iBAEC,GAAG,CAAC,CAAC,OAAS,KAAK,SAAS,CAAC,OAC7B,IAAI,CAAC,MAAK,kBAAA,CAAoB;oBAEjC,IAAI,CAAC,WAAW,CAAC;wBAAE;wBAAM;wBAAc;oBAAO;oBAC9C;uBACK,IAAI,wBAAwB,yBAAyB,MAAM;oBAChE,MAAM,UAAU,CAAA,mBAAA,EAAsB,KAAK,SAAS,CAAC,MAAK,EAAA,EAAK,KAAK,SAAS,CAC3E,sBACD,4BAAA,CAA8B;oBAE/B,IAAI,CAAC,WAAW,CAAC;wBAAE;wBAAM;wBAAc;oBAAO;oBAC9C;;gBAGF,IAAI;gBACJ,IAAI;oBACF,SAAS,CAAA,GAAA,oJAAA,CAAA,8BAA2B,AAA3B,EAA4B,MAAM,MAAM,GAAG,KAAK,CAAC,QAAQ;kBAClE,OAAO,OAAO;oBACd,MAAM,UAAU,iBAAiB,QAAQ,MAAM,OAAO,GAAG,OAAO;oBAChE,IAAI,CAAC,WAAW,CAAC;wBAAE;wBAAM;wBAAc;oBAAO;oBAC9C;;gBAGF,mDAAmD;gBACnD,MAAM,aAAa,MAAM,GAAG,QAAQ,CAAC,QAAQ,IAAI;gBACjD,MAAM,UAAU,uBAAA,IAAI,EAAA,yCAAA,KAAA,2DAA6B,IAAA,CAAjC,IAAI,EAA8B;gBAClD,IAAI,CAAC,WAAW,CAAC;oBAAE;oBAAM;oBAAc;gBAAO;gBAE9C,IAAI,sBAAsB;oBACxB;;;;QAKN;IACF;;;IArYE,OAAO,uBAAA,IAAI,EAAA,yCAAA,KAAA,+CAAiB,IAAA,CAArB,IAAI,EAAoB,OAAO,IAAI;AAC5C,GAAC,gDAAA,SAAA;IAYC,IAAI,IAAI,IAAI,CAAC,QAAQ,CAAC,MAAM;IAC5B,MAAO,MAAM,EAAG;QACd,MAAM,UAAU,IAAI,CAAC,QAAQ,CAAC,EAAE;QAChC,IAAI,CAAA,GAAA,uJAAA,CAAA,qBAAkB,AAAlB,EAAmB,UAAU;YAC/B,MAAM,EAAE,aAAa,EAAE,GAAG,MAAM,GAAG;YACnC,MAAM,MAA6B;gBACjC,GAAG,IAAI;gBACP,SAAU,QAAkC,OAAO,IAAI;gBACvD,SAAU,QAAkC,OAAO,IAAI;;YAEzD,IAAI,eAAe;gBACjB,IAAI,aAAa,GAAG;;YAEtB,OAAO;;;IAGX,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC;AACxB,GAAC,qDAAA,SAAA;IAYC,IAAK,IAAI,IAAI,IAAI,CAAC,QAAQ,CAAC,MAAM,GAAG,GAAG,KAAK,GAAG,IAAK;QAClD,MAAM,UAAU,IAAI,CAAC,QAAQ,CAAC,EAAE;QAChC,IAAI,CAAA,GAAA,uJAAA,CAAA,qBAAkB,AAAlB,EAAmB,YAAY,SAAS,eAAe;YACzD,OAAO,QAAQ,aAAa;;QAE9B,IAAI,CAAA,GAAA,uJAAA,CAAA,qBAAkB,AAAlB,EAAmB,YAAY,SAAS,YAAY,QAAQ;YAC9D,OAAO,QAAQ,UAAU,CAAC,EAAE,CAAC,CAAC,IAAI;;;IAItC;AACF,GAAC,2DAAA,SAAA;IAYC,IAAK,IAAI,IAAI,IAAI,CAAC,QAAQ,CAAC,MAAM,GAAG,GAAG,KAAK,GAAG,IAAK;QAClD,MAAM,UAAU,IAAI,CAAC,QAAQ,CAAC,EAAE;QAChC,IAAI,CAAA,GAAA,uJAAA,CAAA,oBAAiB,AAAjB,EAAkB,YAAY,QAAQ,OAAO,IAAI,MAAM;YACzD,OAAO,QAAQ,OAAO;;QAExB,IACE,CAAA,GAAA,uJAAA,CAAA,gBAAa,AAAb,EAAc,YACd,QAAQ,OAAO,IAAI,QACnB,OAAO,QAAQ,OAAO,KAAK,YAC3B,IAAI,CAAC,QAAQ,CAAC,IAAI,CAChB,CAAC,IACC,EAAE,IAAI,KAAK,eACX,EAAE,UAAU,EAAE,KAAK,CAAC,IAAM,EAAE,IAAI,KAAK,cAAc,EAAE,EAAE,KAAK,QAAQ,YAAY,IAEpF;YACA,OAAO,QAAQ,OAAO;;;IAI1B;AACF,GAAC,oDAAA,SAAA;IAQC,MAAM,QAAyB;QAC7B,mBAAmB;QACnB,eAAe;QACf,cAAc;;IAEhB,KAAK,MAAM,EAAE,KAAK,EAAE,IAAI,IAAI,CAAC,gBAAgB,CAAE;QAC7C,IAAI,OAAO;YACT,MAAM,iBAAiB,IAAI,MAAM,iBAAiB;YAClD,MAAM,aAAa,IAAI,MAAM,aAAa;YAC1C,MAAM,YAAY,IAAI,MAAM,YAAY;;;IAG5C,OAAO;AACT,GAAC,+CAAA,SAAA,6CAgCe,MAAkC;IAChD,IAAI,OAAO,CAAC,IAAI,QAAQ,OAAO,CAAC,GAAG,GAAG;QACpC,MAAM,IAAI,kIAAA,CAAA,cAAW,CACnB;;AAGN,GAAC,4DAAA,SAAA,0DAuP4B,UAAmB;IAC9C,OACE,OAAO,eAAe,WAAW,aAC/B,eAAe,YAAY,cAC3B,KAAK,SAAS,CAAC;AAErB"}},
    {"offset": {"line": 3705, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 3710, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/_vendor/partial-json-parser/parser.ts"],"sourcesContent":["const STR = 0b000000001;\nconst NUM = 0b000000010;\nconst ARR = 0b000000100;\nconst OBJ = 0b000001000;\nconst NULL = 0b000010000;\nconst BOOL = 0b000100000;\nconst NAN = 0b001000000;\nconst INFINITY = 0b010000000;\nconst MINUS_INFINITY = 0b100000000;\n\nconst INF = INFINITY | MINUS_INFINITY;\nconst SPECIAL = NULL | BOOL | INF | NAN;\nconst ATOM = STR | NUM | SPECIAL;\nconst COLLECTION = ARR | OBJ;\nconst ALL = ATOM | COLLECTION;\n\nconst Allow = {\n  STR,\n  NUM,\n  ARR,\n  OBJ,\n  NULL,\n  BOOL,\n  NAN,\n  INFINITY,\n  MINUS_INFINITY,\n  INF,\n  SPECIAL,\n  ATOM,\n  COLLECTION,\n  ALL,\n};\n\n// The JSON string segment was unable to be parsed completely\nclass PartialJSON extends Error {}\n\nclass MalformedJSON extends Error {}\n\n/**\n * Parse incomplete JSON\n * @param {string} jsonString Partial JSON to be parsed\n * @param {number} allowPartial Specify what types are allowed to be partial, see {@link Allow} for details\n * @returns The parsed JSON\n * @throws {PartialJSON} If the JSON is incomplete (related to the `allow` parameter)\n * @throws {MalformedJSON} If the JSON is malformed\n */\nfunction parseJSON(jsonString: string, allowPartial: number = Allow.ALL): any {\n  if (typeof jsonString !== 'string') {\n    throw new TypeError(`expecting str, got ${typeof jsonString}`);\n  }\n  if (!jsonString.trim()) {\n    throw new Error(`${jsonString} is empty`);\n  }\n  return _parseJSON(jsonString.trim(), allowPartial);\n}\n\nconst _parseJSON = (jsonString: string, allow: number) => {\n  const length = jsonString.length;\n  let index = 0;\n\n  const markPartialJSON = (msg: string) => {\n    throw new PartialJSON(`${msg} at position ${index}`);\n  };\n\n  const throwMalformedError = (msg: string) => {\n    throw new MalformedJSON(`${msg} at position ${index}`);\n  };\n\n  const parseAny: () => any = () => {\n    skipBlank();\n    if (index >= length) markPartialJSON('Unexpected end of input');\n    if (jsonString[index] === '\"') return parseStr();\n    if (jsonString[index] === '{') return parseObj();\n    if (jsonString[index] === '[') return parseArr();\n    if (\n      jsonString.substring(index, index + 4) === 'null' ||\n      (Allow.NULL & allow && length - index < 4 && 'null'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 4;\n      return null;\n    }\n    if (\n      jsonString.substring(index, index + 4) === 'true' ||\n      (Allow.BOOL & allow && length - index < 4 && 'true'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 4;\n      return true;\n    }\n    if (\n      jsonString.substring(index, index + 5) === 'false' ||\n      (Allow.BOOL & allow && length - index < 5 && 'false'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 5;\n      return false;\n    }\n    if (\n      jsonString.substring(index, index + 8) === 'Infinity' ||\n      (Allow.INFINITY & allow && length - index < 8 && 'Infinity'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 8;\n      return Infinity;\n    }\n    if (\n      jsonString.substring(index, index + 9) === '-Infinity' ||\n      (Allow.MINUS_INFINITY & allow &&\n        1 < length - index &&\n        length - index < 9 &&\n        '-Infinity'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 9;\n      return -Infinity;\n    }\n    if (\n      jsonString.substring(index, index + 3) === 'NaN' ||\n      (Allow.NAN & allow && length - index < 3 && 'NaN'.startsWith(jsonString.substring(index)))\n    ) {\n      index += 3;\n      return NaN;\n    }\n    return parseNum();\n  };\n\n  const parseStr: () => string = () => {\n    const start = index;\n    let escape = false;\n    index++; // skip initial quote\n    while (index < length && (jsonString[index] !== '\"' || (escape && jsonString[index - 1] === '\\\\'))) {\n      escape = jsonString[index] === '\\\\' ? !escape : false;\n      index++;\n    }\n    if (jsonString.charAt(index) == '\"') {\n      try {\n        return JSON.parse(jsonString.substring(start, ++index - Number(escape)));\n      } catch (e) {\n        throwMalformedError(String(e));\n      }\n    } else if (Allow.STR & allow) {\n      try {\n        return JSON.parse(jsonString.substring(start, index - Number(escape)) + '\"');\n      } catch (e) {\n        // SyntaxError: Invalid escape sequence\n        return JSON.parse(jsonString.substring(start, jsonString.lastIndexOf('\\\\')) + '\"');\n      }\n    }\n    markPartialJSON('Unterminated string literal');\n  };\n\n  const parseObj = () => {\n    index++; // skip initial brace\n    skipBlank();\n    const obj: Record<string, any> = {};\n    try {\n      while (jsonString[index] !== '}') {\n        skipBlank();\n        if (index >= length && Allow.OBJ & allow) return obj;\n        const key = parseStr();\n        skipBlank();\n        index++; // skip colon\n        try {\n          const value = parseAny();\n          Object.defineProperty(obj, key, { value, writable: true, enumerable: true, configurable: true });\n        } catch (e) {\n          if (Allow.OBJ & allow) return obj;\n          else throw e;\n        }\n        skipBlank();\n        if (jsonString[index] === ',') index++; // skip comma\n      }\n    } catch (e) {\n      if (Allow.OBJ & allow) return obj;\n      else markPartialJSON(\"Expected '}' at end of object\");\n    }\n    index++; // skip final brace\n    return obj;\n  };\n\n  const parseArr = () => {\n    index++; // skip initial bracket\n    const arr = [];\n    try {\n      while (jsonString[index] !== ']') {\n        arr.push(parseAny());\n        skipBlank();\n        if (jsonString[index] === ',') {\n          index++; // skip comma\n        }\n      }\n    } catch (e) {\n      if (Allow.ARR & allow) {\n        return arr;\n      }\n      markPartialJSON(\"Expected ']' at end of array\");\n    }\n    index++; // skip final bracket\n    return arr;\n  };\n\n  const parseNum = () => {\n    if (index === 0) {\n      if (jsonString === '-' && Allow.NUM & allow) markPartialJSON(\"Not sure what '-' is\");\n      try {\n        return JSON.parse(jsonString);\n      } catch (e) {\n        if (Allow.NUM & allow) {\n          try {\n            if ('.' === jsonString[jsonString.length - 1])\n              return JSON.parse(jsonString.substring(0, jsonString.lastIndexOf('.')));\n            return JSON.parse(jsonString.substring(0, jsonString.lastIndexOf('e')));\n          } catch (e) {}\n        }\n        throwMalformedError(String(e));\n      }\n    }\n\n    const start = index;\n\n    if (jsonString[index] === '-') index++;\n    while (jsonString[index] && !',]}'.includes(jsonString[index]!)) index++;\n\n    if (index == length && !(Allow.NUM & allow)) markPartialJSON('Unterminated number literal');\n\n    try {\n      return JSON.parse(jsonString.substring(start, index));\n    } catch (e) {\n      if (jsonString.substring(start, index) === '-' && Allow.NUM & allow)\n        markPartialJSON(\"Not sure what '-' is\");\n      try {\n        return JSON.parse(jsonString.substring(start, jsonString.lastIndexOf('e')));\n      } catch (e) {\n        throwMalformedError(String(e));\n      }\n    }\n  };\n\n  const skipBlank = () => {\n    while (index < length && ' \\n\\r\\t'.includes(jsonString[index]!)) {\n      index++;\n    }\n  };\n\n  return parseAny();\n};\n\n// using this function with malformed JSON is undefined behavior\nconst partialParse = (input: string) => parseJSON(input, Allow.ALL ^ Allow.NUM);\n\nexport { partialParse, PartialJSON, MalformedJSON };\n"],"names":[],"mappings":";;;;;AAAA,MAAM,MAAM;AACZ,MAAM,MAAM;AACZ,MAAM,MAAM;AACZ,MAAM,MAAM;AACZ,MAAM,OAAO;AACb,MAAM,OAAO;AACb,MAAM,MAAM;AACZ,MAAM,WAAW;AACjB,MAAM,iBAAiB;AAEvB,MAAM,MAAM,WAAW;AACvB,MAAM,UAAU,OAAO,OAAO,MAAM;AACpC,MAAM,OAAO,MAAM,MAAM;AACzB,MAAM,aAAa,MAAM;AACzB,MAAM,MAAM,OAAO;AAEnB,MAAM,QAAQ;IACZ;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;;AAGF,6DAA6D;AAC7D,MAAM,oBAAoB;;AAE1B,MAAM,sBAAsB;;AAE5B;;;;;;;IAQA,SAAS,UAAU,UAAkB,EAAE,eAAuB,MAAM,GAAG;IACrE,IAAI,OAAO,eAAe,UAAU;QAClC,MAAM,IAAI,UAAU,CAAA,mBAAA,EAAsB,OAAO,WAAU,CAAE;;IAE/D,IAAI,CAAC,WAAW,IAAI,IAAI;QACtB,MAAM,IAAI,MAAM,CAAA,EAAG,WAAU,SAAA,CAAW;;IAE1C,OAAO,WAAW,WAAW,IAAI,IAAI;AACvC;AAEA,MAAM,aAAa,CAAC,YAAoB;IACtC,MAAM,SAAS,WAAW,MAAM;IAChC,IAAI,QAAQ;IAEZ,MAAM,kBAAkB,CAAC;QACvB,MAAM,IAAI,YAAY,CAAA,EAAG,IAAG,aAAA,EAAgB,MAAK,CAAE;IACrD;IAEA,MAAM,sBAAsB,CAAC;QAC3B,MAAM,IAAI,cAAc,CAAA,EAAG,IAAG,aAAA,EAAgB,MAAK,CAAE;IACvD;IAEA,MAAM,WAAsB;QAC1B;QACA,IAAI,SAAS,QAAQ,gBAAgB;QACrC,IAAI,UAAU,CAAC,MAAM,KAAK,KAAK,OAAO;QACtC,IAAI,UAAU,CAAC,MAAM,KAAK,KAAK,OAAO;QACtC,IAAI,UAAU,CAAC,MAAM,KAAK,KAAK,OAAO;QACtC,IACE,WAAW,SAAS,CAAC,OAAO,QAAQ,OAAO,UAC1C,MAAM,IAAI,GAAG,SAAS,SAAS,QAAQ,KAAK,OAAO,UAAU,CAAC,WAAW,SAAS,CAAC,SACpF;YACA,SAAS;YACT,OAAO;;QAET,IACE,WAAW,SAAS,CAAC,OAAO,QAAQ,OAAO,UAC1C,MAAM,IAAI,GAAG,SAAS,SAAS,QAAQ,KAAK,OAAO,UAAU,CAAC,WAAW,SAAS,CAAC,SACpF;YACA,SAAS;YACT,OAAO;;QAET,IACE,WAAW,SAAS,CAAC,OAAO,QAAQ,OAAO,WAC1C,MAAM,IAAI,GAAG,SAAS,SAAS,QAAQ,KAAK,QAAQ,UAAU,CAAC,WAAW,SAAS,CAAC,SACrF;YACA,SAAS;YACT,OAAO;;QAET,IACE,WAAW,SAAS,CAAC,OAAO,QAAQ,OAAO,cAC1C,MAAM,QAAQ,GAAG,SAAS,SAAS,QAAQ,KAAK,WAAW,UAAU,CAAC,WAAW,SAAS,CAAC,SAC5F;YACA,SAAS;YACT,OAAO;;QAET,IACE,WAAW,SAAS,CAAC,OAAO,QAAQ,OAAO,eAC1C,MAAM,cAAc,GAAG,SACtB,IAAI,SAAS,SACb,SAAS,QAAQ,KACjB,YAAY,UAAU,CAAC,WAAW,SAAS,CAAC,SAC9C;YACA,SAAS;YACT,OAAO,CAAC;;QAEV,IACE,WAAW,SAAS,CAAC,OAAO,QAAQ,OAAO,SAC1C,MAAM,GAAG,GAAG,SAAS,SAAS,QAAQ,KAAK,MAAM,UAAU,CAAC,WAAW,SAAS,CAAC,SAClF;YACA,SAAS;YACT,OAAO;;QAET,OAAO;IACT;IAEA,MAAM,WAAyB;QAC7B,MAAM,QAAQ;QACd,IAAI,SAAS;QACb,SAAS,qBAAqB;QAC9B,MAAO,QAAQ,UAAU,CAAC,UAAU,CAAC,MAAM,KAAK,OAAQ,UAAU,UAAU,CAAC,QAAQ,EAAE,KAAK,IAAK,EAAG;YAClG,SAAS,UAAU,CAAC,MAAM,KAAK,OAAO,CAAC,SAAS;YAChD;;QAEF,IAAI,WAAW,MAAM,CAAC,UAAU,KAAK;YACnC,IAAI;gBACF,OAAO,KAAK,KAAK,CAAC,WAAW,SAAS,CAAC,OAAO,EAAE,QAAQ,OAAO;cAC/D,OAAO,GAAG;gBACV,oBAAoB,OAAO;;eAExB,IAAI,MAAM,GAAG,GAAG,OAAO;YAC5B,IAAI;gBACF,OAAO,KAAK,KAAK,CAAC,WAAW,SAAS,CAAC,OAAO,QAAQ,OAAO,WAAW;cACxE,OAAO,GAAG;gBACV,uCAAuC;gBACvC,OAAO,KAAK,KAAK,CAAC,WAAW,SAAS,CAAC,OAAO,WAAW,WAAW,CAAC,SAAS;;;QAGlF,gBAAgB;IAClB;IAEA,MAAM,WAAW;QACf,SAAS,qBAAqB;QAC9B;QACA,MAAM,MAA2B,CAAA;QACjC,IAAI;YACF,MAAO,UAAU,CAAC,MAAM,KAAK,IAAK;gBAChC;gBACA,IAAI,SAAS,UAAU,MAAM,GAAG,GAAG,OAAO,OAAO;gBACjD,MAAM,MAAM;gBACZ;gBACA,SAAS,aAAa;gBACtB,IAAI;oBACF,MAAM,QAAQ;oBACd,OAAO,cAAc,CAAC,KAAK,KAAK;wBAAE;wBAAO,UAAU;wBAAM,YAAY;wBAAM,cAAc;oBAAI;kBAC7F,OAAO,GAAG;oBACV,IAAI,MAAM,GAAG,GAAG,OAAO,OAAO;yBACzB,MAAM;;gBAEb;gBACA,IAAI,UAAU,CAAC,MAAM,KAAK,KAAK,SAAS,aAAa;;UAEvD,OAAO,GAAG;YACV,IAAI,MAAM,GAAG,GAAG,OAAO,OAAO;iBACzB,gBAAgB;;QAEvB,SAAS,mBAAmB;QAC5B,OAAO;IACT;IAEA,MAAM,WAAW;QACf,SAAS,uBAAuB;QAChC,MAAM,MAAM,EAAE;QACd,IAAI;YACF,MAAO,UAAU,CAAC,MAAM,KAAK,IAAK;gBAChC,IAAI,IAAI,CAAC;gBACT;gBACA,IAAI,UAAU,CAAC,MAAM,KAAK,KAAK;oBAC7B,SAAS,aAAa;;;UAG1B,OAAO,GAAG;YACV,IAAI,MAAM,GAAG,GAAG,OAAO;gBACrB,OAAO;;YAET,gBAAgB;;QAElB,SAAS,qBAAqB;QAC9B,OAAO;IACT;IAEA,MAAM,WAAW;QACf,IAAI,UAAU,GAAG;YACf,IAAI,eAAe,OAAO,MAAM,GAAG,GAAG,OAAO,gBAAgB;YAC7D,IAAI;gBACF,OAAO,KAAK,KAAK,CAAC;cAClB,OAAO,GAAG;gBACV,IAAI,MAAM,GAAG,GAAG,OAAO;oBACrB,IAAI;wBACF,IAAI,QAAQ,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE,EAC3C,OAAO,KAAK,KAAK,CAAC,WAAW,SAAS,CAAC,GAAG,WAAW,WAAW,CAAC;wBACnE,OAAO,KAAK,KAAK,CAAC,WAAW,SAAS,CAAC,GAAG,WAAW,WAAW,CAAC;sBACjE,OAAO,GAAG,CAAA;;gBAEd,oBAAoB,OAAO;;;QAI/B,MAAM,QAAQ;QAEd,IAAI,UAAU,CAAC,MAAM,KAAK,KAAK;QAC/B,MAAO,UAAU,CAAC,MAAM,IAAI,CAAC,MAAM,QAAQ,CAAC,UAAU,CAAC,MAAO,EAAG;QAEjE,IAAI,SAAS,UAAU,CAAC,CAAC,MAAM,GAAG,GAAG,KAAK,GAAG,gBAAgB;QAE7D,IAAI;YACF,OAAO,KAAK,KAAK,CAAC,WAAW,SAAS,CAAC,OAAO;UAC9C,OAAO,GAAG;YACV,IAAI,WAAW,SAAS,CAAC,OAAO,WAAW,OAAO,MAAM,GAAG,GAAG,OAC5D,gBAAgB;YAClB,IAAI;gBACF,OAAO,KAAK,KAAK,CAAC,WAAW,SAAS,CAAC,OAAO,WAAW,WAAW,CAAC;cACrE,OAAO,GAAG;gBACV,oBAAoB,OAAO;;;IAGjC;IAEA,MAAM,YAAY;QAChB,MAAO,QAAQ,UAAU,UAAU,QAAQ,CAAC,UAAU,CAAC,MAAO,EAAG;YAC/D;;IAEJ;IAEA,OAAO;AACT;AAEA,gEAAgE;AAChE,MAAM,eAAe,CAAC,QAAkB,UAAU,OAAO,MAAM,GAAG,GAAG,MAAM,GAAG"}},
    {"offset": {"line": 3925, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 3930, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/lib/ChatCompletionStream.ts"],"sourcesContent":["import * as Core from \"../core\";\nimport {\n  OpenAIError,\n  APIUserAbortError,\n  LengthFinishReasonError,\n  ContentFilterFinishReasonError,\n} from \"../error\";\nimport {\n  ChatCompletionTokenLogprob,\n  type ChatCompletion,\n  type ChatCompletionChunk,\n  type ChatCompletionCreateParams,\n  type ChatCompletionCreateParamsStreaming,\n  type ChatCompletionCreateParamsBase,\n} from \"../resources/chat/completions\";\nimport {\n  AbstractChatCompletionRunner,\n  type AbstractChatCompletionRunnerEvents,\n} from './AbstractChatCompletionRunner';\nimport { type ReadableStream } from \"../_shims/index\";\nimport { Stream } from \"../streaming\";\nimport OpenAI from \"../index\";\nimport { ParsedChatCompletion } from \"../resources/beta/chat/completions\";\nimport {\n  AutoParseableResponseFormat,\n  hasAutoParseableInput,\n  isAutoParsableResponseFormat,\n  isAutoParsableTool,\n  maybeParseChatCompletion,\n  shouldParseToolCall,\n} from \"./parser\";\nimport { partialParse } from '../_vendor/partial-json-parser/parser';\n\nexport interface ContentDeltaEvent {\n  delta: string;\n  snapshot: string;\n  parsed: unknown | null;\n}\n\nexport interface ContentDoneEvent<ParsedT = null> {\n  content: string;\n  parsed: ParsedT | null;\n}\n\nexport interface RefusalDeltaEvent {\n  delta: string;\n  snapshot: string;\n}\n\nexport interface RefusalDoneEvent {\n  refusal: string;\n}\n\nexport interface FunctionToolCallArgumentsDeltaEvent {\n  name: string;\n\n  index: number;\n\n  arguments: string;\n\n  parsed_arguments: unknown;\n\n  arguments_delta: string;\n}\n\nexport interface FunctionToolCallArgumentsDoneEvent {\n  name: string;\n\n  index: number;\n\n  arguments: string;\n\n  parsed_arguments: unknown;\n}\n\nexport interface LogProbsContentDeltaEvent {\n  content: Array<ChatCompletionTokenLogprob>;\n  snapshot: Array<ChatCompletionTokenLogprob>;\n}\n\nexport interface LogProbsContentDoneEvent {\n  content: Array<ChatCompletionTokenLogprob>;\n}\n\nexport interface LogProbsRefusalDeltaEvent {\n  refusal: Array<ChatCompletionTokenLogprob>;\n  snapshot: Array<ChatCompletionTokenLogprob>;\n}\n\nexport interface LogProbsRefusalDoneEvent {\n  refusal: Array<ChatCompletionTokenLogprob>;\n}\n\nexport interface ChatCompletionStreamEvents<ParsedT = null> extends AbstractChatCompletionRunnerEvents {\n  content: (contentDelta: string, contentSnapshot: string) => void;\n  chunk: (chunk: ChatCompletionChunk, snapshot: ChatCompletionSnapshot) => void;\n\n  'content.delta': (props: ContentDeltaEvent) => void;\n  'content.done': (props: ContentDoneEvent<ParsedT>) => void;\n\n  'refusal.delta': (props: RefusalDeltaEvent) => void;\n  'refusal.done': (props: RefusalDoneEvent) => void;\n\n  'tool_calls.function.arguments.delta': (props: FunctionToolCallArgumentsDeltaEvent) => void;\n  'tool_calls.function.arguments.done': (props: FunctionToolCallArgumentsDoneEvent) => void;\n\n  'logprobs.content.delta': (props: LogProbsContentDeltaEvent) => void;\n  'logprobs.content.done': (props: LogProbsContentDoneEvent) => void;\n\n  'logprobs.refusal.delta': (props: LogProbsRefusalDeltaEvent) => void;\n  'logprobs.refusal.done': (props: LogProbsRefusalDoneEvent) => void;\n}\n\nexport type ChatCompletionStreamParams = Omit<ChatCompletionCreateParamsBase, 'stream'> & {\n  stream?: true;\n};\n\ninterface ChoiceEventState {\n  content_done: boolean;\n  refusal_done: boolean;\n  logprobs_content_done: boolean;\n  logprobs_refusal_done: boolean;\n  current_tool_call_index: number | null;\n  done_tool_calls: Set<number>;\n}\n\nexport class ChatCompletionStream<ParsedT = null>\n  extends AbstractChatCompletionRunner<ChatCompletionStreamEvents<ParsedT>, ParsedT>\n  implements AsyncIterable<ChatCompletionChunk>\n{\n  #params: ChatCompletionCreateParams | null;\n  #choiceEventStates: ChoiceEventState[];\n  #currentChatCompletionSnapshot: ChatCompletionSnapshot | undefined;\n\n  constructor(params: ChatCompletionCreateParams | null) {\n    super();\n    this.#params = params;\n    this.#choiceEventStates = [];\n  }\n\n  get currentChatCompletionSnapshot(): ChatCompletionSnapshot | undefined {\n    return this.#currentChatCompletionSnapshot;\n  }\n\n  /**\n   * Intended for use on the frontend, consuming a stream produced with\n   * `.toReadableStream()` on the backend.\n   *\n   * Note that messages sent to the model do not appear in `.on('message')`\n   * in this context.\n   */\n  static fromReadableStream(stream: ReadableStream): ChatCompletionStream<null> {\n    const runner = new ChatCompletionStream(null);\n    runner._run(() => runner._fromReadableStream(stream));\n    return runner;\n  }\n\n  static createChatCompletion<ParsedT>(\n    client: OpenAI,\n    params: ChatCompletionStreamParams,\n    options?: Core.RequestOptions,\n  ): ChatCompletionStream<ParsedT> {\n    const runner = new ChatCompletionStream<ParsedT>(params as ChatCompletionCreateParamsStreaming);\n    runner._run(() =>\n      runner._runChatCompletion(\n        client,\n        { ...params, stream: true },\n        { ...options, headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' } },\n      ),\n    );\n    return runner;\n  }\n\n  #beginRequest() {\n    if (this.ended) return;\n    this.#currentChatCompletionSnapshot = undefined;\n  }\n\n  #getChoiceEventState(choice: ChatCompletionSnapshot.Choice): ChoiceEventState {\n    let state = this.#choiceEventStates[choice.index];\n    if (state) {\n      return state;\n    }\n\n    state = {\n      content_done: false,\n      refusal_done: false,\n      logprobs_content_done: false,\n      logprobs_refusal_done: false,\n      done_tool_calls: new Set(),\n      current_tool_call_index: null,\n    };\n    this.#choiceEventStates[choice.index] = state;\n    return state;\n  }\n\n  #addChunk(this: ChatCompletionStream<ParsedT>, chunk: ChatCompletionChunk) {\n    if (this.ended) return;\n\n    const completion = this.#accumulateChatCompletion(chunk);\n    this._emit('chunk', chunk, completion);\n\n    for (const choice of chunk.choices) {\n      const choiceSnapshot = completion.choices[choice.index]!;\n\n      if (\n        choice.delta.content != null &&\n        choiceSnapshot.message?.role === 'assistant' &&\n        choiceSnapshot.message?.content\n      ) {\n        this._emit('content', choice.delta.content, choiceSnapshot.message.content);\n        this._emit('content.delta', {\n          delta: choice.delta.content,\n          snapshot: choiceSnapshot.message.content,\n          parsed: choiceSnapshot.message.parsed,\n        });\n      }\n\n      if (\n        choice.delta.refusal != null &&\n        choiceSnapshot.message?.role === 'assistant' &&\n        choiceSnapshot.message?.refusal\n      ) {\n        this._emit('refusal.delta', {\n          delta: choice.delta.refusal,\n          snapshot: choiceSnapshot.message.refusal,\n        });\n      }\n\n      if (choice.logprobs?.content != null && choiceSnapshot.message?.role === 'assistant') {\n        this._emit('logprobs.content.delta', {\n          content: choice.logprobs?.content,\n          snapshot: choiceSnapshot.logprobs?.content ?? [],\n        });\n      }\n\n      if (choice.logprobs?.refusal != null && choiceSnapshot.message?.role === 'assistant') {\n        this._emit('logprobs.refusal.delta', {\n          refusal: choice.logprobs?.refusal,\n          snapshot: choiceSnapshot.logprobs?.refusal ?? [],\n        });\n      }\n\n      const state = this.#getChoiceEventState(choiceSnapshot);\n\n      if (choiceSnapshot.finish_reason) {\n        this.#emitContentDoneEvents(choiceSnapshot);\n\n        if (state.current_tool_call_index != null) {\n          this.#emitToolCallDoneEvent(choiceSnapshot, state.current_tool_call_index);\n        }\n      }\n\n      for (const toolCall of choice.delta.tool_calls ?? []) {\n        if (state.current_tool_call_index !== toolCall.index) {\n          this.#emitContentDoneEvents(choiceSnapshot);\n\n          // new tool call started, the previous one is done\n          if (state.current_tool_call_index != null) {\n            this.#emitToolCallDoneEvent(choiceSnapshot, state.current_tool_call_index);\n          }\n        }\n\n        state.current_tool_call_index = toolCall.index;\n      }\n\n      for (const toolCallDelta of choice.delta.tool_calls ?? []) {\n        const toolCallSnapshot = choiceSnapshot.message.tool_calls?.[toolCallDelta.index];\n        if (!toolCallSnapshot?.type) {\n          continue;\n        }\n\n        if (toolCallSnapshot?.type === 'function') {\n          this._emit('tool_calls.function.arguments.delta', {\n            name: toolCallSnapshot.function?.name,\n            index: toolCallDelta.index,\n            arguments: toolCallSnapshot.function.arguments,\n            parsed_arguments: toolCallSnapshot.function.parsed_arguments,\n            arguments_delta: toolCallDelta.function?.arguments ?? '',\n          });\n        } else {\n          assertNever(toolCallSnapshot?.type);\n        }\n      }\n    }\n  }\n\n  #emitToolCallDoneEvent(choiceSnapshot: ChatCompletionSnapshot.Choice, toolCallIndex: number) {\n    const state = this.#getChoiceEventState(choiceSnapshot);\n    if (state.done_tool_calls.has(toolCallIndex)) {\n      // we've already fired the done event\n      return;\n    }\n\n    const toolCallSnapshot = choiceSnapshot.message.tool_calls?.[toolCallIndex];\n    if (!toolCallSnapshot) {\n      throw new Error('no tool call snapshot');\n    }\n    if (!toolCallSnapshot.type) {\n      throw new Error('tool call snapshot missing `type`');\n    }\n\n    if (toolCallSnapshot.type === 'function') {\n      const inputTool = this.#params?.tools?.find(\n        (tool) => tool.type === 'function' && tool.function.name === toolCallSnapshot.function.name,\n      );\n\n      this._emit('tool_calls.function.arguments.done', {\n        name: toolCallSnapshot.function.name,\n        index: toolCallIndex,\n        arguments: toolCallSnapshot.function.arguments,\n        parsed_arguments:\n          isAutoParsableTool(inputTool) ? inputTool.$parseRaw(toolCallSnapshot.function.arguments)\n          : inputTool?.function.strict ? JSON.parse(toolCallSnapshot.function.arguments)\n          : null,\n      });\n    } else {\n      assertNever(toolCallSnapshot.type);\n    }\n  }\n\n  #emitContentDoneEvents(choiceSnapshot: ChatCompletionSnapshot.Choice) {\n    const state = this.#getChoiceEventState(choiceSnapshot);\n\n    if (choiceSnapshot.message.content && !state.content_done) {\n      state.content_done = true;\n\n      const responseFormat = this.#getAutoParseableResponseFormat();\n\n      this._emit('content.done', {\n        content: choiceSnapshot.message.content,\n        parsed: responseFormat ? responseFormat.$parseRaw(choiceSnapshot.message.content) : (null as any),\n      });\n    }\n\n    if (choiceSnapshot.message.refusal && !state.refusal_done) {\n      state.refusal_done = true;\n\n      this._emit('refusal.done', { refusal: choiceSnapshot.message.refusal });\n    }\n\n    if (choiceSnapshot.logprobs?.content && !state.logprobs_content_done) {\n      state.logprobs_content_done = true;\n\n      this._emit('logprobs.content.done', { content: choiceSnapshot.logprobs.content });\n    }\n\n    if (choiceSnapshot.logprobs?.refusal && !state.logprobs_refusal_done) {\n      state.logprobs_refusal_done = true;\n\n      this._emit('logprobs.refusal.done', { refusal: choiceSnapshot.logprobs.refusal });\n    }\n  }\n\n  #endRequest(): ParsedChatCompletion<ParsedT> {\n    if (this.ended) {\n      throw new OpenAIError(`stream has ended, this shouldn't happen`);\n    }\n    const snapshot = this.#currentChatCompletionSnapshot;\n    if (!snapshot) {\n      throw new OpenAIError(`request ended without sending any chunks`);\n    }\n    this.#currentChatCompletionSnapshot = undefined;\n    this.#choiceEventStates = [];\n    return finalizeChatCompletion(snapshot, this.#params);\n  }\n\n  protected override async _createChatCompletion(\n    client: OpenAI,\n    params: ChatCompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): Promise<ParsedChatCompletion<ParsedT>> {\n    super._createChatCompletion;\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#beginRequest();\n\n    const stream = await client.chat.completions.create(\n      { ...params, stream: true },\n      { ...options, signal: this.controller.signal },\n    );\n    this._connected();\n    for await (const chunk of stream) {\n      this.#addChunk(chunk);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this._addChatCompletion(this.#endRequest());\n  }\n\n  protected async _fromReadableStream(\n    readableStream: ReadableStream,\n    options?: Core.RequestOptions,\n  ): Promise<ChatCompletion> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this.#beginRequest();\n    this._connected();\n    const stream = Stream.fromReadableStream<ChatCompletionChunk>(readableStream, this.controller);\n    let chatId;\n    for await (const chunk of stream) {\n      if (chatId && chatId !== chunk.id) {\n        // A new request has been made.\n        this._addChatCompletion(this.#endRequest());\n      }\n\n      this.#addChunk(chunk);\n      chatId = chunk.id;\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this._addChatCompletion(this.#endRequest());\n  }\n\n  #getAutoParseableResponseFormat(): AutoParseableResponseFormat<ParsedT> | null {\n    const responseFormat = this.#params?.response_format;\n    if (isAutoParsableResponseFormat<ParsedT>(responseFormat)) {\n      return responseFormat;\n    }\n\n    return null;\n  }\n\n  #accumulateChatCompletion(chunk: ChatCompletionChunk): ChatCompletionSnapshot {\n    let snapshot = this.#currentChatCompletionSnapshot;\n    const { choices, ...rest } = chunk;\n    if (!snapshot) {\n      snapshot = this.#currentChatCompletionSnapshot = {\n        ...rest,\n        choices: [],\n      };\n    } else {\n      Object.assign(snapshot, rest);\n    }\n\n    for (const { delta, finish_reason, index, logprobs = null, ...other } of chunk.choices) {\n      let choice = snapshot.choices[index];\n      if (!choice) {\n        choice = snapshot.choices[index] = { finish_reason, index, message: {}, logprobs, ...other };\n      }\n\n      if (logprobs) {\n        if (!choice.logprobs) {\n          choice.logprobs = Object.assign({}, logprobs);\n        } else {\n          const { content, refusal, ...rest } = logprobs;\n          assertIsEmpty(rest);\n          Object.assign(choice.logprobs, rest);\n\n          if (content) {\n            choice.logprobs.content ??= [];\n            choice.logprobs.content.push(...content);\n          }\n\n          if (refusal) {\n            choice.logprobs.refusal ??= [];\n            choice.logprobs.refusal.push(...refusal);\n          }\n        }\n      }\n\n      if (finish_reason) {\n        choice.finish_reason = finish_reason;\n\n        if (this.#params && hasAutoParseableInput(this.#params)) {\n          if (finish_reason === 'length') {\n            throw new LengthFinishReasonError();\n          }\n\n          if (finish_reason === 'content_filter') {\n            throw new ContentFilterFinishReasonError();\n          }\n        }\n      }\n\n      Object.assign(choice, other);\n\n      if (!delta) continue; // Shouldn't happen; just in case.\n\n      const { content, refusal, function_call, role, tool_calls, ...rest } = delta;\n      assertIsEmpty(rest);\n      Object.assign(choice.message, rest);\n\n      if (refusal) {\n        choice.message.refusal = (choice.message.refusal || '') + refusal;\n      }\n\n      if (role) choice.message.role = role;\n      if (function_call) {\n        if (!choice.message.function_call) {\n          choice.message.function_call = function_call;\n        } else {\n          if (function_call.name) choice.message.function_call.name = function_call.name;\n          if (function_call.arguments) {\n            choice.message.function_call.arguments ??= '';\n            choice.message.function_call.arguments += function_call.arguments;\n          }\n        }\n      }\n      if (content) {\n        choice.message.content = (choice.message.content || '') + content;\n\n        if (!choice.message.refusal && this.#getAutoParseableResponseFormat()) {\n          choice.message.parsed = partialParse(choice.message.content);\n        }\n      }\n\n      if (tool_calls) {\n        if (!choice.message.tool_calls) choice.message.tool_calls = [];\n\n        for (const { index, id, type, function: fn, ...rest } of tool_calls) {\n          const tool_call = (choice.message.tool_calls[index] ??=\n            {} as ChatCompletionSnapshot.Choice.Message.ToolCall);\n          Object.assign(tool_call, rest);\n          if (id) tool_call.id = id;\n          if (type) tool_call.type = type;\n          if (fn) tool_call.function ??= { name: fn.name ?? '', arguments: '' };\n          if (fn?.name) tool_call.function!.name = fn.name;\n          if (fn?.arguments) {\n            tool_call.function!.arguments += fn.arguments;\n\n            if (shouldParseToolCall(this.#params, tool_call)) {\n              tool_call.function!.parsed_arguments = partialParse(tool_call.function!.arguments);\n            }\n          }\n        }\n      }\n    }\n    return snapshot;\n  }\n\n  [Symbol.asyncIterator](this: ChatCompletionStream<ParsedT>): AsyncIterator<ChatCompletionChunk> {\n    const pushQueue: ChatCompletionChunk[] = [];\n    const readQueue: {\n      resolve: (chunk: ChatCompletionChunk | undefined) => void;\n      reject: (err: unknown) => void;\n    }[] = [];\n    let done = false;\n\n    this.on('chunk', (chunk) => {\n      const reader = readQueue.shift();\n      if (reader) {\n        reader.resolve(chunk);\n      } else {\n        pushQueue.push(chunk);\n      }\n    });\n\n    this.on('end', () => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.resolve(undefined);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('abort', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('error', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    return {\n      next: async (): Promise<IteratorResult<ChatCompletionChunk>> => {\n        if (!pushQueue.length) {\n          if (done) {\n            return { value: undefined, done: true };\n          }\n          return new Promise<ChatCompletionChunk | undefined>((resolve, reject) =>\n            readQueue.push({ resolve, reject }),\n          ).then((chunk) => (chunk ? { value: chunk, done: false } : { value: undefined, done: true }));\n        }\n        const chunk = pushQueue.shift()!;\n        return { value: chunk, done: false };\n      },\n      return: async () => {\n        this.abort();\n        return { value: undefined, done: true };\n      },\n    };\n  }\n\n  toReadableStream(): ReadableStream {\n    const stream = new Stream(this[Symbol.asyncIterator].bind(this), this.controller);\n    return stream.toReadableStream();\n  }\n}\n\nfunction finalizeChatCompletion<ParsedT>(\n  snapshot: ChatCompletionSnapshot,\n  params: ChatCompletionCreateParams | null,\n): ParsedChatCompletion<ParsedT> {\n  const { id, choices, created, model, system_fingerprint, ...rest } = snapshot;\n  const completion: ChatCompletion = {\n    ...rest,\n    id,\n    choices: choices.map(\n      ({ message, finish_reason, index, logprobs, ...choiceRest }): ChatCompletion.Choice => {\n        if (!finish_reason) {\n          throw new OpenAIError(`missing finish_reason for choice ${index}`);\n        }\n\n        const { content = null, function_call, tool_calls, ...messageRest } = message;\n        const role = message.role as 'assistant'; // this is what we expect; in theory it could be different which would make our types a slight lie but would be fine.\n        if (!role) {\n          throw new OpenAIError(`missing role for choice ${index}`);\n        }\n\n        if (function_call) {\n          const { arguments: args, name } = function_call;\n          if (args == null) {\n            throw new OpenAIError(`missing function_call.arguments for choice ${index}`);\n          }\n\n          if (!name) {\n            throw new OpenAIError(`missing function_call.name for choice ${index}`);\n          }\n\n          return {\n            ...choiceRest,\n            message: {\n              content,\n              function_call: { arguments: args, name },\n              role,\n              refusal: message.refusal ?? null,\n            },\n            finish_reason,\n            index,\n            logprobs,\n          };\n        }\n\n        if (tool_calls) {\n          return {\n            ...choiceRest,\n            index,\n            finish_reason,\n            logprobs,\n            message: {\n              ...messageRest,\n              role,\n              content,\n              refusal: message.refusal ?? null,\n              tool_calls: tool_calls.map((tool_call, i) => {\n                const { function: fn, type, id, ...toolRest } = tool_call;\n                const { arguments: args, name, ...fnRest } = fn || {};\n                if (id == null) {\n                  throw new OpenAIError(`missing choices[${index}].tool_calls[${i}].id\\n${str(snapshot)}`);\n                }\n                if (type == null) {\n                  throw new OpenAIError(`missing choices[${index}].tool_calls[${i}].type\\n${str(snapshot)}`);\n                }\n                if (name == null) {\n                  throw new OpenAIError(\n                    `missing choices[${index}].tool_calls[${i}].function.name\\n${str(snapshot)}`,\n                  );\n                }\n                if (args == null) {\n                  throw new OpenAIError(\n                    `missing choices[${index}].tool_calls[${i}].function.arguments\\n${str(snapshot)}`,\n                  );\n                }\n\n                return { ...toolRest, id, type, function: { ...fnRest, name, arguments: args } };\n              }),\n            },\n          };\n        }\n        return {\n          ...choiceRest,\n          message: { ...messageRest, content, role, refusal: message.refusal ?? null },\n          finish_reason,\n          index,\n          logprobs,\n        };\n      },\n    ),\n    created,\n    model,\n    object: 'chat.completion',\n    ...(system_fingerprint ? { system_fingerprint } : {}),\n  };\n\n  return maybeParseChatCompletion(completion, params);\n}\n\nfunction str(x: unknown) {\n  return JSON.stringify(x);\n}\n\n/**\n * Represents a streamed chunk of a chat completion response returned by model,\n * based on the provided input.\n */\nexport interface ChatCompletionSnapshot {\n  /**\n   * A unique identifier for the chat completion.\n   */\n  id: string;\n\n  /**\n   * A list of chat completion choices. Can be more than one if `n` is greater\n   * than 1.\n   */\n  choices: Array<ChatCompletionSnapshot.Choice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the chat completion was created.\n   */\n  created: number;\n\n  /**\n   * The model to generate the completion.\n   */\n  model: string;\n\n  // Note we do not include an \"object\" type on the snapshot,\n  // because the object is not a valid \"chat.completion\" until finalized.\n  // object: 'chat.completion';\n\n  /**\n   * This fingerprint represents the backend configuration that the model runs with.\n   *\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n}\n\nexport namespace ChatCompletionSnapshot {\n  export interface Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    message: Choice.Message;\n\n    /**\n     * The reason the model stopped generating tokens. This will be `stop` if the model\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\n     * number of tokens specified in the request was reached, `content_filter` if\n     * content was omitted due to a flag from our content filters, or `function_call`\n     * if the model called a function.\n     */\n    finish_reason: ChatCompletion.Choice['finish_reason'] | null;\n\n    /**\n     * Log probability information for the choice.\n     */\n    logprobs: ChatCompletion.Choice.Logprobs | null;\n\n    /**\n     * The index of the choice in the list of choices.\n     */\n    index: number;\n  }\n\n  export namespace Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    export interface Message {\n      /**\n       * The contents of the chunk message.\n       */\n      content?: string | null;\n\n      refusal?: string | null;\n\n      parsed?: unknown | null;\n\n      /**\n       * The name and arguments of a function that should be called, as generated by the\n       * model.\n       */\n      function_call?: Message.FunctionCall;\n\n      tool_calls?: Array<Message.ToolCall>;\n\n      /**\n       * The role of the author of this message.\n       */\n      role?: 'system' | 'user' | 'assistant' | 'function' | 'tool';\n    }\n\n    export namespace Message {\n      export interface ToolCall {\n        /**\n         * The ID of the tool call.\n         */\n        id: string;\n\n        function: ToolCall.Function;\n\n        /**\n         * The type of the tool.\n         */\n        type: 'function';\n      }\n\n      export namespace ToolCall {\n        export interface Function {\n          /**\n           * The arguments to call the function with, as generated by the model in JSON\n           * format. Note that the model does not always generate valid JSON, and may\n           * hallucinate parameters not defined by your function schema. Validate the\n           * arguments in your code before calling your function.\n           */\n          arguments: string;\n\n          parsed_arguments?: unknown;\n\n          /**\n           * The name of the function to call.\n           */\n          name: string;\n        }\n      }\n\n      /**\n       * The name and arguments of a function that should be called, as generated by the\n       * model.\n       */\n      export interface FunctionCall {\n        /**\n         * The arguments to call the function with, as generated by the model in JSON\n         * format. Note that the model does not always generate valid JSON, and may\n         * hallucinate parameters not defined by your function schema. Validate the\n         * arguments in your code before calling your function.\n         */\n        arguments?: string;\n\n        /**\n         * The name of the function to call.\n         */\n        name?: string;\n      }\n    }\n  }\n}\n\ntype AssertIsEmpty<T extends {}> = keyof T extends never ? T : never;\n\n/**\n * Ensures the given argument is an empty object, useful for\n * asserting that all known properties on an object have been\n * destructured.\n */\nfunction assertIsEmpty<T extends {}>(obj: AssertIsEmpty<T>): asserts obj is AssertIsEmpty<T> {\n  return;\n}\n\nfunction assertNever(_x: never) {}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;AA8HM,MAAO,6BACH,gKAAA,CAAA,+BAA0E;IAOlF,YAAY,MAAyC,CAAA;QACnD,KAAK;;QALP,6BAAA,GAAA,CAAA,IAAA,EAAA,KAAA;QACA,wCAAA,GAAA,CAAA,IAAA,EAAA,KAAA;QACA,oDAAA,GAAA,CAAA,IAAA,EAAA,KAAA;QAIE,uBAAA,IAAI,EAAA,8BAAW,QAAM;QACrB,uBAAA,IAAI,EAAA,yCAAsB,EAAE,EAAA;IAC9B;IAEA,IAAI,gCAA6B;QAC/B,OAAO,uBAAA,IAAI,EAAA,qDAAA;IACb;IAEA;;;;;;QAOA,OAAO,mBAAmB,MAAsB,EAAA;QAC9C,MAAM,SAAS,IAAI,qBAAqB;QACxC,OAAO,IAAI,CAAC,IAAM,OAAO,mBAAmB,CAAC;QAC7C,OAAO;IACT;IAEA,OAAO,qBACL,MAAc,EACd,MAAkC,EAClC,OAA6B,EAAA;QAE7B,MAAM,SAAS,IAAI,qBAA8B;QACjD,OAAO,IAAI,CAAC,IACV,OAAO,kBAAkB,CACvB,QACA;gBAAE,GAAG,MAAM;gBAAE,QAAQ;YAAI,GACzB;gBAAE,GAAG,OAAO;gBAAE,SAAS;oBAAE,GAAG,SAAS,OAAO;oBAAE,6BAA6B;gBAAQ;YAAE;QAGzF,OAAO;IACT;IAoMmB,MAAM,sBACvB,MAAc,EACd,MAAkC,EAClC,OAA6B,EAAA;QAE7B,KAAK,CAAC;QACN,MAAM,SAAS,SAAS;QACxB,IAAI,QAAQ;YACV,IAAI,OAAO,OAAO,EAAE,IAAI,CAAC,UAAU,CAAC,KAAK;YACzC,OAAO,gBAAgB,CAAC,SAAS,IAAM,IAAI,CAAC,UAAU,CAAC,KAAK;;QAE9D,uBAAA,IAAI,EAAA,iCAAA,KAAA,oCAAc,IAAA,CAAlB,IAAI;QAEJ,MAAM,SAAS,MAAM,OAAO,IAAI,CAAC,WAAW,CAAC,MAAM,CACjD;YAAE,GAAG,MAAM;YAAE,QAAQ;QAAI,GACzB;YAAE,GAAG,OAAO;YAAE,QAAQ,IAAI,CAAC,UAAU,CAAC,MAAM;QAAA;QAE9C,IAAI,CAAC,UAAU;QACf,WAAW,MAAM,SAAS,OAAQ;YAChC,uBAAA,IAAI,EAAA,iCAAA,KAAA,gCAAU,IAAA,CAAd,IAAI,EAAW;;QAEjB,IAAI,OAAO,UAAU,CAAC,MAAM,EAAE,SAAS;YACrC,MAAM,IAAI,kIAAA,CAAA,oBAAiB;;QAE7B,OAAO,IAAI,CAAC,kBAAkB,CAAC,uBAAA,IAAI,EAAA,iCAAA,KAAA,kCAAY,IAAA,CAAhB,IAAI;IACrC;IAEU,MAAM,oBACd,cAA8B,EAC9B,OAA6B,EAAA;QAE7B,MAAM,SAAS,SAAS;QACxB,IAAI,QAAQ;YACV,IAAI,OAAO,OAAO,EAAE,IAAI,CAAC,UAAU,CAAC,KAAK;YACzC,OAAO,gBAAgB,CAAC,SAAS,IAAM,IAAI,CAAC,UAAU,CAAC,KAAK;;QAE9D,uBAAA,IAAI,EAAA,iCAAA,KAAA,oCAAc,IAAA,CAAlB,IAAI;QACJ,IAAI,CAAC,UAAU;QACf,MAAM,SAAS,sIAAA,CAAA,SAAM,CAAC,kBAAkB,CAAsB,gBAAgB,IAAI,CAAC,UAAU;QAC7F,IAAI;QACJ,WAAW,MAAM,SAAS,OAAQ;YAChC,IAAI,UAAU,WAAW,MAAM,EAAE,EAAE;gBACjC,+BAA+B;gBAC/B,IAAI,CAAC,kBAAkB,CAAC,uBAAA,IAAI,EAAA,iCAAA,KAAA,kCAAY,IAAA,CAAhB,IAAI;;YAG9B,uBAAA,IAAI,EAAA,iCAAA,KAAA,gCAAU,IAAA,CAAd,IAAI,EAAW;YACf,SAAS,MAAM,EAAE;;QAEnB,IAAI,OAAO,UAAU,CAAC,MAAM,EAAE,SAAS;YACrC,MAAM,IAAI,kIAAA,CAAA,oBAAiB;;QAE7B,OAAO,IAAI,CAAC,kBAAkB,CAAC,uBAAA,IAAI,EAAA,iCAAA,KAAA,kCAAY,IAAA,CAAhB,IAAI;IACrC;IAuHA,CAAA,CAAA,+BAAA,IAAA,WAAA,0CAAA,IAAA,WAAA,sDAAA,IAAA,WAAA,kCAAA,IAAA,WAAA,qCAAA,SAAA;QA7WE,IAAI,IAAI,CAAC,KAAK,EAAE;QAChB,uBAAA,IAAI,EAAA,qDAAkC,WAAS;IACjD,GAAC,4CAAA,SAAA,0CAEoB,MAAqC;QACxD,IAAI,QAAQ,uBAAA,IAAI,EAAA,yCAAA,IAAmB,CAAC,OAAO,KAAK,CAAC;QACjD,IAAI,OAAO;YACT,OAAO;;QAGT,QAAQ;YACN,cAAc;YACd,cAAc;YACd,uBAAuB;YACvB,uBAAuB;YACvB,iBAAiB,IAAI;YACrB,yBAAyB;;QAE3B,uBAAA,IAAI,EAAA,yCAAA,IAAmB,CAAC,OAAO,KAAK,CAAC,GAAG;QACxC,OAAO;IACT,GAAC,iCAAA,SAAA,+BAE8C,KAA0B;QACvE,IAAI,IAAI,CAAC,KAAK,EAAE;QAEhB,MAAM,aAAa,uBAAA,IAAI,EAAA,iCAAA,KAAA,gDAA0B,IAAA,CAA9B,IAAI,EAA2B;QAClD,IAAI,CAAC,KAAK,CAAC,SAAS,OAAO;QAE3B,KAAK,MAAM,UAAU,MAAM,OAAO,CAAE;YAClC,MAAM,iBAAiB,WAAW,OAAO,CAAC,OAAO,KAAK,CAAE;YAExD,IACE,OAAO,KAAK,CAAC,OAAO,IAAI,QACxB,eAAe,OAAO,EAAE,SAAS,eACjC,eAAe,OAAO,EAAE,SACxB;gBACA,IAAI,CAAC,KAAK,CAAC,WAAW,OAAO,KAAK,CAAC,OAAO,EAAE,eAAe,OAAO,CAAC,OAAO;gBAC1E,IAAI,CAAC,KAAK,CAAC,iBAAiB;oBAC1B,OAAO,OAAO,KAAK,CAAC,OAAO;oBAC3B,UAAU,eAAe,OAAO,CAAC,OAAO;oBACxC,QAAQ,eAAe,OAAO,CAAC,MAAM;;;YAIzC,IACE,OAAO,KAAK,CAAC,OAAO,IAAI,QACxB,eAAe,OAAO,EAAE,SAAS,eACjC,eAAe,OAAO,EAAE,SACxB;gBACA,IAAI,CAAC,KAAK,CAAC,iBAAiB;oBAC1B,OAAO,OAAO,KAAK,CAAC,OAAO;oBAC3B,UAAU,eAAe,OAAO,CAAC,OAAO;;;YAI5C,IAAI,OAAO,QAAQ,EAAE,WAAW,QAAQ,eAAe,OAAO,EAAE,SAAS,aAAa;gBACpF,IAAI,CAAC,KAAK,CAAC,0BAA0B;oBACnC,SAAS,OAAO,QAAQ,EAAE;oBAC1B,UAAU,eAAe,QAAQ,EAAE,WAAW,EAAE;;;YAIpD,IAAI,OAAO,QAAQ,EAAE,WAAW,QAAQ,eAAe,OAAO,EAAE,SAAS,aAAa;gBACpF,IAAI,CAAC,KAAK,CAAC,0BAA0B;oBACnC,SAAS,OAAO,QAAQ,EAAE;oBAC1B,UAAU,eAAe,QAAQ,EAAE,WAAW,EAAE;;;YAIpD,MAAM,QAAQ,uBAAA,IAAI,EAAA,iCAAA,KAAA,2CAAqB,IAAA,CAAzB,IAAI,EAAsB;YAExC,IAAI,eAAe,aAAa,EAAE;gBAChC,uBAAA,IAAI,EAAA,iCAAA,KAAA,6CAAuB,IAAA,CAA3B,IAAI,EAAwB;gBAE5B,IAAI,MAAM,uBAAuB,IAAI,MAAM;oBACzC,uBAAA,IAAI,EAAA,iCAAA,KAAA,6CAAuB,IAAA,CAA3B,IAAI,EAAwB,gBAAgB,MAAM,uBAAuB;;;YAI7E,KAAK,MAAM,YAAY,OAAO,KAAK,CAAC,UAAU,IAAI,EAAE,CAAE;gBACpD,IAAI,MAAM,uBAAuB,KAAK,SAAS,KAAK,EAAE;oBACpD,uBAAA,IAAI,EAAA,iCAAA,KAAA,6CAAuB,IAAA,CAA3B,IAAI,EAAwB;oBAE5B,kDAAkD;oBAClD,IAAI,MAAM,uBAAuB,IAAI,MAAM;wBACzC,uBAAA,IAAI,EAAA,iCAAA,KAAA,6CAAuB,IAAA,CAA3B,IAAI,EAAwB,gBAAgB,MAAM,uBAAuB;;;gBAI7E,MAAM,uBAAuB,GAAG,SAAS,KAAK;;YAGhD,KAAK,MAAM,iBAAiB,OAAO,KAAK,CAAC,UAAU,IAAI,EAAE,CAAE;gBACzD,MAAM,mBAAmB,eAAe,OAAO,CAAC,UAAU,EAAE,CAAC,cAAc,KAAK,CAAC;gBACjF,IAAI,CAAC,kBAAkB,MAAM;oBAC3B;;gBAGF,IAAI,kBAAkB,SAAS,YAAY;oBACzC,IAAI,CAAC,KAAK,CAAC,uCAAuC;wBAChD,MAAM,iBAAiB,QAAQ,EAAE;wBACjC,OAAO,cAAc,KAAK;wBAC1B,WAAW,iBAAiB,QAAQ,CAAC,SAAS;wBAC9C,kBAAkB,iBAAiB,QAAQ,CAAC,gBAAgB;wBAC5D,iBAAiB,cAAc,QAAQ,EAAE,aAAa;;uBAEnD;oBACL,YAAY,kBAAkB;;;;IAItC,GAAC,8CAAA,SAAA,4CAEsB,cAA6C,EAAE,aAAqB;QACzF,MAAM,QAAQ,uBAAA,IAAI,EAAA,iCAAA,KAAA,2CAAqB,IAAA,CAAzB,IAAI,EAAsB;QACxC,IAAI,MAAM,eAAe,CAAC,GAAG,CAAC,gBAAgB;YAC5C,qCAAqC;YACrC;;QAGF,MAAM,mBAAmB,eAAe,OAAO,CAAC,UAAU,EAAE,CAAC,cAAc;QAC3E,IAAI,CAAC,kBAAkB;YACrB,MAAM,IAAI,MAAM;;QAElB,IAAI,CAAC,iBAAiB,IAAI,EAAE;YAC1B,MAAM,IAAI,MAAM;;QAGlB,IAAI,iBAAiB,IAAI,KAAK,YAAY;YACxC,MAAM,YAAY,uBAAA,IAAI,EAAA,8BAAA,MAAU,OAAO,KACrC,CAAC,OAAS,KAAK,IAAI,KAAK,cAAc,KAAK,QAAQ,CAAC,IAAI,KAAK,iBAAiB,QAAQ,CAAC,IAAI;YAG7F,IAAI,CAAC,KAAK,CAAC,sCAAsC;gBAC/C,MAAM,iBAAiB,QAAQ,CAAC,IAAI;gBACpC,OAAO;gBACP,WAAW,iBAAiB,QAAQ,CAAC,SAAS;gBAC9C,kBACE,CAAA,GAAA,0IAAA,CAAA,qBAAkB,AAAlB,EAAmB,aAAa,UAAU,SAAS,CAAC,iBAAiB,QAAQ,CAAC,SAAS,IACrF,WAAW,SAAS,SAAS,KAAK,KAAK,CAAC,iBAAiB,QAAQ,CAAC,SAAS,IAC3E;;eAED;YACL,YAAY,iBAAiB,IAAI;;IAErC,GAAC,8CAAA,SAAA,4CAEsB,cAA6C;QAClE,MAAM,QAAQ,uBAAA,IAAI,EAAA,iCAAA,KAAA,2CAAqB,IAAA,CAAzB,IAAI,EAAsB;QAExC,IAAI,eAAe,OAAO,CAAC,OAAO,IAAI,CAAC,MAAM,YAAY,EAAE;YACzD,MAAM,YAAY,GAAG;YAErB,MAAM,iBAAiB,uBAAA,IAAI,EAAA,iCAAA,KAAA,sDAAgC,IAAA,CAApC,IAAI;YAE3B,IAAI,CAAC,KAAK,CAAC,gBAAgB;gBACzB,SAAS,eAAe,OAAO,CAAC,OAAO;gBACvC,QAAQ,iBAAiB,eAAe,SAAS,CAAC,eAAe,OAAO,CAAC,OAAO,IAAK;;;QAIzF,IAAI,eAAe,OAAO,CAAC,OAAO,IAAI,CAAC,MAAM,YAAY,EAAE;YACzD,MAAM,YAAY,GAAG;YAErB,IAAI,CAAC,KAAK,CAAC,gBAAgB;gBAAE,SAAS,eAAe,OAAO,CAAC,OAAO;YAAA;;QAGtE,IAAI,eAAe,QAAQ,EAAE,WAAW,CAAC,MAAM,qBAAqB,EAAE;YACpE,MAAM,qBAAqB,GAAG;YAE9B,IAAI,CAAC,KAAK,CAAC,yBAAyB;gBAAE,SAAS,eAAe,QAAQ,CAAC,OAAO;YAAA;;QAGhF,IAAI,eAAe,QAAQ,EAAE,WAAW,CAAC,MAAM,qBAAqB,EAAE;YACpE,MAAM,qBAAqB,GAAG;YAE9B,IAAI,CAAC,KAAK,CAAC,yBAAyB;gBAAE,SAAS,eAAe,QAAQ,CAAC,OAAO;YAAA;;IAElF,GAAC,mCAAA,SAAA;QAGC,IAAI,IAAI,CAAC,KAAK,EAAE;YACd,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC,CAAA,uCAAA,CAAyC;;QAEjE,MAAM,WAAW,uBAAA,IAAI,EAAA,qDAAA;QACrB,IAAI,CAAC,UAAU;YACb,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC,CAAA,wCAAA,CAA0C;;QAElE,uBAAA,IAAI,EAAA,qDAAkC,WAAS;QAC/C,uBAAA,IAAI,EAAA,yCAAsB,EAAE,EAAA;QAC5B,OAAO,uBAAuB,UAAU,uBAAA,IAAI,EAAA,8BAAA;IAC9C,GAAC,uDAAA,SAAA;QA0DC,MAAM,iBAAiB,uBAAA,IAAI,EAAA,8BAAA,MAAU;QACrC,IAAI,CAAA,GAAA,0IAAA,CAAA,+BAA4B,AAA5B,EAAsC,iBAAiB;YACzD,OAAO;;QAGT,OAAO;IACT,GAAC,iDAAA,SAAA,+CAEyB,KAA0B;;QAClD,IAAI,WAAW,uBAAA,IAAI,EAAA,qDAAA;QACnB,MAAM,EAAE,OAAO,EAAE,GAAG,MAAM,GAAG;QAC7B,IAAI,CAAC,UAAU;YACb,WAAW,uBAAA,IAAI,EAAA,qDAAkC;gBAC/C,GAAG,IAAI;gBACP,SAAS,EAAE;eACZ;eACI;YACL,OAAO,MAAM,CAAC,UAAU;;QAG1B,KAAK,MAAM,EAAE,KAAK,EAAE,aAAa,EAAE,KAAK,EAAE,WAAW,IAAI,EAAE,GAAG,OAAO,IAAI,MAAM,OAAO,CAAE;YACtF,IAAI,SAAS,SAAS,OAAO,CAAC,MAAM;YACpC,IAAI,CAAC,QAAQ;gBACX,SAAS,SAAS,OAAO,CAAC,MAAM,GAAG;oBAAE;oBAAe;oBAAO,SAAS,CAAA;oBAAI;oBAAU,GAAG,KAAK;gBAAA;;YAG5F,IAAI,UAAU;gBACZ,IAAI,CAAC,OAAO,QAAQ,EAAE;oBACpB,OAAO,QAAQ,GAAG,OAAO,MAAM,CAAC,CAAA,GAAI;uBAC/B;oBACL,MAAM,EAAE,OAAO,EAAE,OAAO,EAAE,GAAG,MAAM,GAAG;oBACtC,cAAc;oBACd,OAAO,MAAM,CAAC,OAAO,QAAQ,EAAE;oBAE/B,IAAI,SAAS;wBACX,CAAA,KAAA,OAAO,QAAQ,EAAC,OAAO,IAAA,CAAA,GAAP,OAAO,GAAK,EAAE;wBAC9B,OAAO,QAAQ,CAAC,OAAO,CAAC,IAAI,IAAI;;oBAGlC,IAAI,SAAS;wBACX,CAAA,KAAA,OAAO,QAAQ,EAAC,OAAO,IAAA,CAAA,GAAP,OAAO,GAAK,EAAE;wBAC9B,OAAO,QAAQ,CAAC,OAAO,CAAC,IAAI,IAAI;;;;YAKtC,IAAI,eAAe;gBACjB,OAAO,aAAa,GAAG;gBAEvB,IAAI,uBAAA,IAAI,EAAA,8BAAA,QAAY,CAAA,GAAA,0IAAA,CAAA,wBAAqB,AAArB,EAAsB,uBAAA,IAAI,EAAA,8BAAA,OAAW;oBACvD,IAAI,kBAAkB,UAAU;wBAC9B,MAAM,IAAI,kIAAA,CAAA,0BAAuB;;oBAGnC,IAAI,kBAAkB,kBAAkB;wBACtC,MAAM,IAAI,kIAAA,CAAA,iCAA8B;;;;YAK9C,OAAO,MAAM,CAAC,QAAQ;YAEtB,IAAI,CAAC,OAAO,UAAU,kCAAkC;YAExD,MAAM,EAAE,OAAO,EAAE,OAAO,EAAE,aAAa,EAAE,IAAI,EAAE,UAAU,EAAE,GAAG,MAAM,GAAG;YACvE,cAAc;YACd,OAAO,MAAM,CAAC,OAAO,OAAO,EAAE;YAE9B,IAAI,SAAS;gBACX,OAAO,OAAO,CAAC,OAAO,GAAG,CAAC,OAAO,OAAO,CAAC,OAAO,IAAI,EAAE,IAAI;;YAG5D,IAAI,MAAM,OAAO,OAAO,CAAC,IAAI,GAAG;YAChC,IAAI,eAAe;gBACjB,IAAI,CAAC,OAAO,OAAO,CAAC,aAAa,EAAE;oBACjC,OAAO,OAAO,CAAC,aAAa,GAAG;uBAC1B;oBACL,IAAI,cAAc,IAAI,EAAE,OAAO,OAAO,CAAC,aAAa,CAAC,IAAI,GAAG,cAAc,IAAI;oBAC9E,IAAI,cAAc,SAAS,EAAE;wBAC3B,CAAA,KAAA,OAAO,OAAO,CAAC,aAAa,EAAC,SAAS,IAAA,CAAA,GAAT,SAAS,GAAK,EAAE;wBAC7C,OAAO,OAAO,CAAC,aAAa,CAAC,SAAS,IAAI,cAAc,SAAS;;;;YAIvE,IAAI,SAAS;gBACX,OAAO,OAAO,CAAC,OAAO,GAAG,CAAC,OAAO,OAAO,CAAC,OAAO,IAAI,EAAE,IAAI;gBAE1D,IAAI,CAAC,OAAO,OAAO,CAAC,OAAO,IAAI,uBAAA,IAAI,EAAA,iCAAA,KAAA,sDAAgC,IAAA,CAApC,IAAI,GAAoC;oBACrE,OAAO,OAAO,CAAC,MAAM,GAAG,CAAA,GAAA,2KAAA,CAAA,eAAY,AAAZ,EAAa,OAAO,OAAO,CAAC,OAAO;;;YAI/D,IAAI,YAAY;gBACd,IAAI,CAAC,OAAO,OAAO,CAAC,UAAU,EAAE,OAAO,OAAO,CAAC,UAAU,GAAG,EAAE;gBAE9D,KAAK,MAAM,EAAE,KAAK,EAAE,EAAE,EAAE,IAAI,EAAE,UAAU,EAAE,EAAE,GAAG,MAAM,IAAI,WAAY;oBACnE,MAAM,YAAY,CAAA,KAAC,OAAO,OAAO,CAAC,UAAU,CAAA,CAAC,MAAK,IAAA,CAAA,EAAA,CAAL,MAAK,GAChD,CAAA,CAAoD;oBACtD,OAAO,MAAM,CAAC,WAAW;oBACzB,IAAI,IAAI,UAAU,EAAE,GAAG;oBACvB,IAAI,MAAM,UAAU,IAAI,GAAG;oBAC3B,IAAI,IAAI,UAAU,QAAQ,IAAA,CAAlB,UAAU,QAAQ,GAAK;wBAAE,MAAM,GAAG,IAAI,IAAI;wBAAI,WAAW;oBAAE,CAAE;oBACrE,IAAI,IAAI,MAAM,UAAU,QAAS,CAAC,IAAI,GAAG,GAAG,IAAI;oBAChD,IAAI,IAAI,WAAW;wBACjB,UAAU,QAAS,CAAC,SAAS,IAAI,GAAG,SAAS;wBAE7C,IAAI,CAAA,GAAA,0IAAA,CAAA,sBAAmB,AAAnB,EAAoB,uBAAA,IAAI,EAAA,8BAAA,MAAU,YAAY;4BAChD,UAAU,QAAS,CAAC,gBAAgB,GAAG,CAAA,GAAA,2KAAA,CAAA,eAAY,AAAZ,EAAa,UAAU,QAAS,CAAC,SAAS;;;;;;QAM3F,OAAO;IACT,GAEC,OAAO,aAAa,EAAC,GAAA;QACpB,MAAM,YAAmC,EAAE;QAC3C,MAAM,YAGA,EAAE;QACR,IAAI,OAAO;QAEX,IAAI,CAAC,EAAE,CAAC,SAAS,CAAC;YAChB,MAAM,SAAS,UAAU,KAAK;YAC9B,IAAI,QAAQ;gBACV,OAAO,OAAO,CAAC;mBACV;gBACL,UAAU,IAAI,CAAC;;QAEnB;QAEA,IAAI,CAAC,EAAE,CAAC,OAAO;YACb,OAAO;YACP,KAAK,MAAM,UAAU,UAAW;gBAC9B,OAAO,OAAO,CAAC;;YAEjB,UAAU,MAAM,GAAG;QACrB;QAEA,IAAI,CAAC,EAAE,CAAC,SAAS,CAAC;YAChB,OAAO;YACP,KAAK,MAAM,UAAU,UAAW;gBAC9B,OAAO,MAAM,CAAC;;YAEhB,UAAU,MAAM,GAAG;QACrB;QAEA,IAAI,CAAC,EAAE,CAAC,SAAS,CAAC;YAChB,OAAO;YACP,KAAK,MAAM,UAAU,UAAW;gBAC9B,OAAO,MAAM,CAAC;;YAEhB,UAAU,MAAM,GAAG;QACrB;QAEA,OAAO;YACL,MAAM;gBACJ,IAAI,CAAC,UAAU,MAAM,EAAE;oBACrB,IAAI,MAAM;wBACR,OAAO;4BAAE,OAAO;4BAAW,MAAM;wBAAI;;oBAEvC,OAAO,IAAI,QAAyC,CAAC,SAAS,SAC5D,UAAU,IAAI,CAAC;4BAAE;4BAAS;wBAAM,IAChC,IAAI,CAAC,CAAC,QAAW,QAAQ;4BAAE,OAAO;4BAAO,MAAM;wBAAK,IAAK;4BAAE,OAAO;4BAAW,MAAM;wBAAI;;gBAE3F,MAAM,QAAQ,UAAU,KAAK;gBAC7B,OAAO;oBAAE,OAAO;oBAAO,MAAM;gBAAK;YACpC;YACA,QAAQ;gBACN,IAAI,CAAC,KAAK;gBACV,OAAO;oBAAE,OAAO;oBAAW,MAAM;gBAAI;YACvC;;IAEJ;IAEA,mBAAgB;QACd,MAAM,SAAS,IAAI,sIAAA,CAAA,SAAM,CAAC,IAAI,CAAC,OAAO,aAAa,CAAC,CAAC,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,UAAU;QAChF,OAAO,OAAO,gBAAgB;IAChC;;AAGF,SAAS,uBACP,QAAgC,EAChC,MAAyC;IAEzC,MAAM,EAAE,EAAE,EAAE,OAAO,EAAE,OAAO,EAAE,KAAK,EAAE,kBAAkB,EAAE,GAAG,MAAM,GAAG;IACrE,MAAM,aAA6B;QACjC,GAAG,IAAI;QACP;QACA,SAAS,QAAQ,GAAG,CAClB,CAAC,EAAE,OAAO,EAAE,aAAa,EAAE,KAAK,EAAE,QAAQ,EAAE,GAAG,YAAY;YACzD,IAAI,CAAC,eAAe;gBAClB,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC,CAAA,iCAAA,EAAoC,MAAK,CAAE;;YAGnE,MAAM,EAAE,UAAU,IAAI,EAAE,aAAa,EAAE,UAAU,EAAE,GAAG,aAAa,GAAG;YACtE,MAAM,OAAO,QAAQ,IAAmB,EAAE,qHAAqH;YAC/J,IAAI,CAAC,MAAM;gBACT,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC,CAAA,wBAAA,EAA2B,MAAK,CAAE;;YAG1D,IAAI,eAAe;gBACjB,MAAM,EAAE,WAAW,IAAI,EAAE,IAAI,EAAE,GAAG;gBAClC,IAAI,QAAQ,MAAM;oBAChB,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC,CAAA,2CAAA,EAA8C,MAAK,CAAE;;gBAG7E,IAAI,CAAC,MAAM;oBACT,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC,CAAA,sCAAA,EAAyC,MAAK,CAAE;;gBAGxE,OAAO;oBACL,GAAG,UAAU;oBACb,SAAS;wBACP;wBACA,eAAe;4BAAE,WAAW;4BAAM;wBAAI;wBACtC;wBACA,SAAS,QAAQ,OAAO,IAAI;;oBAE9B;oBACA;oBACA;;;YAIJ,IAAI,YAAY;gBACd,OAAO;oBACL,GAAG,UAAU;oBACb;oBACA;oBACA;oBACA,SAAS;wBACP,GAAG,WAAW;wBACd;wBACA;wBACA,SAAS,QAAQ,OAAO,IAAI;wBAC5B,YAAY,WAAW,GAAG,CAAC,CAAC,WAAW;4BACrC,MAAM,EAAE,UAAU,EAAE,EAAE,IAAI,EAAE,EAAE,EAAE,GAAG,UAAU,GAAG;4BAChD,MAAM,EAAE,WAAW,IAAI,EAAE,IAAI,EAAE,GAAG,QAAQ,GAAG,MAAM,CAAA;4BACnD,IAAI,MAAM,MAAM;gCACd,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC,CAAA,gBAAA,EAAmB,MAAK,aAAA,EAAgB,EAAC,MAAA,EAAS,IAAI,UAAS,CAAE;;4BAEzF,IAAI,QAAQ,MAAM;gCAChB,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC,CAAA,gBAAA,EAAmB,MAAK,aAAA,EAAgB,EAAC,QAAA,EAAW,IAAI,UAAS,CAAE;;4BAE3F,IAAI,QAAQ,MAAM;gCAChB,MAAM,IAAI,kIAAA,CAAA,cAAW,CACnB,CAAA,gBAAA,EAAmB,MAAK,aAAA,EAAgB,EAAC,iBAAA,EAAoB,IAAI,UAAS,CAAE;;4BAGhF,IAAI,QAAQ,MAAM;gCAChB,MAAM,IAAI,kIAAA,CAAA,cAAW,CACnB,CAAA,gBAAA,EAAmB,MAAK,aAAA,EAAgB,EAAC,sBAAA,EAAyB,IAAI,UAAS,CAAE;;4BAIrF,OAAO;gCAAE,GAAG,QAAQ;gCAAE;gCAAI;gCAAM,UAAU;oCAAE,GAAG,MAAM;oCAAE;oCAAM,WAAW;gCAAI;4BAAE;wBAChF;;;;YAIN,OAAO;gBACL,GAAG,UAAU;gBACb,SAAS;oBAAE,GAAG,WAAW;oBAAE;oBAAS;oBAAM,SAAS,QAAQ,OAAO,IAAI;gBAAI;gBAC1E;gBACA;gBACA;;QAEJ;QAEF;QACA;QACA,QAAQ;QACR,GAAI,qBAAqB;YAAE;QAAkB,IAAK,CAAA,CAAE;;IAGtD,OAAO,CAAA,GAAA,0IAAA,CAAA,2BAAwB,AAAxB,EAAyB,YAAY;AAC9C;AAEA,SAAS,IAAI,CAAU;IACrB,OAAO,KAAK,SAAS,CAAC;AACxB;AA0JA;;;;IAKA,SAAS,cAA4B,GAAqB;IACxD;AACF;AAEA,SAAS,YAAY,EAAS,GAAG"}},
    {"offset": {"line": 4478, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 4483, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/lib/ChatCompletionStreamingRunner.ts"],"sourcesContent":["import {\n  type ChatCompletionChunk,\n  type ChatCompletionCreateParamsStreaming,\n} from \"../resources/chat/completions\";\nimport { RunnerOptions, type AbstractChatCompletionRunnerEvents } from './AbstractChatCompletionRunner';\nimport { type ReadableStream } from \"../_shims/index\";\nimport { RunnableTools, type BaseFunctionsArgs, type RunnableFunctions } from './RunnableFunction';\nimport { ChatCompletionSnapshot, ChatCompletionStream } from './ChatCompletionStream';\nimport OpenAI from \"../index\";\nimport { AutoParseableTool } from \"./parser\";\n\nexport interface ChatCompletionStreamEvents extends AbstractChatCompletionRunnerEvents {\n  content: (contentDelta: string, contentSnapshot: string) => void;\n  chunk: (chunk: ChatCompletionChunk, snapshot: ChatCompletionSnapshot) => void;\n}\n\nexport type ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\n  ChatCompletionCreateParamsStreaming,\n  'functions'\n> & {\n  functions: RunnableFunctions<FunctionsArgs>;\n};\n\nexport type ChatCompletionStreamingToolRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\n  ChatCompletionCreateParamsStreaming,\n  'tools'\n> & {\n  tools: RunnableTools<FunctionsArgs> | AutoParseableTool<any, true>[];\n};\n\nexport class ChatCompletionStreamingRunner<ParsedT = null>\n  extends ChatCompletionStream<ParsedT>\n  implements AsyncIterable<ChatCompletionChunk>\n{\n  static override fromReadableStream(stream: ReadableStream): ChatCompletionStreamingRunner<null> {\n    const runner = new ChatCompletionStreamingRunner(null);\n    runner._run(() => runner._fromReadableStream(stream));\n    return runner;\n  }\n\n  /** @deprecated - please use `runTools` instead. */\n  static runFunctions<T extends (string | object)[]>(\n    client: OpenAI,\n    params: ChatCompletionStreamingFunctionRunnerParams<T>,\n    options?: RunnerOptions,\n  ): ChatCompletionStreamingRunner<null> {\n    const runner = new ChatCompletionStreamingRunner(null);\n    const opts = {\n      ...options,\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runFunctions' },\n    };\n    runner._run(() => runner._runFunctions(client, params, opts));\n    return runner;\n  }\n\n  static runTools<T extends (string | object)[], ParsedT = null>(\n    client: OpenAI,\n    params: ChatCompletionStreamingToolRunnerParams<T>,\n    options?: RunnerOptions,\n  ): ChatCompletionStreamingRunner<ParsedT> {\n    const runner = new ChatCompletionStreamingRunner<ParsedT>(\n      // @ts-expect-error TODO these types are incompatible\n      params,\n    );\n    const opts = {\n      ...options,\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runTools' },\n    };\n    runner._run(() => runner._runTools(client, params, opts));\n    return runner;\n  }\n}\n"],"names":[],"mappings":";;;;;;AA8BM,MAAO,sCACH,wJAAA,CAAA,uBAA6B;IAGrC,OAAgB,mBAAmB,MAAsB,EAAA;QACvD,MAAM,SAAS,IAAI,8BAA8B;QACjD,OAAO,IAAI,CAAC,IAAM,OAAO,mBAAmB,CAAC;QAC7C,OAAO;IACT;IAEA,iDAAA,GACA,OAAO,aACL,MAAc,EACd,MAAsD,EACtD,OAAuB,EAAA;QAEvB,MAAM,SAAS,IAAI,8BAA8B;QACjD,MAAM,OAAO;YACX,GAAG,OAAO;YACV,SAAS;gBAAE,GAAG,SAAS,OAAO;gBAAE,6BAA6B;YAAc;;QAE7E,OAAO,IAAI,CAAC,IAAM,OAAO,aAAa,CAAC,QAAQ,QAAQ;QACvD,OAAO;IACT;IAEA,OAAO,SACL,MAAc,EACd,MAAkD,EAClD,OAAuB,EAAA;QAEvB,MAAM,SAAS,IAAI,8BACjB,qDAAqD;QACrD;QAEF,MAAM,OAAO;YACX,GAAG,OAAO;YACV,SAAS;gBAAE,GAAG,SAAS,OAAO;gBAAE,6BAA6B;YAAU;;QAEzE,OAAO,IAAI,CAAC,IAAM,OAAO,SAAS,CAAC,QAAQ,QAAQ;QACnD,OAAO;IACT"}},
    {"offset": {"line": 4521, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 4526, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/lib/ChatCompletionRunner.ts"],"sourcesContent":["import {\n  type ChatCompletionMessageParam,\n  type ChatCompletionCreateParamsNonStreaming,\n} from \"../resources/chat/completions\";\nimport { type RunnableFunctions, type BaseFunctionsArgs, RunnableTools } from './RunnableFunction';\nimport {\n  AbstractChatCompletionRunner,\n  AbstractChatCompletionRunnerEvents,\n  RunnerOptions,\n} from './AbstractChatCompletionRunner';\nimport { isAssistantMessage } from './chatCompletionUtils';\nimport OpenAI from \"../index\";\nimport { AutoParseableTool } from \"./parser\";\n\nexport interface ChatCompletionRunnerEvents extends AbstractChatCompletionRunnerEvents {\n  content: (content: string) => void;\n}\n\nexport type ChatCompletionFunctionRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\n  ChatCompletionCreateParamsNonStreaming,\n  'functions'\n> & {\n  functions: RunnableFunctions<FunctionsArgs>;\n};\n\nexport type ChatCompletionToolRunnerParams<FunctionsArgs extends BaseFunctionsArgs> = Omit<\n  ChatCompletionCreateParamsNonStreaming,\n  'tools'\n> & {\n  tools: RunnableTools<FunctionsArgs> | AutoParseableTool<any, true>[];\n};\n\nexport class ChatCompletionRunner<ParsedT = null> extends AbstractChatCompletionRunner<\n  ChatCompletionRunnerEvents,\n  ParsedT\n> {\n  /** @deprecated - please use `runTools` instead. */\n  static runFunctions(\n    client: OpenAI,\n    params: ChatCompletionFunctionRunnerParams<any[]>,\n    options?: RunnerOptions,\n  ): ChatCompletionRunner<null> {\n    const runner = new ChatCompletionRunner();\n    const opts = {\n      ...options,\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runFunctions' },\n    };\n    runner._run(() => runner._runFunctions(client, params, opts));\n    return runner;\n  }\n\n  static runTools<ParsedT>(\n    client: OpenAI,\n    params: ChatCompletionToolRunnerParams<any[]>,\n    options?: RunnerOptions,\n  ): ChatCompletionRunner<ParsedT> {\n    const runner = new ChatCompletionRunner<ParsedT>();\n    const opts = {\n      ...options,\n      headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'runTools' },\n    };\n    runner._run(() => runner._runTools(client, params, opts));\n    return runner;\n  }\n\n  override _addMessage(\n    this: ChatCompletionRunner<ParsedT>,\n    message: ChatCompletionMessageParam,\n    emit: boolean = true,\n  ) {\n    super._addMessage(message, emit);\n    if (isAssistantMessage(message) && message.content) {\n      this._emit('content', message.content as string);\n    }\n  }\n}\n"],"names":[],"mappings":";;;;;;;;AAgCM,MAAO,6BAA6C,gKAAA,CAAA,+BAGzD;IACC,iDAAA,GACA,OAAO,aACL,MAAc,EACd,MAAiD,EACjD,OAAuB,EAAA;QAEvB,MAAM,SAAS,IAAI;QACnB,MAAM,OAAO;YACX,GAAG,OAAO;YACV,SAAS;gBAAE,GAAG,SAAS,OAAO;gBAAE,6BAA6B;YAAc;;QAE7E,OAAO,IAAI,CAAC,IAAM,OAAO,aAAa,CAAC,QAAQ,QAAQ;QACvD,OAAO;IACT;IAEA,OAAO,SACL,MAAc,EACd,MAA6C,EAC7C,OAAuB,EAAA;QAEvB,MAAM,SAAS,IAAI;QACnB,MAAM,OAAO;YACX,GAAG,OAAO;YACV,SAAS;gBAAE,GAAG,SAAS,OAAO;gBAAE,6BAA6B;YAAU;;QAEzE,OAAO,IAAI,CAAC,IAAM,OAAO,SAAS,CAAC,QAAQ,QAAQ;QACnD,OAAO;IACT;IAES,YAEP,OAAmC,EACnC,OAAgB,IAAI,EAAA;QAEpB,KAAK,CAAC,YAAY,SAAS;QAC3B,IAAI,CAAA,GAAA,uJAAA,CAAA,qBAAkB,AAAlB,EAAmB,YAAY,QAAQ,OAAO,EAAE;YAClD,IAAI,CAAC,KAAK,CAAC,WAAW,QAAQ,OAAiB;;IAEnD"}},
    {"offset": {"line": 4566, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 4571, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/beta/chat/completions.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Core from '../../../core';\nimport { APIResource } from '../../../resource';\nimport { ChatCompletionRunner, ChatCompletionFunctionRunnerParams } from '../../../lib/ChatCompletionRunner';\nexport { ChatCompletionRunner, ChatCompletionFunctionRunnerParams } from '../../../lib/ChatCompletionRunner';\nimport {\n  ChatCompletionStreamingRunner,\n  ChatCompletionStreamingFunctionRunnerParams,\n} from '../../../lib/ChatCompletionStreamingRunner';\nexport {\n  ChatCompletionStreamingRunner,\n  ChatCompletionStreamingFunctionRunnerParams,\n} from '../../../lib/ChatCompletionStreamingRunner';\nimport { BaseFunctionsArgs } from '../../../lib/RunnableFunction';\nexport {\n  RunnableFunction,\n  RunnableFunctions,\n  RunnableFunctionWithParse,\n  RunnableFunctionWithoutParse,\n  ParsingFunction,\n  ParsingToolFunction,\n} from '../../../lib/RunnableFunction';\nimport { RunnerOptions } from '../../../lib/AbstractChatCompletionRunner';\nimport { ChatCompletionToolRunnerParams } from '../../../lib/ChatCompletionRunner';\nexport { ChatCompletionToolRunnerParams } from '../../../lib/ChatCompletionRunner';\nimport { ChatCompletionStreamingToolRunnerParams } from '../../../lib/ChatCompletionStreamingRunner';\nexport { ChatCompletionStreamingToolRunnerParams } from '../../../lib/ChatCompletionStreamingRunner';\nimport { ChatCompletionStream, type ChatCompletionStreamParams } from '../../../lib/ChatCompletionStream';\nimport {\n  ChatCompletion,\n  ChatCompletionCreateParamsNonStreaming,\n  ChatCompletionMessage,\n  ChatCompletionMessageToolCall,\n} from '../../chat/completions';\nimport { ExtractParsedContentFromParams, parseChatCompletion, validateInputTools } from '../../../lib/parser';\nexport { ChatCompletionStream, type ChatCompletionStreamParams } from '../../../lib/ChatCompletionStream';\n\nexport interface ParsedFunction extends ChatCompletionMessageToolCall.Function {\n  parsed_arguments?: unknown;\n}\n\nexport interface ParsedFunctionToolCall extends ChatCompletionMessageToolCall {\n  function: ParsedFunction;\n}\n\nexport interface ParsedChatCompletionMessage<ParsedT> extends ChatCompletionMessage {\n  parsed: ParsedT | null;\n  tool_calls: Array<ParsedFunctionToolCall>;\n}\n\nexport interface ParsedChoice<ParsedT> extends ChatCompletion.Choice {\n  message: ParsedChatCompletionMessage<ParsedT>;\n}\n\nexport interface ParsedChatCompletion<ParsedT> extends ChatCompletion {\n  choices: Array<ParsedChoice<ParsedT>>;\n}\n\nexport type ChatCompletionParseParams = ChatCompletionCreateParamsNonStreaming;\n\nexport class Completions extends APIResource {\n  parse<Params extends ChatCompletionParseParams, ParsedT = ExtractParsedContentFromParams<Params>>(\n    body: Params,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<ParsedChatCompletion<ParsedT>> {\n    validateInputTools(body.tools);\n\n    return this._client.chat.completions\n      .create(body, {\n        ...options,\n        headers: {\n          ...options?.headers,\n          'X-Stainless-Helper-Method': 'beta.chat.completions.parse',\n        },\n      })\n      ._thenUnwrap((completion) => parseChatCompletion(completion, body));\n  }\n\n  /**\n   * @deprecated - use `runTools` instead.\n   */\n  runFunctions<FunctionsArgs extends BaseFunctionsArgs>(\n    body: ChatCompletionFunctionRunnerParams<FunctionsArgs>,\n    options?: Core.RequestOptions,\n  ): ChatCompletionRunner<null>;\n  runFunctions<FunctionsArgs extends BaseFunctionsArgs>(\n    body: ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs>,\n    options?: Core.RequestOptions,\n  ): ChatCompletionStreamingRunner<null>;\n  runFunctions<FunctionsArgs extends BaseFunctionsArgs>(\n    body:\n      | ChatCompletionFunctionRunnerParams<FunctionsArgs>\n      | ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs>,\n    options?: Core.RequestOptions,\n  ): ChatCompletionRunner<null> | ChatCompletionStreamingRunner<null> {\n    if (body.stream) {\n      return ChatCompletionStreamingRunner.runFunctions(\n        this._client,\n        body as ChatCompletionStreamingFunctionRunnerParams<FunctionsArgs>,\n        options,\n      );\n    }\n    return ChatCompletionRunner.runFunctions(\n      this._client,\n      body as ChatCompletionFunctionRunnerParams<FunctionsArgs>,\n      options,\n    );\n  }\n\n  /**\n   * A convenience helper for using tool calls with the /chat/completions endpoint\n   * which automatically calls the JavaScript functions you provide and sends their\n   * results back to the /chat/completions endpoint, looping as long as the model\n   * requests function calls.\n   *\n   * For more details and examples, see\n   * [the docs](https://github.com/openai/openai-node#automated-function-calls)\n   */\n  runTools<\n    Params extends ChatCompletionToolRunnerParams<any>,\n    ParsedT = ExtractParsedContentFromParams<Params>,\n  >(body: Params, options?: RunnerOptions): ChatCompletionRunner<ParsedT>;\n\n  runTools<\n    Params extends ChatCompletionStreamingToolRunnerParams<any>,\n    ParsedT = ExtractParsedContentFromParams<Params>,\n  >(body: Params, options?: RunnerOptions): ChatCompletionStreamingRunner<ParsedT>;\n\n  runTools<\n    Params extends ChatCompletionToolRunnerParams<any> | ChatCompletionStreamingToolRunnerParams<any>,\n    ParsedT = ExtractParsedContentFromParams<Params>,\n  >(\n    body: Params,\n    options?: RunnerOptions,\n  ): ChatCompletionRunner<ParsedT> | ChatCompletionStreamingRunner<ParsedT> {\n    if (body.stream) {\n      return ChatCompletionStreamingRunner.runTools(\n        this._client,\n        body as ChatCompletionStreamingToolRunnerParams<any>,\n        options,\n      );\n    }\n\n    return ChatCompletionRunner.runTools(this._client, body as ChatCompletionToolRunnerParams<any>, options);\n  }\n\n  /**\n   * Creates a chat completion stream\n   */\n  stream<Params extends ChatCompletionStreamParams, ParsedT = ExtractParsedContentFromParams<Params>>(\n    body: Params,\n    options?: Core.RequestOptions,\n  ): ChatCompletionStream<ParsedT> {\n    return ChatCompletionStream.createChatCompletion(this._client, body, options);\n  }\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;;;;;;;;;;;AA6DhF,MAAO,oBAAoB,qIAAA,CAAA,cAAW;IAC1C,MACE,IAAY,EACZ,OAA6B,EAAA;QAE7B,CAAA,GAAA,0IAAA,CAAA,qBAAkB,AAAlB,EAAmB,KAAK,KAAK;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,WAAW,CACjC,MAAM,CAAC,MAAM;YACZ,GAAG,OAAO;YACV,SAAS;gBACP,GAAG,SAAS,OAAO;gBACnB,6BAA6B;;WAGhC,WAAW,CAAC,CAAC,aAAe,CAAA,GAAA,0IAAA,CAAA,sBAAmB,AAAnB,EAAoB,YAAY;IACjE;IAaA,aACE,IAE8D,EAC9D,OAA6B,EAAA;QAE7B,IAAI,KAAK,MAAM,EAAE;YACf,OAAO,iKAAA,CAAA,gCAA6B,CAAC,YAAY,CAC/C,IAAI,CAAC,OAAO,EACZ,MACA;;QAGJ,OAAO,wJAAA,CAAA,uBAAoB,CAAC,YAAY,CACtC,IAAI,CAAC,OAAO,EACZ,MACA;IAEJ;IAqBA,SAIE,IAAY,EACZ,OAAuB,EAAA;QAEvB,IAAI,KAAK,MAAM,EAAE;YACf,OAAO,iKAAA,CAAA,gCAA6B,CAAC,QAAQ,CAC3C,IAAI,CAAC,OAAO,EACZ,MACA;;QAIJ,OAAO,wJAAA,CAAA,uBAAoB,CAAC,QAAQ,CAAC,IAAI,CAAC,OAAO,EAAE,MAA6C;IAClG;IAEA;;QAGA,OACE,IAAY,EACZ,OAA6B,EAAA;QAE7B,OAAO,wJAAA,CAAA,uBAAoB,CAAC,oBAAoB,CAAC,IAAI,CAAC,OAAO,EAAE,MAAM;IACvE"}},
    {"offset": {"line": 4619, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 4667, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/beta/chat/chat.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport * as CompletionsAPI from './completions';\n\nexport class Chat extends APIResource {\n  completions: CompletionsAPI.Completions = new CompletionsAPI.Completions(this._client);\n}\n\nexport namespace Chat {\n  export import Completions = CompletionsAPI.Completions;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;AAKhF,MAAO,aAAa,qIAAA,CAAA,cAAW;IAArC,aAAA;;QACE,IAAA,CAAA,WAAW,GAA+B,IAAI,sLAAe,WAAW,CAAC,IAAI,CAAC,OAAO;IACvF;;AAEA,CAAA,SAAiB,IAAI;IACL,KAAA,WAAW,GAAG,sLAAe,WAAW;AACxD,CAAC,EAFgB,QAAI,CAAJ,OAAI,CAAA,CAAA"}},
    {"offset": {"line": 4685, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 4690, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/lib/AssistantStream.ts"],"sourcesContent":["import {\n  TextContentBlock,\n  ImageFileContentBlock,\n  Message,\n  MessageContentDelta,\n  Text,\n  ImageFile,\n  TextDelta,\n  Messages,\n  MessageContent,\n} from \"../resources/beta/threads/messages\";\nimport * as Core from \"../core\";\nimport { RequestOptions } from \"../core\";\nimport {\n  Run,\n  RunCreateParamsBase,\n  RunCreateParamsStreaming,\n  Runs,\n  RunSubmitToolOutputsParamsBase,\n  RunSubmitToolOutputsParamsStreaming,\n} from \"../resources/beta/threads/runs/runs\";\nimport { type ReadableStream } from \"../_shims/index\";\nimport { Stream } from \"../streaming\";\nimport { APIUserAbortError, OpenAIError } from \"../error\";\nimport {\n  AssistantStreamEvent,\n  MessageStreamEvent,\n  RunStepStreamEvent,\n  RunStreamEvent,\n} from \"../resources/beta/assistants\";\nimport { RunStep, RunStepDelta, ToolCall, ToolCallDelta } from \"../resources/beta/threads/runs/steps\";\nimport { ThreadCreateAndRunParamsBase, Threads } from \"../resources/beta/threads/threads\";\nimport { BaseEvents, EventStream } from './EventStream';\nimport MessageDelta = Messages.MessageDelta;\n\nexport interface AssistantStreamEvents extends BaseEvents {\n  run: (run: Run) => void;\n\n  //New event structure\n  messageCreated: (message: Message) => void;\n  messageDelta: (message: MessageDelta, snapshot: Message) => void;\n  messageDone: (message: Message) => void;\n\n  runStepCreated: (runStep: RunStep) => void;\n  runStepDelta: (delta: RunStepDelta, snapshot: Runs.RunStep) => void;\n  runStepDone: (runStep: Runs.RunStep, snapshot: Runs.RunStep) => void;\n\n  toolCallCreated: (toolCall: ToolCall) => void;\n  toolCallDelta: (delta: ToolCallDelta, snapshot: ToolCall) => void;\n  toolCallDone: (toolCall: ToolCall) => void;\n\n  textCreated: (content: Text) => void;\n  textDelta: (delta: TextDelta, snapshot: Text) => void;\n  textDone: (content: Text, snapshot: Message) => void;\n\n  //No created or delta as this is not streamed\n  imageFileDone: (content: ImageFile, snapshot: Message) => void;\n\n  event: (event: AssistantStreamEvent) => void;\n}\n\nexport type ThreadCreateAndRunParamsBaseStream = Omit<ThreadCreateAndRunParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport type RunCreateParamsBaseStream = Omit<RunCreateParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport type RunSubmitToolOutputsParamsStream = Omit<RunSubmitToolOutputsParamsBase, 'stream'> & {\n  stream?: true;\n};\n\nexport class AssistantStream\n  extends EventStream<AssistantStreamEvents>\n  implements AsyncIterable<AssistantStreamEvent>\n{\n  //Track all events in a single list for reference\n  #events: AssistantStreamEvent[] = [];\n\n  //Used to accumulate deltas\n  //We are accumulating many types so the value here is not strict\n  #runStepSnapshots: { [id: string]: Runs.RunStep } = {};\n  #messageSnapshots: { [id: string]: Message } = {};\n  #messageSnapshot: Message | undefined;\n  #finalRun: Run | undefined;\n  #currentContentIndex: number | undefined;\n  #currentContent: MessageContent | undefined;\n  #currentToolCallIndex: number | undefined;\n  #currentToolCall: ToolCall | undefined;\n\n  //For current snapshot methods\n  #currentEvent: AssistantStreamEvent | undefined;\n  #currentRunSnapshot: Run | undefined;\n  #currentRunStepSnapshot: Runs.RunStep | undefined;\n\n  [Symbol.asyncIterator](): AsyncIterator<AssistantStreamEvent> {\n    const pushQueue: AssistantStreamEvent[] = [];\n    const readQueue: {\n      resolve: (chunk: AssistantStreamEvent | undefined) => void;\n      reject: (err: unknown) => void;\n    }[] = [];\n    let done = false;\n\n    //Catch all for passing along all events\n    this.on('event', (event) => {\n      const reader = readQueue.shift();\n      if (reader) {\n        reader.resolve(event);\n      } else {\n        pushQueue.push(event);\n      }\n    });\n\n    this.on('end', () => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.resolve(undefined);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('abort', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    this.on('error', (err) => {\n      done = true;\n      for (const reader of readQueue) {\n        reader.reject(err);\n      }\n      readQueue.length = 0;\n    });\n\n    return {\n      next: async (): Promise<IteratorResult<AssistantStreamEvent>> => {\n        if (!pushQueue.length) {\n          if (done) {\n            return { value: undefined, done: true };\n          }\n          return new Promise<AssistantStreamEvent | undefined>((resolve, reject) =>\n            readQueue.push({ resolve, reject }),\n          ).then((chunk) => (chunk ? { value: chunk, done: false } : { value: undefined, done: true }));\n        }\n        const chunk = pushQueue.shift()!;\n        return { value: chunk, done: false };\n      },\n      return: async () => {\n        this.abort();\n        return { value: undefined, done: true };\n      },\n    };\n  }\n\n  static fromReadableStream(stream: ReadableStream): AssistantStream {\n    const runner = new AssistantStream();\n    runner._run(() => runner._fromReadableStream(stream));\n    return runner;\n  }\n\n  protected async _fromReadableStream(\n    readableStream: ReadableStream,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n    this._connected();\n    const stream = Stream.fromReadableStream<AssistantStreamEvent>(readableStream, this.controller);\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n    return this._addRun(this.#endRequest());\n  }\n\n  toReadableStream(): ReadableStream {\n    const stream = new Stream(this[Symbol.asyncIterator].bind(this), this.controller);\n    return stream.toReadableStream();\n  }\n\n  static createToolAssistantStream(\n    threadId: string,\n    runId: string,\n    runs: Runs,\n    params: RunSubmitToolOutputsParamsStream,\n    options: RequestOptions | undefined,\n  ) {\n    const runner = new AssistantStream();\n    runner._run(() =>\n      runner._runToolAssistantStream(threadId, runId, runs, params, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  protected async _createToolAssistantStream(\n    run: Runs,\n    threadId: string,\n    runId: string,\n    params: RunSubmitToolOutputsParamsStream,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n\n    const body: RunSubmitToolOutputsParamsStreaming = { ...params, stream: true };\n    const stream = await run.submitToolOutputs(threadId, runId, body, {\n      ...options,\n      signal: this.controller.signal,\n    });\n\n    this._connected();\n\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    return this._addRun(this.#endRequest());\n  }\n\n  static createThreadAssistantStream(\n    params: ThreadCreateAndRunParamsBaseStream,\n    thread: Threads,\n    options?: RequestOptions,\n  ) {\n    const runner = new AssistantStream();\n    runner._run(() =>\n      runner._threadAssistantStream(params, thread, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  static createAssistantStream(\n    threadId: string,\n    runs: Runs,\n    params: RunCreateParamsBaseStream,\n    options?: RequestOptions,\n  ) {\n    const runner = new AssistantStream();\n    runner._run(() =>\n      runner._runAssistantStream(threadId, runs, params, {\n        ...options,\n        headers: { ...options?.headers, 'X-Stainless-Helper-Method': 'stream' },\n      }),\n    );\n    return runner;\n  }\n\n  currentEvent(): AssistantStreamEvent | undefined {\n    return this.#currentEvent;\n  }\n\n  currentRun(): Run | undefined {\n    return this.#currentRunSnapshot;\n  }\n\n  currentMessageSnapshot(): Message | undefined {\n    return this.#messageSnapshot;\n  }\n\n  currentRunStepSnapshot(): Runs.RunStep | undefined {\n    return this.#currentRunStepSnapshot;\n  }\n\n  async finalRunSteps(): Promise<Runs.RunStep[]> {\n    await this.done();\n\n    return Object.values(this.#runStepSnapshots);\n  }\n\n  async finalMessages(): Promise<Message[]> {\n    await this.done();\n\n    return Object.values(this.#messageSnapshots);\n  }\n\n  async finalRun(): Promise<Run> {\n    await this.done();\n    if (!this.#finalRun) throw Error('Final run was not received.');\n\n    return this.#finalRun;\n  }\n\n  protected async _createThreadAssistantStream(\n    thread: Threads,\n    params: ThreadCreateAndRunParamsBase,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n\n    const body: RunCreateParamsStreaming = { ...params, stream: true };\n    const stream = await thread.createAndRun(body, { ...options, signal: this.controller.signal });\n\n    this._connected();\n\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    return this._addRun(this.#endRequest());\n  }\n\n  protected async _createAssistantStream(\n    run: Runs,\n    threadId: string,\n    params: RunCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    const signal = options?.signal;\n    if (signal) {\n      if (signal.aborted) this.controller.abort();\n      signal.addEventListener('abort', () => this.controller.abort());\n    }\n\n    const body: RunCreateParamsStreaming = { ...params, stream: true };\n    const stream = await run.create(threadId, body, { ...options, signal: this.controller.signal });\n\n    this._connected();\n\n    for await (const event of stream) {\n      this.#addEvent(event);\n    }\n    if (stream.controller.signal?.aborted) {\n      throw new APIUserAbortError();\n    }\n\n    return this._addRun(this.#endRequest());\n  }\n\n  #addEvent(event: AssistantStreamEvent) {\n    if (this.ended) return;\n\n    this.#currentEvent = event;\n\n    this.#handleEvent(event);\n\n    switch (event.event) {\n      case 'thread.created':\n        //No action on this event.\n        break;\n\n      case 'thread.run.created':\n      case 'thread.run.queued':\n      case 'thread.run.in_progress':\n      case 'thread.run.requires_action':\n      case 'thread.run.completed':\n      case 'thread.run.failed':\n      case 'thread.run.cancelling':\n      case 'thread.run.cancelled':\n      case 'thread.run.expired':\n        this.#handleRun(event);\n        break;\n\n      case 'thread.run.step.created':\n      case 'thread.run.step.in_progress':\n      case 'thread.run.step.delta':\n      case 'thread.run.step.completed':\n      case 'thread.run.step.failed':\n      case 'thread.run.step.cancelled':\n      case 'thread.run.step.expired':\n        this.#handleRunStep(event);\n        break;\n\n      case 'thread.message.created':\n      case 'thread.message.in_progress':\n      case 'thread.message.delta':\n      case 'thread.message.completed':\n      case 'thread.message.incomplete':\n        this.#handleMessage(event);\n        break;\n\n      case 'error':\n        //This is included for completeness, but errors are processed in the SSE event processing so this should not occur\n        throw new Error(\n          'Encountered an error event in event processing - errors should be processed earlier',\n        );\n    }\n  }\n\n  #endRequest(): Run {\n    if (this.ended) {\n      throw new OpenAIError(`stream has ended, this shouldn't happen`);\n    }\n\n    if (!this.#finalRun) throw Error('Final run has not been received');\n\n    return this.#finalRun;\n  }\n\n  #handleMessage(this: AssistantStream, event: MessageStreamEvent) {\n    const [accumulatedMessage, newContent] = this.#accumulateMessage(event, this.#messageSnapshot);\n    this.#messageSnapshot = accumulatedMessage;\n    this.#messageSnapshots[accumulatedMessage.id] = accumulatedMessage;\n\n    for (const content of newContent) {\n      const snapshotContent = accumulatedMessage.content[content.index];\n      if (snapshotContent?.type == 'text') {\n        this._emit('textCreated', snapshotContent.text);\n      }\n    }\n\n    switch (event.event) {\n      case 'thread.message.created':\n        this._emit('messageCreated', event.data);\n        break;\n\n      case 'thread.message.in_progress':\n        break;\n\n      case 'thread.message.delta':\n        this._emit('messageDelta', event.data.delta, accumulatedMessage);\n\n        if (event.data.delta.content) {\n          for (const content of event.data.delta.content) {\n            //If it is text delta, emit a text delta event\n            if (content.type == 'text' && content.text) {\n              let textDelta = content.text;\n              let snapshot = accumulatedMessage.content[content.index];\n              if (snapshot && snapshot.type == 'text') {\n                this._emit('textDelta', textDelta, snapshot.text);\n              } else {\n                throw Error('The snapshot associated with this text delta is not text or missing');\n              }\n            }\n\n            if (content.index != this.#currentContentIndex) {\n              //See if we have in progress content\n              if (this.#currentContent) {\n                switch (this.#currentContent.type) {\n                  case 'text':\n                    this._emit('textDone', this.#currentContent.text, this.#messageSnapshot);\n                    break;\n                  case 'image_file':\n                    this._emit('imageFileDone', this.#currentContent.image_file, this.#messageSnapshot);\n                    break;\n                }\n              }\n\n              this.#currentContentIndex = content.index;\n            }\n\n            this.#currentContent = accumulatedMessage.content[content.index];\n          }\n        }\n\n        break;\n\n      case 'thread.message.completed':\n      case 'thread.message.incomplete':\n        //We emit the latest content we were working on on completion (including incomplete)\n        if (this.#currentContentIndex !== undefined) {\n          const currentContent = event.data.content[this.#currentContentIndex];\n          if (currentContent) {\n            switch (currentContent.type) {\n              case 'image_file':\n                this._emit('imageFileDone', currentContent.image_file, this.#messageSnapshot);\n                break;\n              case 'text':\n                this._emit('textDone', currentContent.text, this.#messageSnapshot);\n                break;\n            }\n          }\n        }\n\n        if (this.#messageSnapshot) {\n          this._emit('messageDone', event.data);\n        }\n\n        this.#messageSnapshot = undefined;\n    }\n  }\n\n  #handleRunStep(this: AssistantStream, event: RunStepStreamEvent) {\n    const accumulatedRunStep = this.#accumulateRunStep(event);\n    this.#currentRunStepSnapshot = accumulatedRunStep;\n\n    switch (event.event) {\n      case 'thread.run.step.created':\n        this._emit('runStepCreated', event.data);\n        break;\n      case 'thread.run.step.delta':\n        const delta = event.data.delta;\n        if (\n          delta.step_details &&\n          delta.step_details.type == 'tool_calls' &&\n          delta.step_details.tool_calls &&\n          accumulatedRunStep.step_details.type == 'tool_calls'\n        ) {\n          for (const toolCall of delta.step_details.tool_calls) {\n            if (toolCall.index == this.#currentToolCallIndex) {\n              this._emit(\n                'toolCallDelta',\n                toolCall,\n                accumulatedRunStep.step_details.tool_calls[toolCall.index] as ToolCall,\n              );\n            } else {\n              if (this.#currentToolCall) {\n                this._emit('toolCallDone', this.#currentToolCall);\n              }\n\n              this.#currentToolCallIndex = toolCall.index;\n              this.#currentToolCall = accumulatedRunStep.step_details.tool_calls[toolCall.index];\n              if (this.#currentToolCall) this._emit('toolCallCreated', this.#currentToolCall);\n            }\n          }\n        }\n\n        this._emit('runStepDelta', event.data.delta, accumulatedRunStep);\n        break;\n      case 'thread.run.step.completed':\n      case 'thread.run.step.failed':\n      case 'thread.run.step.cancelled':\n      case 'thread.run.step.expired':\n        this.#currentRunStepSnapshot = undefined;\n        const details = event.data.step_details;\n        if (details.type == 'tool_calls') {\n          if (this.#currentToolCall) {\n            this._emit('toolCallDone', this.#currentToolCall as ToolCall);\n            this.#currentToolCall = undefined;\n          }\n        }\n        this._emit('runStepDone', event.data, accumulatedRunStep);\n        break;\n      case 'thread.run.step.in_progress':\n        break;\n    }\n  }\n\n  #handleEvent(this: AssistantStream, event: AssistantStreamEvent) {\n    this.#events.push(event);\n    this._emit('event', event);\n  }\n\n  #accumulateRunStep(event: RunStepStreamEvent): Runs.RunStep {\n    switch (event.event) {\n      case 'thread.run.step.created':\n        this.#runStepSnapshots[event.data.id] = event.data;\n        return event.data;\n\n      case 'thread.run.step.delta':\n        let snapshot = this.#runStepSnapshots[event.data.id] as Runs.RunStep;\n        if (!snapshot) {\n          throw Error('Received a RunStepDelta before creation of a snapshot');\n        }\n\n        let data = event.data;\n\n        if (data.delta) {\n          const accumulated = AssistantStream.accumulateDelta(snapshot, data.delta) as Runs.RunStep;\n          this.#runStepSnapshots[event.data.id] = accumulated;\n        }\n\n        return this.#runStepSnapshots[event.data.id] as Runs.RunStep;\n\n      case 'thread.run.step.completed':\n      case 'thread.run.step.failed':\n      case 'thread.run.step.cancelled':\n      case 'thread.run.step.expired':\n      case 'thread.run.step.in_progress':\n        this.#runStepSnapshots[event.data.id] = event.data;\n        break;\n    }\n\n    if (this.#runStepSnapshots[event.data.id]) return this.#runStepSnapshots[event.data.id] as Runs.RunStep;\n    throw new Error('No snapshot available');\n  }\n\n  #accumulateMessage(\n    event: AssistantStreamEvent,\n    snapshot: Message | undefined,\n  ): [Message, MessageContentDelta[]] {\n    let newContent: MessageContentDelta[] = [];\n\n    switch (event.event) {\n      case 'thread.message.created':\n        //On creation the snapshot is just the initial message\n        return [event.data, newContent];\n\n      case 'thread.message.delta':\n        if (!snapshot) {\n          throw Error(\n            'Received a delta with no existing snapshot (there should be one from message creation)',\n          );\n        }\n\n        let data = event.data;\n\n        //If this delta does not have content, nothing to process\n        if (data.delta.content) {\n          for (const contentElement of data.delta.content) {\n            if (contentElement.index in snapshot.content) {\n              let currentContent = snapshot.content[contentElement.index];\n              snapshot.content[contentElement.index] = this.#accumulateContent(\n                contentElement,\n                currentContent,\n              );\n            } else {\n              snapshot.content[contentElement.index] = contentElement as MessageContent;\n              // This is a new element\n              newContent.push(contentElement);\n            }\n          }\n        }\n\n        return [snapshot, newContent];\n\n      case 'thread.message.in_progress':\n      case 'thread.message.completed':\n      case 'thread.message.incomplete':\n        //No changes on other thread events\n        if (snapshot) {\n          return [snapshot, newContent];\n        } else {\n          throw Error('Received thread message event with no existing snapshot');\n        }\n    }\n    throw Error('Tried to accumulate a non-message event');\n  }\n\n  #accumulateContent(\n    contentElement: MessageContentDelta,\n    currentContent: MessageContent | undefined,\n  ): TextContentBlock | ImageFileContentBlock {\n    return AssistantStream.accumulateDelta(currentContent as unknown as Record<any, any>, contentElement) as\n      | TextContentBlock\n      | ImageFileContentBlock;\n  }\n\n  static accumulateDelta(acc: Record<string, any>, delta: Record<string, any>): Record<string, any> {\n    for (const [key, deltaValue] of Object.entries(delta)) {\n      if (!acc.hasOwnProperty(key)) {\n        acc[key] = deltaValue;\n        continue;\n      }\n\n      let accValue = acc[key];\n      if (accValue === null || accValue === undefined) {\n        acc[key] = deltaValue;\n        continue;\n      }\n\n      // We don't accumulate these special properties\n      if (key === 'index' || key === 'type') {\n        acc[key] = deltaValue;\n        continue;\n      }\n\n      // Type-specific accumulation logic\n      if (typeof accValue === 'string' && typeof deltaValue === 'string') {\n        accValue += deltaValue;\n      } else if (typeof accValue === 'number' && typeof deltaValue === 'number') {\n        accValue += deltaValue;\n      } else if (Core.isObj(accValue) && Core.isObj(deltaValue)) {\n        accValue = this.accumulateDelta(accValue as Record<string, any>, deltaValue as Record<string, any>);\n      } else if (Array.isArray(accValue) && Array.isArray(deltaValue)) {\n        if (accValue.every((x) => typeof x === 'string' || typeof x === 'number')) {\n          accValue.push(...deltaValue); // Use spread syntax for efficient addition\n          continue;\n        }\n\n        for (const deltaEntry of deltaValue) {\n          if (!Core.isObj(deltaEntry)) {\n            throw new Error(`Expected array delta entry to be an object but got: ${deltaEntry}`);\n          }\n\n          const index = deltaEntry['index'];\n          if (index == null) {\n            console.error(deltaEntry);\n            throw new Error('Expected array delta entry to have an `index` property');\n          }\n\n          if (typeof index !== 'number') {\n            throw new Error(`Expected array delta entry \\`index\\` property to be a number but got ${index}`);\n          }\n\n          const accEntry = accValue[index];\n          if (accEntry == null) {\n            accValue.push(deltaEntry);\n          } else {\n            accValue[index] = this.accumulateDelta(accEntry, deltaEntry);\n          }\n        }\n        continue;\n      } else {\n        throw Error(`Unhandled record type: ${key}, deltaValue: ${deltaValue}, accValue: ${accValue}`);\n      }\n      acc[key] = accValue;\n    }\n\n    return acc;\n  }\n\n  #handleRun(this: AssistantStream, event: RunStreamEvent) {\n    this.#currentRunSnapshot = event.data;\n    switch (event.event) {\n      case 'thread.run.created':\n        break;\n      case 'thread.run.queued':\n        break;\n      case 'thread.run.in_progress':\n        break;\n      case 'thread.run.requires_action':\n      case 'thread.run.cancelled':\n      case 'thread.run.failed':\n      case 'thread.run.completed':\n      case 'thread.run.expired':\n        this.#finalRun = event.data;\n        if (this.#currentToolCall) {\n          this._emit('toolCallDone', this.#currentToolCall);\n          this.#currentToolCall = undefined;\n        }\n        break;\n      case 'thread.run.cancelling':\n        break;\n    }\n  }\n\n  protected _addRun(run: Run): Run {\n    return run;\n  }\n\n  protected async _threadAssistantStream(\n    params: ThreadCreateAndRunParamsBase,\n    thread: Threads,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    return await this._createThreadAssistantStream(thread, params, options);\n  }\n\n  protected async _runAssistantStream(\n    threadId: string,\n    runs: Runs,\n    params: RunCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    return await this._createAssistantStream(runs, threadId, params, options);\n  }\n\n  protected async _runToolAssistantStream(\n    threadId: string,\n    runId: string,\n    runs: Runs,\n    params: RunSubmitToolOutputsParamsStream,\n    options?: Core.RequestOptions,\n  ): Promise<Run> {\n    return await this._createToolAssistantStream(runs, threadId, runId, params, options);\n  }\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;AAyEM,MAAO,wBACH,+IAAA,CAAA,cAAkC;IAD5C,aAAA;;;QAIE,iDAAiD;QACjD,wBAAA,GAAA,CAAA,IAAA,EAAkC,EAAE;QAEpC,2BAA2B;QAC3B,gEAAgE;QAChE,kCAAA,GAAA,CAAA,IAAA,EAAoD,CAAA;QACpD,kCAAA,GAAA,CAAA,IAAA,EAA+C,CAAA;QAC/C,iCAAA,GAAA,CAAA,IAAA,EAAA,KAAA;QACA,0BAAA,GAAA,CAAA,IAAA,EAAA,KAAA;QACA,qCAAA,GAAA,CAAA,IAAA,EAAA,KAAA;QACA,gCAAA,GAAA,CAAA,IAAA,EAAA,KAAA;QACA,sCAAA,GAAA,CAAA,IAAA,EAAA,KAAA;QACA,iCAAA,GAAA,CAAA,IAAA,EAAA,KAAA;QAEA,8BAA8B;QAC9B,8BAAA,GAAA,CAAA,IAAA,EAAA,KAAA;QACA,oCAAA,GAAA,CAAA,IAAA,EAAA,KAAA;QACA,wCAAA,GAAA,CAAA,IAAA,EAAA,KAAA;IAwqBF;IAtqBE,CAAA,CAAA,0BAAA,IAAA,WAAA,oCAAA,IAAA,WAAA,oCAAA,IAAA,WAAA,mCAAA,IAAA,WAAA,4BAAA,IAAA,WAAA,uCAAA,IAAA,WAAA,kCAAA,IAAA,WAAA,wCAAA,IAAA,WAAA,mCAAA,IAAA,WAAA,gCAAA,IAAA,WAAA,sCAAA,IAAA,WAAA,0CAAA,IAAA,WAAA,6BAAA,IAAA,WAAC,OAAO,aAAa,EAAC,GAAA;QACpB,MAAM,YAAoC,EAAE;QAC5C,MAAM,YAGA,EAAE;QACR,IAAI,OAAO;QAEX,wCAAwC;QACxC,IAAI,CAAC,EAAE,CAAC,SAAS,CAAC;YAChB,MAAM,SAAS,UAAU,KAAK;YAC9B,IAAI,QAAQ;gBACV,OAAO,OAAO,CAAC;mBACV;gBACL,UAAU,IAAI,CAAC;;QAEnB;QAEA,IAAI,CAAC,EAAE,CAAC,OAAO;YACb,OAAO;YACP,KAAK,MAAM,UAAU,UAAW;gBAC9B,OAAO,OAAO,CAAC;;YAEjB,UAAU,MAAM,GAAG;QACrB;QAEA,IAAI,CAAC,EAAE,CAAC,SAAS,CAAC;YAChB,OAAO;YACP,KAAK,MAAM,UAAU,UAAW;gBAC9B,OAAO,MAAM,CAAC;;YAEhB,UAAU,MAAM,GAAG;QACrB;QAEA,IAAI,CAAC,EAAE,CAAC,SAAS,CAAC;YAChB,OAAO;YACP,KAAK,MAAM,UAAU,UAAW;gBAC9B,OAAO,MAAM,CAAC;;YAEhB,UAAU,MAAM,GAAG;QACrB;QAEA,OAAO;YACL,MAAM;gBACJ,IAAI,CAAC,UAAU,MAAM,EAAE;oBACrB,IAAI,MAAM;wBACR,OAAO;4BAAE,OAAO;4BAAW,MAAM;wBAAI;;oBAEvC,OAAO,IAAI,QAA0C,CAAC,SAAS,SAC7D,UAAU,IAAI,CAAC;4BAAE;4BAAS;wBAAM,IAChC,IAAI,CAAC,CAAC,QAAW,QAAQ;4BAAE,OAAO;4BAAO,MAAM;wBAAK,IAAK;4BAAE,OAAO;4BAAW,MAAM;wBAAI;;gBAE3F,MAAM,QAAQ,UAAU,KAAK;gBAC7B,OAAO;oBAAE,OAAO;oBAAO,MAAM;gBAAK;YACpC;YACA,QAAQ;gBACN,IAAI,CAAC,KAAK;gBACV,OAAO;oBAAE,OAAO;oBAAW,MAAM;gBAAI;YACvC;;IAEJ;IAEA,OAAO,mBAAmB,MAAsB,EAAA;QAC9C,MAAM,SAAS,IAAI;QACnB,OAAO,IAAI,CAAC,IAAM,OAAO,mBAAmB,CAAC;QAC7C,OAAO;IACT;IAEU,MAAM,oBACd,cAA8B,EAC9B,OAA6B,EAAA;QAE7B,MAAM,SAAS,SAAS;QACxB,IAAI,QAAQ;YACV,IAAI,OAAO,OAAO,EAAE,IAAI,CAAC,UAAU,CAAC,KAAK;YACzC,OAAO,gBAAgB,CAAC,SAAS,IAAM,IAAI,CAAC,UAAU,CAAC,KAAK;;QAE9D,IAAI,CAAC,UAAU;QACf,MAAM,SAAS,sIAAA,CAAA,SAAM,CAAC,kBAAkB,CAAuB,gBAAgB,IAAI,CAAC,UAAU;QAC9F,WAAW,MAAM,SAAS,OAAQ;YAChC,uBAAA,IAAI,EAAA,4BAAA,KAAA,2BAAU,IAAA,CAAd,IAAI,EAAW;;QAEjB,IAAI,OAAO,UAAU,CAAC,MAAM,EAAE,SAAS;YACrC,MAAM,IAAI,kIAAA,CAAA,oBAAiB;;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,uBAAA,IAAI,EAAA,4BAAA,KAAA,6BAAY,IAAA,CAAhB,IAAI;IAC1B;IAEA,mBAAgB;QACd,MAAM,SAAS,IAAI,sIAAA,CAAA,SAAM,CAAC,IAAI,CAAC,OAAO,aAAa,CAAC,CAAC,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,UAAU;QAChF,OAAO,OAAO,gBAAgB;IAChC;IAEA,OAAO,0BACL,QAAgB,EAChB,KAAa,EACb,IAAU,EACV,MAAwC,EACxC,OAAmC,EAAA;QAEnC,MAAM,SAAS,IAAI;QACnB,OAAO,IAAI,CAAC,IACV,OAAO,uBAAuB,CAAC,UAAU,OAAO,MAAM,QAAQ;gBAC5D,GAAG,OAAO;gBACV,SAAS;oBAAE,GAAG,SAAS,OAAO;oBAAE,6BAA6B;gBAAQ;;QAGzE,OAAO;IACT;IAEU,MAAM,2BACd,GAAS,EACT,QAAgB,EAChB,KAAa,EACb,MAAwC,EACxC,OAA6B,EAAA;QAE7B,MAAM,SAAS,SAAS;QACxB,IAAI,QAAQ;YACV,IAAI,OAAO,OAAO,EAAE,IAAI,CAAC,UAAU,CAAC,KAAK;YACzC,OAAO,gBAAgB,CAAC,SAAS,IAAM,IAAI,CAAC,UAAU,CAAC,KAAK;;QAG9D,MAAM,OAA4C;YAAE,GAAG,MAAM;YAAE,QAAQ;QAAI;QAC3E,MAAM,SAAS,MAAM,IAAI,iBAAiB,CAAC,UAAU,OAAO,MAAM;YAChE,GAAG,OAAO;YACV,QAAQ,IAAI,CAAC,UAAU,CAAC,MAAM;;QAGhC,IAAI,CAAC,UAAU;QAEf,WAAW,MAAM,SAAS,OAAQ;YAChC,uBAAA,IAAI,EAAA,4BAAA,KAAA,2BAAU,IAAA,CAAd,IAAI,EAAW;;QAEjB,IAAI,OAAO,UAAU,CAAC,MAAM,EAAE,SAAS;YACrC,MAAM,IAAI,kIAAA,CAAA,oBAAiB;;QAG7B,OAAO,IAAI,CAAC,OAAO,CAAC,uBAAA,IAAI,EAAA,4BAAA,KAAA,6BAAY,IAAA,CAAhB,IAAI;IAC1B;IAEA,OAAO,4BACL,MAA0C,EAC1C,MAAe,EACf,OAAwB,EAAA;QAExB,MAAM,SAAS,IAAI;QACnB,OAAO,IAAI,CAAC,IACV,OAAO,sBAAsB,CAAC,QAAQ,QAAQ;gBAC5C,GAAG,OAAO;gBACV,SAAS;oBAAE,GAAG,SAAS,OAAO;oBAAE,6BAA6B;gBAAQ;;QAGzE,OAAO;IACT;IAEA,OAAO,sBACL,QAAgB,EAChB,IAAU,EACV,MAAiC,EACjC,OAAwB,EAAA;QAExB,MAAM,SAAS,IAAI;QACnB,OAAO,IAAI,CAAC,IACV,OAAO,mBAAmB,CAAC,UAAU,MAAM,QAAQ;gBACjD,GAAG,OAAO;gBACV,SAAS;oBAAE,GAAG,SAAS,OAAO;oBAAE,6BAA6B;gBAAQ;;QAGzE,OAAO;IACT;IAEA,eAAY;QACV,OAAO,uBAAA,IAAI,EAAA,+BAAA;IACb;IAEA,aAAU;QACR,OAAO,uBAAA,IAAI,EAAA,qCAAA;IACb;IAEA,yBAAsB;QACpB,OAAO,uBAAA,IAAI,EAAA,kCAAA;IACb;IAEA,yBAAsB;QACpB,OAAO,uBAAA,IAAI,EAAA,yCAAA;IACb;IAEA,MAAM,gBAAa;QACjB,MAAM,IAAI,CAAC,IAAI;QAEf,OAAO,OAAO,MAAM,CAAC,uBAAA,IAAI,EAAA,mCAAA;IAC3B;IAEA,MAAM,gBAAa;QACjB,MAAM,IAAI,CAAC,IAAI;QAEf,OAAO,OAAO,MAAM,CAAC,uBAAA,IAAI,EAAA,mCAAA;IAC3B;IAEA,MAAM,WAAQ;QACZ,MAAM,IAAI,CAAC,IAAI;QACf,IAAI,CAAC,uBAAA,IAAI,EAAA,2BAAA,MAAY,MAAM,MAAM;QAEjC,OAAO,uBAAA,IAAI,EAAA,2BAAA;IACb;IAEU,MAAM,6BACd,MAAe,EACf,MAAoC,EACpC,OAA6B,EAAA;QAE7B,MAAM,SAAS,SAAS;QACxB,IAAI,QAAQ;YACV,IAAI,OAAO,OAAO,EAAE,IAAI,CAAC,UAAU,CAAC,KAAK;YACzC,OAAO,gBAAgB,CAAC,SAAS,IAAM,IAAI,CAAC,UAAU,CAAC,KAAK;;QAG9D,MAAM,OAAiC;YAAE,GAAG,MAAM;YAAE,QAAQ;QAAI;QAChE,MAAM,SAAS,MAAM,OAAO,YAAY,CAAC,MAAM;YAAE,GAAG,OAAO;YAAE,QAAQ,IAAI,CAAC,UAAU,CAAC,MAAM;QAAA;QAE3F,IAAI,CAAC,UAAU;QAEf,WAAW,MAAM,SAAS,OAAQ;YAChC,uBAAA,IAAI,EAAA,4BAAA,KAAA,2BAAU,IAAA,CAAd,IAAI,EAAW;;QAEjB,IAAI,OAAO,UAAU,CAAC,MAAM,EAAE,SAAS;YACrC,MAAM,IAAI,kIAAA,CAAA,oBAAiB;;QAG7B,OAAO,IAAI,CAAC,OAAO,CAAC,uBAAA,IAAI,EAAA,4BAAA,KAAA,6BAAY,IAAA,CAAhB,IAAI;IAC1B;IAEU,MAAM,uBACd,GAAS,EACT,QAAgB,EAChB,MAA2B,EAC3B,OAA6B,EAAA;QAE7B,MAAM,SAAS,SAAS;QACxB,IAAI,QAAQ;YACV,IAAI,OAAO,OAAO,EAAE,IAAI,CAAC,UAAU,CAAC,KAAK;YACzC,OAAO,gBAAgB,CAAC,SAAS,IAAM,IAAI,CAAC,UAAU,CAAC,KAAK;;QAG9D,MAAM,OAAiC;YAAE,GAAG,MAAM;YAAE,QAAQ;QAAI;QAChE,MAAM,SAAS,MAAM,IAAI,MAAM,CAAC,UAAU,MAAM;YAAE,GAAG,OAAO;YAAE,QAAQ,IAAI,CAAC,UAAU,CAAC,MAAM;QAAA;QAE5F,IAAI,CAAC,UAAU;QAEf,WAAW,MAAM,SAAS,OAAQ;YAChC,uBAAA,IAAI,EAAA,4BAAA,KAAA,2BAAU,IAAA,CAAd,IAAI,EAAW;;QAEjB,IAAI,OAAO,UAAU,CAAC,MAAM,EAAE,SAAS;YACrC,MAAM,IAAI,kIAAA,CAAA,oBAAiB;;QAG7B,OAAO,IAAI,CAAC,OAAO,CAAC,uBAAA,IAAI,EAAA,4BAAA,KAAA,6BAAY,IAAA,CAAhB,IAAI;IAC1B;IA6SA,OAAO,gBAAgB,GAAwB,EAAE,KAA0B,EAAA;QACzE,KAAK,MAAM,CAAC,KAAK,WAAW,IAAI,OAAO,OAAO,CAAC,OAAQ;YACrD,IAAI,CAAC,IAAI,cAAc,CAAC,MAAM;gBAC5B,GAAG,CAAC,IAAI,GAAG;gBACX;;YAGF,IAAI,WAAW,GAAG,CAAC,IAAI;YACvB,IAAI,aAAa,QAAQ,aAAa,WAAW;gBAC/C,GAAG,CAAC,IAAI,GAAG;gBACX;;YAGF,+CAA+C;YAC/C,IAAI,QAAQ,WAAW,QAAQ,QAAQ;gBACrC,GAAG,CAAC,IAAI,GAAG;gBACX;;YAGF,mCAAmC;YACnC,IAAI,OAAO,aAAa,YAAY,OAAO,eAAe,UAAU;gBAClE,YAAY;mBACP,IAAI,OAAO,aAAa,YAAY,OAAO,eAAe,UAAU;gBACzE,YAAY;mBACP,IAAI,kJAAK,KAAK,CAAC,aAAa,kJAAK,KAAK,CAAC,aAAa;gBACzD,WAAW,IAAI,CAAC,eAAe,CAAC,UAAiC;mBAC5D,IAAI,MAAM,OAAO,CAAC,aAAa,MAAM,OAAO,CAAC,aAAa;gBAC/D,IAAI,SAAS,KAAK,CAAC,CAAC,IAAM,OAAO,MAAM,YAAY,OAAO,MAAM,WAAW;oBACzE,SAAS,IAAI,IAAI,aAAa,2CAA2C;oBACzE;;gBAGF,KAAK,MAAM,cAAc,WAAY;oBACnC,IAAI,CAAC,kJAAK,KAAK,CAAC,aAAa;wBAC3B,MAAM,IAAI,MAAM,CAAA,oDAAA,EAAuD,WAAU,CAAE;;oBAGrF,MAAM,QAAQ,UAAU,CAAC,QAAQ;oBACjC,IAAI,SAAS,MAAM;wBACjB,QAAQ,KAAK,CAAC;wBACd,MAAM,IAAI,MAAM;;oBAGlB,IAAI,OAAO,UAAU,UAAU;wBAC7B,MAAM,IAAI,MAAM,CAAA,qEAAA,EAAwE,MAAK,CAAE;;oBAGjG,MAAM,WAAW,QAAQ,CAAC,MAAM;oBAChC,IAAI,YAAY,MAAM;wBACpB,SAAS,IAAI,CAAC;2BACT;wBACL,QAAQ,CAAC,MAAM,GAAG,IAAI,CAAC,eAAe,CAAC,UAAU;;;gBAGrD;mBACK;gBACL,MAAM,MAAM,CAAA,uBAAA,EAA0B,IAAG,cAAA,EAAiB,WAAU,YAAA,EAAe,SAAQ,CAAE;;YAE/F,GAAG,CAAC,IAAI,GAAG;;QAGb,OAAO;IACT;IA2BU,QAAQ,GAAQ,EAAA;QACxB,OAAO;IACT;IAEU,MAAM,uBACd,MAAoC,EACpC,MAAe,EACf,OAA6B,EAAA;QAE7B,OAAO,MAAM,IAAI,CAAC,4BAA4B,CAAC,QAAQ,QAAQ;IACjE;IAEU,MAAM,oBACd,QAAgB,EAChB,IAAU,EACV,MAA2B,EAC3B,OAA6B,EAAA;QAE7B,OAAO,MAAM,IAAI,CAAC,sBAAsB,CAAC,MAAM,UAAU,QAAQ;IACnE;IAEU,MAAM,wBACd,QAAgB,EAChB,KAAa,EACb,IAAU,EACV,MAAwC,EACxC,OAA6B,EAAA;QAE7B,OAAO,MAAM,IAAI,CAAC,0BAA0B,CAAC,MAAM,UAAU,OAAO,QAAQ;IAC9E;;+DAjaU,KAA2B;IACnC,IAAI,IAAI,CAAC,KAAK,EAAE;IAEhB,uBAAA,IAAI,EAAA,+BAAiB,OAAK;IAE1B,uBAAA,IAAI,EAAA,4BAAA,KAAA,8BAAa,IAAA,CAAjB,IAAI,EAAc;IAElB,OAAQ,MAAM,KAAK;QACjB,KAAK;YAEH;QAEF,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;YACH,uBAAA,IAAI,EAAA,4BAAA,KAAA,4BAAW,IAAA,CAAf,IAAI,EAAY;YAChB;QAEF,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;YACH,uBAAA,IAAI,EAAA,4BAAA,KAAA,gCAAe,IAAA,CAAnB,IAAI,EAAgB;YACpB;QAEF,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;YACH,uBAAA,IAAI,EAAA,4BAAA,KAAA,gCAAe,IAAA,CAAnB,IAAI,EAAgB;YACpB;QAEF,KAAK;YACH,kHAAkH;YAClH,MAAM,IAAI,MACR;;AAGR,GAAC,8BAAA,SAAA;IAGC,IAAI,IAAI,CAAC,KAAK,EAAE;QACd,MAAM,IAAI,kIAAA,CAAA,cAAW,CAAC,CAAA,uCAAA,CAAyC;;IAGjE,IAAI,CAAC,uBAAA,IAAI,EAAA,2BAAA,MAAY,MAAM,MAAM;IAEjC,OAAO,uBAAA,IAAI,EAAA,2BAAA;AACb,GAAC,iCAAA,SAAA,+BAEqC,KAAyB;IAC7D,MAAM,CAAC,oBAAoB,WAAW,GAAG,uBAAA,IAAI,EAAA,4BAAA,KAAA,oCAAmB,IAAA,CAAvB,IAAI,EAAoB,OAAO,uBAAA,IAAI,EAAA,kCAAA;IAC5E,uBAAA,IAAI,EAAA,kCAAoB,oBAAkB;IAC1C,uBAAA,IAAI,EAAA,mCAAA,IAAkB,CAAC,mBAAmB,EAAE,CAAC,GAAG;IAEhD,KAAK,MAAM,WAAW,WAAY;QAChC,MAAM,kBAAkB,mBAAmB,OAAO,CAAC,QAAQ,KAAK,CAAC;QACjE,IAAI,iBAAiB,QAAQ,QAAQ;YACnC,IAAI,CAAC,KAAK,CAAC,eAAe,gBAAgB,IAAI;;;IAIlD,OAAQ,MAAM,KAAK;QACjB,KAAK;YACH,IAAI,CAAC,KAAK,CAAC,kBAAkB,MAAM,IAAI;YACvC;QAEF,KAAK;YACH;QAEF,KAAK;YACH,IAAI,CAAC,KAAK,CAAC,gBAAgB,MAAM,IAAI,CAAC,KAAK,EAAE;YAE7C,IAAI,MAAM,IAAI,CAAC,KAAK,CAAC,OAAO,EAAE;gBAC5B,KAAK,MAAM,WAAW,MAAM,IAAI,CAAC,KAAK,CAAC,OAAO,CAAE;oBAC9C,8CAA8C;oBAC9C,IAAI,QAAQ,IAAI,IAAI,UAAU,QAAQ,IAAI,EAAE;wBAC1C,IAAI,YAAY,QAAQ,IAAI;wBAC5B,IAAI,WAAW,mBAAmB,OAAO,CAAC,QAAQ,KAAK,CAAC;wBACxD,IAAI,YAAY,SAAS,IAAI,IAAI,QAAQ;4BACvC,IAAI,CAAC,KAAK,CAAC,aAAa,WAAW,SAAS,IAAI;+BAC3C;4BACL,MAAM,MAAM;;;oBAIhB,IAAI,QAAQ,KAAK,IAAI,uBAAA,IAAI,EAAA,sCAAA,MAAuB;wBAC9C,oCAAoC;wBACpC,IAAI,uBAAA,IAAI,EAAA,iCAAA,MAAkB;4BACxB,OAAQ,uBAAA,IAAI,EAAA,iCAAA,KAAiB,IAAI;gCAC/B,KAAK;oCACH,IAAI,CAAC,KAAK,CAAC,YAAY,uBAAA,IAAI,EAAA,iCAAA,KAAiB,IAAI,EAAE,uBAAA,IAAI,EAAA,kCAAA;oCACtD;gCACF,KAAK;oCACH,IAAI,CAAC,KAAK,CAAC,iBAAiB,uBAAA,IAAI,EAAA,iCAAA,KAAiB,UAAU,EAAE,uBAAA,IAAI,EAAA,kCAAA;oCACjE;;;wBAIN,uBAAA,IAAI,EAAA,sCAAwB,QAAQ,KAAK,EAAA;;oBAG3C,uBAAA,IAAI,EAAA,iCAAmB,mBAAmB,OAAO,CAAC,QAAQ,KAAK,CAAC,EAAA;;;YAIpE;QAEF,KAAK;QACL,KAAK;YACH,oFAAoF;YACpF,IAAI,uBAAA,IAAI,EAAA,sCAAA,SAA0B,WAAW;gBAC3C,MAAM,iBAAiB,MAAM,IAAI,CAAC,OAAO,CAAC,uBAAA,IAAI,EAAA,sCAAA,KAAsB;gBACpE,IAAI,gBAAgB;oBAClB,OAAQ,eAAe,IAAI;wBACzB,KAAK;4BACH,IAAI,CAAC,KAAK,CAAC,iBAAiB,eAAe,UAAU,EAAE,uBAAA,IAAI,EAAA,kCAAA;4BAC3D;wBACF,KAAK;4BACH,IAAI,CAAC,KAAK,CAAC,YAAY,eAAe,IAAI,EAAE,uBAAA,IAAI,EAAA,kCAAA;4BAChD;;;;YAKR,IAAI,uBAAA,IAAI,EAAA,kCAAA,MAAmB;gBACzB,IAAI,CAAC,KAAK,CAAC,eAAe,MAAM,IAAI;;YAGtC,uBAAA,IAAI,EAAA,kCAAoB,WAAS;;AAEvC,GAAC,iCAAA,SAAA,+BAEqC,KAAyB;IAC7D,MAAM,qBAAqB,uBAAA,IAAI,EAAA,4BAAA,KAAA,oCAAmB,IAAA,CAAvB,IAAI,EAAoB;IACnD,uBAAA,IAAI,EAAA,yCAA2B,oBAAkB;IAEjD,OAAQ,MAAM,KAAK;QACjB,KAAK;YACH,IAAI,CAAC,KAAK,CAAC,kBAAkB,MAAM,IAAI;YACvC;QACF,KAAK;YACH,MAAM,QAAQ,MAAM,IAAI,CAAC,KAAK;YAC9B,IACE,MAAM,YAAY,IAClB,MAAM,YAAY,CAAC,IAAI,IAAI,gBAC3B,MAAM,YAAY,CAAC,UAAU,IAC7B,mBAAmB,YAAY,CAAC,IAAI,IAAI,cACxC;gBACA,KAAK,MAAM,YAAY,MAAM,YAAY,CAAC,UAAU,CAAE;oBACpD,IAAI,SAAS,KAAK,IAAI,uBAAA,IAAI,EAAA,uCAAA,MAAwB;wBAChD,IAAI,CAAC,KAAK,CACR,iBACA,UACA,mBAAmB,YAAY,CAAC,UAAU,CAAC,SAAS,KAAK,CAAa;2BAEnE;wBACL,IAAI,uBAAA,IAAI,EAAA,kCAAA,MAAmB;4BACzB,IAAI,CAAC,KAAK,CAAC,gBAAgB,uBAAA,IAAI,EAAA,kCAAA;;wBAGjC,uBAAA,IAAI,EAAA,uCAAyB,SAAS,KAAK,EAAA;wBAC3C,uBAAA,IAAI,EAAA,kCAAoB,mBAAmB,YAAY,CAAC,UAAU,CAAC,SAAS,KAAK,CAAC,EAAA;wBAClF,IAAI,uBAAA,IAAI,EAAA,kCAAA,MAAmB,IAAI,CAAC,KAAK,CAAC,mBAAmB,uBAAA,IAAI,EAAA,kCAAA;;;;YAKnE,IAAI,CAAC,KAAK,CAAC,gBAAgB,MAAM,IAAI,CAAC,KAAK,EAAE;YAC7C;QACF,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;YACH,uBAAA,IAAI,EAAA,yCAA2B,WAAS;YACxC,MAAM,UAAU,MAAM,IAAI,CAAC,YAAY;YACvC,IAAI,QAAQ,IAAI,IAAI,cAAc;gBAChC,IAAI,uBAAA,IAAI,EAAA,kCAAA,MAAmB;oBACzB,IAAI,CAAC,KAAK,CAAC,gBAAgB,uBAAA,IAAI,EAAA,kCAAA;oBAC/B,uBAAA,IAAI,EAAA,kCAAoB,WAAS;;;YAGrC,IAAI,CAAC,KAAK,CAAC,eAAe,MAAM,IAAI,EAAE;YACtC;QACF,KAAK;YACH;;AAEN,GAAC,+BAAA,SAAA,6BAEmC,KAA2B;IAC7D,uBAAA,IAAI,EAAA,yBAAA,KAAS,IAAI,CAAC;IAClB,IAAI,CAAC,KAAK,CAAC,SAAS;AACtB,GAAC,qCAAA,SAAA,mCAEkB,KAAyB;IAC1C,OAAQ,MAAM,KAAK;QACjB,KAAK;YACH,uBAAA,IAAI,EAAA,mCAAA,IAAkB,CAAC,MAAM,IAAI,CAAC,EAAE,CAAC,GAAG,MAAM,IAAI;YAClD,OAAO,MAAM,IAAI;QAEnB,KAAK;YACH,IAAI,WAAW,uBAAA,IAAI,EAAA,mCAAA,IAAkB,CAAC,MAAM,IAAI,CAAC,EAAE,CAAiB;YACpE,IAAI,CAAC,UAAU;gBACb,MAAM,MAAM;;YAGd,IAAI,OAAO,MAAM,IAAI;YAErB,IAAI,KAAK,KAAK,EAAE;gBACd,MAAM,cAAc,gBAAgB,eAAe,CAAC,UAAU,KAAK,KAAK;gBACxE,uBAAA,IAAI,EAAA,mCAAA,IAAkB,CAAC,MAAM,IAAI,CAAC,EAAE,CAAC,GAAG;;YAG1C,OAAO,uBAAA,IAAI,EAAA,mCAAA,IAAkB,CAAC,MAAM,IAAI,CAAC,EAAE,CAAiB;QAE9D,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;YACH,uBAAA,IAAI,EAAA,mCAAA,IAAkB,CAAC,MAAM,IAAI,CAAC,EAAE,CAAC,GAAG,MAAM,IAAI;YAClD;;IAGJ,IAAI,uBAAA,IAAI,EAAA,mCAAA,IAAkB,CAAC,MAAM,IAAI,CAAC,EAAE,CAAC,EAAE,OAAO,uBAAA,IAAI,EAAA,mCAAA,IAAkB,CAAC,MAAM,IAAI,CAAC,EAAE,CAAiB;IACvG,MAAM,IAAI,MAAM;AAClB,GAAC,qCAAA,SAAA,mCAGC,KAA2B,EAC3B,QAA6B;IAE7B,IAAI,aAAoC,EAAE;IAE1C,OAAQ,MAAM,KAAK;QACjB,KAAK;YACH,sDAAsD;YACtD,OAAO;gBAAC,MAAM,IAAI;gBAAE;aAAW;QAEjC,KAAK;YACH,IAAI,CAAC,UAAU;gBACb,MAAM,MACJ;;YAIJ,IAAI,OAAO,MAAM,IAAI;YAErB,yDAAyD;YACzD,IAAI,KAAK,KAAK,CAAC,OAAO,EAAE;gBACtB,KAAK,MAAM,kBAAkB,KAAK,KAAK,CAAC,OAAO,CAAE;oBAC/C,IAAI,eAAe,KAAK,IAAI,SAAS,OAAO,EAAE;wBAC5C,IAAI,iBAAiB,SAAS,OAAO,CAAC,eAAe,KAAK,CAAC;wBAC3D,SAAS,OAAO,CAAC,eAAe,KAAK,CAAC,GAAG,uBAAA,IAAI,EAAA,4BAAA,KAAA,oCAAmB,IAAA,CAAvB,IAAI,EAC3C,gBACA;2BAEG;wBACL,SAAS,OAAO,CAAC,eAAe,KAAK,CAAC,GAAG;wBACzC,wBAAwB;wBACxB,WAAW,IAAI,CAAC;;;;YAKtB,OAAO;gBAAC;gBAAU;aAAW;QAE/B,KAAK;QACL,KAAK;QACL,KAAK;YACH,mCAAmC;YACnC,IAAI,UAAU;gBACZ,OAAO;oBAAC;oBAAU;iBAAW;mBACxB;gBACL,MAAM,MAAM;;;IAGlB,MAAM,MAAM;AACd,GAAC,qCAAA,SAAA,mCAGC,cAAmC,EACnC,cAA0C;IAE1C,OAAO,gBAAgB,eAAe,CAAC,gBAA+C;AAGxF,GAAC,6BAAA,SAAA,2BAkEiC,KAAqB;IACrD,uBAAA,IAAI,EAAA,qCAAuB,MAAM,IAAI,EAAA;IACrC,OAAQ,MAAM,KAAK;QACjB,KAAK;YACH;QACF,KAAK;YACH;QACF,KAAK;YACH;QACF,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;QACL,KAAK;YACH,uBAAA,IAAI,EAAA,2BAAa,MAAM,IAAI,EAAA;YAC3B,IAAI,uBAAA,IAAI,EAAA,kCAAA,MAAmB;gBACzB,IAAI,CAAC,KAAK,CAAC,gBAAgB,uBAAA,IAAI,EAAA,kCAAA;gBAC/B,uBAAA,IAAI,EAAA,kCAAoB,WAAS;;YAEnC;QACF,KAAK;YACH;;AAEN"}},
    {"offset": {"line": 5279, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 5284, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/beta/threads/messages.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport * as Core from '../../../core';\nimport * as MessagesAPI from './messages';\nimport * as AssistantsAPI from '../assistants';\nimport { CursorPage, type CursorPageParams } from '../../../pagination';\n\nexport class Messages extends APIResource {\n  /**\n   * Create a message.\n   */\n  create(\n    threadId: string,\n    body: MessageCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Message> {\n    return this._client.post(`/threads/${threadId}/messages`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieve a message.\n   */\n  retrieve(threadId: string, messageId: string, options?: Core.RequestOptions): Core.APIPromise<Message> {\n    return this._client.get(`/threads/${threadId}/messages/${messageId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Modifies a message.\n   */\n  update(\n    threadId: string,\n    messageId: string,\n    body: MessageUpdateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Message> {\n    return this._client.post(`/threads/${threadId}/messages/${messageId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of messages for a given thread.\n   */\n  list(\n    threadId: string,\n    query?: MessageListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<MessagesPage, Message>;\n  list(threadId: string, options?: Core.RequestOptions): Core.PagePromise<MessagesPage, Message>;\n  list(\n    threadId: string,\n    query: MessageListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<MessagesPage, Message> {\n    if (isRequestOptions(query)) {\n      return this.list(threadId, {}, query);\n    }\n    return this._client.getAPIList(`/threads/${threadId}/messages`, MessagesPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Deletes a message.\n   */\n  del(threadId: string, messageId: string, options?: Core.RequestOptions): Core.APIPromise<MessageDeleted> {\n    return this._client.delete(`/threads/${threadId}/messages/${messageId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n}\n\nexport class MessagesPage extends CursorPage<Message> {}\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport type Annotation = FileCitationAnnotation | FilePathAnnotation;\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport type AnnotationDelta = FileCitationDeltaAnnotation | FilePathDeltaAnnotation;\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport interface FileCitationAnnotation {\n  end_index: number;\n\n  file_citation: FileCitationAnnotation.FileCitation;\n\n  start_index: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text: string;\n\n  /**\n   * Always `file_citation`.\n   */\n  type: 'file_citation';\n}\n\nexport namespace FileCitationAnnotation {\n  export interface FileCitation {\n    /**\n     * The ID of the specific File the citation is from.\n     */\n    file_id: string;\n  }\n}\n\n/**\n * A citation within the message that points to a specific quote from a specific\n * File associated with the assistant or the message. Generated when the assistant\n * uses the \"file_search\" tool to search files.\n */\nexport interface FileCitationDeltaAnnotation {\n  /**\n   * The index of the annotation in the text content part.\n   */\n  index: number;\n\n  /**\n   * Always `file_citation`.\n   */\n  type: 'file_citation';\n\n  end_index?: number;\n\n  file_citation?: FileCitationDeltaAnnotation.FileCitation;\n\n  start_index?: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text?: string;\n}\n\nexport namespace FileCitationDeltaAnnotation {\n  export interface FileCitation {\n    /**\n     * The ID of the specific File the citation is from.\n     */\n    file_id?: string;\n\n    /**\n     * The specific quote in the file.\n     */\n    quote?: string;\n  }\n}\n\n/**\n * A URL for the file that's generated when the assistant used the\n * `code_interpreter` tool to generate a file.\n */\nexport interface FilePathAnnotation {\n  end_index: number;\n\n  file_path: FilePathAnnotation.FilePath;\n\n  start_index: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text: string;\n\n  /**\n   * Always `file_path`.\n   */\n  type: 'file_path';\n}\n\nexport namespace FilePathAnnotation {\n  export interface FilePath {\n    /**\n     * The ID of the file that was generated.\n     */\n    file_id: string;\n  }\n}\n\n/**\n * A URL for the file that's generated when the assistant used the\n * `code_interpreter` tool to generate a file.\n */\nexport interface FilePathDeltaAnnotation {\n  /**\n   * The index of the annotation in the text content part.\n   */\n  index: number;\n\n  /**\n   * Always `file_path`.\n   */\n  type: 'file_path';\n\n  end_index?: number;\n\n  file_path?: FilePathDeltaAnnotation.FilePath;\n\n  start_index?: number;\n\n  /**\n   * The text in the message content that needs to be replaced.\n   */\n  text?: string;\n}\n\nexport namespace FilePathDeltaAnnotation {\n  export interface FilePath {\n    /**\n     * The ID of the file that was generated.\n     */\n    file_id?: string;\n  }\n}\n\nexport interface ImageFile {\n  /**\n   * The [File](https://platform.openai.com/docs/api-reference/files) ID of the image\n   * in the message content. Set `purpose=\"vision\"` when uploading the File if you\n   * need to later display the file content.\n   */\n  file_id: string;\n\n  /**\n   * Specifies the detail level of the image if specified by the user. `low` uses\n   * fewer tokens, you can opt in to high resolution using `high`.\n   */\n  detail?: 'auto' | 'low' | 'high';\n}\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport interface ImageFileContentBlock {\n  image_file: ImageFile;\n\n  /**\n   * Always `image_file`.\n   */\n  type: 'image_file';\n}\n\nexport interface ImageFileDelta {\n  /**\n   * Specifies the detail level of the image if specified by the user. `low` uses\n   * fewer tokens, you can opt in to high resolution using `high`.\n   */\n  detail?: 'auto' | 'low' | 'high';\n\n  /**\n   * The [File](https://platform.openai.com/docs/api-reference/files) ID of the image\n   * in the message content. Set `purpose=\"vision\"` when uploading the File if you\n   * need to later display the file content.\n   */\n  file_id?: string;\n}\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport interface ImageFileDeltaBlock {\n  /**\n   * The index of the content part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `image_file`.\n   */\n  type: 'image_file';\n\n  image_file?: ImageFileDelta;\n}\n\nexport interface ImageURL {\n  /**\n   * The external URL of the image, must be a supported image types: jpeg, jpg, png,\n   * gif, webp.\n   */\n  url: string;\n\n  /**\n   * Specifies the detail level of the image. `low` uses fewer tokens, you can opt in\n   * to high resolution using `high`. Default value is `auto`\n   */\n  detail?: 'auto' | 'low' | 'high';\n}\n\n/**\n * References an image URL in the content of a message.\n */\nexport interface ImageURLContentBlock {\n  image_url: ImageURL;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'image_url';\n}\n\nexport interface ImageURLDelta {\n  /**\n   * Specifies the detail level of the image. `low` uses fewer tokens, you can opt in\n   * to high resolution using `high`.\n   */\n  detail?: 'auto' | 'low' | 'high';\n\n  /**\n   * The URL of the image, must be a supported image types: jpeg, jpg, png, gif,\n   * webp.\n   */\n  url?: string;\n}\n\n/**\n * References an image URL in the content of a message.\n */\nexport interface ImageURLDeltaBlock {\n  /**\n   * The index of the content part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `image_url`.\n   */\n  type: 'image_url';\n\n  image_url?: ImageURLDelta;\n}\n\n/**\n * Represents a message within a\n * [thread](https://platform.openai.com/docs/api-reference/threads).\n */\nexport interface Message {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * If applicable, the ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) that\n   * authored this message.\n   */\n  assistant_id: string | null;\n\n  /**\n   * A list of files attached to the message, and the tools they were added to.\n   */\n  attachments: Array<Message.Attachment> | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the message was completed.\n   */\n  completed_at: number | null;\n\n  /**\n   * The content of the message in array of text and/or images.\n   */\n  content: Array<MessageContent>;\n\n  /**\n   * The Unix timestamp (in seconds) for when the message was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the message was marked as incomplete.\n   */\n  incomplete_at: number | null;\n\n  /**\n   * On an incomplete message, details about why the message is incomplete.\n   */\n  incomplete_details: Message.IncompleteDetails | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata: unknown | null;\n\n  /**\n   * The object type, which is always `thread.message`.\n   */\n  object: 'thread.message';\n\n  /**\n   * The entity that produced the message. One of `user` or `assistant`.\n   */\n  role: 'user' | 'assistant';\n\n  /**\n   * The ID of the [run](https://platform.openai.com/docs/api-reference/runs)\n   * associated with the creation of this message. Value is `null` when messages are\n   * created manually using the create message or create thread endpoints.\n   */\n  run_id: string | null;\n\n  /**\n   * The status of the message, which can be either `in_progress`, `incomplete`, or\n   * `completed`.\n   */\n  status: 'in_progress' | 'incomplete' | 'completed';\n\n  /**\n   * The [thread](https://platform.openai.com/docs/api-reference/threads) ID that\n   * this message belongs to.\n   */\n  thread_id: string;\n}\n\nexport namespace Message {\n  export interface Attachment {\n    /**\n     * The ID of the file to attach to the message.\n     */\n    file_id?: string;\n\n    /**\n     * The tools to add this file to.\n     */\n    tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.AssistantToolsFileSearchTypeOnly>;\n  }\n\n  export namespace Attachment {\n    export interface AssistantToolsFileSearchTypeOnly {\n      /**\n       * The type of tool being defined: `file_search`\n       */\n      type: 'file_search';\n    }\n  }\n\n  /**\n   * On an incomplete message, details about why the message is incomplete.\n   */\n  export interface IncompleteDetails {\n    /**\n     * The reason the message is incomplete.\n     */\n    reason: 'content_filter' | 'max_tokens' | 'run_cancelled' | 'run_expired' | 'run_failed';\n  }\n}\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport type MessageContent =\n  | ImageFileContentBlock\n  | ImageURLContentBlock\n  | TextContentBlock\n  | RefusalContentBlock;\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport type MessageContentDelta =\n  | ImageFileDeltaBlock\n  | TextDeltaBlock\n  | RefusalDeltaBlock\n  | ImageURLDeltaBlock;\n\n/**\n * References an image [File](https://platform.openai.com/docs/api-reference/files)\n * in the content of a message.\n */\nexport type MessageContentPartParam = ImageFileContentBlock | ImageURLContentBlock | TextContentBlockParam;\n\nexport interface MessageDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'thread.message.deleted';\n}\n\n/**\n * The delta containing the fields that have changed on the Message.\n */\nexport interface MessageDelta {\n  /**\n   * The content of the message in array of text and/or images.\n   */\n  content?: Array<MessageContentDelta>;\n\n  /**\n   * The entity that produced the message. One of `user` or `assistant`.\n   */\n  role?: 'user' | 'assistant';\n}\n\n/**\n * Represents a message delta i.e. any changed fields on a message during\n * streaming.\n */\nexport interface MessageDeltaEvent {\n  /**\n   * The identifier of the message, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The delta containing the fields that have changed on the Message.\n   */\n  delta: MessageDelta;\n\n  /**\n   * The object type, which is always `thread.message.delta`.\n   */\n  object: 'thread.message.delta';\n}\n\n/**\n * The refusal content generated by the assistant.\n */\nexport interface RefusalContentBlock {\n  refusal: string;\n\n  /**\n   * Always `refusal`.\n   */\n  type: 'refusal';\n}\n\n/**\n * The refusal content that is part of a message.\n */\nexport interface RefusalDeltaBlock {\n  /**\n   * The index of the refusal part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `refusal`.\n   */\n  type: 'refusal';\n\n  refusal?: string;\n}\n\nexport interface Text {\n  annotations: Array<Annotation>;\n\n  /**\n   * The data that makes up the text.\n   */\n  value: string;\n}\n\n/**\n * The text content that is part of a message.\n */\nexport interface TextContentBlock {\n  text: Text;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n}\n\n/**\n * The text content that is part of a message.\n */\nexport interface TextContentBlockParam {\n  /**\n   * Text content to be sent to the model\n   */\n  text: string;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n}\n\nexport interface TextDelta {\n  annotations?: Array<AnnotationDelta>;\n\n  /**\n   * The data that makes up the text.\n   */\n  value?: string;\n}\n\n/**\n * The text content that is part of a message.\n */\nexport interface TextDeltaBlock {\n  /**\n   * The index of the content part in the message.\n   */\n  index: number;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n\n  text?: TextDelta;\n}\n\nexport interface MessageCreateParams {\n  /**\n   * The text contents of the message.\n   */\n  content: string | Array<MessageContentPartParam>;\n\n  /**\n   * The role of the entity that is creating the message. Allowed values include:\n   *\n   * - `user`: Indicates the message is sent by an actual user and should be used in\n   *   most cases to represent user-generated messages.\n   * - `assistant`: Indicates the message is generated by the assistant. Use this\n   *   value to insert messages from the assistant into the conversation.\n   */\n  role: 'user' | 'assistant';\n\n  /**\n   * A list of files attached to the message, and the tools they should be added to.\n   */\n  attachments?: Array<MessageCreateParams.Attachment> | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n}\n\nexport namespace MessageCreateParams {\n  export interface Attachment {\n    /**\n     * The ID of the file to attach to the message.\n     */\n    file_id?: string;\n\n    /**\n     * The tools to add this file to.\n     */\n    tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n  }\n\n  export namespace Attachment {\n    export interface FileSearch {\n      /**\n       * The type of tool being defined: `file_search`\n       */\n      type: 'file_search';\n    }\n  }\n}\n\nexport interface MessageUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n}\n\nexport interface MessageListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\n   * fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n\n  /**\n   * Filter messages by the run ID that generated them.\n   */\n  run_id?: string;\n}\n\nexport namespace Messages {\n  export import Annotation = MessagesAPI.Annotation;\n  export import AnnotationDelta = MessagesAPI.AnnotationDelta;\n  export import FileCitationAnnotation = MessagesAPI.FileCitationAnnotation;\n  export import FileCitationDeltaAnnotation = MessagesAPI.FileCitationDeltaAnnotation;\n  export import FilePathAnnotation = MessagesAPI.FilePathAnnotation;\n  export import FilePathDeltaAnnotation = MessagesAPI.FilePathDeltaAnnotation;\n  export import ImageFile = MessagesAPI.ImageFile;\n  export import ImageFileContentBlock = MessagesAPI.ImageFileContentBlock;\n  export import ImageFileDelta = MessagesAPI.ImageFileDelta;\n  export import ImageFileDeltaBlock = MessagesAPI.ImageFileDeltaBlock;\n  export import ImageURL = MessagesAPI.ImageURL;\n  export import ImageURLContentBlock = MessagesAPI.ImageURLContentBlock;\n  export import ImageURLDelta = MessagesAPI.ImageURLDelta;\n  export import ImageURLDeltaBlock = MessagesAPI.ImageURLDeltaBlock;\n  export import Message = MessagesAPI.Message;\n  export import MessageContent = MessagesAPI.MessageContent;\n  export import MessageContentDelta = MessagesAPI.MessageContentDelta;\n  export import MessageContentPartParam = MessagesAPI.MessageContentPartParam;\n  export import MessageDeleted = MessagesAPI.MessageDeleted;\n  export import MessageDelta = MessagesAPI.MessageDelta;\n  export import MessageDeltaEvent = MessagesAPI.MessageDeltaEvent;\n  export import RefusalContentBlock = MessagesAPI.RefusalContentBlock;\n  export import RefusalDeltaBlock = MessagesAPI.RefusalDeltaBlock;\n  export import Text = MessagesAPI.Text;\n  export import TextContentBlock = MessagesAPI.TextContentBlock;\n  export import TextContentBlockParam = MessagesAPI.TextContentBlockParam;\n  export import TextDelta = MessagesAPI.TextDelta;\n  export import TextDeltaBlock = MessagesAPI.TextDeltaBlock;\n  export import MessagesPage = MessagesAPI.MessagesPage;\n  export import MessageCreateParams = MessagesAPI.MessageCreateParams;\n  export import MessageUpdateParams = MessagesAPI.MessageUpdateParams;\n  export import MessageListParams = MessagesAPI.MessageListParams;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;;;;;;AAShF,MAAO,iBAAiB,qIAAA,CAAA,cAAW;IACvC;;QAGA,OACE,QAAgB,EAChB,IAAyB,EACzB,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,CAAA,SAAA,EAAY,SAAQ,SAAA,CAAW,EAAE;YACxD;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;QAGA,SAAS,QAAgB,EAAE,SAAiB,EAAE,OAA6B,EAAA;QACzE,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,CAAA,SAAA,EAAY,SAAQ,UAAA,EAAa,UAAS,CAAE,EAAE;YACpE,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;QAGA,OACE,QAAgB,EAChB,SAAiB,EACjB,IAAyB,EACzB,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,CAAA,SAAA,EAAY,SAAQ,UAAA,EAAa,UAAS,CAAE,EAAE;YACrE;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAWA,KACE,QAAgB,EAChB,QAAiD,CAAA,CAAE,EACnD,OAA6B,EAAA;QAE7B,IAAI,CAAA,GAAA,iJAAA,CAAA,mBAAgB,AAAhB,EAAiB,QAAQ;YAC3B,OAAO,IAAI,CAAC,IAAI,CAAC,UAAU,CAAA,GAAI;;QAEjC,OAAO,IAAI,CAAC,OAAO,CAAC,UAAU,CAAC,CAAA,SAAA,EAAY,SAAQ,SAAA,CAAW,EAAE,cAAc;YAC5E;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;QAGA,IAAI,QAAgB,EAAE,SAAiB,EAAE,OAA6B,EAAA;QACpE,OAAO,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,CAAA,SAAA,EAAY,SAAQ,UAAA,EAAa,UAAS,CAAE,EAAE;YACvE,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;;AAGI,MAAO,qBAAqB,uIAAA,CAAA,aAAmB;;AA8nBrD,CAAA,SAAiB,QAAQ;IA6BT,SAAA,YAAY,GAAG,sKAAY,YAAY;AAIvD,CAAC,EAjCgB,YAAQ,CAAR,WAAQ,CAAA,CAAA"}},
    {"offset": {"line": 5364, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 5369, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/beta/threads/runs/steps.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../../resource';\nimport { isRequestOptions } from '../../../../core';\nimport * as Core from '../../../../core';\nimport * as StepsAPI from './steps';\nimport { CursorPage, type CursorPageParams } from '../../../../pagination';\n\nexport class Steps extends APIResource {\n  /**\n   * Retrieves a run step.\n   */\n  retrieve(\n    threadId: string,\n    runId: string,\n    stepId: string,\n    query?: StepRetrieveParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<RunStep>;\n  retrieve(\n    threadId: string,\n    runId: string,\n    stepId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<RunStep>;\n  retrieve(\n    threadId: string,\n    runId: string,\n    stepId: string,\n    query: StepRetrieveParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<RunStep> {\n    if (isRequestOptions(query)) {\n      return this.retrieve(threadId, runId, stepId, {}, query);\n    }\n    return this._client.get(`/threads/${threadId}/runs/${runId}/steps/${stepId}`, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of run steps belonging to a run.\n   */\n  list(\n    threadId: string,\n    runId: string,\n    query?: StepListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<RunStepsPage, RunStep>;\n  list(\n    threadId: string,\n    runId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<RunStepsPage, RunStep>;\n  list(\n    threadId: string,\n    runId: string,\n    query: StepListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<RunStepsPage, RunStep> {\n    if (isRequestOptions(query)) {\n      return this.list(threadId, runId, {}, query);\n    }\n    return this._client.getAPIList(`/threads/${threadId}/runs/${runId}/steps`, RunStepsPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n}\n\nexport class RunStepsPage extends CursorPage<RunStep> {}\n\n/**\n * Text output from the Code Interpreter tool call as part of a run step.\n */\nexport interface CodeInterpreterLogs {\n  /**\n   * The index of the output in the outputs array.\n   */\n  index: number;\n\n  /**\n   * Always `logs`.\n   */\n  type: 'logs';\n\n  /**\n   * The text output from the Code Interpreter tool call.\n   */\n  logs?: string;\n}\n\nexport interface CodeInterpreterOutputImage {\n  /**\n   * The index of the output in the outputs array.\n   */\n  index: number;\n\n  /**\n   * Always `image`.\n   */\n  type: 'image';\n\n  image?: CodeInterpreterOutputImage.Image;\n}\n\nexport namespace CodeInterpreterOutputImage {\n  export interface Image {\n    /**\n     * The [file](https://platform.openai.com/docs/api-reference/files) ID of the\n     * image.\n     */\n    file_id?: string;\n  }\n}\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport interface CodeInterpreterToolCall {\n  /**\n   * The ID of the tool call.\n   */\n  id: string;\n\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  code_interpreter: CodeInterpreterToolCall.CodeInterpreter;\n\n  /**\n   * The type of tool call. This is always going to be `code_interpreter` for this\n   * type of tool call.\n   */\n  type: 'code_interpreter';\n}\n\nexport namespace CodeInterpreterToolCall {\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  export interface CodeInterpreter {\n    /**\n     * The input to the Code Interpreter tool call.\n     */\n    input: string;\n\n    /**\n     * The outputs from the Code Interpreter tool call. Code Interpreter can output one\n     * or more items, including text (`logs`) or images (`image`). Each of these are\n     * represented by a different object type.\n     */\n    outputs: Array<CodeInterpreter.Logs | CodeInterpreter.Image>;\n  }\n\n  export namespace CodeInterpreter {\n    /**\n     * Text output from the Code Interpreter tool call as part of a run step.\n     */\n    export interface Logs {\n      /**\n       * The text output from the Code Interpreter tool call.\n       */\n      logs: string;\n\n      /**\n       * Always `logs`.\n       */\n      type: 'logs';\n    }\n\n    export interface Image {\n      image: Image.Image;\n\n      /**\n       * Always `image`.\n       */\n      type: 'image';\n    }\n\n    export namespace Image {\n      export interface Image {\n        /**\n         * The [file](https://platform.openai.com/docs/api-reference/files) ID of the\n         * image.\n         */\n        file_id: string;\n      }\n    }\n  }\n}\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport interface CodeInterpreterToolCallDelta {\n  /**\n   * The index of the tool call in the tool calls array.\n   */\n  index: number;\n\n  /**\n   * The type of tool call. This is always going to be `code_interpreter` for this\n   * type of tool call.\n   */\n  type: 'code_interpreter';\n\n  /**\n   * The ID of the tool call.\n   */\n  id?: string;\n\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  code_interpreter?: CodeInterpreterToolCallDelta.CodeInterpreter;\n}\n\nexport namespace CodeInterpreterToolCallDelta {\n  /**\n   * The Code Interpreter tool call definition.\n   */\n  export interface CodeInterpreter {\n    /**\n     * The input to the Code Interpreter tool call.\n     */\n    input?: string;\n\n    /**\n     * The outputs from the Code Interpreter tool call. Code Interpreter can output one\n     * or more items, including text (`logs`) or images (`image`). Each of these are\n     * represented by a different object type.\n     */\n    outputs?: Array<StepsAPI.CodeInterpreterLogs | StepsAPI.CodeInterpreterOutputImage>;\n  }\n}\n\nexport interface FileSearchToolCall {\n  /**\n   * The ID of the tool call object.\n   */\n  id: string;\n\n  /**\n   * For now, this is always going to be an empty object.\n   */\n  file_search: FileSearchToolCall.FileSearch;\n\n  /**\n   * The type of tool call. This is always going to be `file_search` for this type of\n   * tool call.\n   */\n  type: 'file_search';\n}\n\nexport namespace FileSearchToolCall {\n  /**\n   * For now, this is always going to be an empty object.\n   */\n  export interface FileSearch {\n    /**\n     * The ranking options for the file search.\n     */\n    ranking_options?: FileSearch.RankingOptions;\n\n    /**\n     * The results of the file search.\n     */\n    results?: Array<FileSearch.Result>;\n  }\n\n  export namespace FileSearch {\n    /**\n     * The ranking options for the file search.\n     */\n    export interface RankingOptions {\n      /**\n       * The ranker used for the file search.\n       */\n      ranker: 'default_2024_08_21';\n\n      /**\n       * The score threshold for the file search. All values must be a floating point\n       * number between 0 and 1.\n       */\n      score_threshold: number;\n    }\n\n    /**\n     * A result instance of the file search.\n     */\n    export interface Result {\n      /**\n       * The ID of the file that result was found in.\n       */\n      file_id: string;\n\n      /**\n       * The name of the file that result was found in.\n       */\n      file_name: string;\n\n      /**\n       * The score of the result. All values must be a floating point number between 0\n       * and 1.\n       */\n      score: number;\n\n      /**\n       * The content of the result that was found. The content is only included if\n       * requested via the include query parameter.\n       */\n      content?: Array<Result.Content>;\n    }\n\n    export namespace Result {\n      export interface Content {\n        /**\n         * The text content of the file.\n         */\n        text?: string;\n\n        /**\n         * The type of the content.\n         */\n        type?: 'text';\n      }\n    }\n  }\n}\n\nexport interface FileSearchToolCallDelta {\n  /**\n   * For now, this is always going to be an empty object.\n   */\n  file_search: unknown;\n\n  /**\n   * The index of the tool call in the tool calls array.\n   */\n  index: number;\n\n  /**\n   * The type of tool call. This is always going to be `file_search` for this type of\n   * tool call.\n   */\n  type: 'file_search';\n\n  /**\n   * The ID of the tool call object.\n   */\n  id?: string;\n}\n\nexport interface FunctionToolCall {\n  /**\n   * The ID of the tool call object.\n   */\n  id: string;\n\n  /**\n   * The definition of the function that was called.\n   */\n  function: FunctionToolCall.Function;\n\n  /**\n   * The type of tool call. This is always going to be `function` for this type of\n   * tool call.\n   */\n  type: 'function';\n}\n\nexport namespace FunctionToolCall {\n  /**\n   * The definition of the function that was called.\n   */\n  export interface Function {\n    /**\n     * The arguments passed to the function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function.\n     */\n    name: string;\n\n    /**\n     * The output of the function. This will be `null` if the outputs have not been\n     * [submitted](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\n     * yet.\n     */\n    output: string | null;\n  }\n}\n\nexport interface FunctionToolCallDelta {\n  /**\n   * The index of the tool call in the tool calls array.\n   */\n  index: number;\n\n  /**\n   * The type of tool call. This is always going to be `function` for this type of\n   * tool call.\n   */\n  type: 'function';\n\n  /**\n   * The ID of the tool call object.\n   */\n  id?: string;\n\n  /**\n   * The definition of the function that was called.\n   */\n  function?: FunctionToolCallDelta.Function;\n}\n\nexport namespace FunctionToolCallDelta {\n  /**\n   * The definition of the function that was called.\n   */\n  export interface Function {\n    /**\n     * The arguments passed to the function.\n     */\n    arguments?: string;\n\n    /**\n     * The name of the function.\n     */\n    name?: string;\n\n    /**\n     * The output of the function. This will be `null` if the outputs have not been\n     * [submitted](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\n     * yet.\n     */\n    output?: string | null;\n  }\n}\n\n/**\n * Details of the message creation by the run step.\n */\nexport interface MessageCreationStepDetails {\n  message_creation: MessageCreationStepDetails.MessageCreation;\n\n  /**\n   * Always `message_creation`.\n   */\n  type: 'message_creation';\n}\n\nexport namespace MessageCreationStepDetails {\n  export interface MessageCreation {\n    /**\n     * The ID of the message that was created by this run step.\n     */\n    message_id: string;\n  }\n}\n\n/**\n * Represents a step in execution of a run.\n */\nexport interface RunStep {\n  /**\n   * The identifier of the run step, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants)\n   * associated with the run step.\n   */\n  assistant_id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step was cancelled.\n   */\n  cancelled_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step completed.\n   */\n  completed_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step expired. A step is\n   * considered expired if the parent run is expired.\n   */\n  expired_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run step failed.\n   */\n  failed_at: number | null;\n\n  /**\n   * The last error associated with this run step. Will be `null` if there are no\n   * errors.\n   */\n  last_error: RunStep.LastError | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata: unknown | null;\n\n  /**\n   * The object type, which is always `thread.run.step`.\n   */\n  object: 'thread.run.step';\n\n  /**\n   * The ID of the [run](https://platform.openai.com/docs/api-reference/runs) that\n   * this run step is a part of.\n   */\n  run_id: string;\n\n  /**\n   * The status of the run step, which can be either `in_progress`, `cancelled`,\n   * `failed`, `completed`, or `expired`.\n   */\n  status: 'in_progress' | 'cancelled' | 'failed' | 'completed' | 'expired';\n\n  /**\n   * The details of the run step.\n   */\n  step_details: MessageCreationStepDetails | ToolCallsStepDetails;\n\n  /**\n   * The ID of the [thread](https://platform.openai.com/docs/api-reference/threads)\n   * that was run.\n   */\n  thread_id: string;\n\n  /**\n   * The type of run step, which can be either `message_creation` or `tool_calls`.\n   */\n  type: 'message_creation' | 'tool_calls';\n\n  /**\n   * Usage statistics related to the run step. This value will be `null` while the\n   * run step's status is `in_progress`.\n   */\n  usage: RunStep.Usage | null;\n}\n\nexport namespace RunStep {\n  /**\n   * The last error associated with this run step. Will be `null` if there are no\n   * errors.\n   */\n  export interface LastError {\n    /**\n     * One of `server_error` or `rate_limit_exceeded`.\n     */\n    code: 'server_error' | 'rate_limit_exceeded';\n\n    /**\n     * A human-readable description of the error.\n     */\n    message: string;\n  }\n\n  /**\n   * Usage statistics related to the run step. This value will be `null` while the\n   * run step's status is `in_progress`.\n   */\n  export interface Usage {\n    /**\n     * Number of completion tokens used over the course of the run step.\n     */\n    completion_tokens: number;\n\n    /**\n     * Number of prompt tokens used over the course of the run step.\n     */\n    prompt_tokens: number;\n\n    /**\n     * Total number of tokens used (prompt + completion).\n     */\n    total_tokens: number;\n  }\n}\n\n/**\n * The delta containing the fields that have changed on the run step.\n */\nexport interface RunStepDelta {\n  /**\n   * The details of the run step.\n   */\n  step_details?: RunStepDeltaMessageDelta | ToolCallDeltaObject;\n}\n\n/**\n * Represents a run step delta i.e. any changed fields on a run step during\n * streaming.\n */\nexport interface RunStepDeltaEvent {\n  /**\n   * The identifier of the run step, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The delta containing the fields that have changed on the run step.\n   */\n  delta: RunStepDelta;\n\n  /**\n   * The object type, which is always `thread.run.step.delta`.\n   */\n  object: 'thread.run.step.delta';\n}\n\n/**\n * Details of the message creation by the run step.\n */\nexport interface RunStepDeltaMessageDelta {\n  /**\n   * Always `message_creation`.\n   */\n  type: 'message_creation';\n\n  message_creation?: RunStepDeltaMessageDelta.MessageCreation;\n}\n\nexport namespace RunStepDeltaMessageDelta {\n  export interface MessageCreation {\n    /**\n     * The ID of the message that was created by this run step.\n     */\n    message_id?: string;\n  }\n}\n\nexport type RunStepInclude = 'step_details.tool_calls[*].file_search.results[*].content';\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport type ToolCall = CodeInterpreterToolCall | FileSearchToolCall | FunctionToolCall;\n\n/**\n * Details of the Code Interpreter tool call the run step was involved in.\n */\nexport type ToolCallDelta = CodeInterpreterToolCallDelta | FileSearchToolCallDelta | FunctionToolCallDelta;\n\n/**\n * Details of the tool call.\n */\nexport interface ToolCallDeltaObject {\n  /**\n   * Always `tool_calls`.\n   */\n  type: 'tool_calls';\n\n  /**\n   * An array of tool calls the run step was involved in. These can be associated\n   * with one of three types of tools: `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tool_calls?: Array<ToolCallDelta>;\n}\n\n/**\n * Details of the tool call.\n */\nexport interface ToolCallsStepDetails {\n  /**\n   * An array of tool calls the run step was involved in. These can be associated\n   * with one of three types of tools: `code_interpreter`, `file_search`, or\n   * `function`.\n   */\n  tool_calls: Array<ToolCall>;\n\n  /**\n   * Always `tool_calls`.\n   */\n  type: 'tool_calls';\n}\n\nexport interface StepRetrieveParams {\n  /**\n   * A list of additional fields to include in the response. Currently the only\n   * supported value is `step_details.tool_calls[*].file_search.results[*].content`\n   * to fetch the file search result content.\n   *\n   * See the\n   * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search/customizing-file-search-settings)\n   * for more information.\n   */\n  include?: Array<RunStepInclude>;\n}\n\nexport interface StepListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\n   * fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * A list of additional fields to include in the response. Currently the only\n   * supported value is `step_details.tool_calls[*].file_search.results[*].content`\n   * to fetch the file search result content.\n   *\n   * See the\n   * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search/customizing-file-search-settings)\n   * for more information.\n   */\n  include?: Array<RunStepInclude>;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport namespace Steps {\n  export import CodeInterpreterLogs = StepsAPI.CodeInterpreterLogs;\n  export import CodeInterpreterOutputImage = StepsAPI.CodeInterpreterOutputImage;\n  export import CodeInterpreterToolCall = StepsAPI.CodeInterpreterToolCall;\n  export import CodeInterpreterToolCallDelta = StepsAPI.CodeInterpreterToolCallDelta;\n  export import FileSearchToolCall = StepsAPI.FileSearchToolCall;\n  export import FileSearchToolCallDelta = StepsAPI.FileSearchToolCallDelta;\n  export import FunctionToolCall = StepsAPI.FunctionToolCall;\n  export import FunctionToolCallDelta = StepsAPI.FunctionToolCallDelta;\n  export import MessageCreationStepDetails = StepsAPI.MessageCreationStepDetails;\n  export import RunStep = StepsAPI.RunStep;\n  export import RunStepDelta = StepsAPI.RunStepDelta;\n  export import RunStepDeltaEvent = StepsAPI.RunStepDeltaEvent;\n  export import RunStepDeltaMessageDelta = StepsAPI.RunStepDeltaMessageDelta;\n  export import RunStepInclude = StepsAPI.RunStepInclude;\n  export import ToolCall = StepsAPI.ToolCall;\n  export import ToolCallDelta = StepsAPI.ToolCallDelta;\n  export import ToolCallDeltaObject = StepsAPI.ToolCallDeltaObject;\n  export import ToolCallsStepDetails = StepsAPI.ToolCallsStepDetails;\n  export import RunStepsPage = StepsAPI.RunStepsPage;\n  export import StepRetrieveParams = StepsAPI.StepRetrieveParams;\n  export import StepListParams = StepsAPI.StepListParams;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;;;;;;AAQhF,MAAO,cAAc,qIAAA,CAAA,cAAW;IAiBpC,SACE,QAAgB,EAChB,KAAa,EACb,MAAc,EACd,QAAkD,CAAA,CAAE,EACpD,OAA6B,EAAA;QAE7B,IAAI,CAAA,GAAA,iJAAA,CAAA,mBAAgB,AAAhB,EAAiB,QAAQ;YAC3B,OAAO,IAAI,CAAC,QAAQ,CAAC,UAAU,OAAO,QAAQ,CAAA,GAAI;;QAEpD,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,CAAA,SAAA,EAAY,SAAQ,MAAA,EAAS,MAAK,OAAA,EAAU,OAAM,CAAE,EAAE;YAC5E;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAgBA,KACE,QAAgB,EAChB,KAAa,EACb,QAA8C,CAAA,CAAE,EAChD,OAA6B,EAAA;QAE7B,IAAI,CAAA,GAAA,iJAAA,CAAA,mBAAgB,AAAhB,EAAiB,QAAQ;YAC3B,OAAO,IAAI,CAAC,IAAI,CAAC,UAAU,OAAO,CAAA,GAAI;;QAExC,OAAO,IAAI,CAAC,OAAO,CAAC,UAAU,CAAC,CAAA,SAAA,EAAY,SAAQ,MAAA,EAAS,MAAK,MAAA,CAAQ,EAAE,cAAc;YACvF;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;;AAGI,MAAO,qBAAqB,uIAAA,CAAA,aAAmB;;AA2pBrD,CAAA,SAAiB,KAAK;IAmBN,MAAA,YAAY,GAAG,2KAAS,YAAY;AAGpD,CAAC,EAtBgB,SAAK,CAAL,QAAK,CAAA,CAAA"}},
    {"offset": {"line": 5416, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 5421, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/beta/threads/runs/runs.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../../resource';\nimport { isRequestOptions } from '../../../../core';\nimport { APIPromise } from '../../../../core';\nimport * as Core from '../../../../core';\nimport { AssistantStream, RunCreateParamsBaseStream } from '../../../../lib/AssistantStream';\nimport { sleep } from '../../../../core';\nimport { RunSubmitToolOutputsParamsStream } from '../../../../lib/AssistantStream';\nimport * as RunsAPI from './runs';\nimport * as AssistantsAPI from '../../assistants';\nimport * as ChatAPI from '../../../chat/chat';\nimport * as MessagesAPI from '../messages';\nimport * as ThreadsAPI from '../threads';\nimport * as StepsAPI from './steps';\nimport { CursorPage, type CursorPageParams } from '../../../../pagination';\nimport { Stream } from '../../../../streaming';\n\nexport class Runs extends APIResource {\n  steps: StepsAPI.Steps = new StepsAPI.Steps(this._client);\n\n  /**\n   * Create a run.\n   */\n  create(\n    threadId: string,\n    params: RunCreateParamsNonStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Run>;\n  create(\n    threadId: string,\n    params: RunCreateParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  create(\n    threadId: string,\n    params: RunCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent> | Run>;\n  create(\n    threadId: string,\n    params: RunCreateParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>> {\n    const { include, ...body } = params;\n    return this._client.post(`/threads/${threadId}/runs`, {\n      query: { include },\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n      stream: params.stream ?? false,\n    }) as APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  }\n\n  /**\n   * Retrieves a run.\n   */\n  retrieve(threadId: string, runId: string, options?: Core.RequestOptions): Core.APIPromise<Run> {\n    return this._client.get(`/threads/${threadId}/runs/${runId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Modifies a run.\n   */\n  update(\n    threadId: string,\n    runId: string,\n    body: RunUpdateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Run> {\n    return this._client.post(`/threads/${threadId}/runs/${runId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of runs belonging to a thread.\n   */\n  list(\n    threadId: string,\n    query?: RunListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<RunsPage, Run>;\n  list(threadId: string, options?: Core.RequestOptions): Core.PagePromise<RunsPage, Run>;\n  list(\n    threadId: string,\n    query: RunListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<RunsPage, Run> {\n    if (isRequestOptions(query)) {\n      return this.list(threadId, {}, query);\n    }\n    return this._client.getAPIList(`/threads/${threadId}/runs`, RunsPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Cancels a run that is `in_progress`.\n   */\n  cancel(threadId: string, runId: string, options?: Core.RequestOptions): Core.APIPromise<Run> {\n    return this._client.post(`/threads/${threadId}/runs/${runId}/cancel`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * A helper to create a run an poll for a terminal state. More information on Run\n   * lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async createAndPoll(\n    threadId: string,\n    body: RunCreateParamsNonStreaming,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Run> {\n    const run = await this.create(threadId, body, options);\n    return await this.poll(threadId, run.id, options);\n  }\n\n  /**\n   * Create a Run stream\n   *\n   * @deprecated use `stream` instead\n   */\n  createAndStream(\n    threadId: string,\n    body: RunCreateParamsBaseStream,\n    options?: Core.RequestOptions,\n  ): AssistantStream {\n    return AssistantStream.createAssistantStream(threadId, this._client.beta.threads.runs, body, options);\n  }\n\n  /**\n   * A helper to poll a run status until it reaches a terminal state. More\n   * information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async poll(\n    threadId: string,\n    runId: string,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Run> {\n    const headers: { [key: string]: string } = { ...options?.headers, 'X-Stainless-Poll-Helper': 'true' };\n\n    if (options?.pollIntervalMs) {\n      headers['X-Stainless-Custom-Poll-Interval'] = options.pollIntervalMs.toString();\n    }\n\n    while (true) {\n      const { data: run, response } = await this.retrieve(threadId, runId, {\n        ...options,\n        headers: { ...options?.headers, ...headers },\n      }).withResponse();\n\n      switch (run.status) {\n        //If we are in any sort of intermediate state we poll\n        case 'queued':\n        case 'in_progress':\n        case 'cancelling':\n          let sleepInterval = 5000;\n\n          if (options?.pollIntervalMs) {\n            sleepInterval = options.pollIntervalMs;\n          } else {\n            const headerInterval = response.headers.get('openai-poll-after-ms');\n            if (headerInterval) {\n              const headerIntervalMs = parseInt(headerInterval);\n              if (!isNaN(headerIntervalMs)) {\n                sleepInterval = headerIntervalMs;\n              }\n            }\n          }\n          await sleep(sleepInterval);\n          break;\n        //We return the run in any terminal state.\n        case 'requires_action':\n        case 'incomplete':\n        case 'cancelled':\n        case 'completed':\n        case 'failed':\n        case 'expired':\n          return run;\n      }\n    }\n  }\n\n  /**\n   * Create a Run stream\n   */\n  stream(threadId: string, body: RunCreateParamsBaseStream, options?: Core.RequestOptions): AssistantStream {\n    return AssistantStream.createAssistantStream(threadId, this._client.beta.threads.runs, body, options);\n  }\n\n  /**\n   * When a run has the `status: \"requires_action\"` and `required_action.type` is\n   * `submit_tool_outputs`, this endpoint can be used to submit the outputs from the\n   * tool calls once they're all completed. All outputs must be submitted in a single\n   * request.\n   */\n  submitToolOutputs(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParamsNonStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Run>;\n  submitToolOutputs(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  submitToolOutputs(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent> | Run>;\n  submitToolOutputs(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>> {\n    return this._client.post(`/threads/${threadId}/runs/${runId}/submit_tool_outputs`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n      stream: body.stream ?? false,\n    }) as APIPromise<Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  }\n\n  /**\n   * A helper to submit a tool output to a run and poll for a terminal run state.\n   * More information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async submitToolOutputsAndPoll(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParamsNonStreaming,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Run> {\n    const run = await this.submitToolOutputs(threadId, runId, body, options);\n    return await this.poll(threadId, run.id, options);\n  }\n\n  /**\n   * Submit the tool outputs from a previous run and stream the run to a terminal\n   * state. More information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  submitToolOutputsStream(\n    threadId: string,\n    runId: string,\n    body: RunSubmitToolOutputsParamsStream,\n    options?: Core.RequestOptions,\n  ): AssistantStream {\n    return AssistantStream.createToolAssistantStream(\n      threadId,\n      runId,\n      this._client.beta.threads.runs,\n      body,\n      options,\n    );\n  }\n}\n\nexport class RunsPage extends CursorPage<Run> {}\n\n/**\n * Tool call objects\n */\nexport interface RequiredActionFunctionToolCall {\n  /**\n   * The ID of the tool call. This ID must be referenced when you submit the tool\n   * outputs in using the\n   * [Submit tool outputs to run](https://platform.openai.com/docs/api-reference/runs/submitToolOutputs)\n   * endpoint.\n   */\n  id: string;\n\n  /**\n   * The function definition.\n   */\n  function: RequiredActionFunctionToolCall.Function;\n\n  /**\n   * The type of tool call the output is required for. For now, this is always\n   * `function`.\n   */\n  type: 'function';\n}\n\nexport namespace RequiredActionFunctionToolCall {\n  /**\n   * The function definition.\n   */\n  export interface Function {\n    /**\n     * The arguments that the model expects you to pass to the function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function.\n     */\n    name: string;\n  }\n}\n\n/**\n * Represents an execution run on a\n * [thread](https://platform.openai.com/docs/api-reference/threads).\n */\nexport interface Run {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * execution of this run.\n   */\n  assistant_id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was cancelled.\n   */\n  cancelled_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was completed.\n   */\n  completed_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run will expire.\n   */\n  expires_at: number | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run failed.\n   */\n  failed_at: number | null;\n\n  /**\n   * Details on why the run is incomplete. Will be `null` if the run is not\n   * incomplete.\n   */\n  incomplete_details: Run.IncompleteDetails | null;\n\n  /**\n   * The instructions that the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * this run.\n   */\n  instructions: string;\n\n  /**\n   * The last error associated with this run. Will be `null` if there are no errors.\n   */\n  last_error: Run.LastError | null;\n\n  /**\n   * The maximum number of completion tokens specified to have been used over the\n   * course of the run.\n   */\n  max_completion_tokens: number | null;\n\n  /**\n   * The maximum number of prompt tokens specified to have been used over the course\n   * of the run.\n   */\n  max_prompt_tokens: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata: unknown | null;\n\n  /**\n   * The model that the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * this run.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always `thread.run`.\n   */\n  object: 'thread.run';\n\n  /**\n   * Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling/parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls: boolean;\n\n  /**\n   * Details on the action required to continue the run. Will be `null` if no action\n   * is required.\n   */\n  required_action: Run.RequiredAction | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the run was started.\n   */\n  started_at: number | null;\n\n  /**\n   * The status of the run, which can be either `queued`, `in_progress`,\n   * `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`,\n   * `incomplete`, or `expired`.\n   */\n  status: RunStatus;\n\n  /**\n   * The ID of the [thread](https://platform.openai.com/docs/api-reference/threads)\n   * that was executed on as a part of this run.\n   */\n  thread_id: string;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * The list of tools that the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) used for\n   * this run.\n   */\n  tools: Array<AssistantsAPI.AssistantTool>;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy: Run.TruncationStrategy | null;\n\n  /**\n   * Usage statistics related to the run. This value will be `null` if the run is not\n   * in a terminal state (i.e. `in_progress`, `queued`, etc.).\n   */\n  usage: Run.Usage | null;\n\n  /**\n   * The sampling temperature used for this run. If not set, defaults to 1.\n   */\n  temperature?: number | null;\n\n  /**\n   * The nucleus sampling value used for this run. If not set, defaults to 1.\n   */\n  top_p?: number | null;\n}\n\nexport namespace Run {\n  /**\n   * Details on why the run is incomplete. Will be `null` if the run is not\n   * incomplete.\n   */\n  export interface IncompleteDetails {\n    /**\n     * The reason why the run is incomplete. This will point to which specific token\n     * limit was reached over the course of the run.\n     */\n    reason?: 'max_completion_tokens' | 'max_prompt_tokens';\n  }\n\n  /**\n   * The last error associated with this run. Will be `null` if there are no errors.\n   */\n  export interface LastError {\n    /**\n     * One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`.\n     */\n    code: 'server_error' | 'rate_limit_exceeded' | 'invalid_prompt';\n\n    /**\n     * A human-readable description of the error.\n     */\n    message: string;\n  }\n\n  /**\n   * Details on the action required to continue the run. Will be `null` if no action\n   * is required.\n   */\n  export interface RequiredAction {\n    /**\n     * Details on the tool outputs needed for this run to continue.\n     */\n    submit_tool_outputs: RequiredAction.SubmitToolOutputs;\n\n    /**\n     * For now, this is always `submit_tool_outputs`.\n     */\n    type: 'submit_tool_outputs';\n  }\n\n  export namespace RequiredAction {\n    /**\n     * Details on the tool outputs needed for this run to continue.\n     */\n    export interface SubmitToolOutputs {\n      /**\n       * A list of the relevant tool calls.\n       */\n      tool_calls: Array<RunsAPI.RequiredActionFunctionToolCall>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n\n  /**\n   * Usage statistics related to the run. This value will be `null` if the run is not\n   * in a terminal state (i.e. `in_progress`, `queued`, etc.).\n   */\n  export interface Usage {\n    /**\n     * Number of completion tokens used over the course of the run.\n     */\n    completion_tokens: number;\n\n    /**\n     * Number of prompt tokens used over the course of the run.\n     */\n    prompt_tokens: number;\n\n    /**\n     * Total number of tokens used (prompt + completion).\n     */\n    total_tokens: number;\n  }\n}\n\n/**\n * The status of the run, which can be either `queued`, `in_progress`,\n * `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`,\n * `incomplete`, or `expired`.\n */\nexport type RunStatus =\n  | 'queued'\n  | 'in_progress'\n  | 'requires_action'\n  | 'cancelling'\n  | 'cancelled'\n  | 'failed'\n  | 'completed'\n  | 'incomplete'\n  | 'expired';\n\nexport type RunCreateParams = RunCreateParamsNonStreaming | RunCreateParamsStreaming;\n\nexport interface RunCreateParamsBase {\n  /**\n   * Body param: The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Query param: A list of additional fields to include in the response. Currently\n   * the only supported value is\n   * `step_details.tool_calls[*].file_search.results[*].content` to fetch the file\n   * search result content.\n   *\n   * See the\n   * [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search/customizing-file-search-settings)\n   * for more information.\n   */\n  include?: Array<StepsAPI.RunStepInclude>;\n\n  /**\n   * Body param: Appends additional instructions at the end of the instructions for\n   * the run. This is useful for modifying the behavior on a per-run basis without\n   * overriding other instructions.\n   */\n  additional_instructions?: string | null;\n\n  /**\n   * Body param: Adds additional messages to the thread before creating the run.\n   */\n  additional_messages?: Array<RunCreateParams.AdditionalMessage> | null;\n\n  /**\n   * Body param: Overrides the\n   * [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant)\n   * of the assistant. This is useful for modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * Body param: The maximum number of completion tokens that may be used over the\n   * course of the run. The run will make a best effort to use only the number of\n   * completion tokens specified, across multiple turns of the run. If the run\n   * exceeds the number of completion tokens specified, the run will end with status\n   * `incomplete`. See `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * Body param: The maximum number of prompt tokens that may be used over the course\n   * of the run. The run will make a best effort to use only the number of prompt\n   * tokens specified, across multiple turns of the run. If the run exceeds the\n   * number of prompt tokens specified, the run will end with status `incomplete`.\n   * See `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Body param: Set of 16 key-value pairs that can be attached to an object. This\n   * can be useful for storing additional information about the object in a\n   * structured format. Keys can be a maximum of 64 characters long and values can be\n   * a maxium of 512 characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * Body param: The ID of the\n   * [Model](https://platform.openai.com/docs/api-reference/models) to be used to\n   * execute this run. If a value is provided here, it will override the model\n   * associated with the assistant. If not, the model associated with the assistant\n   * will be used.\n   */\n  model?: (string & {}) | ChatAPI.ChatModel | null;\n\n  /**\n   * Body param: Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling/parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls?: boolean;\n\n  /**\n   * Body param: Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream?: boolean | null;\n\n  /**\n   * Body param: What sampling temperature to use, between 0 and 2. Higher values\n   * like 0.8 will make the output more random, while lower values like 0.2 will make\n   * it more focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Body param: Controls which (if any) tool is called by the model. `none` means\n   * the model will not call any tools and instead generates a message. `auto` is the\n   * default value and means the model can pick between generating a message or\n   * calling one or more tools. `required` means the model must call one or more\n   * tools before responding to the user. Specifying a particular tool like\n   * `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * Body param: Override the tools the assistant can use for this run. This is\n   * useful for modifying the behavior on a per-run basis.\n   */\n  tools?: Array<AssistantsAPI.AssistantTool> | null;\n\n  /**\n   * Body param: An alternative to sampling with temperature, called nucleus\n   * sampling, where the model considers the results of the tokens with top_p\n   * probability mass. So 0.1 means only the tokens comprising the top 10%\n   * probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Body param: Controls for how a thread will be truncated prior to the run. Use\n   * this to control the intial context window of the run.\n   */\n  truncation_strategy?: RunCreateParams.TruncationStrategy | null;\n}\n\nexport namespace RunCreateParams {\n  export interface AdditionalMessage {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<AdditionalMessage.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n  }\n\n  export namespace AdditionalMessage {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n    }\n\n    export namespace Attachment {\n      export interface FileSearch {\n        /**\n         * The type of tool being defined: `file_search`\n         */\n        type: 'file_search';\n      }\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n\n  export type RunCreateParamsNonStreaming = RunsAPI.RunCreateParamsNonStreaming;\n  export type RunCreateParamsStreaming = RunsAPI.RunCreateParamsStreaming;\n}\n\nexport interface RunCreateParamsNonStreaming extends RunCreateParamsBase {\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream?: false | null;\n}\n\nexport interface RunCreateParamsStreaming extends RunCreateParamsBase {\n  /**\n   * Body param: If `true`, returns a stream of events that happen during the Run as\n   * server-sent events, terminating when the Run enters a terminal state with a\n   * `data: [DONE]` message.\n   */\n  stream: true;\n}\n\nexport interface RunUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n}\n\nexport interface RunListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\n   * fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport interface RunCreateAndPollParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Appends additional instructions at the end of the instructions for the run. This\n   * is useful for modifying the behavior on a per-run basis without overriding other\n   * instructions.\n   */\n  additional_instructions?: string | null;\n\n  /**\n   * Adds additional messages to the thread before creating the run.\n   */\n  additional_messages?: Array<RunCreateAndPollParams.AdditionalMessage> | null;\n\n  /**\n   * Overrides the\n   * [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant)\n   * of the assistant. This is useful for modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<AssistantsAPI.AssistantTool> | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: RunCreateAndPollParams.TruncationStrategy | null;\n}\n\nexport namespace RunCreateAndPollParams {\n  export interface AdditionalMessage {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<AdditionalMessage.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n  }\n\n  export namespace AdditionalMessage {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nexport interface RunCreateAndStreamParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Appends additional instructions at the end of the instructions for the run. This\n   * is useful for modifying the behavior on a per-run basis without overriding other\n   * instructions.\n   */\n  additional_instructions?: string | null;\n\n  /**\n   * Adds additional messages to the thread before creating the run.\n   */\n  additional_messages?: Array<RunCreateAndStreamParams.AdditionalMessage> | null;\n\n  /**\n   * Overrides the\n   * [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant)\n   * of the assistant. This is useful for modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<AssistantsAPI.AssistantTool> | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: RunCreateAndStreamParams.TruncationStrategy | null;\n}\n\nexport namespace RunCreateAndStreamParams {\n  export interface AdditionalMessage {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<AdditionalMessage.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n  }\n\n  export namespace AdditionalMessage {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nexport interface RunStreamParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Appends additional instructions at the end of the instructions for the run. This\n   * is useful for modifying the behavior on a per-run basis without overriding other\n   * instructions.\n   */\n  additional_instructions?: string | null;\n\n  /**\n   * Adds additional messages to the thread before creating the run.\n   */\n  additional_messages?: Array<RunStreamParams.AdditionalMessage> | null;\n\n  /**\n   * Overrides the\n   * [instructions](https://platform.openai.com/docs/api-reference/assistants/createAssistant)\n   * of the assistant. This is useful for modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: ThreadsAPI.AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: ThreadsAPI.AssistantToolChoiceOption | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<AssistantsAPI.AssistantTool> | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: RunStreamParams.TruncationStrategy | null;\n}\n\nexport namespace RunStreamParams {\n  export interface AdditionalMessage {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<AdditionalMessage.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n  }\n\n  export namespace AdditionalMessage {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nexport type RunSubmitToolOutputsParams =\n  | RunSubmitToolOutputsParamsNonStreaming\n  | RunSubmitToolOutputsParamsStreaming;\n\nexport interface RunSubmitToolOutputsParamsBase {\n  /**\n   * A list of tools for which the outputs are being submitted.\n   */\n  tool_outputs: Array<RunSubmitToolOutputsParams.ToolOutput>;\n\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: boolean | null;\n}\n\nexport namespace RunSubmitToolOutputsParams {\n  export interface ToolOutput {\n    /**\n     * The output of the tool call to be submitted to continue the run.\n     */\n    output?: string;\n\n    /**\n     * The ID of the tool call in the `required_action` object within the run object\n     * the output is being submitted for.\n     */\n    tool_call_id?: string;\n  }\n\n  export type RunSubmitToolOutputsParamsNonStreaming = RunsAPI.RunSubmitToolOutputsParamsNonStreaming;\n  export type RunSubmitToolOutputsParamsStreaming = RunsAPI.RunSubmitToolOutputsParamsStreaming;\n}\n\nexport interface RunSubmitToolOutputsParamsNonStreaming extends RunSubmitToolOutputsParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: false | null;\n}\n\nexport interface RunSubmitToolOutputsParamsStreaming extends RunSubmitToolOutputsParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream: true;\n}\n\nexport interface RunSubmitToolOutputsAndPollParams {\n  /**\n   * A list of tools for which the outputs are being submitted.\n   */\n  tool_outputs: Array<RunSubmitToolOutputsAndPollParams.ToolOutput>;\n}\n\nexport namespace RunSubmitToolOutputsAndPollParams {\n  export interface ToolOutput {\n    /**\n     * The output of the tool call to be submitted to continue the run.\n     */\n    output?: string;\n\n    /**\n     * The ID of the tool call in the `required_action` object within the run object\n     * the output is being submitted for.\n     */\n    tool_call_id?: string;\n  }\n}\n\nexport interface RunSubmitToolOutputsStreamParams {\n  /**\n   * A list of tools for which the outputs are being submitted.\n   */\n  tool_outputs: Array<RunSubmitToolOutputsStreamParams.ToolOutput>;\n}\n\nexport namespace RunSubmitToolOutputsStreamParams {\n  export interface ToolOutput {\n    /**\n     * The output of the tool call to be submitted to continue the run.\n     */\n    output?: string;\n\n    /**\n     * The ID of the tool call in the `required_action` object within the run object\n     * the output is being submitted for.\n     */\n    tool_call_id?: string;\n  }\n}\n\nexport namespace Runs {\n  export import RequiredActionFunctionToolCall = RunsAPI.RequiredActionFunctionToolCall;\n  export import Run = RunsAPI.Run;\n  export import RunStatus = RunsAPI.RunStatus;\n  export import RunsPage = RunsAPI.RunsPage;\n  export import RunCreateParams = RunsAPI.RunCreateParams;\n  export import RunCreateParamsNonStreaming = RunsAPI.RunCreateParamsNonStreaming;\n  export import RunCreateParamsStreaming = RunsAPI.RunCreateParamsStreaming;\n  export import RunUpdateParams = RunsAPI.RunUpdateParams;\n  export import RunListParams = RunsAPI.RunListParams;\n  export import RunCreateAndPollParams = RunsAPI.RunCreateAndPollParams;\n  export import RunCreateAndStreamParams = RunsAPI.RunCreateAndStreamParams;\n  export import RunStreamParams = RunsAPI.RunStreamParams;\n  export import RunSubmitToolOutputsParams = RunsAPI.RunSubmitToolOutputsParams;\n  export import RunSubmitToolOutputsParamsNonStreaming = RunsAPI.RunSubmitToolOutputsParamsNonStreaming;\n  export import RunSubmitToolOutputsParamsStreaming = RunsAPI.RunSubmitToolOutputsParamsStreaming;\n  export import RunSubmitToolOutputsAndPollParams = RunsAPI.RunSubmitToolOutputsAndPollParams;\n  export import RunSubmitToolOutputsStreamParams = RunsAPI.RunSubmitToolOutputsStreamParams;\n  export import Steps = StepsAPI.Steps;\n  export import CodeInterpreterLogs = StepsAPI.CodeInterpreterLogs;\n  export import CodeInterpreterOutputImage = StepsAPI.CodeInterpreterOutputImage;\n  export import CodeInterpreterToolCall = StepsAPI.CodeInterpreterToolCall;\n  export import CodeInterpreterToolCallDelta = StepsAPI.CodeInterpreterToolCallDelta;\n  export import FileSearchToolCall = StepsAPI.FileSearchToolCall;\n  export import FileSearchToolCallDelta = StepsAPI.FileSearchToolCallDelta;\n  export import FunctionToolCall = StepsAPI.FunctionToolCall;\n  export import FunctionToolCallDelta = StepsAPI.FunctionToolCallDelta;\n  export import MessageCreationStepDetails = StepsAPI.MessageCreationStepDetails;\n  export import RunStep = StepsAPI.RunStep;\n  export import RunStepDelta = StepsAPI.RunStepDelta;\n  export import RunStepDeltaEvent = StepsAPI.RunStepDeltaEvent;\n  export import RunStepDeltaMessageDelta = StepsAPI.RunStepDeltaMessageDelta;\n  export import RunStepInclude = StepsAPI.RunStepInclude;\n  export import ToolCall = StepsAPI.ToolCall;\n  export import ToolCallDelta = StepsAPI.ToolCallDelta;\n  export import ToolCallDeltaObject = StepsAPI.ToolCallDeltaObject;\n  export import ToolCallsStepDetails = StepsAPI.ToolCallsStepDetails;\n  export import RunStepsPage = StepsAPI.RunStepsPage;\n  export import StepRetrieveParams = StepsAPI.StepRetrieveParams;\n  export import StepListParams = StepsAPI.StepListParams;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;;;;;;;;;;;AAkBhF,MAAO,aAAa,qIAAA,CAAA,cAAW;IAArC,aAAA;;QACE,IAAA,CAAA,KAAK,GAAmB,IAAI,2KAAS,KAAK,CAAC,IAAI,CAAC,OAAO;IA+PzD;IA3OE,OACE,QAAgB,EAChB,MAAuB,EACvB,OAA6B,EAAA;QAE7B,MAAM,EAAE,OAAO,EAAE,GAAG,MAAM,GAAG;QAC7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,CAAA,SAAA,EAAY,SAAQ,KAAA,CAAO,EAAE;YACpD,OAAO;gBAAE;YAAO;YAChB;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;YAC9D,QAAQ,OAAO,MAAM,IAAI;;IAE7B;IAEA;;QAGA,SAAS,QAAgB,EAAE,KAAa,EAAE,OAA6B,EAAA;QACrE,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,CAAA,SAAA,EAAY,SAAQ,MAAA,EAAS,MAAK,CAAE,EAAE;YAC5D,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;QAGA,OACE,QAAgB,EAChB,KAAa,EACb,IAAqB,EACrB,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,CAAA,SAAA,EAAY,SAAQ,MAAA,EAAS,MAAK,CAAE,EAAE;YAC7D;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAWA,KACE,QAAgB,EAChB,QAA6C,CAAA,CAAE,EAC/C,OAA6B,EAAA;QAE7B,IAAI,CAAA,GAAA,iJAAA,CAAA,mBAAgB,AAAhB,EAAiB,QAAQ;YAC3B,OAAO,IAAI,CAAC,IAAI,CAAC,UAAU,CAAA,GAAI;;QAEjC,OAAO,IAAI,CAAC,OAAO,CAAC,UAAU,CAAC,CAAA,SAAA,EAAY,SAAQ,KAAA,CAAO,EAAE,UAAU;YACpE;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;QAGA,OAAO,QAAgB,EAAE,KAAa,EAAE,OAA6B,EAAA;QACnE,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,CAAA,SAAA,EAAY,SAAQ,MAAA,EAAS,MAAK,OAAA,CAAS,EAAE;YACpE,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;;;QAKA,MAAM,cACJ,QAAgB,EAChB,IAAiC,EACjC,OAA2D,EAAA;QAE3D,MAAM,MAAM,MAAM,IAAI,CAAC,MAAM,CAAC,UAAU,MAAM;QAC9C,OAAO,MAAM,IAAI,CAAC,IAAI,CAAC,UAAU,IAAI,EAAE,EAAE;IAC3C;IAEA;;;;QAKA,gBACE,QAAgB,EAChB,IAA+B,EAC/B,OAA6B,EAAA;QAE7B,OAAO,mJAAA,CAAA,kBAAe,CAAC,qBAAqB,CAAC,UAAU,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,OAAO,CAAC,IAAI,EAAE,MAAM;IAC/F;IAEA;;;;QAKA,MAAM,KACJ,QAAgB,EAChB,KAAa,EACb,OAA2D,EAAA;QAE3D,MAAM,UAAqC;YAAE,GAAG,SAAS,OAAO;YAAE,2BAA2B;QAAM;QAEnG,IAAI,SAAS,gBAAgB;YAC3B,OAAO,CAAC,mCAAmC,GAAG,QAAQ,cAAc,CAAC,QAAQ;;QAG/E,MAAO,KAAM;YACX,MAAM,EAAE,MAAM,GAAG,EAAE,QAAQ,EAAE,GAAG,MAAM,IAAI,CAAC,QAAQ,CAAC,UAAU,OAAO;gBACnE,GAAG,OAAO;gBACV,SAAS;oBAAE,GAAG,SAAS,OAAO;oBAAE,GAAG,OAAO;gBAAA;eACzC,YAAY;YAEf,OAAQ,IAAI,MAAM;gBAChB,qDAAqD;gBACrD,KAAK;gBACL,KAAK;gBACL,KAAK;oBACH,IAAI,gBAAgB;oBAEpB,IAAI,SAAS,gBAAgB;wBAC3B,gBAAgB,QAAQ,cAAc;2BACjC;wBACL,MAAM,iBAAiB,SAAS,OAAO,CAAC,GAAG,CAAC;wBAC5C,IAAI,gBAAgB;4BAClB,MAAM,mBAAmB,SAAS;4BAClC,IAAI,CAAC,MAAM,mBAAmB;gCAC5B,gBAAgB;;;;oBAItB,MAAM,CAAA,GAAA,iJAAA,CAAA,QAAK,AAAL,EAAM;oBACZ;gBACF,0CAA0C;gBAC1C,KAAK;gBACL,KAAK;gBACL,KAAK;gBACL,KAAK;gBACL,KAAK;gBACL,KAAK;oBACH,OAAO;;;IAGf;IAEA;;QAGA,OAAO,QAAgB,EAAE,IAA+B,EAAE,OAA6B,EAAA;QACrF,OAAO,mJAAA,CAAA,kBAAe,CAAC,qBAAqB,CAAC,UAAU,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,OAAO,CAAC,IAAI,EAAE,MAAM;IAC/F;IA0BA,kBACE,QAAgB,EAChB,KAAa,EACb,IAAgC,EAChC,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,CAAA,SAAA,EAAY,SAAQ,MAAA,EAAS,MAAK,oBAAA,CAAsB,EAAE;YACjF;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;YAC9D,QAAQ,KAAK,MAAM,IAAI;;IAE3B;IAEA;;;;QAKA,MAAM,yBACJ,QAAgB,EAChB,KAAa,EACb,IAA4C,EAC5C,OAA2D,EAAA;QAE3D,MAAM,MAAM,MAAM,IAAI,CAAC,iBAAiB,CAAC,UAAU,OAAO,MAAM;QAChE,OAAO,MAAM,IAAI,CAAC,IAAI,CAAC,UAAU,IAAI,EAAE,EAAE;IAC3C;IAEA;;;;QAKA,wBACE,QAAgB,EAChB,KAAa,EACb,IAAsC,EACtC,OAA6B,EAAA;QAE7B,OAAO,mJAAA,CAAA,kBAAe,CAAC,yBAAyB,CAC9C,UACA,OACA,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,OAAO,CAAC,IAAI,EAC9B,MACA;IAEJ;;AAGI,MAAO,iBAAiB,uIAAA,CAAA,aAAe;;AAi0C7C,CAAA,SAAiB,IAAI;IAIL,KAAA,QAAQ,GAAG,0KAAQ,QAAQ;IAc3B,KAAA,KAAK,GAAG,2KAAS,KAAK;IAmBtB,KAAA,YAAY,GAAG,2KAAS,YAAY;AAGpD,CAAC,EAxCgB,QAAI,CAAJ,OAAI,CAAA,CAAA"}},
    {"offset": {"line": 5611, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 5616, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/beta/threads/threads.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport { AssistantStream, ThreadCreateAndRunParamsBaseStream } from '../../../lib/AssistantStream';\nimport { APIPromise } from '../../../core';\nimport * as Core from '../../../core';\nimport * as ThreadsAPI from './threads';\nimport * as Shared from '../../shared';\nimport * as AssistantsAPI from '../assistants';\nimport * as ChatAPI from '../../chat/chat';\nimport * as MessagesAPI from './messages';\nimport * as VectorStoresAPI from '../vector-stores/vector-stores';\nimport * as RunsAPI from './runs/runs';\nimport { Stream } from '../../../streaming';\n\nexport class Threads extends APIResource {\n  runs: RunsAPI.Runs = new RunsAPI.Runs(this._client);\n  messages: MessagesAPI.Messages = new MessagesAPI.Messages(this._client);\n\n  /**\n   * Create a thread.\n   */\n  create(body?: ThreadCreateParams, options?: Core.RequestOptions): Core.APIPromise<Thread>;\n  create(options?: Core.RequestOptions): Core.APIPromise<Thread>;\n  create(\n    body: ThreadCreateParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Thread> {\n    if (isRequestOptions(body)) {\n      return this.create({}, body);\n    }\n    return this._client.post('/threads', {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves a thread.\n   */\n  retrieve(threadId: string, options?: Core.RequestOptions): Core.APIPromise<Thread> {\n    return this._client.get(`/threads/${threadId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Modifies a thread.\n   */\n  update(threadId: string, body: ThreadUpdateParams, options?: Core.RequestOptions): Core.APIPromise<Thread> {\n    return this._client.post(`/threads/${threadId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Delete a thread.\n   */\n  del(threadId: string, options?: Core.RequestOptions): Core.APIPromise<ThreadDeleted> {\n    return this._client.delete(`/threads/${threadId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Create a thread and run it in one request.\n   */\n  createAndRun(\n    body: ThreadCreateAndRunParamsNonStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<RunsAPI.Run>;\n  createAndRun(\n    body: ThreadCreateAndRunParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  createAndRun(\n    body: ThreadCreateAndRunParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<AssistantsAPI.AssistantStreamEvent> | RunsAPI.Run>;\n  createAndRun(\n    body: ThreadCreateAndRunParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<RunsAPI.Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>> {\n    return this._client.post('/threads/runs', {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n      stream: body.stream ?? false,\n    }) as APIPromise<RunsAPI.Run> | APIPromise<Stream<AssistantsAPI.AssistantStreamEvent>>;\n  }\n\n  /**\n   * A helper to create a thread, start a run and then poll for a terminal state.\n   * More information on Run lifecycles can be found here:\n   * https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps\n   */\n  async createAndRunPoll(\n    body: ThreadCreateAndRunParamsNonStreaming,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<Threads.Run> {\n    const run = await this.createAndRun(body, options);\n    return await this.runs.poll(run.thread_id, run.id, options);\n  }\n\n  /**\n   * Create a thread and stream the run back\n   */\n  createAndRunStream(\n    body: ThreadCreateAndRunParamsBaseStream,\n    options?: Core.RequestOptions,\n  ): AssistantStream {\n    return AssistantStream.createThreadAssistantStream(body, this._client.beta.threads, options);\n  }\n}\n\n/**\n * Specifies the format that the model must output. Compatible with\n * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n *\n * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n * Outputs which ensures the model will match your supplied JSON schema. Learn more\n * in the\n * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n *\n * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n * message the model generates is valid JSON.\n *\n * **Important:** when using JSON mode, you **must** also instruct the model to\n * produce JSON yourself via a system or user message. Without this, the model may\n * generate an unending stream of whitespace until the generation reaches the token\n * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n * the message content may be partially cut off if `finish_reason=\"length\"`, which\n * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n * max context length.\n */\nexport type AssistantResponseFormatOption =\n  | 'auto'\n  | Shared.ResponseFormatText\n  | Shared.ResponseFormatJSONObject\n  | Shared.ResponseFormatJSONSchema;\n\n/**\n * Specifies a tool the model should use. Use to force the model to call a specific\n * tool.\n */\nexport interface AssistantToolChoice {\n  /**\n   * The type of the tool. If type is `function`, the function name must be set\n   */\n  type: 'function' | 'code_interpreter' | 'file_search';\n\n  function?: AssistantToolChoiceFunction;\n}\n\nexport interface AssistantToolChoiceFunction {\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n}\n\n/**\n * Controls which (if any) tool is called by the model. `none` means the model will\n * not call any tools and instead generates a message. `auto` is the default value\n * and means the model can pick between generating a message or calling one or more\n * tools. `required` means the model must call one or more tools before responding\n * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n * call that tool.\n */\nexport type AssistantToolChoiceOption = 'none' | 'auto' | 'required' | AssistantToolChoice;\n\n/**\n * Represents a thread that contains\n * [messages](https://platform.openai.com/docs/api-reference/messages).\n */\nexport interface Thread {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the thread was created.\n   */\n  created_at: number;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata: unknown | null;\n\n  /**\n   * The object type, which is always `thread`.\n   */\n  object: 'thread';\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  tool_resources: Thread.ToolResources | null;\n}\n\nexport namespace Thread {\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this thread. There can be a maximum of 1 vector store attached to\n       * the thread.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport interface ThreadDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'thread.deleted';\n}\n\nexport interface ThreadCreateParams {\n  /**\n   * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n   * start the thread with.\n   */\n  messages?: Array<ThreadCreateParams.Message>;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  tool_resources?: ThreadCreateParams.ToolResources | null;\n}\n\nexport namespace ThreadCreateParams {\n  export interface Message {\n    /**\n     * The text contents of the message.\n     */\n    content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n    /**\n     * The role of the entity that is creating the message. Allowed values include:\n     *\n     * - `user`: Indicates the message is sent by an actual user and should be used in\n     *   most cases to represent user-generated messages.\n     * - `assistant`: Indicates the message is generated by the assistant. Use this\n     *   value to insert messages from the assistant into the conversation.\n     */\n    role: 'user' | 'assistant';\n\n    /**\n     * A list of files attached to the message, and the tools they should be added to.\n     */\n    attachments?: Array<Message.Attachment> | null;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n  }\n\n  export namespace Message {\n    export interface Attachment {\n      /**\n       * The ID of the file to attach to the message.\n       */\n      file_id?: string;\n\n      /**\n       * The tools to add this file to.\n       */\n      tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n    }\n\n    export namespace Attachment {\n      export interface FileSearch {\n        /**\n         * The type of tool being defined: `file_search`\n         */\n        type: 'file_search';\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this thread. There can be a maximum of 1 vector store attached to\n       * the thread.\n       */\n      vector_store_ids?: Array<string>;\n\n      /**\n       * A helper to create a\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n       * store attached to the thread.\n       */\n      vector_stores?: Array<FileSearch.VectorStore>;\n    }\n\n    export namespace FileSearch {\n      export interface VectorStore {\n        /**\n         * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n         * strategy. Only applicable if `file_ids` is non-empty.\n         */\n        chunking_strategy?: VectorStoresAPI.FileChunkingStrategyParam;\n\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n         * add to the vector store. There can be a maximum of 10000 files in a vector\n         * store.\n         */\n        file_ids?: Array<string>;\n\n        /**\n         * Set of 16 key-value pairs that can be attached to a vector store. This can be\n         * useful for storing additional information about the vector store in a structured\n         * format. Keys can be a maximum of 64 characters long and values can be a maxium\n         * of 512 characters long.\n         */\n        metadata?: unknown;\n      }\n    }\n  }\n}\n\nexport interface ThreadUpdateParams {\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  tool_resources?: ThreadUpdateParams.ToolResources | null;\n}\n\nexport namespace ThreadUpdateParams {\n  /**\n   * A set of resources that are made available to the assistant's tools in this\n   * thread. The resources are specific to the type of tool. For example, the\n   * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n   * tool requires a list of vector store IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this thread. There can be a maximum of 1 vector store attached to\n       * the thread.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n}\n\nexport type ThreadCreateAndRunParams =\n  | ThreadCreateAndRunParamsNonStreaming\n  | ThreadCreateAndRunParamsStreaming;\n\nexport interface ThreadCreateAndRunParamsBase {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Override the default system message of the assistant. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?: (string & {}) | ChatAPI.ChatModel | null;\n\n  /**\n   * Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling/parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls?: boolean;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: AssistantResponseFormatOption | null;\n\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: boolean | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  thread?: ThreadCreateAndRunParams.Thread;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: AssistantToolChoiceOption | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: ThreadCreateAndRunParams.ToolResources | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<\n    AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool | AssistantsAPI.FunctionTool\n  > | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: ThreadCreateAndRunParams.TruncationStrategy | null;\n}\n\nexport namespace ThreadCreateAndRunParams {\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  export interface Thread {\n    /**\n     * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n     * start the thread with.\n     */\n    messages?: Array<Thread.Message>;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    tool_resources?: Thread.ToolResources | null;\n  }\n\n  export namespace Thread {\n    export interface Message {\n      /**\n       * The text contents of the message.\n       */\n      content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n      /**\n       * The role of the entity that is creating the message. Allowed values include:\n       *\n       * - `user`: Indicates the message is sent by an actual user and should be used in\n       *   most cases to represent user-generated messages.\n       * - `assistant`: Indicates the message is generated by the assistant. Use this\n       *   value to insert messages from the assistant into the conversation.\n       */\n      role: 'user' | 'assistant';\n\n      /**\n       * A list of files attached to the message, and the tools they should be added to.\n       */\n      attachments?: Array<Message.Attachment> | null;\n\n      /**\n       * Set of 16 key-value pairs that can be attached to an object. This can be useful\n       * for storing additional information about the object in a structured format. Keys\n       * can be a maximum of 64 characters long and values can be a maxium of 512\n       * characters long.\n       */\n      metadata?: unknown | null;\n    }\n\n    export namespace Message {\n      export interface Attachment {\n        /**\n         * The ID of the file to attach to the message.\n         */\n        file_id?: string;\n\n        /**\n         * The tools to add this file to.\n         */\n        tools?: Array<AssistantsAPI.CodeInterpreterTool | Attachment.FileSearch>;\n      }\n\n      export namespace Attachment {\n        export interface FileSearch {\n          /**\n           * The type of tool being defined: `file_search`\n           */\n          type: 'file_search';\n        }\n      }\n    }\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    export interface ToolResources {\n      code_interpreter?: ToolResources.CodeInterpreter;\n\n      file_search?: ToolResources.FileSearch;\n    }\n\n    export namespace ToolResources {\n      export interface CodeInterpreter {\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n         * available to the `code_interpreter` tool. There can be a maximum of 20 files\n         * associated with the tool.\n         */\n        file_ids?: Array<string>;\n      }\n\n      export interface FileSearch {\n        /**\n         * The\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * attached to this thread. There can be a maximum of 1 vector store attached to\n         * the thread.\n         */\n        vector_store_ids?: Array<string>;\n\n        /**\n         * A helper to create a\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n         * store attached to the thread.\n         */\n        vector_stores?: Array<FileSearch.VectorStore>;\n      }\n\n      export namespace FileSearch {\n        export interface VectorStore {\n          /**\n           * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n           * strategy. Only applicable if `file_ids` is non-empty.\n           */\n          chunking_strategy?: VectorStoresAPI.FileChunkingStrategyParam;\n\n          /**\n           * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n           * add to the vector store. There can be a maximum of 10000 files in a vector\n           * store.\n           */\n          file_ids?: Array<string>;\n\n          /**\n           * Set of 16 key-value pairs that can be attached to a vector store. This can be\n           * useful for storing additional information about the vector store in a structured\n           * format. Keys can be a maximum of 64 characters long and values can be a maxium\n           * of 512 characters long.\n           */\n          metadata?: unknown;\n        }\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n\n  export type ThreadCreateAndRunParamsNonStreaming = ThreadsAPI.ThreadCreateAndRunParamsNonStreaming;\n  export type ThreadCreateAndRunParamsStreaming = ThreadsAPI.ThreadCreateAndRunParamsStreaming;\n}\n\nexport interface ThreadCreateAndRunParamsNonStreaming extends ThreadCreateAndRunParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream?: false | null;\n}\n\nexport interface ThreadCreateAndRunParamsStreaming extends ThreadCreateAndRunParamsBase {\n  /**\n   * If `true`, returns a stream of events that happen during the Run as server-sent\n   * events, terminating when the Run enters a terminal state with a `data: [DONE]`\n   * message.\n   */\n  stream: true;\n}\n\nexport interface ThreadCreateAndRunPollParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Override the default system message of the assistant. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  thread?: ThreadCreateAndRunPollParams.Thread;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: AssistantToolChoiceOption | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: ThreadCreateAndRunPollParams.ToolResources | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<\n    AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool | AssistantsAPI.FunctionTool\n  > | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: ThreadCreateAndRunPollParams.TruncationStrategy | null;\n}\n\nexport namespace ThreadCreateAndRunPollParams {\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  export interface Thread {\n    /**\n     * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n     * start the thread with.\n     */\n    messages?: Array<Thread.Message>;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    tool_resources?: Thread.ToolResources | null;\n  }\n\n  export namespace Thread {\n    export interface Message {\n      /**\n       * The text contents of the message.\n       */\n      content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n      /**\n       * The role of the entity that is creating the message. Allowed values include:\n       *\n       * - `user`: Indicates the message is sent by an actual user and should be used in\n       *   most cases to represent user-generated messages.\n       * - `assistant`: Indicates the message is generated by the assistant. Use this\n       *   value to insert messages from the assistant into the conversation.\n       */\n      role: 'user' | 'assistant';\n\n      /**\n       * A list of files attached to the message, and the tools they should be added to.\n       */\n      attachments?: Array<Message.Attachment> | null;\n\n      /**\n       * Set of 16 key-value pairs that can be attached to an object. This can be useful\n       * for storing additional information about the object in a structured format. Keys\n       * can be a maximum of 64 characters long and values can be a maxium of 512\n       * characters long.\n       */\n      metadata?: unknown | null;\n    }\n\n    export namespace Message {\n      export interface Attachment {\n        /**\n         * The ID of the file to attach to the message.\n         */\n        file_id?: string;\n\n        /**\n         * The tools to add this file to.\n         */\n        tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n      }\n    }\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    export interface ToolResources {\n      code_interpreter?: ToolResources.CodeInterpreter;\n\n      file_search?: ToolResources.FileSearch;\n    }\n\n    export namespace ToolResources {\n      export interface CodeInterpreter {\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n         * available to the `code_interpreter` tool. There can be a maximum of 20 files\n         * associated with the tool.\n         */\n        file_ids?: Array<string>;\n      }\n\n      export interface FileSearch {\n        /**\n         * The\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * attached to this thread. There can be a maximum of 1 vector store attached to\n         * the thread.\n         */\n        vector_store_ids?: Array<string>;\n\n        /**\n         * A helper to create a\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n         * store attached to the thread.\n         */\n        vector_stores?: Array<FileSearch.VectorStore>;\n      }\n\n      export namespace FileSearch {\n        export interface VectorStore {\n          /**\n           * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n           * add to the vector store. There can be a maximum of 10000 files in a vector\n           * store.\n           */\n          file_ids?: Array<string>;\n\n          /**\n           * Set of 16 key-value pairs that can be attached to a vector store. This can be\n           * useful for storing additional information about the vector store in a structured\n           * format. Keys can be a maximum of 64 characters long and values can be a maxium\n           * of 512 characters long.\n           */\n          metadata?: unknown;\n        }\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nexport interface ThreadCreateAndRunStreamParams {\n  /**\n   * The ID of the\n   * [assistant](https://platform.openai.com/docs/api-reference/assistants) to use to\n   * execute this run.\n   */\n  assistant_id: string;\n\n  /**\n   * Override the default system message of the assistant. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  instructions?: string | null;\n\n  /**\n   * The maximum number of completion tokens that may be used over the course of the\n   * run. The run will make a best effort to use only the number of completion tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * completion tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of prompt tokens that may be used over the course of the run.\n   * The run will make a best effort to use only the number of prompt tokens\n   * specified, across multiple turns of the run. If the run exceeds the number of\n   * prompt tokens specified, the run will end with status `incomplete`. See\n   * `incomplete_details` for more info.\n   */\n  max_prompt_tokens?: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The ID of the [Model](https://platform.openai.com/docs/api-reference/models) to\n   * be used to execute this run. If a value is provided here, it will override the\n   * model associated with the assistant. If not, the model associated with the\n   * assistant will be used.\n   */\n  model?:\n    | (string & {})\n    | 'gpt-4o'\n    | 'gpt-4o-2024-05-13'\n    | 'gpt-4-turbo'\n    | 'gpt-4-turbo-2024-04-09'\n    | 'gpt-4-0125-preview'\n    | 'gpt-4-turbo-preview'\n    | 'gpt-4-1106-preview'\n    | 'gpt-4-vision-preview'\n    | 'gpt-4'\n    | 'gpt-4-0314'\n    | 'gpt-4-0613'\n    | 'gpt-4-32k'\n    | 'gpt-4-32k-0314'\n    | 'gpt-4-32k-0613'\n    | 'gpt-3.5-turbo'\n    | 'gpt-3.5-turbo-16k'\n    | 'gpt-3.5-turbo-0613'\n    | 'gpt-3.5-turbo-1106'\n    | 'gpt-3.5-turbo-0125'\n    | 'gpt-3.5-turbo-16k-0613'\n    | null;\n\n  /**\n   * Specifies the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4),\n   * and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which guarantees the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?: AssistantResponseFormatOption | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   */\n  temperature?: number | null;\n\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  thread?: ThreadCreateAndRunStreamParams.Thread;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tools and instead generates a message. `auto` is the default value\n   * and means the model can pick between generating a message or calling one or more\n   * tools. `required` means the model must call one or more tools before responding\n   * to the user. Specifying a particular tool like `{\"type\": \"file_search\"}` or\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   */\n  tool_choice?: AssistantToolChoiceOption | null;\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  tool_resources?: ThreadCreateAndRunStreamParams.ToolResources | null;\n\n  /**\n   * Override the tools the assistant can use for this run. This is useful for\n   * modifying the behavior on a per-run basis.\n   */\n  tools?: Array<\n    AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool | AssistantsAPI.FunctionTool\n  > | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or temperature but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  truncation_strategy?: ThreadCreateAndRunStreamParams.TruncationStrategy | null;\n}\n\nexport namespace ThreadCreateAndRunStreamParams {\n  /**\n   * If no thread is provided, an empty thread will be created.\n   */\n  export interface Thread {\n    /**\n     * A list of [messages](https://platform.openai.com/docs/api-reference/messages) to\n     * start the thread with.\n     */\n    messages?: Array<Thread.Message>;\n\n    /**\n     * Set of 16 key-value pairs that can be attached to an object. This can be useful\n     * for storing additional information about the object in a structured format. Keys\n     * can be a maximum of 64 characters long and values can be a maxium of 512\n     * characters long.\n     */\n    metadata?: unknown | null;\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    tool_resources?: Thread.ToolResources | null;\n  }\n\n  export namespace Thread {\n    export interface Message {\n      /**\n       * The text contents of the message.\n       */\n      content: string | Array<MessagesAPI.MessageContentPartParam>;\n\n      /**\n       * The role of the entity that is creating the message. Allowed values include:\n       *\n       * - `user`: Indicates the message is sent by an actual user and should be used in\n       *   most cases to represent user-generated messages.\n       * - `assistant`: Indicates the message is generated by the assistant. Use this\n       *   value to insert messages from the assistant into the conversation.\n       */\n      role: 'user' | 'assistant';\n\n      /**\n       * A list of files attached to the message, and the tools they should be added to.\n       */\n      attachments?: Array<Message.Attachment> | null;\n\n      /**\n       * Set of 16 key-value pairs that can be attached to an object. This can be useful\n       * for storing additional information about the object in a structured format. Keys\n       * can be a maximum of 64 characters long and values can be a maxium of 512\n       * characters long.\n       */\n      metadata?: unknown | null;\n    }\n\n    export namespace Message {\n      export interface Attachment {\n        /**\n         * The ID of the file to attach to the message.\n         */\n        file_id?: string;\n\n        /**\n         * The tools to add this file to.\n         */\n        tools?: Array<AssistantsAPI.CodeInterpreterTool | AssistantsAPI.FileSearchTool>;\n      }\n    }\n\n    /**\n     * A set of resources that are made available to the assistant's tools in this\n     * thread. The resources are specific to the type of tool. For example, the\n     * `code_interpreter` tool requires a list of file IDs, while the `file_search`\n     * tool requires a list of vector store IDs.\n     */\n    export interface ToolResources {\n      code_interpreter?: ToolResources.CodeInterpreter;\n\n      file_search?: ToolResources.FileSearch;\n    }\n\n    export namespace ToolResources {\n      export interface CodeInterpreter {\n        /**\n         * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n         * available to the `code_interpreter` tool. There can be a maximum of 20 files\n         * associated with the tool.\n         */\n        file_ids?: Array<string>;\n      }\n\n      export interface FileSearch {\n        /**\n         * The\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * attached to this thread. There can be a maximum of 1 vector store attached to\n         * the thread.\n         */\n        vector_store_ids?: Array<string>;\n\n        /**\n         * A helper to create a\n         * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n         * with file_ids and attach it to this thread. There can be a maximum of 1 vector\n         * store attached to the thread.\n         */\n        vector_stores?: Array<FileSearch.VectorStore>;\n      }\n\n      export namespace FileSearch {\n        export interface VectorStore {\n          /**\n           * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs to\n           * add to the vector store. There can be a maximum of 10000 files in a vector\n           * store.\n           */\n          file_ids?: Array<string>;\n\n          /**\n           * Set of 16 key-value pairs that can be attached to a vector store. This can be\n           * useful for storing additional information about the vector store in a structured\n           * format. Keys can be a maximum of 64 characters long and values can be a maxium\n           * of 512 characters long.\n           */\n          metadata?: unknown;\n        }\n      }\n    }\n  }\n\n  /**\n   * A set of resources that are used by the assistant's tools. The resources are\n   * specific to the type of tool. For example, the `code_interpreter` tool requires\n   * a list of file IDs, while the `file_search` tool requires a list of vector store\n   * IDs.\n   */\n  export interface ToolResources {\n    code_interpreter?: ToolResources.CodeInterpreter;\n\n    file_search?: ToolResources.FileSearch;\n  }\n\n  export namespace ToolResources {\n    export interface CodeInterpreter {\n      /**\n       * A list of [file](https://platform.openai.com/docs/api-reference/files) IDs made\n       * available to the `code_interpreter` tool. There can be a maximum of 20 files\n       * associated with the tool.\n       */\n      file_ids?: Array<string>;\n    }\n\n    export interface FileSearch {\n      /**\n       * The ID of the\n       * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n       * attached to this assistant. There can be a maximum of 1 vector store attached to\n       * the assistant.\n       */\n      vector_store_ids?: Array<string>;\n    }\n  }\n\n  /**\n   * Controls for how a thread will be truncated prior to the run. Use this to\n   * control the intial context window of the run.\n   */\n  export interface TruncationStrategy {\n    /**\n     * The truncation strategy to use for the thread. The default is `auto`. If set to\n     * `last_messages`, the thread will be truncated to the n most recent messages in\n     * the thread. When set to `auto`, messages in the middle of the thread will be\n     * dropped to fit the context length of the model, `max_prompt_tokens`.\n     */\n    type: 'auto' | 'last_messages';\n\n    /**\n     * The number of most recent messages from the thread when constructing the context\n     * for the run.\n     */\n    last_messages?: number | null;\n  }\n}\n\nexport namespace Threads {\n  export import AssistantResponseFormatOption = ThreadsAPI.AssistantResponseFormatOption;\n  export import AssistantToolChoice = ThreadsAPI.AssistantToolChoice;\n  export import AssistantToolChoiceFunction = ThreadsAPI.AssistantToolChoiceFunction;\n  export import AssistantToolChoiceOption = ThreadsAPI.AssistantToolChoiceOption;\n  export import Thread = ThreadsAPI.Thread;\n  export import ThreadDeleted = ThreadsAPI.ThreadDeleted;\n  export import ThreadCreateParams = ThreadsAPI.ThreadCreateParams;\n  export import ThreadUpdateParams = ThreadsAPI.ThreadUpdateParams;\n  export import ThreadCreateAndRunParams = ThreadsAPI.ThreadCreateAndRunParams;\n  export import ThreadCreateAndRunParamsNonStreaming = ThreadsAPI.ThreadCreateAndRunParamsNonStreaming;\n  export import ThreadCreateAndRunParamsStreaming = ThreadsAPI.ThreadCreateAndRunParamsStreaming;\n  export import ThreadCreateAndRunPollParams = ThreadsAPI.ThreadCreateAndRunPollParams;\n  export import ThreadCreateAndRunStreamParams = ThreadsAPI.ThreadCreateAndRunStreamParams;\n  export import Runs = RunsAPI.Runs;\n  export import RequiredActionFunctionToolCall = RunsAPI.RequiredActionFunctionToolCall;\n  export import Run = RunsAPI.Run;\n  export import RunStatus = RunsAPI.RunStatus;\n  export import RunsPage = RunsAPI.RunsPage;\n  export import RunCreateParams = RunsAPI.RunCreateParams;\n  export import RunCreateParamsNonStreaming = RunsAPI.RunCreateParamsNonStreaming;\n  export import RunCreateParamsStreaming = RunsAPI.RunCreateParamsStreaming;\n  export import RunUpdateParams = RunsAPI.RunUpdateParams;\n  export import RunListParams = RunsAPI.RunListParams;\n  export import RunCreateAndPollParams = RunsAPI.RunCreateAndPollParams;\n  export import RunCreateAndStreamParams = RunsAPI.RunCreateAndStreamParams;\n  export import RunStreamParams = RunsAPI.RunStreamParams;\n  export import RunSubmitToolOutputsParams = RunsAPI.RunSubmitToolOutputsParams;\n  export import RunSubmitToolOutputsParamsNonStreaming = RunsAPI.RunSubmitToolOutputsParamsNonStreaming;\n  export import RunSubmitToolOutputsParamsStreaming = RunsAPI.RunSubmitToolOutputsParamsStreaming;\n  export import RunSubmitToolOutputsAndPollParams = RunsAPI.RunSubmitToolOutputsAndPollParams;\n  export import RunSubmitToolOutputsStreamParams = RunsAPI.RunSubmitToolOutputsStreamParams;\n  export import Messages = MessagesAPI.Messages;\n  export import Annotation = MessagesAPI.Annotation;\n  export import AnnotationDelta = MessagesAPI.AnnotationDelta;\n  export import FileCitationAnnotation = MessagesAPI.FileCitationAnnotation;\n  export import FileCitationDeltaAnnotation = MessagesAPI.FileCitationDeltaAnnotation;\n  export import FilePathAnnotation = MessagesAPI.FilePathAnnotation;\n  export import FilePathDeltaAnnotation = MessagesAPI.FilePathDeltaAnnotation;\n  export import ImageFile = MessagesAPI.ImageFile;\n  export import ImageFileContentBlock = MessagesAPI.ImageFileContentBlock;\n  export import ImageFileDelta = MessagesAPI.ImageFileDelta;\n  export import ImageFileDeltaBlock = MessagesAPI.ImageFileDeltaBlock;\n  export import ImageURL = MessagesAPI.ImageURL;\n  export import ImageURLContentBlock = MessagesAPI.ImageURLContentBlock;\n  export import ImageURLDelta = MessagesAPI.ImageURLDelta;\n  export import ImageURLDeltaBlock = MessagesAPI.ImageURLDeltaBlock;\n  export import Message = MessagesAPI.Message;\n  export import MessageContent = MessagesAPI.MessageContent;\n  export import MessageContentDelta = MessagesAPI.MessageContentDelta;\n  export import MessageContentPartParam = MessagesAPI.MessageContentPartParam;\n  export import MessageDeleted = MessagesAPI.MessageDeleted;\n  export import MessageDelta = MessagesAPI.MessageDelta;\n  export import MessageDeltaEvent = MessagesAPI.MessageDeltaEvent;\n  export import RefusalContentBlock = MessagesAPI.RefusalContentBlock;\n  export import RefusalDeltaBlock = MessagesAPI.RefusalDeltaBlock;\n  export import Text = MessagesAPI.Text;\n  export import TextContentBlock = MessagesAPI.TextContentBlock;\n  export import TextContentBlockParam = MessagesAPI.TextContentBlockParam;\n  export import TextDelta = MessagesAPI.TextDelta;\n  export import TextDeltaBlock = MessagesAPI.TextDeltaBlock;\n  export import MessagesPage = MessagesAPI.MessagesPage;\n  export import MessageCreateParams = MessagesAPI.MessageCreateParams;\n  export import MessageUpdateParams = MessagesAPI.MessageUpdateParams;\n  export import MessageListParams = MessagesAPI.MessageListParams;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;;;;;;;AAgBhF,MAAO,gBAAgB,qIAAA,CAAA,cAAW;IAAxC,aAAA;;QACE,IAAA,CAAA,IAAI,GAAiB,IAAI,0KAAQ,IAAI,CAAC,IAAI,CAAC,OAAO;QAClD,IAAA,CAAA,QAAQ,GAAyB,IAAI,sKAAY,QAAQ,CAAC,IAAI,CAAC,OAAO;IAqGxE;IA9FE,OACE,OAAiD,CAAA,CAAE,EACnD,OAA6B,EAAA;QAE7B,IAAI,CAAA,GAAA,iJAAA,CAAA,mBAAgB,AAAhB,EAAiB,OAAO;YAC1B,OAAO,IAAI,CAAC,MAAM,CAAC,CAAA,GAAI;;QAEzB,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,YAAY;YACnC;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;QAGA,SAAS,QAAgB,EAAE,OAA6B,EAAA;QACtD,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,CAAA,SAAA,EAAY,SAAQ,CAAE,EAAE;YAC9C,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;QAGA,OAAO,QAAgB,EAAE,IAAwB,EAAE,OAA6B,EAAA;QAC9E,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,CAAA,SAAA,EAAY,SAAQ,CAAE,EAAE;YAC/C;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;QAGA,IAAI,QAAgB,EAAE,OAA6B,EAAA;QACjD,OAAO,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,CAAA,SAAA,EAAY,SAAQ,CAAE,EAAE;YACjD,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAiBA,aACE,IAA8B,EAC9B,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,iBAAiB;YACxC;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;YAC9D,QAAQ,KAAK,MAAM,IAAI;;IAE3B;IAEA;;;;QAKA,MAAM,iBACJ,IAA0C,EAC1C,OAA2D,EAAA;QAE3D,MAAM,MAAM,MAAM,IAAI,CAAC,YAAY,CAAC,MAAM;QAC1C,OAAO,MAAM,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,SAAS,EAAE,IAAI,EAAE,EAAE;IACrD;IAEA;;QAGA,mBACE,IAAwC,EACxC,OAA6B,EAAA;QAE7B,OAAO,mJAAA,CAAA,kBAAe,CAAC,2BAA2B,CAAC,MAAM,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,OAAO,EAAE;IACtF;;AA61CF,CAAA,SAAiB,OAAO;IAcR,QAAA,IAAI,GAAG,0KAAQ,IAAI;IAInB,QAAA,QAAQ,GAAG,0KAAQ,QAAQ;IAc3B,QAAA,QAAQ,GAAG,sKAAY,QAAQ;IA6B/B,QAAA,YAAY,GAAG,sKAAY,YAAY;AAIvD,CAAC,EAjEgB,WAAO,CAAP,UAAO,CAAA,CAAA"}},
    {"offset": {"line": 5715, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 5720, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/beta/vector-stores/files.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport { sleep, Uploadable, isRequestOptions } from '../../../core';\nimport * as Core from '../../../core';\nimport * as FilesAPI from './files';\nimport * as VectorStoresAPI from './vector-stores';\nimport { CursorPage, type CursorPageParams } from '../../../pagination';\n\nexport class Files extends APIResource {\n  /**\n   * Create a vector store file by attaching a\n   * [File](https://platform.openai.com/docs/api-reference/files) to a\n   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object).\n   */\n  create(\n    vectorStoreId: string,\n    body: FileCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFile> {\n    return this._client.post(`/vector_stores/${vectorStoreId}/files`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves a vector store file.\n   */\n  retrieve(\n    vectorStoreId: string,\n    fileId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFile> {\n    return this._client.get(`/vector_stores/${vectorStoreId}/files/${fileId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of vector store files.\n   */\n  list(\n    vectorStoreId: string,\n    query?: FileListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, VectorStoreFile>;\n  list(\n    vectorStoreId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, VectorStoreFile>;\n  list(\n    vectorStoreId: string,\n    query: FileListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, VectorStoreFile> {\n    if (isRequestOptions(query)) {\n      return this.list(vectorStoreId, {}, query);\n    }\n    return this._client.getAPIList(`/vector_stores/${vectorStoreId}/files`, VectorStoreFilesPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Delete a vector store file. This will remove the file from the vector store but\n   * the file itself will not be deleted. To delete the file, use the\n   * [delete file](https://platform.openai.com/docs/api-reference/files/delete)\n   * endpoint.\n   */\n  del(\n    vectorStoreId: string,\n    fileId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFileDeleted> {\n    return this._client.delete(`/vector_stores/${vectorStoreId}/files/${fileId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Attach a file to the given vector store and wait for it to be processed.\n   */\n  async createAndPoll(\n    vectorStoreId: string,\n    body: FileCreateParams,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const file = await this.create(vectorStoreId, body, options);\n    return await this.poll(vectorStoreId, file.id, options);\n  }\n\n  /**\n   * Wait for the vector store file to finish processing.\n   *\n   * Note: this will return even if the file failed to process, you need to check\n   * file.last_error and file.status to handle these cases\n   */\n  async poll(\n    vectorStoreId: string,\n    fileId: string,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const headers: { [key: string]: string } = { ...options?.headers, 'X-Stainless-Poll-Helper': 'true' };\n    if (options?.pollIntervalMs) {\n      headers['X-Stainless-Custom-Poll-Interval'] = options.pollIntervalMs.toString();\n    }\n    while (true) {\n      const fileResponse = await this.retrieve(vectorStoreId, fileId, {\n        ...options,\n        headers,\n      }).withResponse();\n\n      const file = fileResponse.data;\n\n      switch (file.status) {\n        case 'in_progress':\n          let sleepInterval = 5000;\n\n          if (options?.pollIntervalMs) {\n            sleepInterval = options.pollIntervalMs;\n          } else {\n            const headerInterval = fileResponse.response.headers.get('openai-poll-after-ms');\n            if (headerInterval) {\n              const headerIntervalMs = parseInt(headerInterval);\n              if (!isNaN(headerIntervalMs)) {\n                sleepInterval = headerIntervalMs;\n              }\n            }\n          }\n          await sleep(sleepInterval);\n          break;\n        case 'failed':\n        case 'completed':\n          return file;\n      }\n    }\n  }\n\n  /**\n   * Upload a file to the `files` API and then attach it to the given vector store.\n   *\n   * Note the file will be asynchronously processed (you can use the alternative\n   * polling helper method to wait for processing to complete).\n   */\n  async upload(\n    vectorStoreId: string,\n    file: Uploadable,\n    options?: Core.RequestOptions,\n  ): Promise<VectorStoreFile> {\n    const fileInfo = await this._client.files.create({ file: file, purpose: 'assistants' }, options);\n    return this.create(vectorStoreId, { file_id: fileInfo.id }, options);\n  }\n\n  /**\n   * Add a file to a vector store and poll until processing is complete.\n   */\n  async uploadAndPoll(\n    vectorStoreId: string,\n    file: Uploadable,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFile> {\n    const fileInfo = await this.upload(vectorStoreId, file, options);\n    return await this.poll(vectorStoreId, fileInfo.id, options);\n  }\n}\n\nexport class VectorStoreFilesPage extends CursorPage<VectorStoreFile> {}\n\n/**\n * A list of files attached to a vector store.\n */\nexport interface VectorStoreFile {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store file was created.\n   */\n  created_at: number;\n\n  /**\n   * The last error associated with this vector store file. Will be `null` if there\n   * are no errors.\n   */\n  last_error: VectorStoreFile.LastError | null;\n\n  /**\n   * The object type, which is always `vector_store.file`.\n   */\n  object: 'vector_store.file';\n\n  /**\n   * The status of the vector store file, which can be either `in_progress`,\n   * `completed`, `cancelled`, or `failed`. The status `completed` indicates that the\n   * vector store file is ready for use.\n   */\n  status: 'in_progress' | 'completed' | 'cancelled' | 'failed';\n\n  /**\n   * The total vector store usage in bytes. Note that this may be different from the\n   * original file size.\n   */\n  usage_bytes: number;\n\n  /**\n   * The ID of the\n   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n   * that the [File](https://platform.openai.com/docs/api-reference/files) is\n   * attached to.\n   */\n  vector_store_id: string;\n\n  /**\n   * The strategy used to chunk the file.\n   */\n  chunking_strategy?: VectorStoresAPI.FileChunkingStrategy;\n}\n\nexport namespace VectorStoreFile {\n  /**\n   * The last error associated with this vector store file. Will be `null` if there\n   * are no errors.\n   */\n  export interface LastError {\n    /**\n     * One of `server_error` or `rate_limit_exceeded`.\n     */\n    code: 'server_error' | 'unsupported_file' | 'invalid_file';\n\n    /**\n     * A human-readable description of the error.\n     */\n    message: string;\n  }\n}\n\nexport interface VectorStoreFileDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'vector_store.file.deleted';\n}\n\nexport interface FileCreateParams {\n  /**\n   * A [File](https://platform.openai.com/docs/api-reference/files) ID that the\n   * vector store should use. Useful for tools like `file_search` that can access\n   * files.\n   */\n  file_id: string;\n\n  /**\n   * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n   * strategy. Only applicable if `file_ids` is non-empty.\n   */\n  chunking_strategy?: VectorStoresAPI.FileChunkingStrategyParam;\n}\n\nexport interface FileListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\n   * fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.\n   */\n  filter?: 'in_progress' | 'completed' | 'failed' | 'cancelled';\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport namespace Files {\n  export import VectorStoreFile = FilesAPI.VectorStoreFile;\n  export import VectorStoreFileDeleted = FilesAPI.VectorStoreFileDeleted;\n  export import VectorStoreFilesPage = FilesAPI.VectorStoreFilesPage;\n  export import FileCreateParams = FilesAPI.FileCreateParams;\n  export import FileListParams = FilesAPI.FileListParams;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;;;;;;AAShF,MAAO,cAAc,qIAAA,CAAA,cAAW;IACpC;;;;QAKA,OACE,aAAqB,EACrB,IAAsB,EACtB,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,CAAA,eAAA,EAAkB,cAAa,MAAA,CAAQ,EAAE;YAChE;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;QAGA,SACE,aAAqB,EACrB,MAAc,EACd,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,CAAA,eAAA,EAAkB,cAAa,OAAA,EAAU,OAAM,CAAE,EAAE;YACzE,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAcA,KACE,aAAqB,EACrB,QAA8C,CAAA,CAAE,EAChD,OAA6B,EAAA;QAE7B,IAAI,CAAA,GAAA,iJAAA,CAAA,mBAAgB,AAAhB,EAAiB,QAAQ;YAC3B,OAAO,IAAI,CAAC,IAAI,CAAC,eAAe,CAAA,GAAI;;QAEtC,OAAO,IAAI,CAAC,OAAO,CAAC,UAAU,CAAC,CAAA,eAAA,EAAkB,cAAa,MAAA,CAAQ,EAAE,sBAAsB;YAC5F;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;;;;QAMA,IACE,aAAqB,EACrB,MAAc,EACd,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,CAAA,eAAA,EAAkB,cAAa,OAAA,EAAU,OAAM,CAAE,EAAE;YAC5E,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;QAGA,MAAM,cACJ,aAAqB,EACrB,IAAsB,EACtB,OAA2D,EAAA;QAE3D,MAAM,OAAO,MAAM,IAAI,CAAC,MAAM,CAAC,eAAe,MAAM;QACpD,OAAO,MAAM,IAAI,CAAC,IAAI,CAAC,eAAe,KAAK,EAAE,EAAE;IACjD;IAEA;;;;;QAMA,MAAM,KACJ,aAAqB,EACrB,MAAc,EACd,OAA2D,EAAA;QAE3D,MAAM,UAAqC;YAAE,GAAG,SAAS,OAAO;YAAE,2BAA2B;QAAM;QACnG,IAAI,SAAS,gBAAgB;YAC3B,OAAO,CAAC,mCAAmC,GAAG,QAAQ,cAAc,CAAC,QAAQ;;QAE/E,MAAO,KAAM;YACX,MAAM,eAAe,MAAM,IAAI,CAAC,QAAQ,CAAC,eAAe,QAAQ;gBAC9D,GAAG,OAAO;gBACV;eACC,YAAY;YAEf,MAAM,OAAO,aAAa,IAAI;YAE9B,OAAQ,KAAK,MAAM;gBACjB,KAAK;oBACH,IAAI,gBAAgB;oBAEpB,IAAI,SAAS,gBAAgB;wBAC3B,gBAAgB,QAAQ,cAAc;2BACjC;wBACL,MAAM,iBAAiB,aAAa,QAAQ,CAAC,OAAO,CAAC,GAAG,CAAC;wBACzD,IAAI,gBAAgB;4BAClB,MAAM,mBAAmB,SAAS;4BAClC,IAAI,CAAC,MAAM,mBAAmB;gCAC5B,gBAAgB;;;;oBAItB,MAAM,CAAA,GAAA,iJAAA,CAAA,QAAK,AAAL,EAAM;oBACZ;gBACF,KAAK;gBACL,KAAK;oBACH,OAAO;;;IAGf;IAEA;;;;;QAMA,MAAM,OACJ,aAAqB,EACrB,IAAgB,EAChB,OAA6B,EAAA;QAE7B,MAAM,WAAW,MAAM,IAAI,CAAC,OAAO,CAAC,KAAK,CAAC,MAAM,CAAC;YAAE,MAAM;YAAM,SAAS;QAAY,GAAI;QACxF,OAAO,IAAI,CAAC,MAAM,CAAC,eAAe;YAAE,SAAS,SAAS,EAAE;QAAA,GAAI;IAC9D;IAEA;;QAGA,MAAM,cACJ,aAAqB,EACrB,IAAgB,EAChB,OAA2D,EAAA;QAE3D,MAAM,WAAW,MAAM,IAAI,CAAC,MAAM,CAAC,eAAe,MAAM;QACxD,OAAO,MAAM,IAAI,CAAC,IAAI,CAAC,eAAe,SAAS,EAAE,EAAE;IACrD;;AAGI,MAAO,6BAA6B,uIAAA,CAAA,aAA2B;;AAoHrE,CAAA,SAAiB,KAAK;IAGN,MAAA,oBAAoB,GAAG,4KAAS,oBAAoB;AAGpE,CAAC,EANgB,SAAK,CAAL,QAAK,CAAA,CAAA"}},
    {"offset": {"line": 5860, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 5865, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/lib/Util.ts"],"sourcesContent":["/**\n * Like `Promise.allSettled()` but throws an error if any promises are rejected.\n */\nexport const allSettledWithThrow = async <R>(promises: Promise<R>[]): Promise<R[]> => {\n  const results = await Promise.allSettled(promises);\n  const rejected = results.filter((result): result is PromiseRejectedResult => result.status === 'rejected');\n  if (rejected.length) {\n    for (const result of rejected) {\n      console.error(result.reason);\n    }\n\n    throw new Error(`${rejected.length} promise(s) failed - see the above errors`);\n  }\n\n  // Note: TS was complaining about using `.filter().map()` here for some reason\n  const values: R[] = [];\n  for (const result of results) {\n    if (result.status === 'fulfilled') {\n      values.push(result.value);\n    }\n  }\n  return values;\n};\n"],"names":[],"mappings":"AAAA;;;;;AAGO,MAAM,sBAAsB,OAAU;IAC3C,MAAM,UAAU,MAAM,QAAQ,UAAU,CAAC;IACzC,MAAM,WAAW,QAAQ,MAAM,CAAC,CAAC,SAA4C,OAAO,MAAM,KAAK;IAC/F,IAAI,SAAS,MAAM,EAAE;QACnB,KAAK,MAAM,UAAU,SAAU;YAC7B,QAAQ,KAAK,CAAC,OAAO,MAAM;;QAG7B,MAAM,IAAI,MAAM,CAAA,EAAG,SAAS,MAAM,CAAA,yCAAA,CAA2C;;IAG/E,8EAA8E;IAC9E,MAAM,SAAc,EAAE;IACtB,KAAK,MAAM,UAAU,QAAS;QAC5B,IAAI,OAAO,MAAM,KAAK,aAAa;YACjC,OAAO,IAAI,CAAC,OAAO,KAAK;;;IAG5B,OAAO;AACT"}},
    {"offset": {"line": 5888, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 5893, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/beta/vector-stores/file-batches.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport { sleep } from '../../../core';\nimport { Uploadable } from '../../../core';\nimport { allSettledWithThrow } from '../../../lib/Util';\nimport * as Core from '../../../core';\nimport * as FileBatchesAPI from './file-batches';\nimport * as FilesAPI from './files';\nimport { VectorStoreFilesPage } from './files';\nimport * as VectorStoresAPI from './vector-stores';\nimport { type CursorPageParams } from '../../../pagination';\n\nexport class FileBatches extends APIResource {\n  /**\n   * Create a vector store file batch.\n   */\n  create(\n    vectorStoreId: string,\n    body: FileBatchCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFileBatch> {\n    return this._client.post(`/vector_stores/${vectorStoreId}/file_batches`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves a vector store file batch.\n   */\n  retrieve(\n    vectorStoreId: string,\n    batchId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFileBatch> {\n    return this._client.get(`/vector_stores/${vectorStoreId}/file_batches/${batchId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Cancel a vector store file batch. This attempts to cancel the processing of\n   * files in this batch as soon as possible.\n   */\n  cancel(\n    vectorStoreId: string,\n    batchId: string,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStoreFileBatch> {\n    return this._client.post(`/vector_stores/${vectorStoreId}/file_batches/${batchId}/cancel`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Create a vector store batch and poll until all files have been processed.\n   */\n  async createAndPoll(\n    vectorStoreId: string,\n    body: FileBatchCreateParams,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFileBatch> {\n    const batch = await this.create(vectorStoreId, body);\n    return await this.poll(vectorStoreId, batch.id, options);\n  }\n\n  /**\n   * Returns a list of vector store files in a batch.\n   */\n  listFiles(\n    vectorStoreId: string,\n    batchId: string,\n    query?: FileBatchListFilesParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, FilesAPI.VectorStoreFile>;\n  listFiles(\n    vectorStoreId: string,\n    batchId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, FilesAPI.VectorStoreFile>;\n  listFiles(\n    vectorStoreId: string,\n    batchId: string,\n    query: FileBatchListFilesParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoreFilesPage, FilesAPI.VectorStoreFile> {\n    if (isRequestOptions(query)) {\n      return this.listFiles(vectorStoreId, batchId, {}, query);\n    }\n    return this._client.getAPIList(\n      `/vector_stores/${vectorStoreId}/file_batches/${batchId}/files`,\n      VectorStoreFilesPage,\n      { query, ...options, headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers } },\n    );\n  }\n\n  /**\n   * Wait for the given file batch to be processed.\n   *\n   * Note: this will return even if one of the files failed to process, you need to\n   * check batch.file_counts.failed_count to handle this case.\n   */\n  async poll(\n    vectorStoreId: string,\n    batchId: string,\n    options?: Core.RequestOptions & { pollIntervalMs?: number },\n  ): Promise<VectorStoreFileBatch> {\n    const headers: { [key: string]: string } = { ...options?.headers, 'X-Stainless-Poll-Helper': 'true' };\n    if (options?.pollIntervalMs) {\n      headers['X-Stainless-Custom-Poll-Interval'] = options.pollIntervalMs.toString();\n    }\n\n    while (true) {\n      const { data: batch, response } = await this.retrieve(vectorStoreId, batchId, {\n        ...options,\n        headers,\n      }).withResponse();\n\n      switch (batch.status) {\n        case 'in_progress':\n          let sleepInterval = 5000;\n\n          if (options?.pollIntervalMs) {\n            sleepInterval = options.pollIntervalMs;\n          } else {\n            const headerInterval = response.headers.get('openai-poll-after-ms');\n            if (headerInterval) {\n              const headerIntervalMs = parseInt(headerInterval);\n              if (!isNaN(headerIntervalMs)) {\n                sleepInterval = headerIntervalMs;\n              }\n            }\n          }\n          await sleep(sleepInterval);\n          break;\n        case 'failed':\n        case 'cancelled':\n        case 'completed':\n          return batch;\n      }\n    }\n  }\n\n  /**\n   * Uploads the given files concurrently and then creates a vector store file batch.\n   *\n   * The concurrency limit is configurable using the `maxConcurrency` parameter.\n   */\n  async uploadAndPoll(\n    vectorStoreId: string,\n    { files, fileIds = [] }: { files: Uploadable[]; fileIds?: string[] },\n    options?: Core.RequestOptions & { pollIntervalMs?: number; maxConcurrency?: number },\n  ): Promise<VectorStoreFileBatch> {\n    if (files == null || files.length == 0) {\n      throw new Error(\n        `No \\`files\\` provided to process. If you've already uploaded files you should use \\`.createAndPoll()\\` instead`,\n      );\n    }\n\n    const configuredConcurrency = options?.maxConcurrency ?? 5;\n\n    // We cap the number of workers at the number of files (so we don't start any unnecessary workers)\n    const concurrencyLimit = Math.min(configuredConcurrency, files.length);\n\n    const client = this._client;\n    const fileIterator = files.values();\n    const allFileIds: string[] = [...fileIds];\n\n    // This code is based on this design. The libraries don't accommodate our environment limits.\n    // https://stackoverflow.com/questions/40639432/what-is-the-best-way-to-limit-concurrency-when-using-es6s-promise-all\n    async function processFiles(iterator: IterableIterator<Uploadable>) {\n      for (let item of iterator) {\n        const fileObj = await client.files.create({ file: item, purpose: 'assistants' }, options);\n        allFileIds.push(fileObj.id);\n      }\n    }\n\n    // Start workers to process results\n    const workers = Array(concurrencyLimit).fill(fileIterator).map(processFiles);\n\n    // Wait for all processing to complete.\n    await allSettledWithThrow(workers);\n\n    return await this.createAndPoll(vectorStoreId, {\n      file_ids: allFileIds,\n    });\n  }\n}\n\n/**\n * A batch of files attached to a vector store.\n */\nexport interface VectorStoreFileBatch {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store files batch was\n   * created.\n   */\n  created_at: number;\n\n  file_counts: VectorStoreFileBatch.FileCounts;\n\n  /**\n   * The object type, which is always `vector_store.file_batch`.\n   */\n  object: 'vector_store.files_batch';\n\n  /**\n   * The status of the vector store files batch, which can be either `in_progress`,\n   * `completed`, `cancelled` or `failed`.\n   */\n  status: 'in_progress' | 'completed' | 'cancelled' | 'failed';\n\n  /**\n   * The ID of the\n   * [vector store](https://platform.openai.com/docs/api-reference/vector-stores/object)\n   * that the [File](https://platform.openai.com/docs/api-reference/files) is\n   * attached to.\n   */\n  vector_store_id: string;\n}\n\nexport namespace VectorStoreFileBatch {\n  export interface FileCounts {\n    /**\n     * The number of files that where cancelled.\n     */\n    cancelled: number;\n\n    /**\n     * The number of files that have been processed.\n     */\n    completed: number;\n\n    /**\n     * The number of files that have failed to process.\n     */\n    failed: number;\n\n    /**\n     * The number of files that are currently being processed.\n     */\n    in_progress: number;\n\n    /**\n     * The total number of files.\n     */\n    total: number;\n  }\n}\n\nexport interface FileBatchCreateParams {\n  /**\n   * A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that\n   * the vector store should use. Useful for tools like `file_search` that can access\n   * files.\n   */\n  file_ids: Array<string>;\n\n  /**\n   * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n   * strategy. Only applicable if `file_ids` is non-empty.\n   */\n  chunking_strategy?: VectorStoresAPI.FileChunkingStrategyParam;\n}\n\nexport interface FileBatchListFilesParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\n   * fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Filter by file status. One of `in_progress`, `completed`, `failed`, `cancelled`.\n   */\n  filter?: 'in_progress' | 'completed' | 'failed' | 'cancelled';\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport namespace FileBatches {\n  export import VectorStoreFileBatch = FileBatchesAPI.VectorStoreFileBatch;\n  export import FileBatchCreateParams = FileBatchesAPI.FileBatchCreateParams;\n  export import FileBatchListFilesParams = FileBatchesAPI.FileBatchListFilesParams;\n}\n\nexport { VectorStoreFilesPage };\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;;;;;;AAchF,MAAO,oBAAoB,qIAAA,CAAA,cAAW;IAC1C;;QAGA,OACE,aAAqB,EACrB,IAA2B,EAC3B,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,CAAA,eAAA,EAAkB,cAAa,aAAA,CAAe,EAAE;YACvE;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;QAGA,SACE,aAAqB,EACrB,OAAe,EACf,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,CAAA,eAAA,EAAkB,cAAa,cAAA,EAAiB,QAAO,CAAE,EAAE;YACjF,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;;QAIA,OACE,aAAqB,EACrB,OAAe,EACf,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,CAAA,eAAA,EAAkB,cAAa,cAAA,EAAiB,QAAO,OAAA,CAAS,EAAE;YACzF,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;QAGA,MAAM,cACJ,aAAqB,EACrB,IAA2B,EAC3B,OAA2D,EAAA;QAE3D,MAAM,QAAQ,MAAM,IAAI,CAAC,MAAM,CAAC,eAAe;QAC/C,OAAO,MAAM,IAAI,CAAC,IAAI,CAAC,eAAe,MAAM,EAAE,EAAE;IAClD;IAgBA,UACE,aAAqB,EACrB,OAAe,EACf,QAAwD,CAAA,CAAE,EAC1D,OAA6B,EAAA;QAE7B,IAAI,CAAA,GAAA,iJAAA,CAAA,mBAAgB,AAAhB,EAAiB,QAAQ;YAC3B,OAAO,IAAI,CAAC,SAAS,CAAC,eAAe,SAAS,CAAA,GAAI;;QAEpD,OAAO,IAAI,CAAC,OAAO,CAAC,UAAU,CAC5B,CAAA,eAAA,EAAkB,cAAa,cAAA,EAAiB,QAAO,MAAA,CAAQ,EAC/D,2KAAA,CAAA,uBAAoB,EACpB;YAAE;YAAO,GAAG,OAAO;YAAE,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;QAAE;IAEzF;IAEA;;;;;QAMA,MAAM,KACJ,aAAqB,EACrB,OAAe,EACf,OAA2D,EAAA;QAE3D,MAAM,UAAqC;YAAE,GAAG,SAAS,OAAO;YAAE,2BAA2B;QAAM;QACnG,IAAI,SAAS,gBAAgB;YAC3B,OAAO,CAAC,mCAAmC,GAAG,QAAQ,cAAc,CAAC,QAAQ;;QAG/E,MAAO,KAAM;YACX,MAAM,EAAE,MAAM,KAAK,EAAE,QAAQ,EAAE,GAAG,MAAM,IAAI,CAAC,QAAQ,CAAC,eAAe,SAAS;gBAC5E,GAAG,OAAO;gBACV;eACC,YAAY;YAEf,OAAQ,MAAM,MAAM;gBAClB,KAAK;oBACH,IAAI,gBAAgB;oBAEpB,IAAI,SAAS,gBAAgB;wBAC3B,gBAAgB,QAAQ,cAAc;2BACjC;wBACL,MAAM,iBAAiB,SAAS,OAAO,CAAC,GAAG,CAAC;wBAC5C,IAAI,gBAAgB;4BAClB,MAAM,mBAAmB,SAAS;4BAClC,IAAI,CAAC,MAAM,mBAAmB;gCAC5B,gBAAgB;;;;oBAItB,MAAM,CAAA,GAAA,iJAAA,CAAA,QAAK,AAAL,EAAM;oBACZ;gBACF,KAAK;gBACL,KAAK;gBACL,KAAK;oBACH,OAAO;;;IAGf;IAEA;;;;QAKA,MAAM,cACJ,aAAqB,EACrB,EAAE,KAAK,EAAE,UAAU,EAAE,EAA+C,EACpE,OAAoF,EAAA;QAEpF,IAAI,SAAS,QAAQ,MAAM,MAAM,IAAI,GAAG;YACtC,MAAM,IAAI,MACR,CAAA,8GAAA,CAAgH;;QAIpH,MAAM,wBAAwB,SAAS,kBAAkB;QAEzD,kGAAkG;QAClG,MAAM,mBAAmB,KAAK,GAAG,CAAC,uBAAuB,MAAM,MAAM;QAErE,MAAM,SAAS,IAAI,CAAC,OAAO;QAC3B,MAAM,eAAe,MAAM,MAAM;QACjC,MAAM,aAAuB;eAAI;SAAQ;QAEzC,6FAA6F;QAC7F,qHAAqH;QACrH,eAAe,aAAa,QAAsC;YAChE,KAAK,IAAI,QAAQ,SAAU;gBACzB,MAAM,UAAU,MAAM,OAAO,KAAK,CAAC,MAAM,CAAC;oBAAE,MAAM;oBAAM,SAAS;gBAAY,GAAI;gBACjF,WAAW,IAAI,CAAC,QAAQ,EAAE;;QAE9B;QAEA,mCAAmC;QACnC,MAAM,UAAU,MAAM,kBAAkB,IAAI,CAAC,cAAc,GAAG,CAAC;QAE/D,uCAAuC;QACvC,MAAM,CAAA,GAAA,wIAAA,CAAA,sBAAmB,AAAnB,EAAoB;QAE1B,OAAO,MAAM,IAAI,CAAC,aAAa,CAAC,eAAe;YAC7C,UAAU;;IAEd;;AAyGF,CAAA,SAAiB,WAAW,GAI5B,CAAC,EAJgB,eAAW,CAAX,cAAW,CAAA,CAAA"}},
    {"offset": {"line": 6042, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6079, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/beta/vector-stores/vector-stores.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport * as Core from '../../../core';\nimport * as VectorStoresAPI from './vector-stores';\nimport * as FileBatchesAPI from './file-batches';\nimport * as FilesAPI from './files';\nimport { CursorPage, type CursorPageParams } from '../../../pagination';\n\nexport class VectorStores extends APIResource {\n  files: FilesAPI.Files = new FilesAPI.Files(this._client);\n  fileBatches: FileBatchesAPI.FileBatches = new FileBatchesAPI.FileBatches(this._client);\n\n  /**\n   * Create a vector store.\n   */\n  create(body: VectorStoreCreateParams, options?: Core.RequestOptions): Core.APIPromise<VectorStore> {\n    return this._client.post('/vector_stores', {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Retrieves a vector store.\n   */\n  retrieve(vectorStoreId: string, options?: Core.RequestOptions): Core.APIPromise<VectorStore> {\n    return this._client.get(`/vector_stores/${vectorStoreId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Modifies a vector store.\n   */\n  update(\n    vectorStoreId: string,\n    body: VectorStoreUpdateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<VectorStore> {\n    return this._client.post(`/vector_stores/${vectorStoreId}`, {\n      body,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Returns a list of vector stores.\n   */\n  list(\n    query?: VectorStoreListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoresPage, VectorStore>;\n  list(options?: Core.RequestOptions): Core.PagePromise<VectorStoresPage, VectorStore>;\n  list(\n    query: VectorStoreListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<VectorStoresPage, VectorStore> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/vector_stores', VectorStoresPage, {\n      query,\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n\n  /**\n   * Delete a vector store.\n   */\n  del(vectorStoreId: string, options?: Core.RequestOptions): Core.APIPromise<VectorStoreDeleted> {\n    return this._client.delete(`/vector_stores/${vectorStoreId}`, {\n      ...options,\n      headers: { 'OpenAI-Beta': 'assistants=v2', ...options?.headers },\n    });\n  }\n}\n\nexport class VectorStoresPage extends CursorPage<VectorStore> {}\n\n/**\n * The default strategy. This strategy currently uses a `max_chunk_size_tokens` of\n * `800` and `chunk_overlap_tokens` of `400`.\n */\nexport interface AutoFileChunkingStrategyParam {\n  /**\n   * Always `auto`.\n   */\n  type: 'auto';\n}\n\n/**\n * The strategy used to chunk the file.\n */\nexport type FileChunkingStrategy = StaticFileChunkingStrategyObject | OtherFileChunkingStrategyObject;\n\n/**\n * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n * strategy. Only applicable if `file_ids` is non-empty.\n */\nexport type FileChunkingStrategyParam = AutoFileChunkingStrategyParam | StaticFileChunkingStrategyParam;\n\n/**\n * This is returned when the chunking strategy is unknown. Typically, this is\n * because the file was indexed before the `chunking_strategy` concept was\n * introduced in the API.\n */\nexport interface OtherFileChunkingStrategyObject {\n  /**\n   * Always `other`.\n   */\n  type: 'other';\n}\n\nexport interface StaticFileChunkingStrategy {\n  /**\n   * The number of tokens that overlap between chunks. The default value is `400`.\n   *\n   * Note that the overlap must not exceed half of `max_chunk_size_tokens`.\n   */\n  chunk_overlap_tokens: number;\n\n  /**\n   * The maximum number of tokens in each chunk. The default value is `800`. The\n   * minimum value is `100` and the maximum value is `4096`.\n   */\n  max_chunk_size_tokens: number;\n}\n\nexport interface StaticFileChunkingStrategyObject {\n  static: StaticFileChunkingStrategy;\n\n  /**\n   * Always `static`.\n   */\n  type: 'static';\n}\n\nexport interface StaticFileChunkingStrategyParam {\n  static: StaticFileChunkingStrategy;\n\n  /**\n   * Always `static`.\n   */\n  type: 'static';\n}\n\n/**\n * A vector store is a collection of processed files can be used by the\n * `file_search` tool.\n */\nexport interface VectorStore {\n  /**\n   * The identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store was created.\n   */\n  created_at: number;\n\n  file_counts: VectorStore.FileCounts;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store was last active.\n   */\n  last_active_at: number | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata: unknown | null;\n\n  /**\n   * The name of the vector store.\n   */\n  name: string;\n\n  /**\n   * The object type, which is always `vector_store`.\n   */\n  object: 'vector_store';\n\n  /**\n   * The status of the vector store, which can be either `expired`, `in_progress`, or\n   * `completed`. A status of `completed` indicates that the vector store is ready\n   * for use.\n   */\n  status: 'expired' | 'in_progress' | 'completed';\n\n  /**\n   * The total number of bytes used by the files in the vector store.\n   */\n  usage_bytes: number;\n\n  /**\n   * The expiration policy for a vector store.\n   */\n  expires_after?: VectorStore.ExpiresAfter;\n\n  /**\n   * The Unix timestamp (in seconds) for when the vector store will expire.\n   */\n  expires_at?: number | null;\n}\n\nexport namespace VectorStore {\n  export interface FileCounts {\n    /**\n     * The number of files that were cancelled.\n     */\n    cancelled: number;\n\n    /**\n     * The number of files that have been successfully processed.\n     */\n    completed: number;\n\n    /**\n     * The number of files that have failed to process.\n     */\n    failed: number;\n\n    /**\n     * The number of files that are currently being processed.\n     */\n    in_progress: number;\n\n    /**\n     * The total number of files.\n     */\n    total: number;\n  }\n\n  /**\n   * The expiration policy for a vector store.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `last_active_at`.\n     */\n    anchor: 'last_active_at';\n\n    /**\n     * The number of days after the anchor time that the vector store will expire.\n     */\n    days: number;\n  }\n}\n\nexport interface VectorStoreDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'vector_store.deleted';\n}\n\nexport interface VectorStoreCreateParams {\n  /**\n   * The chunking strategy used to chunk the file(s). If not set, will use the `auto`\n   * strategy. Only applicable if `file_ids` is non-empty.\n   */\n  chunking_strategy?: FileChunkingStrategyParam;\n\n  /**\n   * The expiration policy for a vector store.\n   */\n  expires_after?: VectorStoreCreateParams.ExpiresAfter;\n\n  /**\n   * A list of [File](https://platform.openai.com/docs/api-reference/files) IDs that\n   * the vector store should use. Useful for tools like `file_search` that can access\n   * files.\n   */\n  file_ids?: Array<string>;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The name of the vector store.\n   */\n  name?: string;\n}\n\nexport namespace VectorStoreCreateParams {\n  /**\n   * The expiration policy for a vector store.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `last_active_at`.\n     */\n    anchor: 'last_active_at';\n\n    /**\n     * The number of days after the anchor time that the vector store will expire.\n     */\n    days: number;\n  }\n}\n\nexport interface VectorStoreUpdateParams {\n  /**\n   * The expiration policy for a vector store.\n   */\n  expires_after?: VectorStoreUpdateParams.ExpiresAfter | null;\n\n  /**\n   * Set of 16 key-value pairs that can be attached to an object. This can be useful\n   * for storing additional information about the object in a structured format. Keys\n   * can be a maximum of 64 characters long and values can be a maxium of 512\n   * characters long.\n   */\n  metadata?: unknown | null;\n\n  /**\n   * The name of the vector store.\n   */\n  name?: string | null;\n}\n\nexport namespace VectorStoreUpdateParams {\n  /**\n   * The expiration policy for a vector store.\n   */\n  export interface ExpiresAfter {\n    /**\n     * Anchor timestamp after which the expiration policy applies. Supported anchors:\n     * `last_active_at`.\n     */\n    anchor: 'last_active_at';\n\n    /**\n     * The number of days after the anchor time that the vector store will expire.\n     */\n    days: number;\n  }\n}\n\nexport interface VectorStoreListParams extends CursorPageParams {\n  /**\n   * A cursor for use in pagination. `before` is an object ID that defines your place\n   * in the list. For instance, if you make a list request and receive 100 objects,\n   * ending with obj_foo, your subsequent call can include before=obj_foo in order to\n   * fetch the previous page of the list.\n   */\n  before?: string;\n\n  /**\n   * Sort order by the `created_at` timestamp of the objects. `asc` for ascending\n   * order and `desc` for descending order.\n   */\n  order?: 'asc' | 'desc';\n}\n\nexport namespace VectorStores {\n  export import AutoFileChunkingStrategyParam = VectorStoresAPI.AutoFileChunkingStrategyParam;\n  export import FileChunkingStrategy = VectorStoresAPI.FileChunkingStrategy;\n  export import FileChunkingStrategyParam = VectorStoresAPI.FileChunkingStrategyParam;\n  export import OtherFileChunkingStrategyObject = VectorStoresAPI.OtherFileChunkingStrategyObject;\n  export import StaticFileChunkingStrategy = VectorStoresAPI.StaticFileChunkingStrategy;\n  export import StaticFileChunkingStrategyObject = VectorStoresAPI.StaticFileChunkingStrategyObject;\n  export import StaticFileChunkingStrategyParam = VectorStoresAPI.StaticFileChunkingStrategyParam;\n  export import VectorStore = VectorStoresAPI.VectorStore;\n  export import VectorStoreDeleted = VectorStoresAPI.VectorStoreDeleted;\n  export import VectorStoresPage = VectorStoresAPI.VectorStoresPage;\n  export import VectorStoreCreateParams = VectorStoresAPI.VectorStoreCreateParams;\n  export import VectorStoreUpdateParams = VectorStoresAPI.VectorStoreUpdateParams;\n  export import VectorStoreListParams = VectorStoresAPI.VectorStoreListParams;\n  export import Files = FilesAPI.Files;\n  export import VectorStoreFile = FilesAPI.VectorStoreFile;\n  export import VectorStoreFileDeleted = FilesAPI.VectorStoreFileDeleted;\n  export import VectorStoreFilesPage = FilesAPI.VectorStoreFilesPage;\n  export import FileCreateParams = FilesAPI.FileCreateParams;\n  export import FileListParams = FilesAPI.FileListParams;\n  export import FileBatches = FileBatchesAPI.FileBatches;\n  export import VectorStoreFileBatch = FileBatchesAPI.VectorStoreFileBatch;\n  export import FileBatchCreateParams = FileBatchesAPI.FileBatchCreateParams;\n  export import FileBatchListFilesParams = FileBatchesAPI.FileBatchListFilesParams;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;;;;;;;;;;AAUhF,MAAO,qBAAqB,qIAAA,CAAA,cAAW;IAA7C,aAAA;;QACE,IAAA,CAAA,KAAK,GAAmB,IAAI,4KAAS,KAAK,CAAC,IAAI,CAAC,OAAO;QACvD,IAAA,CAAA,WAAW,GAA+B,IAAI,sMAAe,WAAW,CAAC,IAAI,CAAC,OAAO;IAqEvF;IAnEE;;QAGA,OAAO,IAA6B,EAAE,OAA6B,EAAA;QACjE,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,kBAAkB;YACzC;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;QAGA,SAAS,aAAqB,EAAE,OAA6B,EAAA;QAC3D,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,CAAA,eAAA,EAAkB,cAAa,CAAE,EAAE;YACzD,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;QAGA,OACE,aAAqB,EACrB,IAA6B,EAC7B,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,CAAA,eAAA,EAAkB,cAAa,CAAE,EAAE;YAC1D;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAUA,KACE,QAAqD,CAAA,CAAE,EACvD,OAA6B,EAAA;QAE7B,IAAI,CAAA,GAAA,iJAAA,CAAA,mBAAgB,AAAhB,EAAiB,QAAQ;YAC3B,OAAO,IAAI,CAAC,IAAI,CAAC,CAAA,GAAI;;QAEvB,OAAO,IAAI,CAAC,OAAO,CAAC,UAAU,CAAC,kBAAkB,kBAAkB;YACjE;YACA,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;IAEA;;QAGA,IAAI,aAAqB,EAAE,OAA6B,EAAA;QACtD,OAAO,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,CAAA,eAAA,EAAkB,cAAa,CAAE,EAAE;YAC5D,GAAG,OAAO;YACV,SAAS;gBAAE,eAAe;gBAAiB,GAAG,SAAS,OAAO;YAAA;;IAElE;;AAGI,MAAO,yBAAyB,uIAAA,CAAA,aAAuB;;AAkS7D,CAAA,SAAiB,YAAY;IAUb,aAAA,gBAAgB,GAAG,uLAAgB,gBAAgB;IAInD,aAAA,KAAK,GAAG,4KAAS,KAAK;IAGtB,aAAA,oBAAoB,GAAG,4KAAS,oBAAoB;IAGpD,aAAA,WAAW,GAAG,sMAAe,WAAW;AAIxD,CAAC,EAxBgB,gBAAY,CAAZ,eAAY,CAAA,CAAA"}},
    {"offset": {"line": 6171, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6176, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/beta/beta.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as AssistantsAPI from './assistants';\nimport * as ChatAPI from './chat/chat';\nimport * as ThreadsAPI from './threads/threads';\nimport * as VectorStoresAPI from './vector-stores/vector-stores';\n\nexport class Beta extends APIResource {\n  vectorStores: VectorStoresAPI.VectorStores = new VectorStoresAPI.VectorStores(this._client);\n  chat: ChatAPI.Chat = new ChatAPI.Chat(this._client);\n  assistants: AssistantsAPI.Assistants = new AssistantsAPI.Assistants(this._client);\n  threads: ThreadsAPI.Threads = new ThreadsAPI.Threads(this._client);\n}\n\nexport namespace Beta {\n  export import VectorStores = VectorStoresAPI.VectorStores;\n  export import AutoFileChunkingStrategyParam = VectorStoresAPI.AutoFileChunkingStrategyParam;\n  export import FileChunkingStrategy = VectorStoresAPI.FileChunkingStrategy;\n  export import FileChunkingStrategyParam = VectorStoresAPI.FileChunkingStrategyParam;\n  export import OtherFileChunkingStrategyObject = VectorStoresAPI.OtherFileChunkingStrategyObject;\n  export import StaticFileChunkingStrategy = VectorStoresAPI.StaticFileChunkingStrategy;\n  export import StaticFileChunkingStrategyObject = VectorStoresAPI.StaticFileChunkingStrategyObject;\n  export import StaticFileChunkingStrategyParam = VectorStoresAPI.StaticFileChunkingStrategyParam;\n  export import VectorStore = VectorStoresAPI.VectorStore;\n  export import VectorStoreDeleted = VectorStoresAPI.VectorStoreDeleted;\n  export import VectorStoresPage = VectorStoresAPI.VectorStoresPage;\n  export import VectorStoreCreateParams = VectorStoresAPI.VectorStoreCreateParams;\n  export import VectorStoreUpdateParams = VectorStoresAPI.VectorStoreUpdateParams;\n  export import VectorStoreListParams = VectorStoresAPI.VectorStoreListParams;\n  export import Chat = ChatAPI.Chat;\n  export import Assistants = AssistantsAPI.Assistants;\n  export import Assistant = AssistantsAPI.Assistant;\n  export import AssistantDeleted = AssistantsAPI.AssistantDeleted;\n  export import AssistantStreamEvent = AssistantsAPI.AssistantStreamEvent;\n  export import AssistantTool = AssistantsAPI.AssistantTool;\n  export import CodeInterpreterTool = AssistantsAPI.CodeInterpreterTool;\n  export import FileSearchTool = AssistantsAPI.FileSearchTool;\n  export import FunctionTool = AssistantsAPI.FunctionTool;\n  export import MessageStreamEvent = AssistantsAPI.MessageStreamEvent;\n  export import RunStepStreamEvent = AssistantsAPI.RunStepStreamEvent;\n  export import RunStreamEvent = AssistantsAPI.RunStreamEvent;\n  export import ThreadStreamEvent = AssistantsAPI.ThreadStreamEvent;\n  export import AssistantsPage = AssistantsAPI.AssistantsPage;\n  export import AssistantCreateParams = AssistantsAPI.AssistantCreateParams;\n  export import AssistantUpdateParams = AssistantsAPI.AssistantUpdateParams;\n  export import AssistantListParams = AssistantsAPI.AssistantListParams;\n  export import Threads = ThreadsAPI.Threads;\n  export import AssistantResponseFormatOption = ThreadsAPI.AssistantResponseFormatOption;\n  export import AssistantToolChoice = ThreadsAPI.AssistantToolChoice;\n  export import AssistantToolChoiceFunction = ThreadsAPI.AssistantToolChoiceFunction;\n  export import AssistantToolChoiceOption = ThreadsAPI.AssistantToolChoiceOption;\n  export import Thread = ThreadsAPI.Thread;\n  export import ThreadDeleted = ThreadsAPI.ThreadDeleted;\n  export import ThreadCreateParams = ThreadsAPI.ThreadCreateParams;\n  export import ThreadUpdateParams = ThreadsAPI.ThreadUpdateParams;\n  export import ThreadCreateAndRunParams = ThreadsAPI.ThreadCreateAndRunParams;\n  export import ThreadCreateAndRunParamsNonStreaming = ThreadsAPI.ThreadCreateAndRunParamsNonStreaming;\n  export import ThreadCreateAndRunParamsStreaming = ThreadsAPI.ThreadCreateAndRunParamsStreaming;\n  export import ThreadCreateAndRunPollParams = ThreadsAPI.ThreadCreateAndRunPollParams;\n  export import ThreadCreateAndRunStreamParams = ThreadsAPI.ThreadCreateAndRunStreamParams;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;;;;;;;AAQhF,MAAO,aAAa,qIAAA,CAAA,cAAW;IAArC,aAAA;;QACE,IAAA,CAAA,YAAY,GAAiC,IAAI,uLAAgB,YAAY,CAAC,IAAI,CAAC,OAAO;QAC1F,IAAA,CAAA,IAAI,GAAiB,IAAI,+JAAQ,IAAI,CAAC,IAAI,CAAC,OAAO;QAClD,IAAA,CAAA,UAAU,GAA6B,IAAI,6JAAc,UAAU,CAAC,IAAI,CAAC,OAAO;QAChF,IAAA,CAAA,OAAO,GAAuB,IAAI,qKAAW,OAAO,CAAC,IAAI,CAAC,OAAO;IACnE;;AAEA,CAAA,SAAiB,IAAI;IACL,KAAA,YAAY,GAAG,uLAAgB,YAAY;IAU3C,KAAA,gBAAgB,GAAG,uLAAgB,gBAAgB;IAInD,KAAA,IAAI,GAAG,+JAAQ,IAAI;IACnB,KAAA,UAAU,GAAG,6JAAc,UAAU;IAYrC,KAAA,cAAc,GAAG,6JAAc,cAAc;IAI7C,KAAA,OAAO,GAAG,qKAAW,OAAO;AAc5C,CAAC,EA9CgB,QAAI,CAAJ,OAAI,CAAA,CAAA"}},
    {"offset": {"line": 6208, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6213, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/completions.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport { APIPromise } from '../core';\nimport * as Core from '../core';\nimport * as CompletionsAPI from './completions';\nimport * as ChatCompletionsAPI from './chat/completions';\nimport { Stream } from '../streaming';\n\nexport class Completions extends APIResource {\n  /**\n   * Creates a completion for the provided prompt and parameters.\n   */\n  create(body: CompletionCreateParamsNonStreaming, options?: Core.RequestOptions): APIPromise<Completion>;\n  create(\n    body: CompletionCreateParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<Completion>>;\n  create(\n    body: CompletionCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<Completion> | Completion>;\n  create(\n    body: CompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<Completion> | APIPromise<Stream<Completion>> {\n    return this._client.post('/completions', { body, ...options, stream: body.stream ?? false }) as\n      | APIPromise<Completion>\n      | APIPromise<Stream<Completion>>;\n  }\n}\n\n/**\n * Represents a completion response from the API. Note: both the streamed and\n * non-streamed response objects share the same shape (unlike the chat endpoint).\n */\nexport interface Completion {\n  /**\n   * A unique identifier for the completion.\n   */\n  id: string;\n\n  /**\n   * The list of completion choices the model generated for the input prompt.\n   */\n  choices: Array<CompletionChoice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the completion was created.\n   */\n  created: number;\n\n  /**\n   * The model used for completion.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always \"text_completion\"\n   */\n  object: 'text_completion';\n\n  /**\n   * This fingerprint represents the backend configuration that the model runs with.\n   *\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n\n  /**\n   * Usage statistics for the completion request.\n   */\n  usage?: CompletionUsage;\n}\n\nexport interface CompletionChoice {\n  /**\n   * The reason the model stopped generating tokens. This will be `stop` if the model\n   * hit a natural stop point or a provided stop sequence, `length` if the maximum\n   * number of tokens specified in the request was reached, or `content_filter` if\n   * content was omitted due to a flag from our content filters.\n   */\n  finish_reason: 'stop' | 'length' | 'content_filter';\n\n  index: number;\n\n  logprobs: CompletionChoice.Logprobs | null;\n\n  text: string;\n}\n\nexport namespace CompletionChoice {\n  export interface Logprobs {\n    text_offset?: Array<number>;\n\n    token_logprobs?: Array<number>;\n\n    tokens?: Array<string>;\n\n    top_logprobs?: Array<Record<string, number>>;\n  }\n}\n\n/**\n * Usage statistics for the completion request.\n */\nexport interface CompletionUsage {\n  /**\n   * Number of tokens in the generated completion.\n   */\n  completion_tokens: number;\n\n  /**\n   * Number of tokens in the prompt.\n   */\n  prompt_tokens: number;\n\n  /**\n   * Total number of tokens used in the request (prompt + completion).\n   */\n  total_tokens: number;\n\n  /**\n   * Breakdown of tokens used in a completion.\n   */\n  completion_tokens_details?: CompletionUsage.CompletionTokensDetails;\n\n  /**\n   * Breakdown of tokens used in the prompt.\n   */\n  prompt_tokens_details?: CompletionUsage.PromptTokensDetails;\n}\n\nexport namespace CompletionUsage {\n  /**\n   * Breakdown of tokens used in a completion.\n   */\n  export interface CompletionTokensDetails {\n    /**\n     * Audio input tokens generated by the model.\n     */\n    audio_tokens?: number;\n\n    /**\n     * Tokens generated by the model for reasoning.\n     */\n    reasoning_tokens?: number;\n  }\n\n  /**\n   * Breakdown of tokens used in the prompt.\n   */\n  export interface PromptTokensDetails {\n    /**\n     * Audio input tokens present in the prompt.\n     */\n    audio_tokens?: number;\n\n    /**\n     * Cached tokens present in the prompt.\n     */\n    cached_tokens?: number;\n  }\n}\n\nexport type CompletionCreateParams = CompletionCreateParamsNonStreaming | CompletionCreateParamsStreaming;\n\nexport interface CompletionCreateParamsBase {\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models/overview) for\n   * descriptions of them.\n   */\n  model: (string & {}) | 'gpt-3.5-turbo-instruct' | 'davinci-002' | 'babbage-002';\n\n  /**\n   * The prompt(s) to generate completions for, encoded as a string, array of\n   * strings, array of tokens, or array of token arrays.\n   *\n   * Note that <|endoftext|> is the document separator that the model sees during\n   * training, so if a prompt is not specified the model will generate as if from the\n   * beginning of a new document.\n   */\n  prompt: string | Array<string> | Array<number> | Array<Array<number>> | null;\n\n  /**\n   * Generates `best_of` completions server-side and returns the \"best\" (the one with\n   * the highest log probability per token). Results cannot be streamed.\n   *\n   * When used with `n`, `best_of` controls the number of candidate completions and\n   * `n` specifies how many to return – `best_of` must be greater than `n`.\n   *\n   * **Note:** Because this parameter generates many completions, it can quickly\n   * consume your token quota. Use carefully and ensure that you have reasonable\n   * settings for `max_tokens` and `stop`.\n   */\n  best_of?: number | null;\n\n  /**\n   * Echo back the prompt in addition to the completion\n   */\n  echo?: boolean | null;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on their\n   * existing frequency in the text so far, decreasing the model's likelihood to\n   * repeat the same line verbatim.\n   *\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation/parameter-details)\n   */\n  frequency_penalty?: number | null;\n\n  /**\n   * Modify the likelihood of specified tokens appearing in the completion.\n   *\n   * Accepts a JSON object that maps tokens (specified by their token ID in the GPT\n   * tokenizer) to an associated bias value from -100 to 100. You can use this\n   * [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs.\n   * Mathematically, the bias is added to the logits generated by the model prior to\n   * sampling. The exact effect will vary per model, but values between -1 and 1\n   * should decrease or increase likelihood of selection; values like -100 or 100\n   * should result in a ban or exclusive selection of the relevant token.\n   *\n   * As an example, you can pass `{\"50256\": -100}` to prevent the <|endoftext|> token\n   * from being generated.\n   */\n  logit_bias?: Record<string, number> | null;\n\n  /**\n   * Include the log probabilities on the `logprobs` most likely output tokens, as\n   * well the chosen tokens. For example, if `logprobs` is 5, the API will return a\n   * list of the 5 most likely tokens. The API will always return the `logprob` of\n   * the sampled token, so there may be up to `logprobs+1` elements in the response.\n   *\n   * The maximum value for `logprobs` is 5.\n   */\n  logprobs?: number | null;\n\n  /**\n   * The maximum number of [tokens](/tokenizer) that can be generated in the\n   * completion.\n   *\n   * The token count of your prompt plus `max_tokens` cannot exceed the model's\n   * context length.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\n   * for counting tokens.\n   */\n  max_tokens?: number | null;\n\n  /**\n   * How many completions to generate for each prompt.\n   *\n   * **Note:** Because this parameter generates many completions, it can quickly\n   * consume your token quota. Use carefully and ensure that you have reasonable\n   * settings for `max_tokens` and `stop`.\n   */\n  n?: number | null;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on\n   * whether they appear in the text so far, increasing the model's likelihood to\n   * talk about new topics.\n   *\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation/parameter-details)\n   */\n  presence_penalty?: number | null;\n\n  /**\n   * If specified, our system will make a best effort to sample deterministically,\n   * such that repeated requests with the same `seed` and parameters should return\n   * the same result.\n   *\n   * Determinism is not guaranteed, and you should refer to the `system_fingerprint`\n   * response parameter to monitor changes in the backend.\n   */\n  seed?: number | null;\n\n  /**\n   * Up to 4 sequences where the API will stop generating further tokens. The\n   * returned text will not contain the stop sequence.\n   */\n  stop?: string | null | Array<string>;\n\n  /**\n   * Whether to stream back partial progress. If set, tokens will be sent as\n   * data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream?: boolean | null;\n\n  /**\n   * Options for streaming response. Only set this when you set `stream: true`.\n   */\n  stream_options?: ChatCompletionsAPI.ChatCompletionStreamOptions | null;\n\n  /**\n   * The suffix that comes after a completion of inserted text.\n   *\n   * This parameter is only supported for `gpt-3.5-turbo-instruct`.\n   */\n  suffix?: string | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   *\n   * We generally recommend altering this or `top_p` but not both.\n   */\n  temperature?: number | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or `temperature` but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\n   */\n  user?: string;\n}\n\nexport namespace CompletionCreateParams {\n  export type CompletionCreateParamsNonStreaming = CompletionsAPI.CompletionCreateParamsNonStreaming;\n  export type CompletionCreateParamsStreaming = CompletionsAPI.CompletionCreateParamsStreaming;\n}\n\nexport interface CompletionCreateParamsNonStreaming extends CompletionCreateParamsBase {\n  /**\n   * Whether to stream back partial progress. If set, tokens will be sent as\n   * data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream?: false | null;\n}\n\nexport interface CompletionCreateParamsStreaming extends CompletionCreateParamsBase {\n  /**\n   * Whether to stream back partial progress. If set, tokens will be sent as\n   * data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream: true;\n}\n\nexport namespace Completions {\n  export import Completion = CompletionsAPI.Completion;\n  export import CompletionChoice = CompletionsAPI.CompletionChoice;\n  export import CompletionUsage = CompletionsAPI.CompletionUsage;\n  export import CompletionCreateParams = CompletionsAPI.CompletionCreateParams;\n  export import CompletionCreateParamsNonStreaming = CompletionsAPI.CompletionCreateParamsNonStreaming;\n  export import CompletionCreateParamsStreaming = CompletionsAPI.CompletionCreateParamsStreaming;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;AAShF,MAAO,oBAAoB,qIAAA,CAAA,cAAW;IAa1C,OACE,IAA4B,EAC5B,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,gBAAgB;YAAE;YAAM,GAAG,OAAO;YAAE,QAAQ,KAAK,MAAM,IAAI;QAAK;IAG3F;;AA8UF,CAAA,SAAiB,WAAW,GAO5B,CAAC,EAPgB,eAAW,CAAX,cAAW,CAAA,CAAA"}},
    {"offset": {"line": 6230, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6235, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/embeddings.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport * as Core from '../core';\nimport * as EmbeddingsAPI from './embeddings';\n\nexport class Embeddings extends APIResource {\n  /**\n   * Creates an embedding vector representing the input text.\n   */\n  create(\n    body: EmbeddingCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<CreateEmbeddingResponse> {\n    return this._client.post('/embeddings', { body, ...options });\n  }\n}\n\nexport interface CreateEmbeddingResponse {\n  /**\n   * The list of embeddings generated by the model.\n   */\n  data: Array<Embedding>;\n\n  /**\n   * The name of the model used to generate the embedding.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always \"list\".\n   */\n  object: 'list';\n\n  /**\n   * The usage information for the request.\n   */\n  usage: CreateEmbeddingResponse.Usage;\n}\n\nexport namespace CreateEmbeddingResponse {\n  /**\n   * The usage information for the request.\n   */\n  export interface Usage {\n    /**\n     * The number of tokens used by the prompt.\n     */\n    prompt_tokens: number;\n\n    /**\n     * The total number of tokens used by the request.\n     */\n    total_tokens: number;\n  }\n}\n\n/**\n * Represents an embedding vector returned by embedding endpoint.\n */\nexport interface Embedding {\n  /**\n   * The embedding vector, which is a list of floats. The length of vector depends on\n   * the model as listed in the\n   * [embedding guide](https://platform.openai.com/docs/guides/embeddings).\n   */\n  embedding: Array<number>;\n\n  /**\n   * The index of the embedding in the list of embeddings.\n   */\n  index: number;\n\n  /**\n   * The object type, which is always \"embedding\".\n   */\n  object: 'embedding';\n}\n\nexport type EmbeddingModel = 'text-embedding-ada-002' | 'text-embedding-3-small' | 'text-embedding-3-large';\n\nexport interface EmbeddingCreateParams {\n  /**\n   * Input text to embed, encoded as a string or array of tokens. To embed multiple\n   * inputs in a single request, pass an array of strings or array of token arrays.\n   * The input must not exceed the max input tokens for the model (8192 tokens for\n   * `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048\n   * dimensions or less.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\n   * for counting tokens.\n   */\n  input: string | Array<string> | Array<number> | Array<Array<number>>;\n\n  /**\n   * ID of the model to use. You can use the\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\n   * see all of your available models, or see our\n   * [Model overview](https://platform.openai.com/docs/models/overview) for\n   * descriptions of them.\n   */\n  model: (string & {}) | EmbeddingModel;\n\n  /**\n   * The number of dimensions the resulting output embeddings should have. Only\n   * supported in `text-embedding-3` and later models.\n   */\n  dimensions?: number;\n\n  /**\n   * The format to return the embeddings in. Can be either `float` or\n   * [`base64`](https://pypi.org/project/pybase64/).\n   */\n  encoding_format?: 'float' | 'base64';\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\n   */\n  user?: string;\n}\n\nexport namespace Embeddings {\n  export import CreateEmbeddingResponse = EmbeddingsAPI.CreateEmbeddingResponse;\n  export import Embedding = EmbeddingsAPI.Embedding;\n  export import EmbeddingModel = EmbeddingsAPI.EmbeddingModel;\n  export import EmbeddingCreateParams = EmbeddingsAPI.EmbeddingCreateParams;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;AAMhF,MAAO,mBAAmB,qIAAA,CAAA,cAAW;IACzC;;QAGA,OACE,IAA2B,EAC3B,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,eAAe;YAAE;YAAM,GAAG,OAAO;QAAA;IAC5D;;AA2GF,CAAA,SAAiB,UAAU,GAK3B,CAAC,EALgB,cAAU,CAAV,aAAU,CAAA,CAAA"}},
    {"offset": {"line": 6253, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6258, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/files.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport { isRequestOptions } from '../core';\nimport { sleep } from '../core';\nimport { APIConnectionTimeoutError } from '../error';\nimport * as Core from '../core';\nimport * as FilesAPI from './files';\nimport { Page } from '../pagination';\nimport { type Response } from '../_shims/index';\n\nexport class Files extends APIResource {\n  /**\n   * Upload a file that can be used across various endpoints. Individual files can be\n   * up to 512 MB, and the size of all files uploaded by one organization can be up\n   * to 100 GB.\n   *\n   * The Assistants API supports files up to 2 million tokens and of specific file\n   * types. See the\n   * [Assistants Tools guide](https://platform.openai.com/docs/assistants/tools) for\n   * details.\n   *\n   * The Fine-tuning API only supports `.jsonl` files. The input also has certain\n   * required formats for fine-tuning\n   * [chat](https://platform.openai.com/docs/api-reference/fine-tuning/chat-input) or\n   * [completions](https://platform.openai.com/docs/api-reference/fine-tuning/completions-input)\n   * models.\n   *\n   * The Batch API only supports `.jsonl` files up to 100 MB in size. The input also\n   * has a specific required\n   * [format](https://platform.openai.com/docs/api-reference/batch/request-input).\n   *\n   * Please [contact us](https://help.openai.com/) if you need to increase these\n   * storage limits.\n   */\n  create(body: FileCreateParams, options?: Core.RequestOptions): Core.APIPromise<FileObject> {\n    return this._client.post('/files', Core.multipartFormRequestOptions({ body, ...options }));\n  }\n\n  /**\n   * Returns information about a specific file.\n   */\n  retrieve(fileId: string, options?: Core.RequestOptions): Core.APIPromise<FileObject> {\n    return this._client.get(`/files/${fileId}`, options);\n  }\n\n  /**\n   * Returns a list of files that belong to the user's organization.\n   */\n  list(query?: FileListParams, options?: Core.RequestOptions): Core.PagePromise<FileObjectsPage, FileObject>;\n  list(options?: Core.RequestOptions): Core.PagePromise<FileObjectsPage, FileObject>;\n  list(\n    query: FileListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FileObjectsPage, FileObject> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/files', FileObjectsPage, { query, ...options });\n  }\n\n  /**\n   * Delete a file.\n   */\n  del(fileId: string, options?: Core.RequestOptions): Core.APIPromise<FileDeleted> {\n    return this._client.delete(`/files/${fileId}`, options);\n  }\n\n  /**\n   * Returns the contents of the specified file.\n   */\n  content(fileId: string, options?: Core.RequestOptions): Core.APIPromise<Response> {\n    return this._client.get(`/files/${fileId}/content`, { ...options, __binaryResponse: true });\n  }\n\n  /**\n   * Returns the contents of the specified file.\n   *\n   * @deprecated The `.content()` method should be used instead\n   */\n  retrieveContent(fileId: string, options?: Core.RequestOptions): Core.APIPromise<string> {\n    return this._client.get(`/files/${fileId}/content`, {\n      ...options,\n      headers: { Accept: 'application/json', ...options?.headers },\n    });\n  }\n\n  /**\n   * Waits for the given file to be processed, default timeout is 30 mins.\n   */\n  async waitForProcessing(\n    id: string,\n    { pollInterval = 5000, maxWait = 30 * 60 * 1000 }: { pollInterval?: number; maxWait?: number } = {},\n  ): Promise<FileObject> {\n    const TERMINAL_STATES = new Set(['processed', 'error', 'deleted']);\n\n    const start = Date.now();\n    let file = await this.retrieve(id);\n\n    while (!file.status || !TERMINAL_STATES.has(file.status)) {\n      await sleep(pollInterval);\n\n      file = await this.retrieve(id);\n      if (Date.now() - start > maxWait) {\n        throw new APIConnectionTimeoutError({\n          message: `Giving up on waiting for file ${id} to finish processing after ${maxWait} milliseconds.`,\n        });\n      }\n    }\n\n    return file;\n  }\n}\n\n/**\n * Note: no pagination actually occurs yet, this is for forwards-compatibility.\n */\nexport class FileObjectsPage extends Page<FileObject> {}\n\nexport type FileContent = string;\n\nexport interface FileDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: 'file';\n}\n\n/**\n * The `File` object represents a document that has been uploaded to OpenAI.\n */\nexport interface FileObject {\n  /**\n   * The file identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The size of the file, in bytes.\n   */\n  bytes: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the file was created.\n   */\n  created_at: number;\n\n  /**\n   * The name of the file.\n   */\n  filename: string;\n\n  /**\n   * The object type, which is always `file`.\n   */\n  object: 'file';\n\n  /**\n   * The intended purpose of the file. Supported values are `assistants`,\n   * `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results`\n   * and `vision`.\n   */\n  purpose:\n    | 'assistants'\n    | 'assistants_output'\n    | 'batch'\n    | 'batch_output'\n    | 'fine-tune'\n    | 'fine-tune-results'\n    | 'vision';\n\n  /**\n   * @deprecated: Deprecated. The current status of the file, which can be either\n   * `uploaded`, `processed`, or `error`.\n   */\n  status: 'uploaded' | 'processed' | 'error';\n\n  /**\n   * @deprecated: Deprecated. For details on why a fine-tuning training file failed\n   * validation, see the `error` field on `fine_tuning.job`.\n   */\n  status_details?: string;\n}\n\n/**\n * The intended purpose of the uploaded file.\n *\n * Use \"assistants\" for\n * [Assistants](https://platform.openai.com/docs/api-reference/assistants) and\n * [Message](https://platform.openai.com/docs/api-reference/messages) files,\n * \"vision\" for Assistants image file inputs, \"batch\" for\n * [Batch API](https://platform.openai.com/docs/guides/batch), and \"fine-tune\" for\n * [Fine-tuning](https://platform.openai.com/docs/api-reference/fine-tuning).\n */\nexport type FilePurpose = 'assistants' | 'batch' | 'fine-tune' | 'vision';\n\nexport interface FileCreateParams {\n  /**\n   * The File object (not file name) to be uploaded.\n   */\n  file: Core.Uploadable;\n\n  /**\n   * The intended purpose of the uploaded file.\n   *\n   * Use \"assistants\" for\n   * [Assistants](https://platform.openai.com/docs/api-reference/assistants) and\n   * [Message](https://platform.openai.com/docs/api-reference/messages) files,\n   * \"vision\" for Assistants image file inputs, \"batch\" for\n   * [Batch API](https://platform.openai.com/docs/guides/batch), and \"fine-tune\" for\n   * [Fine-tuning](https://platform.openai.com/docs/api-reference/fine-tuning).\n   */\n  purpose: FilePurpose;\n}\n\nexport interface FileListParams {\n  /**\n   * Only return files with the given purpose.\n   */\n  purpose?: string;\n}\n\nexport namespace Files {\n  export import FileContent = FilesAPI.FileContent;\n  export import FileDeleted = FilesAPI.FileDeleted;\n  export import FileObject = FilesAPI.FileObject;\n  export import FilePurpose = FilesAPI.FilePurpose;\n  export import FileObjectsPage = FilesAPI.FileObjectsPage;\n  export import FileCreateParams = FilesAPI.FileCreateParams;\n  export import FileListParams = FilesAPI.FileListParams;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;;;;;;;;;;;AAWhF,MAAO,cAAc,qIAAA,CAAA,cAAW;IACpC;;;;;;;;;;;;;;;;;;;;;;QAuBA,OAAO,IAAsB,EAAE,OAA6B,EAAA;QAC1D,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,UAAU,kJAAK,2BAA2B,CAAC;YAAE;YAAM,GAAG,OAAO;QAAA;IACxF;IAEA;;QAGA,SAAS,MAAc,EAAE,OAA6B,EAAA;QACpD,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,CAAA,OAAA,EAAU,OAAM,CAAE,EAAE;IAC9C;IAOA,KACE,QAA8C,CAAA,CAAE,EAChD,OAA6B,EAAA;QAE7B,IAAI,CAAA,GAAA,iJAAA,CAAA,mBAAgB,AAAhB,EAAiB,QAAQ;YAC3B,OAAO,IAAI,CAAC,IAAI,CAAC,CAAA,GAAI;;QAEvB,OAAO,IAAI,CAAC,OAAO,CAAC,UAAU,CAAC,UAAU,iBAAiB;YAAE;YAAO,GAAG,OAAO;QAAA;IAC/E;IAEA;;QAGA,IAAI,MAAc,EAAE,OAA6B,EAAA;QAC/C,OAAO,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,CAAA,OAAA,EAAU,OAAM,CAAE,EAAE;IACjD;IAEA;;QAGA,QAAQ,MAAc,EAAE,OAA6B,EAAA;QACnD,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,CAAA,OAAA,EAAU,OAAM,QAAA,CAAU,EAAE;YAAE,GAAG,OAAO;YAAE,kBAAkB;QAAI;IAC1F;IAEA;;;;QAKA,gBAAgB,MAAc,EAAE,OAA6B,EAAA;QAC3D,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,CAAA,OAAA,EAAU,OAAM,QAAA,CAAU,EAAE;YAClD,GAAG,OAAO;YACV,SAAS;gBAAE,QAAQ;gBAAoB,GAAG,SAAS,OAAO;YAAA;;IAE9D;IAEA;;QAGA,MAAM,kBACJ,EAAU,EACV,EAAE,eAAe,IAAI,EAAE,UAAU,KAAK,KAAK,IAAI,EAAA,GAAkD,CAAA,CAAE,EAAA;QAEnG,MAAM,kBAAkB,IAAI,IAAI;YAAC;YAAa;YAAS;SAAU;QAEjE,MAAM,QAAQ,KAAK,GAAG;QACtB,IAAI,OAAO,MAAM,IAAI,CAAC,QAAQ,CAAC;QAE/B,MAAO,CAAC,KAAK,MAAM,IAAI,CAAC,gBAAgB,GAAG,CAAC,KAAK,MAAM,EAAG;YACxD,MAAM,CAAA,GAAA,iJAAA,CAAA,QAAK,AAAL,EAAM;YAEZ,OAAO,MAAM,IAAI,CAAC,QAAQ,CAAC;YAC3B,IAAI,KAAK,GAAG,KAAK,QAAQ,SAAS;gBAChC,MAAM,IAAI,kIAAA,CAAA,4BAAyB,CAAC;oBAClC,SAAS,CAAA,8BAAA,EAAiC,GAAE,4BAAA,EAA+B,QAAO,cAAA,CAAgB;;;;QAKxG,OAAO;IACT;;AAMI,MAAO,wBAAwB,uIAAA,CAAA,OAAgB;;AA0GrD,CAAA,SAAiB,KAAK;IAKN,MAAA,eAAe,GAAG,gJAAS,eAAe;AAG1D,CAAC,EARgB,SAAK,CAAL,QAAK,CAAA,CAAA"}},
    {"offset": {"line": 6373, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6378, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/fine-tuning/jobs/checkpoints.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport * as Core from '../../../core';\nimport * as CheckpointsAPI from './checkpoints';\nimport { CursorPage, type CursorPageParams } from '../../../pagination';\n\nexport class Checkpoints extends APIResource {\n  /**\n   * List checkpoints for a fine-tuning job.\n   */\n  list(\n    fineTuningJobId: string,\n    query?: CheckpointListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobCheckpointsPage, FineTuningJobCheckpoint>;\n  list(\n    fineTuningJobId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobCheckpointsPage, FineTuningJobCheckpoint>;\n  list(\n    fineTuningJobId: string,\n    query: CheckpointListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobCheckpointsPage, FineTuningJobCheckpoint> {\n    if (isRequestOptions(query)) {\n      return this.list(fineTuningJobId, {}, query);\n    }\n    return this._client.getAPIList(\n      `/fine_tuning/jobs/${fineTuningJobId}/checkpoints`,\n      FineTuningJobCheckpointsPage,\n      { query, ...options },\n    );\n  }\n}\n\nexport class FineTuningJobCheckpointsPage extends CursorPage<FineTuningJobCheckpoint> {}\n\n/**\n * The `fine_tuning.job.checkpoint` object represents a model checkpoint for a\n * fine-tuning job that is ready to use.\n */\nexport interface FineTuningJobCheckpoint {\n  /**\n   * The checkpoint identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the checkpoint was created.\n   */\n  created_at: number;\n\n  /**\n   * The name of the fine-tuned checkpoint model that is created.\n   */\n  fine_tuned_model_checkpoint: string;\n\n  /**\n   * The name of the fine-tuning job that this checkpoint was created from.\n   */\n  fine_tuning_job_id: string;\n\n  /**\n   * Metrics at the step number during the fine-tuning job.\n   */\n  metrics: FineTuningJobCheckpoint.Metrics;\n\n  /**\n   * The object type, which is always \"fine_tuning.job.checkpoint\".\n   */\n  object: 'fine_tuning.job.checkpoint';\n\n  /**\n   * The step number that the checkpoint was created at.\n   */\n  step_number: number;\n}\n\nexport namespace FineTuningJobCheckpoint {\n  /**\n   * Metrics at the step number during the fine-tuning job.\n   */\n  export interface Metrics {\n    full_valid_loss?: number;\n\n    full_valid_mean_token_accuracy?: number;\n\n    step?: number;\n\n    train_loss?: number;\n\n    train_mean_token_accuracy?: number;\n\n    valid_loss?: number;\n\n    valid_mean_token_accuracy?: number;\n  }\n}\n\nexport interface CheckpointListParams extends CursorPageParams {}\n\nexport namespace Checkpoints {\n  export import FineTuningJobCheckpoint = CheckpointsAPI.FineTuningJobCheckpoint;\n  export import FineTuningJobCheckpointsPage = CheckpointsAPI.FineTuningJobCheckpointsPage;\n  export import CheckpointListParams = CheckpointsAPI.CheckpointListParams;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;;;;;;AAQhF,MAAO,oBAAoB,qIAAA,CAAA,cAAW;IAa1C,KACE,eAAuB,EACvB,QAAoD,CAAA,CAAE,EACtD,OAA6B,EAAA;QAE7B,IAAI,CAAA,GAAA,iJAAA,CAAA,mBAAgB,AAAhB,EAAiB,QAAQ;YAC3B,OAAO,IAAI,CAAC,IAAI,CAAC,iBAAiB,CAAA,GAAI;;QAExC,OAAO,IAAI,CAAC,OAAO,CAAC,UAAU,CAC5B,CAAA,kBAAA,EAAqB,gBAAe,YAAA,CAAc,EAClD,8BACA;YAAE;YAAO,GAAG,OAAO;QAAA;IAEvB;;AAGI,MAAO,qCAAqC,uIAAA,CAAA,aAAmC;;AAkErF,CAAA,SAAiB,WAAW;IAEZ,YAAA,4BAA4B,GAAG,gLAAe,4BAA4B;AAE1F,CAAC,EAJgB,eAAW,CAAX,cAAW,CAAA,CAAA"}},
    {"offset": {"line": 6408, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6413, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/fine-tuning/jobs/jobs.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../../resource';\nimport { isRequestOptions } from '../../../core';\nimport * as Core from '../../../core';\nimport * as JobsAPI from './jobs';\nimport * as CheckpointsAPI from './checkpoints';\nimport { CursorPage, type CursorPageParams } from '../../../pagination';\n\nexport class Jobs extends APIResource {\n  checkpoints: CheckpointsAPI.Checkpoints = new CheckpointsAPI.Checkpoints(this._client);\n\n  /**\n   * Creates a fine-tuning job which begins the process of creating a new model from\n   * a given dataset.\n   *\n   * Response includes details of the enqueued job including job status and the name\n   * of the fine-tuned models once complete.\n   *\n   * [Learn more about fine-tuning](https://platform.openai.com/docs/guides/fine-tuning)\n   */\n  create(body: JobCreateParams, options?: Core.RequestOptions): Core.APIPromise<FineTuningJob> {\n    return this._client.post('/fine_tuning/jobs', { body, ...options });\n  }\n\n  /**\n   * Get info about a fine-tuning job.\n   *\n   * [Learn more about fine-tuning](https://platform.openai.com/docs/guides/fine-tuning)\n   */\n  retrieve(fineTuningJobId: string, options?: Core.RequestOptions): Core.APIPromise<FineTuningJob> {\n    return this._client.get(`/fine_tuning/jobs/${fineTuningJobId}`, options);\n  }\n\n  /**\n   * List your organization's fine-tuning jobs\n   */\n  list(\n    query?: JobListParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobsPage, FineTuningJob>;\n  list(options?: Core.RequestOptions): Core.PagePromise<FineTuningJobsPage, FineTuningJob>;\n  list(\n    query: JobListParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobsPage, FineTuningJob> {\n    if (isRequestOptions(query)) {\n      return this.list({}, query);\n    }\n    return this._client.getAPIList('/fine_tuning/jobs', FineTuningJobsPage, { query, ...options });\n  }\n\n  /**\n   * Immediately cancel a fine-tune job.\n   */\n  cancel(fineTuningJobId: string, options?: Core.RequestOptions): Core.APIPromise<FineTuningJob> {\n    return this._client.post(`/fine_tuning/jobs/${fineTuningJobId}/cancel`, options);\n  }\n\n  /**\n   * Get status updates for a fine-tuning job.\n   */\n  listEvents(\n    fineTuningJobId: string,\n    query?: JobListEventsParams,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobEventsPage, FineTuningJobEvent>;\n  listEvents(\n    fineTuningJobId: string,\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobEventsPage, FineTuningJobEvent>;\n  listEvents(\n    fineTuningJobId: string,\n    query: JobListEventsParams | Core.RequestOptions = {},\n    options?: Core.RequestOptions,\n  ): Core.PagePromise<FineTuningJobEventsPage, FineTuningJobEvent> {\n    if (isRequestOptions(query)) {\n      return this.listEvents(fineTuningJobId, {}, query);\n    }\n    return this._client.getAPIList(`/fine_tuning/jobs/${fineTuningJobId}/events`, FineTuningJobEventsPage, {\n      query,\n      ...options,\n    });\n  }\n}\n\nexport class FineTuningJobsPage extends CursorPage<FineTuningJob> {}\n\nexport class FineTuningJobEventsPage extends CursorPage<FineTuningJobEvent> {}\n\n/**\n * The `fine_tuning.job` object represents a fine-tuning job that has been created\n * through the API.\n */\nexport interface FineTuningJob {\n  /**\n   * The object identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job was created.\n   */\n  created_at: number;\n\n  /**\n   * For fine-tuning jobs that have `failed`, this will contain more information on\n   * the cause of the failure.\n   */\n  error: FineTuningJob.Error | null;\n\n  /**\n   * The name of the fine-tuned model that is being created. The value will be null\n   * if the fine-tuning job is still running.\n   */\n  fine_tuned_model: string | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job was finished. The\n   * value will be null if the fine-tuning job is still running.\n   */\n  finished_at: number | null;\n\n  /**\n   * The hyperparameters used for the fine-tuning job. See the\n   * [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning) for\n   * more details.\n   */\n  hyperparameters: FineTuningJob.Hyperparameters;\n\n  /**\n   * The base model that is being fine-tuned.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always \"fine_tuning.job\".\n   */\n  object: 'fine_tuning.job';\n\n  /**\n   * The organization that owns the fine-tuning job.\n   */\n  organization_id: string;\n\n  /**\n   * The compiled results file ID(s) for the fine-tuning job. You can retrieve the\n   * results with the\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n   */\n  result_files: Array<string>;\n\n  /**\n   * The seed used for the fine-tuning job.\n   */\n  seed: number;\n\n  /**\n   * The current status of the fine-tuning job, which can be either\n   * `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`.\n   */\n  status: 'validating_files' | 'queued' | 'running' | 'succeeded' | 'failed' | 'cancelled';\n\n  /**\n   * The total number of billable tokens processed by this fine-tuning job. The value\n   * will be null if the fine-tuning job is still running.\n   */\n  trained_tokens: number | null;\n\n  /**\n   * The file ID used for training. You can retrieve the training data with the\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n   */\n  training_file: string;\n\n  /**\n   * The file ID used for validation. You can retrieve the validation results with\n   * the\n   * [Files API](https://platform.openai.com/docs/api-reference/files/retrieve-contents).\n   */\n  validation_file: string | null;\n\n  /**\n   * The Unix timestamp (in seconds) for when the fine-tuning job is estimated to\n   * finish. The value will be null if the fine-tuning job is not running.\n   */\n  estimated_finish?: number | null;\n\n  /**\n   * A list of integrations to enable for this fine-tuning job.\n   */\n  integrations?: Array<FineTuningJobWandbIntegrationObject> | null;\n}\n\nexport namespace FineTuningJob {\n  /**\n   * For fine-tuning jobs that have `failed`, this will contain more information on\n   * the cause of the failure.\n   */\n  export interface Error {\n    /**\n     * A machine-readable error code.\n     */\n    code: string;\n\n    /**\n     * A human-readable error message.\n     */\n    message: string;\n\n    /**\n     * The parameter that was invalid, usually `training_file` or `validation_file`.\n     * This field will be null if the failure was not parameter-specific.\n     */\n    param: string | null;\n  }\n\n  /**\n   * The hyperparameters used for the fine-tuning job. See the\n   * [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning) for\n   * more details.\n   */\n  export interface Hyperparameters {\n    /**\n     * The number of epochs to train the model for. An epoch refers to one full cycle\n     * through the training dataset. \"auto\" decides the optimal number of epochs based\n     * on the size of the dataset. If setting the number manually, we support any\n     * number between 1 and 50 epochs.\n     */\n    n_epochs: 'auto' | number;\n  }\n}\n\n/**\n * Fine-tuning job event object\n */\nexport interface FineTuningJobEvent {\n  id: string;\n\n  created_at: number;\n\n  level: 'info' | 'warn' | 'error';\n\n  message: string;\n\n  object: 'fine_tuning.job.event';\n}\n\nexport type FineTuningJobIntegration = FineTuningJobWandbIntegrationObject;\n\n/**\n * The settings for your integration with Weights and Biases. This payload\n * specifies the project that metrics will be sent to. Optionally, you can set an\n * explicit display name for your run, add tags to your run, and set a default\n * entity (team, username, etc) to be associated with your run.\n */\nexport interface FineTuningJobWandbIntegration {\n  /**\n   * The name of the project that the new run will be created under.\n   */\n  project: string;\n\n  /**\n   * The entity to use for the run. This allows you to set the team or username of\n   * the WandB user that you would like associated with the run. If not set, the\n   * default entity for the registered WandB API key is used.\n   */\n  entity?: string | null;\n\n  /**\n   * A display name to set for the run. If not set, we will use the Job ID as the\n   * name.\n   */\n  name?: string | null;\n\n  /**\n   * A list of tags to be attached to the newly created run. These tags are passed\n   * through directly to WandB. Some default tags are generated by OpenAI:\n   * \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n   */\n  tags?: Array<string>;\n}\n\nexport interface FineTuningJobWandbIntegrationObject {\n  /**\n   * The type of the integration being enabled for the fine-tuning job\n   */\n  type: 'wandb';\n\n  /**\n   * The settings for your integration with Weights and Biases. This payload\n   * specifies the project that metrics will be sent to. Optionally, you can set an\n   * explicit display name for your run, add tags to your run, and set a default\n   * entity (team, username, etc) to be associated with your run.\n   */\n  wandb: FineTuningJobWandbIntegration;\n}\n\nexport interface JobCreateParams {\n  /**\n   * The name of the model to fine-tune. You can select one of the\n   * [supported models](https://platform.openai.com/docs/guides/fine-tuning/which-models-can-be-fine-tuned).\n   */\n  model: (string & {}) | 'babbage-002' | 'davinci-002' | 'gpt-3.5-turbo' | 'gpt-4o-mini';\n\n  /**\n   * The ID of an uploaded file that contains training data.\n   *\n   * See [upload file](https://platform.openai.com/docs/api-reference/files/create)\n   * for how to upload a file.\n   *\n   * Your dataset must be formatted as a JSONL file. Additionally, you must upload\n   * your file with the purpose `fine-tune`.\n   *\n   * The contents of the file should differ depending on if the model uses the\n   * [chat](https://platform.openai.com/docs/api-reference/fine-tuning/chat-input) or\n   * [completions](https://platform.openai.com/docs/api-reference/fine-tuning/completions-input)\n   * format.\n   *\n   * See the [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning)\n   * for more details.\n   */\n  training_file: string;\n\n  /**\n   * The hyperparameters used for the fine-tuning job.\n   */\n  hyperparameters?: JobCreateParams.Hyperparameters;\n\n  /**\n   * A list of integrations to enable for your fine-tuning job.\n   */\n  integrations?: Array<JobCreateParams.Integration> | null;\n\n  /**\n   * The seed controls the reproducibility of the job. Passing in the same seed and\n   * job parameters should produce the same results, but may differ in rare cases. If\n   * a seed is not specified, one will be generated for you.\n   */\n  seed?: number | null;\n\n  /**\n   * A string of up to 64 characters that will be added to your fine-tuned model\n   * name.\n   *\n   * For example, a `suffix` of \"custom-model-name\" would produce a model name like\n   * `ft:gpt-4o-mini:openai:custom-model-name:7p4lURel`.\n   */\n  suffix?: string | null;\n\n  /**\n   * The ID of an uploaded file that contains validation data.\n   *\n   * If you provide this file, the data is used to generate validation metrics\n   * periodically during fine-tuning. These metrics can be viewed in the fine-tuning\n   * results file. The same data should not be present in both train and validation\n   * files.\n   *\n   * Your dataset must be formatted as a JSONL file. You must upload your file with\n   * the purpose `fine-tune`.\n   *\n   * See the [fine-tuning guide](https://platform.openai.com/docs/guides/fine-tuning)\n   * for more details.\n   */\n  validation_file?: string | null;\n}\n\nexport namespace JobCreateParams {\n  /**\n   * The hyperparameters used for the fine-tuning job.\n   */\n  export interface Hyperparameters {\n    /**\n     * Number of examples in each batch. A larger batch size means that model\n     * parameters are updated less frequently, but with lower variance.\n     */\n    batch_size?: 'auto' | number;\n\n    /**\n     * Scaling factor for the learning rate. A smaller learning rate may be useful to\n     * avoid overfitting.\n     */\n    learning_rate_multiplier?: 'auto' | number;\n\n    /**\n     * The number of epochs to train the model for. An epoch refers to one full cycle\n     * through the training dataset.\n     */\n    n_epochs?: 'auto' | number;\n  }\n\n  export interface Integration {\n    /**\n     * The type of integration to enable. Currently, only \"wandb\" (Weights and Biases)\n     * is supported.\n     */\n    type: 'wandb';\n\n    /**\n     * The settings for your integration with Weights and Biases. This payload\n     * specifies the project that metrics will be sent to. Optionally, you can set an\n     * explicit display name for your run, add tags to your run, and set a default\n     * entity (team, username, etc) to be associated with your run.\n     */\n    wandb: Integration.Wandb;\n  }\n\n  export namespace Integration {\n    /**\n     * The settings for your integration with Weights and Biases. This payload\n     * specifies the project that metrics will be sent to. Optionally, you can set an\n     * explicit display name for your run, add tags to your run, and set a default\n     * entity (team, username, etc) to be associated with your run.\n     */\n    export interface Wandb {\n      /**\n       * The name of the project that the new run will be created under.\n       */\n      project: string;\n\n      /**\n       * The entity to use for the run. This allows you to set the team or username of\n       * the WandB user that you would like associated with the run. If not set, the\n       * default entity for the registered WandB API key is used.\n       */\n      entity?: string | null;\n\n      /**\n       * A display name to set for the run. If not set, we will use the Job ID as the\n       * name.\n       */\n      name?: string | null;\n\n      /**\n       * A list of tags to be attached to the newly created run. These tags are passed\n       * through directly to WandB. Some default tags are generated by OpenAI:\n       * \"openai/finetune\", \"openai/{base-model}\", \"openai/{ftjob-abcdef}\".\n       */\n      tags?: Array<string>;\n    }\n  }\n}\n\nexport interface JobListParams extends CursorPageParams {}\n\nexport interface JobListEventsParams extends CursorPageParams {}\n\nexport namespace Jobs {\n  export import FineTuningJob = JobsAPI.FineTuningJob;\n  export import FineTuningJobEvent = JobsAPI.FineTuningJobEvent;\n  export import FineTuningJobIntegration = JobsAPI.FineTuningJobIntegration;\n  export import FineTuningJobWandbIntegration = JobsAPI.FineTuningJobWandbIntegration;\n  export import FineTuningJobWandbIntegrationObject = JobsAPI.FineTuningJobWandbIntegrationObject;\n  export import FineTuningJobsPage = JobsAPI.FineTuningJobsPage;\n  export import FineTuningJobEventsPage = JobsAPI.FineTuningJobEventsPage;\n  export import JobCreateParams = JobsAPI.JobCreateParams;\n  export import JobListParams = JobsAPI.JobListParams;\n  export import JobListEventsParams = JobsAPI.JobListEventsParams;\n  export import Checkpoints = CheckpointsAPI.Checkpoints;\n  export import FineTuningJobCheckpoint = CheckpointsAPI.FineTuningJobCheckpoint;\n  export import FineTuningJobCheckpointsPage = CheckpointsAPI.FineTuningJobCheckpointsPage;\n  export import CheckpointListParams = CheckpointsAPI.CheckpointListParams;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;;;;;;;;;AAShF,MAAO,aAAa,qIAAA,CAAA,cAAW;IAArC,aAAA;;QACE,IAAA,CAAA,WAAW,GAA+B,IAAI,gLAAe,WAAW,CAAC,IAAI,CAAC,OAAO;IA0EvF;IAxEE;;;;;;;;QASA,OAAO,IAAqB,EAAE,OAA6B,EAAA;QACzD,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,qBAAqB;YAAE;YAAM,GAAG,OAAO;QAAA;IAClE;IAEA;;;;QAKA,SAAS,eAAuB,EAAE,OAA6B,EAAA;QAC7D,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,CAAA,kBAAA,EAAqB,gBAAe,CAAE,EAAE;IAClE;IAUA,KACE,QAA6C,CAAA,CAAE,EAC/C,OAA6B,EAAA;QAE7B,IAAI,CAAA,GAAA,iJAAA,CAAA,mBAAgB,AAAhB,EAAiB,QAAQ;YAC3B,OAAO,IAAI,CAAC,IAAI,CAAC,CAAA,GAAI;;QAEvB,OAAO,IAAI,CAAC,OAAO,CAAC,UAAU,CAAC,qBAAqB,oBAAoB;YAAE;YAAO,GAAG,OAAO;QAAA;IAC7F;IAEA;;QAGA,OAAO,eAAuB,EAAE,OAA6B,EAAA;QAC3D,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,CAAA,kBAAA,EAAqB,gBAAe,OAAA,CAAS,EAAE;IAC1E;IAcA,WACE,eAAuB,EACvB,QAAmD,CAAA,CAAE,EACrD,OAA6B,EAAA;QAE7B,IAAI,CAAA,GAAA,iJAAA,CAAA,mBAAgB,AAAhB,EAAiB,QAAQ;YAC3B,OAAO,IAAI,CAAC,UAAU,CAAC,iBAAiB,CAAA,GAAI;;QAE9C,OAAO,IAAI,CAAC,OAAO,CAAC,UAAU,CAAC,CAAA,kBAAA,EAAqB,gBAAe,OAAA,CAAS,EAAE,yBAAyB;YACrG;YACA,GAAG,OAAO;;IAEd;;AAGI,MAAO,2BAA2B,uIAAA,CAAA,aAAyB;;AAE3D,MAAO,gCAAgC,uIAAA,CAAA,aAA8B;;AAuW3E,CAAA,SAAiB,IAAI;IAML,KAAA,kBAAkB,GAAG,yKAAQ,kBAAkB;IAC/C,KAAA,uBAAuB,GAAG,yKAAQ,uBAAuB;IAIzD,KAAA,WAAW,GAAG,gLAAe,WAAW;IAExC,KAAA,4BAA4B,GAAG,gLAAe,4BAA4B;AAE1F,CAAC,EAfgB,QAAI,CAAJ,OAAI,CAAA,CAAA"}},
    {"offset": {"line": 6490, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6495, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/fine-tuning/fine-tuning.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as JobsAPI from './jobs/jobs';\n\nexport class FineTuning extends APIResource {\n  jobs: JobsAPI.Jobs = new JobsAPI.Jobs(this._client);\n}\n\nexport namespace FineTuning {\n  export import Jobs = JobsAPI.Jobs;\n  export import FineTuningJob = JobsAPI.FineTuningJob;\n  export import FineTuningJobEvent = JobsAPI.FineTuningJobEvent;\n  export import FineTuningJobIntegration = JobsAPI.FineTuningJobIntegration;\n  export import FineTuningJobWandbIntegration = JobsAPI.FineTuningJobWandbIntegration;\n  export import FineTuningJobWandbIntegrationObject = JobsAPI.FineTuningJobWandbIntegrationObject;\n  export import FineTuningJobsPage = JobsAPI.FineTuningJobsPage;\n  export import FineTuningJobEventsPage = JobsAPI.FineTuningJobEventsPage;\n  export import JobCreateParams = JobsAPI.JobCreateParams;\n  export import JobListParams = JobsAPI.JobListParams;\n  export import JobListEventsParams = JobsAPI.JobListEventsParams;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;AAKhF,MAAO,mBAAmB,qIAAA,CAAA,cAAW;IAA3C,aAAA;;QACE,IAAA,CAAA,IAAI,GAAiB,IAAI,yKAAQ,IAAI,CAAC,IAAI,CAAC,OAAO;IACpD;;AAEA,CAAA,SAAiB,UAAU;IACX,WAAA,IAAI,GAAG,yKAAQ,IAAI;IAMnB,WAAA,kBAAkB,GAAG,yKAAQ,kBAAkB;IAC/C,WAAA,uBAAuB,GAAG,yKAAQ,uBAAuB;AAIzE,CAAC,EAZgB,cAAU,CAAV,aAAU,CAAA,CAAA"}},
    {"offset": {"line": 6515, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6520, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/images.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport * as Core from '../core';\nimport * as ImagesAPI from './images';\n\nexport class Images extends APIResource {\n  /**\n   * Creates a variation of a given image.\n   */\n  createVariation(\n    body: ImageCreateVariationParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<ImagesResponse> {\n    return this._client.post('/images/variations', Core.multipartFormRequestOptions({ body, ...options }));\n  }\n\n  /**\n   * Creates an edited or extended image given an original image and a prompt.\n   */\n  edit(body: ImageEditParams, options?: Core.RequestOptions): Core.APIPromise<ImagesResponse> {\n    return this._client.post('/images/edits', Core.multipartFormRequestOptions({ body, ...options }));\n  }\n\n  /**\n   * Creates an image given a prompt.\n   */\n  generate(body: ImageGenerateParams, options?: Core.RequestOptions): Core.APIPromise<ImagesResponse> {\n    return this._client.post('/images/generations', { body, ...options });\n  }\n}\n\n/**\n * Represents the url or the content of an image generated by the OpenAI API.\n */\nexport interface Image {\n  /**\n   * The base64-encoded JSON of the generated image, if `response_format` is\n   * `b64_json`.\n   */\n  b64_json?: string;\n\n  /**\n   * The prompt that was used to generate the image, if there was any revision to the\n   * prompt.\n   */\n  revised_prompt?: string;\n\n  /**\n   * The URL of the generated image, if `response_format` is `url` (default).\n   */\n  url?: string;\n}\n\nexport type ImageModel = 'dall-e-2' | 'dall-e-3';\n\nexport interface ImagesResponse {\n  created: number;\n\n  data: Array<Image>;\n}\n\nexport interface ImageCreateVariationParams {\n  /**\n   * The image to use as the basis for the variation(s). Must be a valid PNG file,\n   * less than 4MB, and square.\n   */\n  image: Core.Uploadable;\n\n  /**\n   * The model to use for image generation. Only `dall-e-2` is supported at this\n   * time.\n   */\n  model?: (string & {}) | ImageModel | null;\n\n  /**\n   * The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only\n   * `n=1` is supported.\n   */\n  n?: number | null;\n\n  /**\n   * The format in which the generated images are returned. Must be one of `url` or\n   * `b64_json`. URLs are only valid for 60 minutes after the image has been\n   * generated.\n   */\n  response_format?: 'url' | 'b64_json' | null;\n\n  /**\n   * The size of the generated images. Must be one of `256x256`, `512x512`, or\n   * `1024x1024`.\n   */\n  size?: '256x256' | '512x512' | '1024x1024' | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\n   */\n  user?: string;\n}\n\nexport interface ImageEditParams {\n  /**\n   * The image to edit. Must be a valid PNG file, less than 4MB, and square. If mask\n   * is not provided, image must have transparency, which will be used as the mask.\n   */\n  image: Core.Uploadable;\n\n  /**\n   * A text description of the desired image(s). The maximum length is 1000\n   * characters.\n   */\n  prompt: string;\n\n  /**\n   * An additional image whose fully transparent areas (e.g. where alpha is zero)\n   * indicate where `image` should be edited. Must be a valid PNG file, less than\n   * 4MB, and have the same dimensions as `image`.\n   */\n  mask?: Core.Uploadable;\n\n  /**\n   * The model to use for image generation. Only `dall-e-2` is supported at this\n   * time.\n   */\n  model?: (string & {}) | ImageModel | null;\n\n  /**\n   * The number of images to generate. Must be between 1 and 10.\n   */\n  n?: number | null;\n\n  /**\n   * The format in which the generated images are returned. Must be one of `url` or\n   * `b64_json`. URLs are only valid for 60 minutes after the image has been\n   * generated.\n   */\n  response_format?: 'url' | 'b64_json' | null;\n\n  /**\n   * The size of the generated images. Must be one of `256x256`, `512x512`, or\n   * `1024x1024`.\n   */\n  size?: '256x256' | '512x512' | '1024x1024' | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\n   */\n  user?: string;\n}\n\nexport interface ImageGenerateParams {\n  /**\n   * A text description of the desired image(s). The maximum length is 1000\n   * characters for `dall-e-2` and 4000 characters for `dall-e-3`.\n   */\n  prompt: string;\n\n  /**\n   * The model to use for image generation.\n   */\n  model?: (string & {}) | ImageModel | null;\n\n  /**\n   * The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only\n   * `n=1` is supported.\n   */\n  n?: number | null;\n\n  /**\n   * The quality of the image that will be generated. `hd` creates images with finer\n   * details and greater consistency across the image. This param is only supported\n   * for `dall-e-3`.\n   */\n  quality?: 'standard' | 'hd';\n\n  /**\n   * The format in which the generated images are returned. Must be one of `url` or\n   * `b64_json`. URLs are only valid for 60 minutes after the image has been\n   * generated.\n   */\n  response_format?: 'url' | 'b64_json' | null;\n\n  /**\n   * The size of the generated images. Must be one of `256x256`, `512x512`, or\n   * `1024x1024` for `dall-e-2`. Must be one of `1024x1024`, `1792x1024`, or\n   * `1024x1792` for `dall-e-3` models.\n   */\n  size?: '256x256' | '512x512' | '1024x1024' | '1792x1024' | '1024x1792' | null;\n\n  /**\n   * The style of the generated images. Must be one of `vivid` or `natural`. Vivid\n   * causes the model to lean towards generating hyper-real and dramatic images.\n   * Natural causes the model to produce more natural, less hyper-real looking\n   * images. This param is only supported for `dall-e-3`.\n   */\n  style?: 'vivid' | 'natural' | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\n   */\n  user?: string;\n}\n\nexport namespace Images {\n  export import Image = ImagesAPI.Image;\n  export import ImageModel = ImagesAPI.ImageModel;\n  export import ImagesResponse = ImagesAPI.ImagesResponse;\n  export import ImageCreateVariationParams = ImagesAPI.ImageCreateVariationParams;\n  export import ImageEditParams = ImagesAPI.ImageEditParams;\n  export import ImageGenerateParams = ImagesAPI.ImageGenerateParams;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;AAMhF,MAAO,eAAe,qIAAA,CAAA,cAAW;IACrC;;QAGA,gBACE,IAAgC,EAChC,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,sBAAsB,kJAAK,2BAA2B,CAAC;YAAE;YAAM,GAAG,OAAO;QAAA;IACpG;IAEA;;QAGA,KAAK,IAAqB,EAAE,OAA6B,EAAA;QACvD,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,iBAAiB,kJAAK,2BAA2B,CAAC;YAAE;YAAM,GAAG,OAAO;QAAA;IAC/F;IAEA;;QAGA,SAAS,IAAyB,EAAE,OAA6B,EAAA;QAC/D,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,uBAAuB;YAAE;YAAM,GAAG,OAAO;QAAA;IACpE;;AAoLF,CAAA,SAAiB,MAAM,GAOvB,CAAC,EAPgB,UAAM,CAAN,SAAM,CAAA,CAAA"}},
    {"offset": {"line": 6556, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6561, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/models.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport * as Core from '../core';\nimport * as ModelsAPI from './models';\nimport { Page } from '../pagination';\n\nexport class Models extends APIResource {\n  /**\n   * Retrieves a model instance, providing basic information about the model such as\n   * the owner and permissioning.\n   */\n  retrieve(model: string, options?: Core.RequestOptions): Core.APIPromise<Model> {\n    return this._client.get(`/models/${model}`, options);\n  }\n\n  /**\n   * Lists the currently available models, and provides basic information about each\n   * one such as the owner and availability.\n   */\n  list(options?: Core.RequestOptions): Core.PagePromise<ModelsPage, Model> {\n    return this._client.getAPIList('/models', ModelsPage, options);\n  }\n\n  /**\n   * Delete a fine-tuned model. You must have the Owner role in your organization to\n   * delete a model.\n   */\n  del(model: string, options?: Core.RequestOptions): Core.APIPromise<ModelDeleted> {\n    return this._client.delete(`/models/${model}`, options);\n  }\n}\n\n/**\n * Note: no pagination actually occurs yet, this is for forwards-compatibility.\n */\nexport class ModelsPage extends Page<Model> {}\n\n/**\n * Describes an OpenAI model offering that can be used with the API.\n */\nexport interface Model {\n  /**\n   * The model identifier, which can be referenced in the API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) when the model was created.\n   */\n  created: number;\n\n  /**\n   * The object type, which is always \"model\".\n   */\n  object: 'model';\n\n  /**\n   * The organization that owns the model.\n   */\n  owned_by: string;\n}\n\nexport interface ModelDeleted {\n  id: string;\n\n  deleted: boolean;\n\n  object: string;\n}\n\nexport namespace Models {\n  export import Model = ModelsAPI.Model;\n  export import ModelDeleted = ModelsAPI.ModelDeleted;\n  export import ModelsPage = ModelsAPI.ModelsPage;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;;;;AAOhF,MAAO,eAAe,qIAAA,CAAA,cAAW;IACrC;;;QAIA,SAAS,KAAa,EAAE,OAA6B,EAAA;QACnD,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,CAAA,QAAA,EAAW,MAAK,CAAE,EAAE;IAC9C;IAEA;;;QAIA,KAAK,OAA6B,EAAA;QAChC,OAAO,IAAI,CAAC,OAAO,CAAC,UAAU,CAAC,WAAW,YAAY;IACxD;IAEA;;;QAIA,IAAI,KAAa,EAAE,OAA6B,EAAA;QAC9C,OAAO,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,CAAA,QAAA,EAAW,MAAK,CAAE,EAAE;IACjD;;AAMI,MAAO,mBAAmB,uIAAA,CAAA,OAAW;;AAmC3C,CAAA,SAAiB,MAAM;IAGP,OAAA,UAAU,GAAG,iJAAU,UAAU;AACjD,CAAC,EAJgB,UAAM,CAAN,SAAM,CAAA,CAAA"}},
    {"offset": {"line": 6598, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6603, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/moderations.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../resource';\nimport * as Core from '../core';\nimport * as ModerationsAPI from './moderations';\n\nexport class Moderations extends APIResource {\n  /**\n   * Classifies if text and/or image inputs are potentially harmful. Learn more in\n   * the [moderation guide](https://platform.openai.com/docs/guides/moderation).\n   */\n  create(\n    body: ModerationCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<ModerationCreateResponse> {\n    return this._client.post('/moderations', { body, ...options });\n  }\n}\n\nexport interface Moderation {\n  /**\n   * A list of the categories, and whether they are flagged or not.\n   */\n  categories: Moderation.Categories;\n\n  /**\n   * A list of the categories along with the input type(s) that the score applies to.\n   */\n  category_applied_input_types: Moderation.CategoryAppliedInputTypes;\n\n  /**\n   * A list of the categories along with their scores as predicted by model.\n   */\n  category_scores: Moderation.CategoryScores;\n\n  /**\n   * Whether any of the below categories are flagged.\n   */\n  flagged: boolean;\n}\n\nexport namespace Moderation {\n  /**\n   * A list of the categories, and whether they are flagged or not.\n   */\n  export interface Categories {\n    /**\n     * Content that expresses, incites, or promotes harassing language towards any\n     * target.\n     */\n    harassment: boolean;\n\n    /**\n     * Harassment content that also includes violence or serious harm towards any\n     * target.\n     */\n    'harassment/threatening': boolean;\n\n    /**\n     * Content that expresses, incites, or promotes hate based on race, gender,\n     * ethnicity, religion, nationality, sexual orientation, disability status, or\n     * caste. Hateful content aimed at non-protected groups (e.g., chess players) is\n     * harassment.\n     */\n    hate: boolean;\n\n    /**\n     * Hateful content that also includes violence or serious harm towards the targeted\n     * group based on race, gender, ethnicity, religion, nationality, sexual\n     * orientation, disability status, or caste.\n     */\n    'hate/threatening': boolean;\n\n    /**\n     * Content that includes instructions or advice that facilitate the planning or\n     * execution of wrongdoing, or that gives advice or instruction on how to commit\n     * illicit acts. For example, \"how to shoplift\" would fit this category.\n     */\n    illicit: boolean;\n\n    /**\n     * Content that includes instructions or advice that facilitate the planning or\n     * execution of wrongdoing that also includes violence, or that gives advice or\n     * instruction on the procurement of any weapon.\n     */\n    'illicit/violent': boolean;\n\n    /**\n     * Content that promotes, encourages, or depicts acts of self-harm, such as\n     * suicide, cutting, and eating disorders.\n     */\n    'self-harm': boolean;\n\n    /**\n     * Content that encourages performing acts of self-harm, such as suicide, cutting,\n     * and eating disorders, or that gives instructions or advice on how to commit such\n     * acts.\n     */\n    'self-harm/instructions': boolean;\n\n    /**\n     * Content where the speaker expresses that they are engaging or intend to engage\n     * in acts of self-harm, such as suicide, cutting, and eating disorders.\n     */\n    'self-harm/intent': boolean;\n\n    /**\n     * Content meant to arouse sexual excitement, such as the description of sexual\n     * activity, or that promotes sexual services (excluding sex education and\n     * wellness).\n     */\n    sexual: boolean;\n\n    /**\n     * Sexual content that includes an individual who is under 18 years old.\n     */\n    'sexual/minors': boolean;\n\n    /**\n     * Content that depicts death, violence, or physical injury.\n     */\n    violence: boolean;\n\n    /**\n     * Content that depicts death, violence, or physical injury in graphic detail.\n     */\n    'violence/graphic': boolean;\n  }\n\n  /**\n   * A list of the categories along with the input type(s) that the score applies to.\n   */\n  export interface CategoryAppliedInputTypes {\n    /**\n     * The applied input type(s) for the category 'harassment'.\n     */\n    harassment: Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'harassment/threatening'.\n     */\n    'harassment/threatening': Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'hate'.\n     */\n    hate: Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'hate/threatening'.\n     */\n    'hate/threatening': Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'illicit'.\n     */\n    illicit: Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'illicit/violent'.\n     */\n    'illicit/violent': Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'self-harm'.\n     */\n    'self-harm': Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'self-harm/instructions'.\n     */\n    'self-harm/instructions': Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'self-harm/intent'.\n     */\n    'self-harm/intent': Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'sexual'.\n     */\n    sexual: Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'sexual/minors'.\n     */\n    'sexual/minors': Array<'text'>;\n\n    /**\n     * The applied input type(s) for the category 'violence'.\n     */\n    violence: Array<'text' | 'image'>;\n\n    /**\n     * The applied input type(s) for the category 'violence/graphic'.\n     */\n    'violence/graphic': Array<'text' | 'image'>;\n  }\n\n  /**\n   * A list of the categories along with their scores as predicted by model.\n   */\n  export interface CategoryScores {\n    /**\n     * The score for the category 'harassment'.\n     */\n    harassment: number;\n\n    /**\n     * The score for the category 'harassment/threatening'.\n     */\n    'harassment/threatening': number;\n\n    /**\n     * The score for the category 'hate'.\n     */\n    hate: number;\n\n    /**\n     * The score for the category 'hate/threatening'.\n     */\n    'hate/threatening': number;\n\n    /**\n     * The score for the category 'illicit'.\n     */\n    illicit: number;\n\n    /**\n     * The score for the category 'illicit/violent'.\n     */\n    'illicit/violent': number;\n\n    /**\n     * The score for the category 'self-harm'.\n     */\n    'self-harm': number;\n\n    /**\n     * The score for the category 'self-harm/instructions'.\n     */\n    'self-harm/instructions': number;\n\n    /**\n     * The score for the category 'self-harm/intent'.\n     */\n    'self-harm/intent': number;\n\n    /**\n     * The score for the category 'sexual'.\n     */\n    sexual: number;\n\n    /**\n     * The score for the category 'sexual/minors'.\n     */\n    'sexual/minors': number;\n\n    /**\n     * The score for the category 'violence'.\n     */\n    violence: number;\n\n    /**\n     * The score for the category 'violence/graphic'.\n     */\n    'violence/graphic': number;\n  }\n}\n\n/**\n * An object describing an image to classify.\n */\nexport interface ModerationImageURLInput {\n  /**\n   * Contains either an image URL or a data URL for a base64 encoded image.\n   */\n  image_url: ModerationImageURLInput.ImageURL;\n\n  /**\n   * Always `image_url`.\n   */\n  type: 'image_url';\n}\n\nexport namespace ModerationImageURLInput {\n  /**\n   * Contains either an image URL or a data URL for a base64 encoded image.\n   */\n  export interface ImageURL {\n    /**\n     * Either a URL of the image or the base64 encoded image data.\n     */\n    url: string;\n  }\n}\n\nexport type ModerationModel =\n  | 'omni-moderation-latest'\n  | 'omni-moderation-2024-09-26'\n  | 'text-moderation-latest'\n  | 'text-moderation-stable';\n\n/**\n * An object describing an image to classify.\n */\nexport type ModerationMultiModalInput = ModerationImageURLInput | ModerationTextInput;\n\n/**\n * An object describing text to classify.\n */\nexport interface ModerationTextInput {\n  /**\n   * A string of text to classify.\n   */\n  text: string;\n\n  /**\n   * Always `text`.\n   */\n  type: 'text';\n}\n\n/**\n * Represents if a given text input is potentially harmful.\n */\nexport interface ModerationCreateResponse {\n  /**\n   * The unique identifier for the moderation request.\n   */\n  id: string;\n\n  /**\n   * The model used to generate the moderation results.\n   */\n  model: string;\n\n  /**\n   * A list of moderation objects.\n   */\n  results: Array<Moderation>;\n}\n\nexport interface ModerationCreateParams {\n  /**\n   * Input (or inputs) to classify. Can be a single string, an array of strings, or\n   * an array of multi-modal input objects similar to other models.\n   */\n  input: string | Array<string> | Array<ModerationMultiModalInput>;\n\n  /**\n   * The content moderation model you would like to use. Learn more in\n   * [the moderation guide](https://platform.openai.com/docs/guides/moderation), and\n   * learn about available models\n   * [here](https://platform.openai.com/docs/models/moderation).\n   */\n  model?: (string & {}) | ModerationModel;\n}\n\nexport namespace Moderations {\n  export import Moderation = ModerationsAPI.Moderation;\n  export import ModerationImageURLInput = ModerationsAPI.ModerationImageURLInput;\n  export import ModerationModel = ModerationsAPI.ModerationModel;\n  export import ModerationMultiModalInput = ModerationsAPI.ModerationMultiModalInput;\n  export import ModerationTextInput = ModerationsAPI.ModerationTextInput;\n  export import ModerationCreateResponse = ModerationsAPI.ModerationCreateResponse;\n  export import ModerationCreateParams = ModerationsAPI.ModerationCreateParams;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;AAMhF,MAAO,oBAAoB,qIAAA,CAAA,cAAW;IAC1C;;;QAIA,OACE,IAA4B,EAC5B,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,gBAAgB;YAAE;YAAM,GAAG,OAAO;QAAA;IAC7D;;AAuVF,CAAA,SAAiB,WAAW,GAQ5B,CAAC,EARgB,eAAW,CAAX,cAAW,CAAA,CAAA"}},
    {"offset": {"line": 6622, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6627, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/uploads/parts.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as Core from '../../core';\nimport * as PartsAPI from './parts';\n\nexport class Parts extends APIResource {\n  /**\n   * Adds a\n   * [Part](https://platform.openai.com/docs/api-reference/uploads/part-object) to an\n   * [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object.\n   * A Part represents a chunk of bytes from the file you are trying to upload.\n   *\n   * Each Part can be at most 64 MB, and you can add Parts until you hit the Upload\n   * maximum of 8 GB.\n   *\n   * It is possible to add multiple Parts in parallel. You can decide the intended\n   * order of the Parts when you\n   * [complete the Upload](https://platform.openai.com/docs/api-reference/uploads/complete).\n   */\n  create(\n    uploadId: string,\n    body: PartCreateParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<UploadPart> {\n    return this._client.post(\n      `/uploads/${uploadId}/parts`,\n      Core.multipartFormRequestOptions({ body, ...options }),\n    );\n  }\n}\n\n/**\n * The upload Part represents a chunk of bytes we can add to an Upload object.\n */\nexport interface UploadPart {\n  /**\n   * The upload Part unique identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The Unix timestamp (in seconds) for when the Part was created.\n   */\n  created_at: number;\n\n  /**\n   * The object type, which is always `upload.part`.\n   */\n  object: 'upload.part';\n\n  /**\n   * The ID of the Upload object that this Part was added to.\n   */\n  upload_id: string;\n}\n\nexport interface PartCreateParams {\n  /**\n   * The chunk of bytes for this Part.\n   */\n  data: Core.Uploadable;\n}\n\nexport namespace Parts {\n  export import UploadPart = PartsAPI.UploadPart;\n  export import PartCreateParams = PartsAPI.PartCreateParams;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;AAMhF,MAAO,cAAc,qIAAA,CAAA,cAAW;IACpC;;;;;;;;;;;;QAaA,OACE,QAAgB,EAChB,IAAsB,EACtB,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CACtB,CAAA,SAAA,EAAY,SAAQ,MAAA,CAAQ,EAC5B,kJAAK,2BAA2B,CAAC;YAAE;YAAM,GAAG,OAAO;QAAA;IAEvD;;AAmCF,CAAA,SAAiB,KAAK,GAGtB,CAAC,EAHgB,SAAK,CAAL,QAAK,CAAA,CAAA"}},
    {"offset": {"line": 6657, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6662, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/uploads/uploads.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as Core from '../../core';\nimport * as UploadsAPI from './uploads';\nimport * as FilesAPI from '../files';\nimport * as PartsAPI from './parts';\n\nexport class Uploads extends APIResource {\n  parts: PartsAPI.Parts = new PartsAPI.Parts(this._client);\n\n  /**\n   * Creates an intermediate\n   * [Upload](https://platform.openai.com/docs/api-reference/uploads/object) object\n   * that you can add\n   * [Parts](https://platform.openai.com/docs/api-reference/uploads/part-object) to.\n   * Currently, an Upload can accept at most 8 GB in total and expires after an hour\n   * after you create it.\n   *\n   * Once you complete the Upload, we will create a\n   * [File](https://platform.openai.com/docs/api-reference/files/object) object that\n   * contains all the parts you uploaded. This File is usable in the rest of our\n   * platform as a regular File object.\n   *\n   * For certain `purpose`s, the correct `mime_type` must be specified. Please refer\n   * to documentation for the supported MIME types for your use case:\n   *\n   * - [Assistants](https://platform.openai.com/docs/assistants/tools/file-search/supported-files)\n   *\n   * For guidance on the proper filename extensions for each purpose, please follow\n   * the documentation on\n   * [creating a File](https://platform.openai.com/docs/api-reference/files/create).\n   */\n  create(body: UploadCreateParams, options?: Core.RequestOptions): Core.APIPromise<Upload> {\n    return this._client.post('/uploads', { body, ...options });\n  }\n\n  /**\n   * Cancels the Upload. No Parts may be added after an Upload is cancelled.\n   */\n  cancel(uploadId: string, options?: Core.RequestOptions): Core.APIPromise<Upload> {\n    return this._client.post(`/uploads/${uploadId}/cancel`, options);\n  }\n\n  /**\n   * Completes the\n   * [Upload](https://platform.openai.com/docs/api-reference/uploads/object).\n   *\n   * Within the returned Upload object, there is a nested\n   * [File](https://platform.openai.com/docs/api-reference/files/object) object that\n   * is ready to use in the rest of the platform.\n   *\n   * You can specify the order of the Parts by passing in an ordered list of the Part\n   * IDs.\n   *\n   * The number of bytes uploaded upon completion must match the number of bytes\n   * initially specified when creating the Upload object. No Parts may be added after\n   * an Upload is completed.\n   */\n  complete(\n    uploadId: string,\n    body: UploadCompleteParams,\n    options?: Core.RequestOptions,\n  ): Core.APIPromise<Upload> {\n    return this._client.post(`/uploads/${uploadId}/complete`, { body, ...options });\n  }\n}\n\n/**\n * The Upload object can accept byte chunks in the form of Parts.\n */\nexport interface Upload {\n  /**\n   * The Upload unique identifier, which can be referenced in API endpoints.\n   */\n  id: string;\n\n  /**\n   * The intended number of bytes to be uploaded.\n   */\n  bytes: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the Upload was created.\n   */\n  created_at: number;\n\n  /**\n   * The Unix timestamp (in seconds) for when the Upload was created.\n   */\n  expires_at: number;\n\n  /**\n   * The name of the file to be uploaded.\n   */\n  filename: string;\n\n  /**\n   * The object type, which is always \"upload\".\n   */\n  object: 'upload';\n\n  /**\n   * The intended purpose of the file.\n   * [Please refer here](https://platform.openai.com/docs/api-reference/files/object#files/object-purpose)\n   * for acceptable values.\n   */\n  purpose: string;\n\n  /**\n   * The status of the Upload.\n   */\n  status: 'pending' | 'completed' | 'cancelled' | 'expired';\n\n  /**\n   * The ready File object after the Upload is completed.\n   */\n  file?: FilesAPI.FileObject | null;\n}\n\nexport interface UploadCreateParams {\n  /**\n   * The number of bytes in the file you are uploading.\n   */\n  bytes: number;\n\n  /**\n   * The name of the file to upload.\n   */\n  filename: string;\n\n  /**\n   * The MIME type of the file.\n   *\n   * This must fall within the supported MIME types for your file purpose. See the\n   * supported MIME types for assistants and vision.\n   */\n  mime_type: string;\n\n  /**\n   * The intended purpose of the uploaded file.\n   *\n   * See the\n   * [documentation on File purposes](https://platform.openai.com/docs/api-reference/files/create#files-create-purpose).\n   */\n  purpose: FilesAPI.FilePurpose;\n}\n\nexport interface UploadCompleteParams {\n  /**\n   * The ordered list of Part IDs.\n   */\n  part_ids: Array<string>;\n\n  /**\n   * The optional md5 checksum for the file contents to verify if the bytes uploaded\n   * matches what you expect.\n   */\n  md5?: string;\n}\n\nexport namespace Uploads {\n  export import Upload = UploadsAPI.Upload;\n  export import UploadCreateParams = UploadsAPI.UploadCreateParams;\n  export import UploadCompleteParams = UploadsAPI.UploadCompleteParams;\n  export import Parts = PartsAPI.Parts;\n  export import UploadPart = PartsAPI.UploadPart;\n  export import PartCreateParams = PartsAPI.PartCreateParams;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;AAQhF,MAAO,gBAAgB,qIAAA,CAAA,cAAW;IAAxC,aAAA;;QACE,IAAA,CAAA,KAAK,GAAmB,IAAI,2JAAS,KAAK,CAAC,IAAI,CAAC,OAAO;IAyDzD;IAvDE;;;;;;;;;;;;;;;;;;;;;QAsBA,OAAO,IAAwB,EAAE,OAA6B,EAAA;QAC5D,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,YAAY;YAAE;YAAM,GAAG,OAAO;QAAA;IACzD;IAEA;;QAGA,OAAO,QAAgB,EAAE,OAA6B,EAAA;QACpD,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,CAAA,SAAA,EAAY,SAAQ,OAAA,CAAS,EAAE;IAC1D;IAEA;;;;;;;;;;;;;;QAeA,SACE,QAAgB,EAChB,IAA0B,EAC1B,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,CAAA,SAAA,EAAY,SAAQ,SAAA,CAAW,EAAE;YAAE;YAAM,GAAG,OAAO;QAAA;IAC9E;;AAgGF,CAAA,SAAiB,OAAO;IAIR,QAAA,KAAK,GAAG,2JAAS,KAAK;AAGtC,CAAC,EAPgB,WAAO,CAAP,UAAO,CAAA,CAAA"}},
    {"offset": {"line": 6732, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6737, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/chat/index.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nexport {\n  ChatCompletion,\n  ChatCompletionAssistantMessageParam,\n  ChatCompletionChunk,\n  ChatCompletionContentPart,\n  ChatCompletionContentPartImage,\n  ChatCompletionContentPartRefusal,\n  ChatCompletionContentPartText,\n  ChatCompletionFunctionCallOption,\n  ChatCompletionFunctionMessageParam,\n  ChatCompletionMessage,\n  ChatCompletionMessageParam,\n  ChatCompletionMessageToolCall,\n  ChatCompletionNamedToolChoice,\n  ChatCompletionRole,\n  ChatCompletionStreamOptions,\n  ChatCompletionSystemMessageParam,\n  ChatCompletionTokenLogprob,\n  ChatCompletionTool,\n  ChatCompletionToolChoiceOption,\n  ChatCompletionToolMessageParam,\n  ChatCompletionUserMessageParam,\n  CreateChatCompletionRequestMessage,\n  ChatCompletionCreateParams,\n  CompletionCreateParams,\n  ChatCompletionCreateParamsNonStreaming,\n  CompletionCreateParamsNonStreaming,\n  ChatCompletionCreateParamsStreaming,\n  CompletionCreateParamsStreaming,\n  Completions,\n} from './completions';\nexport { ChatModel, Chat } from './chat';\n"],"names":[],"mappings":"AAAA,sFAAsF"}},
    {"offset": {"line": 6742, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6755, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/chat/completions.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport { APIPromise } from '../../core';\nimport * as Core from '../../core';\nimport * as ChatCompletionsAPI from './completions';\nimport * as CompletionsAPI from '../completions';\nimport * as Shared from '../shared';\nimport * as ChatAPI from './chat';\nimport { Stream } from '../../streaming';\n\nexport class Completions extends APIResource {\n  /**\n   * Creates a model response for the given chat conversation.\n   */\n  create(\n    body: ChatCompletionCreateParamsNonStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<ChatCompletion>;\n  create(\n    body: ChatCompletionCreateParamsStreaming,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<ChatCompletionChunk>>;\n  create(\n    body: ChatCompletionCreateParamsBase,\n    options?: Core.RequestOptions,\n  ): APIPromise<Stream<ChatCompletionChunk> | ChatCompletion>;\n  create(\n    body: ChatCompletionCreateParams,\n    options?: Core.RequestOptions,\n  ): APIPromise<ChatCompletion> | APIPromise<Stream<ChatCompletionChunk>> {\n    return this._client.post('/chat/completions', { body, ...options, stream: body.stream ?? false }) as\n      | APIPromise<ChatCompletion>\n      | APIPromise<Stream<ChatCompletionChunk>>;\n  }\n}\n\n/**\n * Represents a chat completion response returned by model, based on the provided\n * input.\n */\nexport interface ChatCompletion {\n  /**\n   * A unique identifier for the chat completion.\n   */\n  id: string;\n\n  /**\n   * A list of chat completion choices. Can be more than one if `n` is greater\n   * than 1.\n   */\n  choices: Array<ChatCompletion.Choice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the chat completion was created.\n   */\n  created: number;\n\n  /**\n   * The model used for the chat completion.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always `chat.completion`.\n   */\n  object: 'chat.completion';\n\n  /**\n   * The service tier used for processing the request. This field is only included if\n   * the `service_tier` parameter is specified in the request.\n   */\n  service_tier?: 'scale' | 'default' | null;\n\n  /**\n   * This fingerprint represents the backend configuration that the model runs with.\n   *\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n\n  /**\n   * Usage statistics for the completion request.\n   */\n  usage?: CompletionsAPI.CompletionUsage;\n}\n\nexport namespace ChatCompletion {\n  export interface Choice {\n    /**\n     * The reason the model stopped generating tokens. This will be `stop` if the model\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\n     * number of tokens specified in the request was reached, `content_filter` if\n     * content was omitted due to a flag from our content filters, `tool_calls` if the\n     * model called a tool, or `function_call` (deprecated) if the model called a\n     * function.\n     */\n    finish_reason: 'stop' | 'length' | 'tool_calls' | 'content_filter' | 'function_call';\n\n    /**\n     * The index of the choice in the list of choices.\n     */\n    index: number;\n\n    /**\n     * Log probability information for the choice.\n     */\n    logprobs: Choice.Logprobs | null;\n\n    /**\n     * A chat completion message generated by the model.\n     */\n    message: ChatCompletionsAPI.ChatCompletionMessage;\n  }\n\n  export namespace Choice {\n    /**\n     * Log probability information for the choice.\n     */\n    export interface Logprobs {\n      /**\n       * A list of message content tokens with log probability information.\n       */\n      content: Array<ChatCompletionsAPI.ChatCompletionTokenLogprob> | null;\n\n      /**\n       * A list of message refusal tokens with log probability information.\n       */\n      refusal: Array<ChatCompletionsAPI.ChatCompletionTokenLogprob> | null;\n    }\n  }\n}\n\nexport interface ChatCompletionAssistantMessageParam {\n  /**\n   * The role of the messages author, in this case `assistant`.\n   */\n  role: 'assistant';\n\n  /**\n   * The contents of the assistant message. Required unless `tool_calls` or\n   * `function_call` is specified.\n   */\n  content?: string | Array<ChatCompletionContentPartText | ChatCompletionContentPartRefusal> | null;\n\n  /**\n   * @deprecated: Deprecated and replaced by `tool_calls`. The name and arguments of\n   * a function that should be called, as generated by the model.\n   */\n  function_call?: ChatCompletionAssistantMessageParam.FunctionCall | null;\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n\n  /**\n   * The refusal message by the assistant.\n   */\n  refusal?: string | null;\n\n  /**\n   * The tool calls generated by the model, such as function calls.\n   */\n  tool_calls?: Array<ChatCompletionMessageToolCall>;\n}\n\nexport namespace ChatCompletionAssistantMessageParam {\n  /**\n   * @deprecated: Deprecated and replaced by `tool_calls`. The name and arguments of\n   * a function that should be called, as generated by the model.\n   */\n  export interface FunctionCall {\n    /**\n     * The arguments to call the function with, as generated by the model in JSON\n     * format. Note that the model does not always generate valid JSON, and may\n     * hallucinate parameters not defined by your function schema. Validate the\n     * arguments in your code before calling your function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * Represents a streamed chunk of a chat completion response returned by model,\n * based on the provided input.\n */\nexport interface ChatCompletionChunk {\n  /**\n   * A unique identifier for the chat completion. Each chunk has the same ID.\n   */\n  id: string;\n\n  /**\n   * A list of chat completion choices. Can contain more than one elements if `n` is\n   * greater than 1. Can also be empty for the last chunk if you set\n   * `stream_options: {\"include_usage\": true}`.\n   */\n  choices: Array<ChatCompletionChunk.Choice>;\n\n  /**\n   * The Unix timestamp (in seconds) of when the chat completion was created. Each\n   * chunk has the same timestamp.\n   */\n  created: number;\n\n  /**\n   * The model to generate the completion.\n   */\n  model: string;\n\n  /**\n   * The object type, which is always `chat.completion.chunk`.\n   */\n  object: 'chat.completion.chunk';\n\n  /**\n   * The service tier used for processing the request. This field is only included if\n   * the `service_tier` parameter is specified in the request.\n   */\n  service_tier?: 'scale' | 'default' | null;\n\n  /**\n   * This fingerprint represents the backend configuration that the model runs with.\n   * Can be used in conjunction with the `seed` request parameter to understand when\n   * backend changes have been made that might impact determinism.\n   */\n  system_fingerprint?: string;\n\n  /**\n   * An optional field that will only be present when you set\n   * `stream_options: {\"include_usage\": true}` in your request. When present, it\n   * contains a null value except for the last chunk which contains the token usage\n   * statistics for the entire request.\n   */\n  usage?: CompletionsAPI.CompletionUsage;\n}\n\nexport namespace ChatCompletionChunk {\n  export interface Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    delta: Choice.Delta;\n\n    /**\n     * The reason the model stopped generating tokens. This will be `stop` if the model\n     * hit a natural stop point or a provided stop sequence, `length` if the maximum\n     * number of tokens specified in the request was reached, `content_filter` if\n     * content was omitted due to a flag from our content filters, `tool_calls` if the\n     * model called a tool, or `function_call` (deprecated) if the model called a\n     * function.\n     */\n    finish_reason: 'stop' | 'length' | 'tool_calls' | 'content_filter' | 'function_call' | null;\n\n    /**\n     * The index of the choice in the list of choices.\n     */\n    index: number;\n\n    /**\n     * Log probability information for the choice.\n     */\n    logprobs?: Choice.Logprobs | null;\n  }\n\n  export namespace Choice {\n    /**\n     * A chat completion delta generated by streamed model responses.\n     */\n    export interface Delta {\n      /**\n       * The contents of the chunk message.\n       */\n      content?: string | null;\n\n      /**\n       * @deprecated: Deprecated and replaced by `tool_calls`. The name and arguments of\n       * a function that should be called, as generated by the model.\n       */\n      function_call?: Delta.FunctionCall;\n\n      /**\n       * The refusal message generated by the model.\n       */\n      refusal?: string | null;\n\n      /**\n       * The role of the author of this message.\n       */\n      role?: 'system' | 'user' | 'assistant' | 'tool';\n\n      tool_calls?: Array<Delta.ToolCall>;\n    }\n\n    export namespace Delta {\n      /**\n       * @deprecated: Deprecated and replaced by `tool_calls`. The name and arguments of\n       * a function that should be called, as generated by the model.\n       */\n      export interface FunctionCall {\n        /**\n         * The arguments to call the function with, as generated by the model in JSON\n         * format. Note that the model does not always generate valid JSON, and may\n         * hallucinate parameters not defined by your function schema. Validate the\n         * arguments in your code before calling your function.\n         */\n        arguments?: string;\n\n        /**\n         * The name of the function to call.\n         */\n        name?: string;\n      }\n\n      export interface ToolCall {\n        index: number;\n\n        /**\n         * The ID of the tool call.\n         */\n        id?: string;\n\n        function?: ToolCall.Function;\n\n        /**\n         * The type of the tool. Currently, only `function` is supported.\n         */\n        type?: 'function';\n      }\n\n      export namespace ToolCall {\n        export interface Function {\n          /**\n           * The arguments to call the function with, as generated by the model in JSON\n           * format. Note that the model does not always generate valid JSON, and may\n           * hallucinate parameters not defined by your function schema. Validate the\n           * arguments in your code before calling your function.\n           */\n          arguments?: string;\n\n          /**\n           * The name of the function to call.\n           */\n          name?: string;\n        }\n      }\n    }\n\n    /**\n     * Log probability information for the choice.\n     */\n    export interface Logprobs {\n      /**\n       * A list of message content tokens with log probability information.\n       */\n      content: Array<ChatCompletionsAPI.ChatCompletionTokenLogprob> | null;\n\n      /**\n       * A list of message refusal tokens with log probability information.\n       */\n      refusal: Array<ChatCompletionsAPI.ChatCompletionTokenLogprob> | null;\n    }\n  }\n}\n\nexport type ChatCompletionContentPart = ChatCompletionContentPartText | ChatCompletionContentPartImage;\n\nexport interface ChatCompletionContentPartImage {\n  image_url: ChatCompletionContentPartImage.ImageURL;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'image_url';\n}\n\nexport namespace ChatCompletionContentPartImage {\n  export interface ImageURL {\n    /**\n     * Either a URL of the image or the base64 encoded image data.\n     */\n    url: string;\n\n    /**\n     * Specifies the detail level of the image. Learn more in the\n     * [Vision guide](https://platform.openai.com/docs/guides/vision/low-or-high-fidelity-image-understanding).\n     */\n    detail?: 'auto' | 'low' | 'high';\n  }\n}\n\nexport interface ChatCompletionContentPartRefusal {\n  /**\n   * The refusal message generated by the model.\n   */\n  refusal: string;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'refusal';\n}\n\nexport interface ChatCompletionContentPartText {\n  /**\n   * The text content.\n   */\n  text: string;\n\n  /**\n   * The type of the content part.\n   */\n  type: 'text';\n}\n\n/**\n * Specifying a particular function via `{\"name\": \"my_function\"}` forces the model\n * to call that function.\n */\nexport interface ChatCompletionFunctionCallOption {\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n}\n\n/**\n * @deprecated\n */\nexport interface ChatCompletionFunctionMessageParam {\n  /**\n   * The contents of the function message.\n   */\n  content: string | null;\n\n  /**\n   * The name of the function to call.\n   */\n  name: string;\n\n  /**\n   * The role of the messages author, in this case `function`.\n   */\n  role: 'function';\n}\n\n/**\n * A chat completion message generated by the model.\n */\nexport interface ChatCompletionMessage {\n  /**\n   * The contents of the message.\n   */\n  content: string | null;\n\n  /**\n   * The refusal message generated by the model.\n   */\n  refusal: string | null;\n\n  /**\n   * The role of the author of this message.\n   */\n  role: 'assistant';\n\n  /**\n   * @deprecated: Deprecated and replaced by `tool_calls`. The name and arguments of\n   * a function that should be called, as generated by the model.\n   */\n  function_call?: ChatCompletionMessage.FunctionCall | null;\n\n  /**\n   * The tool calls generated by the model, such as function calls.\n   */\n  tool_calls?: Array<ChatCompletionMessageToolCall>;\n}\n\nexport namespace ChatCompletionMessage {\n  /**\n   * @deprecated: Deprecated and replaced by `tool_calls`. The name and arguments of\n   * a function that should be called, as generated by the model.\n   */\n  export interface FunctionCall {\n    /**\n     * The arguments to call the function with, as generated by the model in JSON\n     * format. Note that the model does not always generate valid JSON, and may\n     * hallucinate parameters not defined by your function schema. Validate the\n     * arguments in your code before calling your function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\nexport type ChatCompletionMessageParam =\n  | ChatCompletionSystemMessageParam\n  | ChatCompletionUserMessageParam\n  | ChatCompletionAssistantMessageParam\n  | ChatCompletionToolMessageParam\n  | ChatCompletionFunctionMessageParam;\n\nexport interface ChatCompletionMessageToolCall {\n  /**\n   * The ID of the tool call.\n   */\n  id: string;\n\n  /**\n   * The function that the model called.\n   */\n  function: ChatCompletionMessageToolCall.Function;\n\n  /**\n   * The type of the tool. Currently, only `function` is supported.\n   */\n  type: 'function';\n}\n\nexport namespace ChatCompletionMessageToolCall {\n  /**\n   * The function that the model called.\n   */\n  export interface Function {\n    /**\n     * The arguments to call the function with, as generated by the model in JSON\n     * format. Note that the model does not always generate valid JSON, and may\n     * hallucinate parameters not defined by your function schema. Validate the\n     * arguments in your code before calling your function.\n     */\n    arguments: string;\n\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * Specifies a tool the model should use. Use to force the model to call a specific\n * function.\n */\nexport interface ChatCompletionNamedToolChoice {\n  function: ChatCompletionNamedToolChoice.Function;\n\n  /**\n   * The type of the tool. Currently, only `function` is supported.\n   */\n  type: 'function';\n}\n\nexport namespace ChatCompletionNamedToolChoice {\n  export interface Function {\n    /**\n     * The name of the function to call.\n     */\n    name: string;\n  }\n}\n\n/**\n * The role of the author of a message\n */\nexport type ChatCompletionRole = 'system' | 'user' | 'assistant' | 'tool' | 'function';\n\n/**\n * Options for streaming response. Only set this when you set `stream: true`.\n */\nexport interface ChatCompletionStreamOptions {\n  /**\n   * If set, an additional chunk will be streamed before the `data: [DONE]` message.\n   * The `usage` field on this chunk shows the token usage statistics for the entire\n   * request, and the `choices` field will always be an empty array. All other chunks\n   * will also include a `usage` field, but with a null value.\n   */\n  include_usage?: boolean;\n}\n\nexport interface ChatCompletionSystemMessageParam {\n  /**\n   * The contents of the system message.\n   */\n  content: string | Array<ChatCompletionContentPartText>;\n\n  /**\n   * The role of the messages author, in this case `system`.\n   */\n  role: 'system';\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n}\n\nexport interface ChatCompletionTokenLogprob {\n  /**\n   * The token.\n   */\n  token: string;\n\n  /**\n   * A list of integers representing the UTF-8 bytes representation of the token.\n   * Useful in instances where characters are represented by multiple tokens and\n   * their byte representations must be combined to generate the correct text\n   * representation. Can be `null` if there is no bytes representation for the token.\n   */\n  bytes: Array<number> | null;\n\n  /**\n   * The log probability of this token, if it is within the top 20 most likely\n   * tokens. Otherwise, the value `-9999.0` is used to signify that the token is very\n   * unlikely.\n   */\n  logprob: number;\n\n  /**\n   * List of the most likely tokens and their log probability, at this token\n   * position. In rare cases, there may be fewer than the number of requested\n   * `top_logprobs` returned.\n   */\n  top_logprobs: Array<ChatCompletionTokenLogprob.TopLogprob>;\n}\n\nexport namespace ChatCompletionTokenLogprob {\n  export interface TopLogprob {\n    /**\n     * The token.\n     */\n    token: string;\n\n    /**\n     * A list of integers representing the UTF-8 bytes representation of the token.\n     * Useful in instances where characters are represented by multiple tokens and\n     * their byte representations must be combined to generate the correct text\n     * representation. Can be `null` if there is no bytes representation for the token.\n     */\n    bytes: Array<number> | null;\n\n    /**\n     * The log probability of this token, if it is within the top 20 most likely\n     * tokens. Otherwise, the value `-9999.0` is used to signify that the token is very\n     * unlikely.\n     */\n    logprob: number;\n  }\n}\n\nexport interface ChatCompletionTool {\n  function: Shared.FunctionDefinition;\n\n  /**\n   * The type of the tool. Currently, only `function` is supported.\n   */\n  type: 'function';\n}\n\n/**\n * Controls which (if any) tool is called by the model. `none` means the model will\n * not call any tool and instead generates a message. `auto` means the model can\n * pick between generating a message or calling one or more tools. `required` means\n * the model must call one or more tools. Specifying a particular tool via\n * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n * call that tool.\n *\n * `none` is the default when no tools are present. `auto` is the default if tools\n * are present.\n */\nexport type ChatCompletionToolChoiceOption = 'none' | 'auto' | 'required' | ChatCompletionNamedToolChoice;\n\nexport interface ChatCompletionToolMessageParam {\n  /**\n   * The contents of the tool message.\n   */\n  content: string | Array<ChatCompletionContentPartText>;\n\n  /**\n   * The role of the messages author, in this case `tool`.\n   */\n  role: 'tool';\n\n  /**\n   * Tool call that this message is responding to.\n   */\n  tool_call_id: string;\n}\n\nexport interface ChatCompletionUserMessageParam {\n  /**\n   * The contents of the user message.\n   */\n  content: string | Array<ChatCompletionContentPart>;\n\n  /**\n   * The role of the messages author, in this case `user`.\n   */\n  role: 'user';\n\n  /**\n   * An optional name for the participant. Provides the model information to\n   * differentiate between participants of the same role.\n   */\n  name?: string;\n}\n\n/**\n * @deprecated ChatCompletionMessageParam should be used instead\n */\nexport type CreateChatCompletionRequestMessage = ChatCompletionMessageParam;\n\nexport type ChatCompletionCreateParams =\n  | ChatCompletionCreateParamsNonStreaming\n  | ChatCompletionCreateParamsStreaming;\n\nexport interface ChatCompletionCreateParamsBase {\n  /**\n   * A list of messages comprising the conversation so far. Depending on the\n   * [model](https://platform.openai.com/docs/models) you use, different message\n   * types (modalities) are supported, like\n   * [text](https://platform.openai.com/docs/guides/text-generation),\n   * [images](https://platform.openai.com/docs/guides/vision), and\n   * [audio](https://platform.openai.com/docs/guides/audio).\n   */\n  messages: Array<ChatCompletionMessageParam>;\n\n  /**\n   * ID of the model to use. See the\n   * [model endpoint compatibility](https://platform.openai.com/docs/models/model-endpoint-compatibility)\n   * table for details on which models work with the Chat API.\n   */\n  model: (string & {}) | ChatAPI.ChatModel;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on their\n   * existing frequency in the text so far, decreasing the model's likelihood to\n   * repeat the same line verbatim.\n   *\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation/parameter-details)\n   */\n  frequency_penalty?: number | null;\n\n  /**\n   * Deprecated in favor of `tool_choice`.\n   *\n   * Controls which (if any) function is called by the model. `none` means the model\n   * will not call a function and instead generates a message. `auto` means the model\n   * can pick between generating a message or calling a function. Specifying a\n   * particular function via `{\"name\": \"my_function\"}` forces the model to call that\n   * function.\n   *\n   * `none` is the default when no functions are present. `auto` is the default if\n   * functions are present.\n   */\n  function_call?: 'none' | 'auto' | ChatCompletionFunctionCallOption;\n\n  /**\n   * Deprecated in favor of `tools`.\n   *\n   * A list of functions the model may generate JSON inputs for.\n   */\n  functions?: Array<ChatCompletionCreateParams.Function>;\n\n  /**\n   * Modify the likelihood of specified tokens appearing in the completion.\n   *\n   * Accepts a JSON object that maps tokens (specified by their token ID in the\n   * tokenizer) to an associated bias value from -100 to 100. Mathematically, the\n   * bias is added to the logits generated by the model prior to sampling. The exact\n   * effect will vary per model, but values between -1 and 1 should decrease or\n   * increase likelihood of selection; values like -100 or 100 should result in a ban\n   * or exclusive selection of the relevant token.\n   */\n  logit_bias?: Record<string, number> | null;\n\n  /**\n   * Whether to return log probabilities of the output tokens or not. If true,\n   * returns the log probabilities of each output token returned in the `content` of\n   * `message`.\n   */\n  logprobs?: boolean | null;\n\n  /**\n   * An upper bound for the number of tokens that can be generated for a completion,\n   * including visible output tokens and\n   * [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).\n   */\n  max_completion_tokens?: number | null;\n\n  /**\n   * The maximum number of [tokens](/tokenizer) that can be generated in the chat\n   * completion. This value can be used to control\n   * [costs](https://openai.com/api/pricing/) for text generated via API.\n   *\n   * This value is now deprecated in favor of `max_completion_tokens`, and is not\n   * compatible with\n   * [o1 series models](https://platform.openai.com/docs/guides/reasoning).\n   */\n  max_tokens?: number | null;\n\n  /**\n   * Developer-defined tags and values used for filtering completions in the\n   * [dashboard](https://platform.openai.com/completions).\n   */\n  metadata?: Record<string, string> | null;\n\n  /**\n   * How many chat completion choices to generate for each input message. Note that\n   * you will be charged based on the number of generated tokens across all of the\n   * choices. Keep `n` as `1` to minimize costs.\n   */\n  n?: number | null;\n\n  /**\n   * Whether to enable\n   * [parallel function calling](https://platform.openai.com/docs/guides/function-calling/parallel-function-calling)\n   * during tool use.\n   */\n  parallel_tool_calls?: boolean;\n\n  /**\n   * Number between -2.0 and 2.0. Positive values penalize new tokens based on\n   * whether they appear in the text so far, increasing the model's likelihood to\n   * talk about new topics.\n   *\n   * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/text-generation/parameter-details)\n   */\n  presence_penalty?: number | null;\n\n  /**\n   * An object specifying the format that the model must output. Compatible with\n   * [GPT-4o](https://platform.openai.com/docs/models/gpt-4o),\n   * [GPT-4o mini](https://platform.openai.com/docs/models/gpt-4o-mini),\n   * [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo) and\n   * all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.\n   *\n   * Setting to `{ \"type\": \"json_schema\", \"json_schema\": {...} }` enables Structured\n   * Outputs which ensures the model will match your supplied JSON schema. Learn more\n   * in the\n   * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n   *\n   * Setting to `{ \"type\": \"json_object\" }` enables JSON mode, which ensures the\n   * message the model generates is valid JSON.\n   *\n   * **Important:** when using JSON mode, you **must** also instruct the model to\n   * produce JSON yourself via a system or user message. Without this, the model may\n   * generate an unending stream of whitespace until the generation reaches the token\n   * limit, resulting in a long-running and seemingly \"stuck\" request. Also note that\n   * the message content may be partially cut off if `finish_reason=\"length\"`, which\n   * indicates the generation exceeded `max_tokens` or the conversation exceeded the\n   * max context length.\n   */\n  response_format?:\n    | Shared.ResponseFormatText\n    | Shared.ResponseFormatJSONObject\n    | Shared.ResponseFormatJSONSchema;\n\n  /**\n   * This feature is in Beta. If specified, our system will make a best effort to\n   * sample deterministically, such that repeated requests with the same `seed` and\n   * parameters should return the same result. Determinism is not guaranteed, and you\n   * should refer to the `system_fingerprint` response parameter to monitor changes\n   * in the backend.\n   */\n  seed?: number | null;\n\n  /**\n   * Specifies the latency tier to use for processing the request. This parameter is\n   * relevant for customers subscribed to the scale tier service:\n   *\n   * - If set to 'auto', and the Project is Scale tier enabled, the system will\n   *   utilize scale tier credits until they are exhausted.\n   * - If set to 'auto', and the Project is not Scale tier enabled, the request will\n   *   be processed using the default service tier with a lower uptime SLA and no\n   *   latency guarentee.\n   * - If set to 'default', the request will be processed using the default service\n   *   tier with a lower uptime SLA and no latency guarentee.\n   * - When not set, the default behavior is 'auto'.\n   *\n   * When this parameter is set, the response body will include the `service_tier`\n   * utilized.\n   */\n  service_tier?: 'auto' | 'default' | null;\n\n  /**\n   * Up to 4 sequences where the API will stop generating further tokens.\n   */\n  stop?: string | null | Array<string>;\n\n  /**\n   * Whether or not to store the output of this completion request for traffic\n   * logging in the [dashboard](https://platform.openai.com/completions).\n   */\n  store?: boolean | null;\n\n  /**\n   * If set, partial message deltas will be sent, like in ChatGPT. Tokens will be\n   * sent as data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream?: boolean | null;\n\n  /**\n   * Options for streaming response. Only set this when you set `stream: true`.\n   */\n  stream_options?: ChatCompletionStreamOptions | null;\n\n  /**\n   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will\n   * make the output more random, while lower values like 0.2 will make it more\n   * focused and deterministic.\n   *\n   * We generally recommend altering this or `top_p` but not both.\n   */\n  temperature?: number | null;\n\n  /**\n   * Controls which (if any) tool is called by the model. `none` means the model will\n   * not call any tool and instead generates a message. `auto` means the model can\n   * pick between generating a message or calling one or more tools. `required` means\n   * the model must call one or more tools. Specifying a particular tool via\n   * `{\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}` forces the model to\n   * call that tool.\n   *\n   * `none` is the default when no tools are present. `auto` is the default if tools\n   * are present.\n   */\n  tool_choice?: ChatCompletionToolChoiceOption;\n\n  /**\n   * A list of tools the model may call. Currently, only functions are supported as a\n   * tool. Use this to provide a list of functions the model may generate JSON inputs\n   * for. A max of 128 functions are supported.\n   */\n  tools?: Array<ChatCompletionTool>;\n\n  /**\n   * An integer between 0 and 20 specifying the number of most likely tokens to\n   * return at each token position, each with an associated log probability.\n   * `logprobs` must be set to `true` if this parameter is used.\n   */\n  top_logprobs?: number | null;\n\n  /**\n   * An alternative to sampling with temperature, called nucleus sampling, where the\n   * model considers the results of the tokens with top_p probability mass. So 0.1\n   * means only the tokens comprising the top 10% probability mass are considered.\n   *\n   * We generally recommend altering this or `temperature` but not both.\n   */\n  top_p?: number | null;\n\n  /**\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\n   * and detect abuse.\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).\n   */\n  user?: string;\n}\n\nexport namespace ChatCompletionCreateParams {\n  /**\n   * @deprecated\n   */\n  export interface Function {\n    /**\n     * The name of the function to be called. Must be a-z, A-Z, 0-9, or contain\n     * underscores and dashes, with a maximum length of 64.\n     */\n    name: string;\n\n    /**\n     * A description of what the function does, used by the model to choose when and\n     * how to call the function.\n     */\n    description?: string;\n\n    /**\n     * The parameters the functions accepts, described as a JSON Schema object. See the\n     * [guide](https://platform.openai.com/docs/guides/function-calling) for examples,\n     * and the\n     * [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for\n     * documentation about the format.\n     *\n     * Omitting `parameters` defines a function with an empty parameter list.\n     */\n    parameters?: Shared.FunctionParameters;\n  }\n\n  export type ChatCompletionCreateParamsNonStreaming =\n    ChatCompletionsAPI.ChatCompletionCreateParamsNonStreaming;\n  export type ChatCompletionCreateParamsStreaming = ChatCompletionsAPI.ChatCompletionCreateParamsStreaming;\n}\n\n/**\n * @deprecated Use ChatCompletionCreateParams instead\n */\nexport type CompletionCreateParams = ChatCompletionCreateParams;\n\nexport interface ChatCompletionCreateParamsNonStreaming extends ChatCompletionCreateParamsBase {\n  /**\n   * If set, partial message deltas will be sent, like in ChatGPT. Tokens will be\n   * sent as data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream?: false | null;\n}\n\n/**\n * @deprecated Use ChatCompletionCreateParamsNonStreaming instead\n */\nexport type CompletionCreateParamsNonStreaming = ChatCompletionCreateParamsNonStreaming;\n\nexport interface ChatCompletionCreateParamsStreaming extends ChatCompletionCreateParamsBase {\n  /**\n   * If set, partial message deltas will be sent, like in ChatGPT. Tokens will be\n   * sent as data-only\n   * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)\n   * as they become available, with the stream terminated by a `data: [DONE]`\n   * message.\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).\n   */\n  stream: true;\n}\n\n/**\n * @deprecated Use ChatCompletionCreateParamsStreaming instead\n */\nexport type CompletionCreateParamsStreaming = ChatCompletionCreateParamsStreaming;\n\nexport namespace Completions {\n  export import ChatCompletion = ChatCompletionsAPI.ChatCompletion;\n  export import ChatCompletionAssistantMessageParam = ChatCompletionsAPI.ChatCompletionAssistantMessageParam;\n  export import ChatCompletionChunk = ChatCompletionsAPI.ChatCompletionChunk;\n  export import ChatCompletionContentPart = ChatCompletionsAPI.ChatCompletionContentPart;\n  export import ChatCompletionContentPartImage = ChatCompletionsAPI.ChatCompletionContentPartImage;\n  export import ChatCompletionContentPartRefusal = ChatCompletionsAPI.ChatCompletionContentPartRefusal;\n  export import ChatCompletionContentPartText = ChatCompletionsAPI.ChatCompletionContentPartText;\n  export import ChatCompletionFunctionCallOption = ChatCompletionsAPI.ChatCompletionFunctionCallOption;\n  export import ChatCompletionFunctionMessageParam = ChatCompletionsAPI.ChatCompletionFunctionMessageParam;\n  export import ChatCompletionMessage = ChatCompletionsAPI.ChatCompletionMessage;\n  export import ChatCompletionMessageParam = ChatCompletionsAPI.ChatCompletionMessageParam;\n  export import ChatCompletionMessageToolCall = ChatCompletionsAPI.ChatCompletionMessageToolCall;\n  export import ChatCompletionNamedToolChoice = ChatCompletionsAPI.ChatCompletionNamedToolChoice;\n  export import ChatCompletionRole = ChatCompletionsAPI.ChatCompletionRole;\n  export import ChatCompletionStreamOptions = ChatCompletionsAPI.ChatCompletionStreamOptions;\n  export import ChatCompletionSystemMessageParam = ChatCompletionsAPI.ChatCompletionSystemMessageParam;\n  export import ChatCompletionTokenLogprob = ChatCompletionsAPI.ChatCompletionTokenLogprob;\n  export import ChatCompletionTool = ChatCompletionsAPI.ChatCompletionTool;\n  export import ChatCompletionToolChoiceOption = ChatCompletionsAPI.ChatCompletionToolChoiceOption;\n  export import ChatCompletionToolMessageParam = ChatCompletionsAPI.ChatCompletionToolMessageParam;\n  export import ChatCompletionUserMessageParam = ChatCompletionsAPI.ChatCompletionUserMessageParam;\n  /**\n   * @deprecated ChatCompletionMessageParam should be used instead\n   */\n  export import CreateChatCompletionRequestMessage = ChatCompletionsAPI.CreateChatCompletionRequestMessage;\n  export import ChatCompletionCreateParams = ChatCompletionsAPI.ChatCompletionCreateParams;\n  export import CompletionCreateParams = ChatCompletionsAPI.CompletionCreateParams;\n  export import ChatCompletionCreateParamsNonStreaming = ChatCompletionsAPI.ChatCompletionCreateParamsNonStreaming;\n  export import CompletionCreateParamsNonStreaming = ChatCompletionsAPI.CompletionCreateParamsNonStreaming;\n  export import ChatCompletionCreateParamsStreaming = ChatCompletionsAPI.ChatCompletionCreateParamsStreaming;\n  export import CompletionCreateParamsStreaming = ChatCompletionsAPI.CompletionCreateParamsStreaming;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;AAWhF,MAAO,oBAAoB,qIAAA,CAAA,cAAW;IAgB1C,OACE,IAAgC,EAChC,OAA6B,EAAA;QAE7B,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,qBAAqB;YAAE;YAAM,GAAG,OAAO;YAAE,QAAQ,KAAK,MAAM,IAAI;QAAK;IAGhG;;AAs/BF,CAAA,SAAiB,WAAW,GAgC5B,CAAC,EAhCgB,eAAW,CAAX,cAAW,CAAA,CAAA"}},
    {"offset": {"line": 6772, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6777, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/chat/chat.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport { APIResource } from '../../resource';\nimport * as ChatAPI from './chat';\nimport * as CompletionsAPI from './completions';\n\nexport class Chat extends APIResource {\n  completions: CompletionsAPI.Completions = new CompletionsAPI.Completions(this._client);\n}\n\nexport type ChatModel =\n  | 'o1-preview'\n  | 'o1-preview-2024-09-12'\n  | 'o1-mini'\n  | 'o1-mini-2024-09-12'\n  | 'gpt-4o'\n  | 'gpt-4o-2024-08-06'\n  | 'gpt-4o-2024-05-13'\n  | 'gpt-4o-realtime-preview-2024-10-01'\n  | 'chatgpt-4o-latest'\n  | 'gpt-4o-mini'\n  | 'gpt-4o-mini-2024-07-18'\n  | 'gpt-4-turbo'\n  | 'gpt-4-turbo-2024-04-09'\n  | 'gpt-4-0125-preview'\n  | 'gpt-4-turbo-preview'\n  | 'gpt-4-1106-preview'\n  | 'gpt-4-vision-preview'\n  | 'gpt-4'\n  | 'gpt-4-0314'\n  | 'gpt-4-0613'\n  | 'gpt-4-32k'\n  | 'gpt-4-32k-0314'\n  | 'gpt-4-32k-0613'\n  | 'gpt-3.5-turbo'\n  | 'gpt-3.5-turbo-16k'\n  | 'gpt-3.5-turbo-0301'\n  | 'gpt-3.5-turbo-0613'\n  | 'gpt-3.5-turbo-1106'\n  | 'gpt-3.5-turbo-0125'\n  | 'gpt-3.5-turbo-16k-0613';\n\nexport namespace Chat {\n  export import ChatModel = ChatAPI.ChatModel;\n  export import Completions = CompletionsAPI.Completions;\n  export import ChatCompletion = CompletionsAPI.ChatCompletion;\n  export import ChatCompletionAssistantMessageParam = CompletionsAPI.ChatCompletionAssistantMessageParam;\n  export import ChatCompletionChunk = CompletionsAPI.ChatCompletionChunk;\n  export import ChatCompletionContentPart = CompletionsAPI.ChatCompletionContentPart;\n  export import ChatCompletionContentPartImage = CompletionsAPI.ChatCompletionContentPartImage;\n  export import ChatCompletionContentPartRefusal = CompletionsAPI.ChatCompletionContentPartRefusal;\n  export import ChatCompletionContentPartText = CompletionsAPI.ChatCompletionContentPartText;\n  export import ChatCompletionFunctionCallOption = CompletionsAPI.ChatCompletionFunctionCallOption;\n  export import ChatCompletionFunctionMessageParam = CompletionsAPI.ChatCompletionFunctionMessageParam;\n  export import ChatCompletionMessage = CompletionsAPI.ChatCompletionMessage;\n  export import ChatCompletionMessageParam = CompletionsAPI.ChatCompletionMessageParam;\n  export import ChatCompletionMessageToolCall = CompletionsAPI.ChatCompletionMessageToolCall;\n  export import ChatCompletionNamedToolChoice = CompletionsAPI.ChatCompletionNamedToolChoice;\n  export import ChatCompletionRole = CompletionsAPI.ChatCompletionRole;\n  export import ChatCompletionStreamOptions = CompletionsAPI.ChatCompletionStreamOptions;\n  export import ChatCompletionSystemMessageParam = CompletionsAPI.ChatCompletionSystemMessageParam;\n  export import ChatCompletionTokenLogprob = CompletionsAPI.ChatCompletionTokenLogprob;\n  export import ChatCompletionTool = CompletionsAPI.ChatCompletionTool;\n  export import ChatCompletionToolChoiceOption = CompletionsAPI.ChatCompletionToolChoiceOption;\n  export import ChatCompletionToolMessageParam = CompletionsAPI.ChatCompletionToolMessageParam;\n  export import ChatCompletionUserMessageParam = CompletionsAPI.ChatCompletionUserMessageParam;\n  /**\n   * @deprecated ChatCompletionMessageParam should be used instead\n   */\n  export import CreateChatCompletionRequestMessage = CompletionsAPI.CreateChatCompletionRequestMessage;\n  export import ChatCompletionCreateParams = CompletionsAPI.ChatCompletionCreateParams;\n  export import CompletionCreateParams = CompletionsAPI.CompletionCreateParams;\n  export import ChatCompletionCreateParamsNonStreaming = CompletionsAPI.ChatCompletionCreateParamsNonStreaming;\n  export import CompletionCreateParamsNonStreaming = CompletionsAPI.CompletionCreateParamsNonStreaming;\n  export import ChatCompletionCreateParamsStreaming = CompletionsAPI.ChatCompletionCreateParamsStreaming;\n  export import CompletionCreateParamsStreaming = CompletionsAPI.CompletionCreateParamsStreaming;\n}\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;AAMhF,MAAO,aAAa,qIAAA,CAAA,cAAW;IAArC,aAAA;;QACE,IAAA,CAAA,WAAW,GAA+B,IAAI,8JAAe,WAAW,CAAC,IAAI,CAAC,OAAO;IACvF;;AAkCA,CAAA,SAAiB,IAAI;IAEL,KAAA,WAAW,GAAG,8JAAe,WAAW;AAgCxD,CAAC,EAlCgB,QAAI,CAAJ,OAAI,CAAA,CAAA"}},
    {"offset": {"line": 6795, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6825, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/resources/shared.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nexport interface ErrorObject {\n  code: string | null;\n\n  message: string;\n\n  param: string | null;\n\n  type: string;\n}\n\nexport interface FunctionDefinition {\n  /**\n   * The name of the function to be called. Must be a-z, A-Z, 0-9, or contain\n   * underscores and dashes, with a maximum length of 64.\n   */\n  name: string;\n\n  /**\n   * A description of what the function does, used by the model to choose when and\n   * how to call the function.\n   */\n  description?: string;\n\n  /**\n   * The parameters the functions accepts, described as a JSON Schema object. See the\n   * [guide](https://platform.openai.com/docs/guides/function-calling) for examples,\n   * and the\n   * [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for\n   * documentation about the format.\n   *\n   * Omitting `parameters` defines a function with an empty parameter list.\n   */\n  parameters?: FunctionParameters;\n\n  /**\n   * Whether to enable strict schema adherence when generating the function call. If\n   * set to true, the model will follow the exact schema defined in the `parameters`\n   * field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn\n   * more about Structured Outputs in the\n   * [function calling guide](docs/guides/function-calling).\n   */\n  strict?: boolean | null;\n}\n\n/**\n * The parameters the functions accepts, described as a JSON Schema object. See the\n * [guide](https://platform.openai.com/docs/guides/function-calling) for examples,\n * and the\n * [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for\n * documentation about the format.\n *\n * Omitting `parameters` defines a function with an empty parameter list.\n */\nexport type FunctionParameters = Record<string, unknown>;\n\nexport interface ResponseFormatJSONObject {\n  /**\n   * The type of response format being defined: `json_object`\n   */\n  type: 'json_object';\n}\n\nexport interface ResponseFormatJSONSchema {\n  json_schema: ResponseFormatJSONSchema.JSONSchema;\n\n  /**\n   * The type of response format being defined: `json_schema`\n   */\n  type: 'json_schema';\n}\n\nexport namespace ResponseFormatJSONSchema {\n  export interface JSONSchema {\n    /**\n     * The name of the response format. Must be a-z, A-Z, 0-9, or contain underscores\n     * and dashes, with a maximum length of 64.\n     */\n    name: string;\n\n    /**\n     * A description of what the response format is for, used by the model to determine\n     * how to respond in the format.\n     */\n    description?: string;\n\n    /**\n     * The schema for the response format, described as a JSON Schema object.\n     */\n    schema?: Record<string, unknown>;\n\n    /**\n     * Whether to enable strict schema adherence when generating the output. If set to\n     * true, the model will always follow the exact schema defined in the `schema`\n     * field. Only a subset of JSON Schema is supported when `strict` is `true`. To\n     * learn more, read the\n     * [Structured Outputs guide](https://platform.openai.com/docs/guides/structured-outputs).\n     */\n    strict?: boolean | null;\n  }\n}\n\nexport interface ResponseFormatText {\n  /**\n   * The type of response format being defined: `text`\n   */\n  type: 'text';\n}\n"],"names":[],"mappings":"AAAA,sFAAsF"}},
    {"offset": {"line": 6829, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 6896, "column": 0}, "map": {"version":3,"sources":["/turbopack/[project]/node_modules/openai/src/index.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\n\nimport * as Errors from './error';\nimport * as Uploads from './uploads';\nimport { type Agent, type RequestInit } from './_shims/index';\nimport * as qs from './internal/qs';\nimport * as Core from './core';\nimport * as Pagination from './pagination';\nimport * as API from './resources/index';\n\nexport interface ClientOptions {\n  /**\n   * Defaults to process.env['OPENAI_API_KEY'].\n   */\n  apiKey?: string | undefined;\n\n  /**\n   * Defaults to process.env['OPENAI_ORG_ID'].\n   */\n  organization?: string | null | undefined;\n\n  /**\n   * Defaults to process.env['OPENAI_PROJECT_ID'].\n   */\n  project?: string | null | undefined;\n\n  /**\n   * Override the default base URL for the API, e.g., \"https://api.example.com/v2/\"\n   *\n   * Defaults to process.env['OPENAI_BASE_URL'].\n   */\n  baseURL?: string | null | undefined;\n\n  /**\n   * The maximum amount of time (in milliseconds) that the client should wait for a response\n   * from the server before timing out a single request.\n   *\n   * Note that request timeouts are retried by default, so in a worst-case scenario you may wait\n   * much longer than this timeout before the promise succeeds or fails.\n   */\n  timeout?: number;\n\n  /**\n   * An HTTP agent used to manage HTTP(S) connections.\n   *\n   * If not provided, an agent will be constructed by default in the Node.js environment,\n   * otherwise no agent is used.\n   */\n  httpAgent?: Agent;\n\n  /**\n   * Specify a custom `fetch` function implementation.\n   *\n   * If not provided, we use `node-fetch` on Node.js and otherwise expect that `fetch` is\n   * defined globally.\n   */\n  fetch?: Core.Fetch | undefined;\n\n  /**\n   * The maximum number of times that the client will retry a request in case of a\n   * temporary failure, like a network error or a 5XX error from the server.\n   *\n   * @default 2\n   */\n  maxRetries?: number;\n\n  /**\n   * Default headers to include with every request to the API.\n   *\n   * These can be removed in individual requests by explicitly setting the\n   * header to `undefined` or `null` in request options.\n   */\n  defaultHeaders?: Core.Headers;\n\n  /**\n   * Default query parameters to include with every request to the API.\n   *\n   * These can be removed in individual requests by explicitly setting the\n   * param to `undefined` in request options.\n   */\n  defaultQuery?: Core.DefaultQuery;\n\n  /**\n   * By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n   * Only set this option to `true` if you understand the risks and have appropriate mitigations in place.\n   */\n  dangerouslyAllowBrowser?: boolean;\n}\n\n/**\n * API Client for interfacing with the OpenAI API.\n */\nexport class OpenAI extends Core.APIClient {\n  apiKey: string;\n  organization: string | null;\n  project: string | null;\n\n  private _options: ClientOptions;\n\n  /**\n   * API Client for interfacing with the OpenAI API.\n   *\n   * @param {string | undefined} [opts.apiKey=process.env['OPENAI_API_KEY'] ?? undefined]\n   * @param {string | null | undefined} [opts.organization=process.env['OPENAI_ORG_ID'] ?? null]\n   * @param {string | null | undefined} [opts.project=process.env['OPENAI_PROJECT_ID'] ?? null]\n   * @param {string} [opts.baseURL=process.env['OPENAI_BASE_URL'] ?? https://api.openai.com/v1] - Override the default base URL for the API.\n   * @param {number} [opts.timeout=10 minutes] - The maximum amount of time (in milliseconds) the client will wait for a response before timing out.\n   * @param {number} [opts.httpAgent] - An HTTP agent used to manage HTTP(s) connections.\n   * @param {Core.Fetch} [opts.fetch] - Specify a custom `fetch` function implementation.\n   * @param {number} [opts.maxRetries=2] - The maximum number of times the client will retry a request.\n   * @param {Core.Headers} opts.defaultHeaders - Default headers to include with every request to the API.\n   * @param {Core.DefaultQuery} opts.defaultQuery - Default query parameters to include with every request to the API.\n   * @param {boolean} [opts.dangerouslyAllowBrowser=false] - By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n   */\n  constructor({\n    baseURL = Core.readEnv('OPENAI_BASE_URL'),\n    apiKey = Core.readEnv('OPENAI_API_KEY'),\n    organization = Core.readEnv('OPENAI_ORG_ID') ?? null,\n    project = Core.readEnv('OPENAI_PROJECT_ID') ?? null,\n    ...opts\n  }: ClientOptions = {}) {\n    if (apiKey === undefined) {\n      throw new Errors.OpenAIError(\n        \"The OPENAI_API_KEY environment variable is missing or empty; either provide it, or instantiate the OpenAI client with an apiKey option, like new OpenAI({ apiKey: 'My API Key' }).\",\n      );\n    }\n\n    const options: ClientOptions = {\n      apiKey,\n      organization,\n      project,\n      ...opts,\n      baseURL: baseURL || `https://api.openai.com/v1`,\n    };\n\n    if (!options.dangerouslyAllowBrowser && Core.isRunningInBrowser()) {\n      throw new Errors.OpenAIError(\n        \"It looks like you're running in a browser-like environment.\\n\\nThis is disabled by default, as it risks exposing your secret API credentials to attackers.\\nIf you understand the risks and have appropriate mitigations in place,\\nyou can set the `dangerouslyAllowBrowser` option to `true`, e.g.,\\n\\nnew OpenAI({ apiKey, dangerouslyAllowBrowser: true });\\n\\nhttps://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\\n\",\n      );\n    }\n\n    super({\n      baseURL: options.baseURL!,\n      timeout: options.timeout ?? 600000 /* 10 minutes */,\n      httpAgent: options.httpAgent,\n      maxRetries: options.maxRetries,\n      fetch: options.fetch,\n    });\n\n    this._options = options;\n\n    this.apiKey = apiKey;\n    this.organization = organization;\n    this.project = project;\n  }\n\n  completions: API.Completions = new API.Completions(this);\n  chat: API.Chat = new API.Chat(this);\n  embeddings: API.Embeddings = new API.Embeddings(this);\n  files: API.Files = new API.Files(this);\n  images: API.Images = new API.Images(this);\n  audio: API.Audio = new API.Audio(this);\n  moderations: API.Moderations = new API.Moderations(this);\n  models: API.Models = new API.Models(this);\n  fineTuning: API.FineTuning = new API.FineTuning(this);\n  beta: API.Beta = new API.Beta(this);\n  batches: API.Batches = new API.Batches(this);\n  uploads: API.Uploads = new API.Uploads(this);\n\n  protected override defaultQuery(): Core.DefaultQuery | undefined {\n    return this._options.defaultQuery;\n  }\n\n  protected override defaultHeaders(opts: Core.FinalRequestOptions): Core.Headers {\n    return {\n      ...super.defaultHeaders(opts),\n      'OpenAI-Organization': this.organization,\n      'OpenAI-Project': this.project,\n      ...this._options.defaultHeaders,\n    };\n  }\n\n  protected override authHeaders(opts: Core.FinalRequestOptions): Core.Headers {\n    return { Authorization: `Bearer ${this.apiKey}` };\n  }\n\n  protected override stringifyQuery(query: Record<string, unknown>): string {\n    return qs.stringify(query, { arrayFormat: 'brackets' });\n  }\n\n  static OpenAI = this;\n  static DEFAULT_TIMEOUT = 600000; // 10 minutes\n\n  static OpenAIError = Errors.OpenAIError;\n  static APIError = Errors.APIError;\n  static APIConnectionError = Errors.APIConnectionError;\n  static APIConnectionTimeoutError = Errors.APIConnectionTimeoutError;\n  static APIUserAbortError = Errors.APIUserAbortError;\n  static NotFoundError = Errors.NotFoundError;\n  static ConflictError = Errors.ConflictError;\n  static RateLimitError = Errors.RateLimitError;\n  static BadRequestError = Errors.BadRequestError;\n  static AuthenticationError = Errors.AuthenticationError;\n  static InternalServerError = Errors.InternalServerError;\n  static PermissionDeniedError = Errors.PermissionDeniedError;\n  static UnprocessableEntityError = Errors.UnprocessableEntityError;\n\n  static toFile = Uploads.toFile;\n  static fileFromPath = Uploads.fileFromPath;\n}\n\nexport const {\n  OpenAIError,\n  APIError,\n  APIConnectionError,\n  APIConnectionTimeoutError,\n  APIUserAbortError,\n  NotFoundError,\n  ConflictError,\n  RateLimitError,\n  BadRequestError,\n  AuthenticationError,\n  InternalServerError,\n  PermissionDeniedError,\n  UnprocessableEntityError,\n} = Errors;\n\nexport import toFile = Uploads.toFile;\nexport import fileFromPath = Uploads.fileFromPath;\n\nexport namespace OpenAI {\n  export import RequestOptions = Core.RequestOptions;\n\n  export import Page = Pagination.Page;\n  export import PageResponse = Pagination.PageResponse;\n\n  export import CursorPage = Pagination.CursorPage;\n  export import CursorPageParams = Pagination.CursorPageParams;\n  export import CursorPageResponse = Pagination.CursorPageResponse;\n\n  export import Completions = API.Completions;\n  export import Completion = API.Completion;\n  export import CompletionChoice = API.CompletionChoice;\n  export import CompletionUsage = API.CompletionUsage;\n  export import CompletionCreateParams = API.CompletionCreateParams;\n  export import CompletionCreateParamsNonStreaming = API.CompletionCreateParamsNonStreaming;\n  export import CompletionCreateParamsStreaming = API.CompletionCreateParamsStreaming;\n\n  export import Chat = API.Chat;\n  export import ChatModel = API.ChatModel;\n  export import ChatCompletion = API.ChatCompletion;\n  export import ChatCompletionAssistantMessageParam = API.ChatCompletionAssistantMessageParam;\n  export import ChatCompletionChunk = API.ChatCompletionChunk;\n  export import ChatCompletionContentPart = API.ChatCompletionContentPart;\n  export import ChatCompletionContentPartImage = API.ChatCompletionContentPartImage;\n  export import ChatCompletionContentPartRefusal = API.ChatCompletionContentPartRefusal;\n  export import ChatCompletionContentPartText = API.ChatCompletionContentPartText;\n  export import ChatCompletionFunctionCallOption = API.ChatCompletionFunctionCallOption;\n  export import ChatCompletionFunctionMessageParam = API.ChatCompletionFunctionMessageParam;\n  export import ChatCompletionMessage = API.ChatCompletionMessage;\n  export import ChatCompletionMessageParam = API.ChatCompletionMessageParam;\n  export import ChatCompletionMessageToolCall = API.ChatCompletionMessageToolCall;\n  export import ChatCompletionNamedToolChoice = API.ChatCompletionNamedToolChoice;\n  export import ChatCompletionRole = API.ChatCompletionRole;\n  export import ChatCompletionStreamOptions = API.ChatCompletionStreamOptions;\n  export import ChatCompletionSystemMessageParam = API.ChatCompletionSystemMessageParam;\n  export import ChatCompletionTokenLogprob = API.ChatCompletionTokenLogprob;\n  export import ChatCompletionTool = API.ChatCompletionTool;\n  export import ChatCompletionToolChoiceOption = API.ChatCompletionToolChoiceOption;\n  export import ChatCompletionToolMessageParam = API.ChatCompletionToolMessageParam;\n  export import ChatCompletionUserMessageParam = API.ChatCompletionUserMessageParam;\n  export import ChatCompletionCreateParams = API.ChatCompletionCreateParams;\n  export import ChatCompletionCreateParamsNonStreaming = API.ChatCompletionCreateParamsNonStreaming;\n  export import ChatCompletionCreateParamsStreaming = API.ChatCompletionCreateParamsStreaming;\n\n  export import Embeddings = API.Embeddings;\n  export import CreateEmbeddingResponse = API.CreateEmbeddingResponse;\n  export import Embedding = API.Embedding;\n  export import EmbeddingModel = API.EmbeddingModel;\n  export import EmbeddingCreateParams = API.EmbeddingCreateParams;\n\n  export import Files = API.Files;\n  export import FileContent = API.FileContent;\n  export import FileDeleted = API.FileDeleted;\n  export import FileObject = API.FileObject;\n  export import FilePurpose = API.FilePurpose;\n  export import FileObjectsPage = API.FileObjectsPage;\n  export import FileCreateParams = API.FileCreateParams;\n  export import FileListParams = API.FileListParams;\n\n  export import Images = API.Images;\n  export import Image = API.Image;\n  export import ImageModel = API.ImageModel;\n  export import ImagesResponse = API.ImagesResponse;\n  export import ImageCreateVariationParams = API.ImageCreateVariationParams;\n  export import ImageEditParams = API.ImageEditParams;\n  export import ImageGenerateParams = API.ImageGenerateParams;\n\n  export import Audio = API.Audio;\n  export import AudioModel = API.AudioModel;\n  export import AudioResponseFormat = API.AudioResponseFormat;\n\n  export import Moderations = API.Moderations;\n  export import Moderation = API.Moderation;\n  export import ModerationImageURLInput = API.ModerationImageURLInput;\n  export import ModerationModel = API.ModerationModel;\n  export import ModerationMultiModalInput = API.ModerationMultiModalInput;\n  export import ModerationTextInput = API.ModerationTextInput;\n  export import ModerationCreateResponse = API.ModerationCreateResponse;\n  export import ModerationCreateParams = API.ModerationCreateParams;\n\n  export import Models = API.Models;\n  export import Model = API.Model;\n  export import ModelDeleted = API.ModelDeleted;\n  export import ModelsPage = API.ModelsPage;\n\n  export import FineTuning = API.FineTuning;\n\n  export import Beta = API.Beta;\n\n  export import Batches = API.Batches;\n  export import Batch = API.Batch;\n  export import BatchError = API.BatchError;\n  export import BatchRequestCounts = API.BatchRequestCounts;\n  export import BatchesPage = API.BatchesPage;\n  export import BatchCreateParams = API.BatchCreateParams;\n  export import BatchListParams = API.BatchListParams;\n\n  export import Uploads = API.Uploads;\n  export import Upload = API.Upload;\n  export import UploadCreateParams = API.UploadCreateParams;\n  export import UploadCompleteParams = API.UploadCompleteParams;\n\n  export import ErrorObject = API.ErrorObject;\n  export import FunctionDefinition = API.FunctionDefinition;\n  export import FunctionParameters = API.FunctionParameters;\n  export import ResponseFormatJSONObject = API.ResponseFormatJSONObject;\n  export import ResponseFormatJSONSchema = API.ResponseFormatJSONSchema;\n  export import ResponseFormatText = API.ResponseFormatText;\n}\n\n// ---------------------- Azure ----------------------\n\n/** API Client for interfacing with the Azure OpenAI API. */\nexport interface AzureClientOptions extends ClientOptions {\n  /**\n   * Defaults to process.env['OPENAI_API_VERSION'].\n   */\n  apiVersion?: string | undefined;\n\n  /**\n   * Your Azure endpoint, including the resource, e.g. `https://example-resource.azure.openai.com/`\n   */\n  endpoint?: string | undefined;\n\n  /**\n   * A model deployment, if given, sets the base client URL to include `/deployments/{deployment}`.\n   * Note: this means you won't be able to use non-deployment endpoints. Not supported with Assistants APIs.\n   */\n  deployment?: string | undefined;\n\n  /**\n   * Defaults to process.env['AZURE_OPENAI_API_KEY'].\n   */\n  apiKey?: string | undefined;\n\n  /**\n   * A function that returns an access token for Microsoft Entra (formerly known as Azure Active Directory),\n   * which will be invoked on every request.\n   */\n  azureADTokenProvider?: (() => Promise<string>) | undefined;\n}\n\n/** API Client for interfacing with the Azure OpenAI API. */\nexport class AzureOpenAI extends OpenAI {\n  private _azureADTokenProvider: (() => Promise<string>) | undefined;\n  private _deployment: string | undefined;\n  apiVersion: string = '';\n  /**\n   * API Client for interfacing with the Azure OpenAI API.\n   *\n   * @param {string | undefined} [opts.apiVersion=process.env['OPENAI_API_VERSION'] ?? undefined]\n   * @param {string | undefined} [opts.endpoint=process.env['AZURE_OPENAI_ENDPOINT'] ?? undefined] - Your Azure endpoint, including the resource, e.g. `https://example-resource.azure.openai.com/`\n   * @param {string | undefined} [opts.apiKey=process.env['AZURE_OPENAI_API_KEY'] ?? undefined]\n   * @param {string | undefined} opts.deployment - A model deployment, if given, sets the base client URL to include `/deployments/{deployment}`.\n   * @param {string | null | undefined} [opts.organization=process.env['OPENAI_ORG_ID'] ?? null]\n   * @param {string} [opts.baseURL=process.env['OPENAI_BASE_URL']] - Sets the base URL for the API, e.g. `https://example-resource.azure.openai.com/openai/`.\n   * @param {number} [opts.timeout=10 minutes] - The maximum amount of time (in milliseconds) the client will wait for a response before timing out.\n   * @param {number} [opts.httpAgent] - An HTTP agent used to manage HTTP(s) connections.\n   * @param {Core.Fetch} [opts.fetch] - Specify a custom `fetch` function implementation.\n   * @param {number} [opts.maxRetries=2] - The maximum number of times the client will retry a request.\n   * @param {Core.Headers} opts.defaultHeaders - Default headers to include with every request to the API.\n   * @param {Core.DefaultQuery} opts.defaultQuery - Default query parameters to include with every request to the API.\n   * @param {boolean} [opts.dangerouslyAllowBrowser=false] - By default, client-side use of this library is not allowed, as it risks exposing your secret API credentials to attackers.\n   */\n  constructor({\n    baseURL = Core.readEnv('OPENAI_BASE_URL'),\n    apiKey = Core.readEnv('AZURE_OPENAI_API_KEY'),\n    apiVersion = Core.readEnv('OPENAI_API_VERSION'),\n    endpoint,\n    deployment,\n    azureADTokenProvider,\n    dangerouslyAllowBrowser,\n    ...opts\n  }: AzureClientOptions = {}) {\n    if (!apiVersion) {\n      throw new Errors.OpenAIError(\n        \"The OPENAI_API_VERSION environment variable is missing or empty; either provide it, or instantiate the AzureOpenAI client with an apiVersion option, like new AzureOpenAI({ apiVersion: 'My API Version' }).\",\n      );\n    }\n\n    if (typeof azureADTokenProvider === 'function') {\n      dangerouslyAllowBrowser = true;\n    }\n\n    if (!azureADTokenProvider && !apiKey) {\n      throw new Errors.OpenAIError(\n        'Missing credentials. Please pass one of `apiKey` and `azureADTokenProvider`, or set the `AZURE_OPENAI_API_KEY` environment variable.',\n      );\n    }\n\n    if (azureADTokenProvider && apiKey) {\n      throw new Errors.OpenAIError(\n        'The `apiKey` and `azureADTokenProvider` arguments are mutually exclusive; only one can be passed at a time.',\n      );\n    }\n\n    // define a sentinel value to avoid any typing issues\n    apiKey ??= API_KEY_SENTINEL;\n\n    opts.defaultQuery = { ...opts.defaultQuery, 'api-version': apiVersion };\n\n    if (!baseURL) {\n      if (!endpoint) {\n        endpoint = process.env['AZURE_OPENAI_ENDPOINT'];\n      }\n\n      if (!endpoint) {\n        throw new Errors.OpenAIError(\n          'Must provide one of the `baseURL` or `endpoint` arguments, or the `AZURE_OPENAI_ENDPOINT` environment variable',\n        );\n      }\n\n      baseURL = `${endpoint}/openai`;\n    } else {\n      if (endpoint) {\n        throw new Errors.OpenAIError('baseURL and endpoint are mutually exclusive');\n      }\n    }\n\n    super({\n      apiKey,\n      baseURL,\n      ...opts,\n      ...(dangerouslyAllowBrowser !== undefined ? { dangerouslyAllowBrowser } : {}),\n    });\n\n    this._azureADTokenProvider = azureADTokenProvider;\n    this.apiVersion = apiVersion;\n    this._deployment = deployment;\n  }\n\n  override buildRequest(options: Core.FinalRequestOptions<unknown>): {\n    req: RequestInit;\n    url: string;\n    timeout: number;\n  } {\n    if (_deployments_endpoints.has(options.path) && options.method === 'post' && options.body !== undefined) {\n      if (!Core.isObj(options.body)) {\n        throw new Error('Expected request body to be an object');\n      }\n      const model = this._deployment || options.body['model'];\n      if (model !== undefined && !this.baseURL.includes('/deployments')) {\n        options.path = `/deployments/${model}${options.path}`;\n      }\n    }\n    return super.buildRequest(options);\n  }\n\n  private async _getAzureADToken(): Promise<string | undefined> {\n    if (typeof this._azureADTokenProvider === 'function') {\n      const token = await this._azureADTokenProvider();\n      if (!token || typeof token !== 'string') {\n        throw new Errors.OpenAIError(\n          `Expected 'azureADTokenProvider' argument to return a string but it returned ${token}`,\n        );\n      }\n      return token;\n    }\n    return undefined;\n  }\n\n  protected override authHeaders(opts: Core.FinalRequestOptions): Core.Headers {\n    return {};\n  }\n\n  protected override async prepareOptions(opts: Core.FinalRequestOptions<unknown>): Promise<void> {\n    /**\n     * The user should provide a bearer token provider if they want\n     * to use Azure AD authentication. The user shouldn't set the\n     * Authorization header manually because the header is overwritten\n     * with the Azure AD token if a bearer token provider is provided.\n     */\n    if (opts.headers?.['api-key']) {\n      return super.prepareOptions(opts);\n    }\n    const token = await this._getAzureADToken();\n    opts.headers ??= {};\n    if (token) {\n      opts.headers['Authorization'] = `Bearer ${token}`;\n    } else if (this.apiKey !== API_KEY_SENTINEL) {\n      opts.headers['api-key'] = this.apiKey;\n    } else {\n      throw new Errors.OpenAIError('Unable to handle auth');\n    }\n    return super.prepareOptions(opts);\n  }\n}\n\nconst _deployments_endpoints = new Set([\n  '/completions',\n  '/chat/completions',\n  '/embeddings',\n  '/audio/transcriptions',\n  '/audio/translations',\n  '/audio/speech',\n  '/images/generations',\n]);\n\nconst API_KEY_SENTINEL = '<Missing Key>';\n\n// ---------------------- End Azure ----------------------\n\nexport default OpenAI;\n"],"names":[],"mappings":"AAAA,sFAAsF;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA4FhF,MAAO,eAAe,kJAAK,SAAS;IAOxC;;;;;;;;;;;;;;QAeA,YAAY,EACV,UAAU,kJAAK,OAAO,CAAC,kBAAkB,EACzC,SAAS,kJAAK,OAAO,CAAC,iBAAiB,EACvC,eAAe,kJAAK,OAAO,CAAC,oBAAoB,IAAI,EACpD,UAAU,kJAAK,OAAO,CAAC,wBAAwB,IAAI,EACnD,GAAG,MAAI,GACU,CAAA,CAAE,CAAA;QACnB,IAAI,WAAW,WAAW;YACxB,MAAM,IAAI,mIAAO,WAAW,CAC1B;;QAIJ,MAAM,UAAyB;YAC7B;YACA;YACA;YACA,GAAG,IAAI;YACP,SAAS,WAAW,CAAA,yBAAA,CAA2B;;QAGjD,IAAI,CAAC,QAAQ,uBAAuB,IAAI,kJAAK,kBAAkB,IAAI;YACjE,MAAM,IAAI,mIAAO,WAAW,CAC1B;;QAIJ,KAAK,CAAC;YACJ,SAAS,QAAQ,OAAQ;YACzB,SAAS,QAAQ,OAAO,IAAI,OAAO,cAAA;YACnC,WAAW,QAAQ,SAAS;YAC5B,YAAY,QAAQ,UAAU;YAC9B,OAAO,QAAQ,KAAK;;QAUxB,IAAA,CAAA,WAAW,GAAoB,IAAI,gKAAI,WAAW,CAAC,IAAI;QACvD,IAAA,CAAA,IAAI,GAAa,IAAI,gKAAI,IAAI,CAAC,IAAI;QAClC,IAAA,CAAA,UAAU,GAAmB,IAAI,gKAAI,UAAU,CAAC,IAAI;QACpD,IAAA,CAAA,KAAK,GAAc,IAAI,gKAAI,KAAK,CAAC,IAAI;QACrC,IAAA,CAAA,MAAM,GAAe,IAAI,gKAAI,MAAM,CAAC,IAAI;QACxC,IAAA,CAAA,KAAK,GAAc,IAAI,gKAAI,KAAK,CAAC,IAAI;QACrC,IAAA,CAAA,WAAW,GAAoB,IAAI,gKAAI,WAAW,CAAC,IAAI;QACvD,IAAA,CAAA,MAAM,GAAe,IAAI,gKAAI,MAAM,CAAC,IAAI;QACxC,IAAA,CAAA,UAAU,GAAmB,IAAI,gKAAI,UAAU,CAAC,IAAI;QACpD,IAAA,CAAA,IAAI,GAAa,IAAI,gKAAI,IAAI,CAAC,IAAI;QAClC,IAAA,CAAA,OAAO,GAAgB,IAAI,gKAAI,OAAO,CAAC,IAAI;QAC3C,IAAA,CAAA,OAAO,GAAgB,IAAI,gKAAI,OAAO,CAAC,IAAI;QAlBzC,IAAI,CAAC,QAAQ,GAAG;QAEhB,IAAI,CAAC,MAAM,GAAG;QACd,IAAI,CAAC,YAAY,GAAG;QACpB,IAAI,CAAC,OAAO,GAAG;IACjB;IAemB,eAAY;QAC7B,OAAO,IAAI,CAAC,QAAQ,CAAC,YAAY;IACnC;IAEmB,eAAe,IAA8B,EAAA;QAC9D,OAAO;YACL,GAAG,KAAK,CAAC,eAAe,KAAK;YAC7B,uBAAuB,IAAI,CAAC,YAAY;YACxC,kBAAkB,IAAI,CAAC,OAAO;YAC9B,GAAG,IAAI,CAAC,QAAQ,CAAC,cAAc;;IAEnC;IAEmB,YAAY,IAA8B,EAAA;QAC3D,OAAO;YAAE,eAAe,CAAA,OAAA,EAAU,IAAI,CAAC,MAAM,CAAA,CAAE;QAAA;IACjD;IAEmB,eAAe,KAA8B,EAAA;QAC9D,OAAO,qKAAG,SAAS,CAAC,OAAO;YAAE,aAAa;QAAU;IACtD;;;AAEO,OAAA,MAAM,GAAG;AACT,OAAA,eAAe,GAAG,QAAQ,aAAa;AAEvC,OAAA,WAAW,GAAG,mIAAO,WAAW;AAChC,OAAA,QAAQ,GAAG,mIAAO,QAAQ;AAC1B,OAAA,kBAAkB,GAAG,mIAAO,kBAAkB;AAC9C,OAAA,yBAAyB,GAAG,mIAAO,yBAAyB;AAC5D,OAAA,iBAAiB,GAAG,mIAAO,iBAAiB;AAC5C,OAAA,aAAa,GAAG,mIAAO,aAAa;AACpC,OAAA,aAAa,GAAG,mIAAO,aAAa;AACpC,OAAA,cAAc,GAAG,mIAAO,cAAc;AACtC,OAAA,eAAe,GAAG,mIAAO,eAAe;AACxC,OAAA,mBAAmB,GAAG,mIAAO,mBAAmB;AAChD,OAAA,mBAAmB,GAAG,mIAAO,mBAAmB;AAChD,OAAA,qBAAqB,GAAG,mIAAO,qBAAqB;AACpD,OAAA,wBAAwB,GAAG,mIAAO,wBAAwB;AAE1D,OAAA,MAAM,GAAG,qJAAQ,MAAM;AACvB,OAAA,YAAY,GAAG,qJAAQ,YAAY;AAGrC,MAAM,EACX,WAAW,EACX,QAAQ,EACR,kBAAkB,EAClB,yBAAyB,EACzB,iBAAiB,EACjB,aAAa,EACb,aAAa,EACb,cAAc,EACd,eAAe,EACf,mBAAmB,EACnB,mBAAmB,EACnB,qBAAqB,EACrB,wBAAwB,EACzB,GAAG;AAEE,IAAQ,SAAS,qJAAQ,MAAM;AAC/B,IAAQ,eAAe,qJAAQ,YAAY;AAEjD,CAAA,SAAiB,MAAM;IAGP,OAAA,IAAI,GAAG,wIAAW,IAAI;IAGtB,OAAA,UAAU,GAAG,wIAAW,UAAU;IAIlC,OAAA,WAAW,GAAG,gKAAI,WAAW;IAQ7B,OAAA,IAAI,GAAG,gKAAI,IAAI;IA2Bf,OAAA,UAAU,GAAG,gKAAI,UAAU;IAM3B,OAAA,KAAK,GAAG,gKAAI,KAAK;IAKjB,OAAA,eAAe,GAAG,gKAAI,eAAe;IAIrC,OAAA,MAAM,GAAG,gKAAI,MAAM;IAQnB,OAAA,KAAK,GAAG,gKAAI,KAAK;IAIjB,OAAA,WAAW,GAAG,gKAAI,WAAW;IAS7B,OAAA,MAAM,GAAG,gKAAI,MAAM;IAGnB,OAAA,UAAU,GAAG,gKAAI,UAAU;IAE3B,OAAA,UAAU,GAAG,gKAAI,UAAU;IAE3B,OAAA,IAAI,GAAG,gKAAI,IAAI;IAEf,OAAA,OAAO,GAAG,gKAAI,OAAO;IAIrB,OAAA,WAAW,GAAG,gKAAI,WAAW;IAI7B,OAAA,OAAO,GAAG,gKAAI,OAAO;AAWrC,CAAC,EA7GgB,UAAM,CAAN,SAAM,CAAA,CAAA;AAgJjB,MAAO,oBAAoB;IAI/B;;;;;;;;;;;;;;;;QAiBA,YAAY,EACV,UAAU,kJAAK,OAAO,CAAC,kBAAkB,EACzC,SAAS,kJAAK,OAAO,CAAC,uBAAuB,EAC7C,aAAa,kJAAK,OAAO,CAAC,qBAAqB,EAC/C,QAAQ,EACR,UAAU,EACV,oBAAoB,EACpB,uBAAuB,EACvB,GAAG,MAAI,GACe,CAAA,CAAE,CAAA;QACxB,IAAI,CAAC,YAAY;YACf,MAAM,IAAI,mIAAO,WAAW,CAC1B;;QAIJ,IAAI,OAAO,yBAAyB,YAAY;YAC9C,0BAA0B;;QAG5B,IAAI,CAAC,wBAAwB,CAAC,QAAQ;YACpC,MAAM,IAAI,mIAAO,WAAW,CAC1B;;QAIJ,IAAI,wBAAwB,QAAQ;YAClC,MAAM,IAAI,mIAAO,WAAW,CAC1B;;QAIJ,qDAAqD;QACrD,UAAM,CAAN,SAAW,gBAAgB;QAE3B,KAAK,YAAY,GAAG;YAAE,GAAG,KAAK,YAAY;YAAE,eAAe;QAAU;QAErE,IAAI,CAAC,SAAS;YACZ,IAAI,CAAC,UAAU;gBACb,WAAW,QAAQ,GAAG,CAAC,wBAAwB;;YAGjD,IAAI,CAAC,UAAU;gBACb,MAAM,IAAI,mIAAO,WAAW,CAC1B;;YAIJ,UAAU,CAAA,EAAG,SAAQ,OAAA,CAAS;eACzB;YACL,IAAI,UAAU;gBACZ,MAAM,IAAI,mIAAO,WAAW,CAAC;;;QAIjC,KAAK,CAAC;YACJ;YACA;YACA,GAAG,IAAI;YACP,GAAI,4BAA4B,YAAY;gBAAE;YAAuB,IAAK,CAAA,CAAE;;QA7EhF,IAAA,CAAA,UAAU,GAAW;QAgFnB,IAAI,CAAC,qBAAqB,GAAG;QAC7B,IAAI,CAAC,UAAU,GAAG;QAClB,IAAI,CAAC,WAAW,GAAG;IACrB;IAES,aAAa,OAA0C,EAAA;QAK9D,IAAI,uBAAuB,GAAG,CAAC,QAAQ,IAAI,KAAK,QAAQ,MAAM,KAAK,UAAU,QAAQ,IAAI,KAAK,WAAW;YACvG,IAAI,CAAC,kJAAK,KAAK,CAAC,QAAQ,IAAI,GAAG;gBAC7B,MAAM,IAAI,MAAM;;YAElB,MAAM,QAAQ,IAAI,CAAC,WAAW,IAAI,QAAQ,IAAI,CAAC,QAAQ;YACvD,IAAI,UAAU,aAAa,CAAC,IAAI,CAAC,OAAO,CAAC,QAAQ,CAAC,iBAAiB;gBACjE,QAAQ,IAAI,GAAG,CAAA,aAAA,EAAgB,MAAK,EAAG,QAAQ,IAAI,CAAA,CAAE;;;QAGzD,OAAO,KAAK,CAAC,aAAa;IAC5B;IAEQ,MAAM,mBAAgB;QAC5B,IAAI,OAAO,IAAI,CAAC,qBAAqB,KAAK,YAAY;YACpD,MAAM,QAAQ,MAAM,IAAI,CAAC,qBAAqB;YAC9C,IAAI,CAAC,SAAS,OAAO,UAAU,UAAU;gBACvC,MAAM,IAAI,mIAAO,WAAW,CAC1B,CAAA,4EAAA,EAA+E,MAAK,CAAE;;YAG1F,OAAO;;QAET,OAAO;IACT;IAEmB,YAAY,IAA8B,EAAA;QAC3D,OAAO,CAAA;IACT;IAEmB,MAAM,eAAe,IAAuC,EAAA;QAC7E;;;;;YAMA,IAAI,KAAK,OAAO,EAAE,CAAC,UAAU,EAAE;YAC7B,OAAO,KAAK,CAAC,eAAe;;QAE9B,MAAM,QAAQ,MAAM,IAAI,CAAC,gBAAgB;QACzC,KAAK,OAAO,IAAA,CAAZ,KAAK,OAAO,GAAK,CAAA,CAAE;QACnB,IAAI,OAAO;YACT,KAAK,OAAO,CAAC,gBAAgB,GAAG,CAAA,OAAA,EAAU,MAAK,CAAE;eAC5C,IAAI,IAAI,CAAC,MAAM,KAAK,kBAAkB;YAC3C,KAAK,OAAO,CAAC,UAAU,GAAG,IAAI,CAAC,MAAM;eAChC;YACL,MAAM,IAAI,mIAAO,WAAW,CAAC;;QAE/B,OAAO,KAAK,CAAC,eAAe;IAC9B;;AAGF,MAAM,yBAAyB,IAAI,IAAI;IACrC;IACA;IACA;IACA;IACA;IACA;IACA;CACD;AAED,MAAM,mBAAmB;uCAIV"}},
    {"offset": {"line": 7166, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}}]
}