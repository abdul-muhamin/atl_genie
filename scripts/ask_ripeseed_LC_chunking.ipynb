{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-YhhpMmRV1W"
   },
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain_community\n",
    "!pip install openai\n",
    "!pip install pinecone-client\n",
    "!pip install google-cloud-storage\n",
    "!pip install Python-dotenv\n",
    "!pip install Firebase-admin\n",
    "!pip install spacy\n",
    "!pip install langchain_openai\n",
    "!pip install pypdf\n",
    "!pip install pdfminer\n",
    "!pip install unstructured\n",
    "!pip install unstructured[pdf]\n",
    "!pip install docx2txt\n",
    "!pip install langchainhub\n",
    "!sudo apt-get install libgl1-mesa-glx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IT7vwaqwbuE7"
   },
   "outputs": [],
   "source": [
    "!pip install Pinecone\n",
    "!pip install --quiet langchain_experimental langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iTA_FbxncJDB"
   },
   "outputs": [],
   "source": [
    "from operator import le\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import SpacyTextSplitter\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import OnlinePDFLoader\n",
    "import os\n",
    "import spacy\n",
    "import uuid\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import OnlinePDFLoader\n",
    "from langchain_community.vectorstores.pinecone import Pinecone\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "# Conversation imports\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.chains.history_aware_retriever import create_history_aware_retriever\n",
    "from langchain_community.document_loaders import OnlinePDFLoader, TextLoader\n",
    "from langchain_community.document_loaders import Docx2txtLoader, PyPDFDirectoryLoader\n",
    "import shutil\n",
    "import uuid\n",
    "from langchain.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.chains import create_extraction_chain\n",
    "from typing import Optional, List\n",
    "from langchain.chains import create_extraction_chain_pydantic\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain import hub\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qGMFlu2xcblg"
   },
   "outputs": [],
   "source": [
    "def load_document():\n",
    "    # use the uploads_dir in your DirectoryLoader\n",
    "    loader = PyPDFDirectoryLoader(\"../Documents/\", glob=\"*.pdf\")\n",
    "    docs = loader.load()\n",
    "    print(\"docs:\", docs)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1jmpsYKdGdV"
   },
   "outputs": [],
   "source": [
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0h59iNHezlOE"
   },
   "outputs": [],
   "source": [
    "def upload_documents_service():\n",
    "    pinecone = Pinecone(api_key = \"42dfe5b5-e733-4640-a90c-16f2a99b2e48\")\n",
    "    index = pinecone.Index(\"index02\")\n",
    "    docs = load_document()\n",
    "    for doc in docs:\n",
    "      print(\"current document \",doc)\n",
    "      text = doc.page_content\n",
    "      embeddings_model = OpenAIEmbeddings(openai_api_key=\"sk-sEnWhfLa_EQqqYf4tqMfKNj1EJNgTQNbheVCoLJ-QvT3BlbkFJmFyceS00ttsaLH-4PUDo5EBrejSkpCGmLAVE7bnLEA\")\n",
    "      text_splitter = RecursiveCharacterTextSplitter()\n",
    "\n",
    "      #chunks = text_splitter.split_text(text)\n",
    "\n",
    "      # chunks = text_splitter.create_documents([text])\n",
    "      chunks =  text_splitter.create_documents([text])\n",
    "\n",
    "      # embeddings_arrays = embeddings_model.embed_documents(\n",
    "      #     [chunk.page_content.replace(\"\\n\", \" \") for chunk in chunks]\n",
    "      # )\n",
    "\n",
    "      batch_size = 100\n",
    "      batch = []\n",
    "\n",
    "      for idx in range(len(chunks)):\n",
    "          chunk = chunks[idx]\n",
    "          vector = {\n",
    "              \"id\": str(uuid.uuid4()),\n",
    "              \"values\": embeddings_model.embed_query(\n",
    "                  chunk.page_content.replace(\"\\n\", \" \")\n",
    "              ),\n",
    "              \"metadata\": {\n",
    "                  **chunk.metadata,\n",
    "                  \"text\": chunk.page_content,\n",
    "                  \"id\": \"123\",\n",
    "              },\n",
    "          }\n",
    "          batch.append(vector)\n",
    "\n",
    "          # When batch is full, or it's the last item, upsert the vectors\n",
    "          if len(batch) == batch_size or idx == len(chunks) - 1:\n",
    "              index.upsert(vectors=batch)\n",
    "\n",
    "              # Empty the batch\n",
    "              batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "id": "cnfWmaRu0ZA_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs: [Document(metadata={'source': '..\\\\Documents\\\\TEST.pdf', 'page': 0}, page_content='It\\nis\\na\\nsample\\nfile\\nfor\\ntesting\\nask-ripeseed')]\n",
      "current document  page_content='It\n",
      "is\n",
      "a\n",
      "sample\n",
      "file\n",
      "for\n",
      "testing\n",
      "ask-ripeseed' metadata={'source': '..\\\\Documents\\\\TEST.pdf', 'page': 0}\n",
      "document uploaded\n"
     ]
    }
   ],
   "source": [
    "upload_documents_service()\n",
    "print(\"document uploaded\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
